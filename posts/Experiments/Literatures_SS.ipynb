{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cc2af85d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"선행연구 조사 - 소스분리\"\n",
    "subtitle: \"Literatures - Music Source Separation\"\n",
    "author: \"Cheonghyo Cho\"\n",
    "date: \"2023-02-24\"\n",
    "categories: [선행연구, 소스분리, 오디오 분해]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81621424",
   "metadata": {},
   "source": [
    "**MIR Literatures - Music Source Separation**\n",
    "\n",
    "이론보다는 실증 연구를 바탕으로 선행연구들을 직접 조사하였다. 언어음(speech) 보다는 음악이 포함된 소스 분리 위주의 연구로 조사하였다. 논문은 연도 순으로 정리되어 있으며, 연구에서 쓰이는 데이터, 피쳐, 모형, 성과지표를 함께 게재하였다. 각각 항목에 따라 주로 사용되는 것과 시간에 따른 추세를 확인할 수 있다.\n",
    "\n",
    "\n",
    "논문 제목을 클릭하면 해당 논문의 DOI 주소로 이동한다.\n",
    "\n",
    "*새롭게 찾은 연구는 수시로 추가할 예정이다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c989ed",
   "metadata": {},
   "source": [
    "# 선행연구 조사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d86c6e",
   "metadata": {},
   "source": [
    "|논문|데이터|피쳐/인풋|모형|성과지표|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|[M. Spiertz and V. Gnann (2009)](https://www.ient.rwth-aachen.de/cms/dafx09/)|EBU speech, [Instruments Data](https://link.springer.com/book/10.1007/978-0-387-21603-4)|Spectrogram|MFCC K-means, NMF|SAR, SDR, SIR, SER|\n",
    "|[G. Mysore, P. Smaragdis, and B. Raj (2010)](https://link.springer.com/chapter/10.1007/978-3-642-15995-4_18)|[TIMIT speech](https://catalog.ldc.upenn.edu/LDC93s1)|Spectrogram|Non-negative Factorial HMM|SAR, SDR, SIR|\n",
    "|[R. Jaiswal, *et, al.* (2011)](https://ieeexplore.ieee.org/abstract/document/5946386)|[Orchestral Instruments](https://www.worldcat.org/ko/title/peter-siedlaczeks-advanced-orchestra-upgrade-97/oclc/43566640)|Magnitude Spectrogram|Shifted-NMF|SAR, SDR, SIR|\n",
    "|[E. Grais, M.U. Sen, and H. Erdogan (2014)](https://ieeexplore.ieee.org/abstract/document/6854299)|[TIMIT speech](https://catalog.ldc.upenn.edu/LDC93s1), Piano data|Spectrogram|DNN, Energy Minimization|SNR, SDR, SIR|\n",
    "|[S. Uhlich, F. Giron, and Y. Mitsufuji (2015)](https://ieeexplore.ieee.org/abstract/document/7178348)|[TRIOS](https://zenodo.org/record/6797837#.Y_h6ZnZByUk) (\"Brahms\",\"Lussier\")|Spectrogram|DNN|SAR, SDR, SIR|\n",
    "|[A.A. Nugraha, A. Liutkus, and E. Vincent (2016)](https://ieeexplore.ieee.org/abstract/document/7760548)|SISEC 2015 dataset|Spectrogram|DNN + Wiener filter|SAR, SDR, SIR, ISR|\n",
    "|[A. Jansson, *et al.* (2017)](https://openaccess.city.ac.uk/id/eprint/19289/)|Train: Large (original, instrumental) songs , Test:iKala, MedleyDB|Spectrogram|U-Net|SAR, NSDR, SIR|\n",
    "|[P. Chandna, *et al.* (2017)](https://link.springer.com/chapter/10.1007/978-3-319-53547-0_25)|[DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|*DeepConvSep* (CNN-based)|SAR, SDR, SIR, ISR|\n",
    "|[Y. Luo, *et al.* (2017)](https://ieeexplore.ieee.org/abstract/document/7952118)|[DSD100-remix](https://sigsep.github.io/datasets/dsd100.html), iKala|Spectrogram|*Chimera*(Deep clustering, Bi-LSTM)|SDR|\n",
    "|[S. Uhlich, *et al.* (2017)](https://ieeexplore.ieee.org/abstract/document/7952158)|[DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|*BLEND*(FNN(feed-forward) + Bi-LSTM)|SDR|\n",
    "|[N. Takahashi and Y. Mitsufuji (2017)](https://ieeexplore.ieee.org/abstract/document/8169987)|[DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|MM(Multiscale Multiband) DenseNet|SDR|\n",
    "|[D. Stoller, S. Ewert, and S. Dixon (2018)](https://arxiv.org/abs/1806.03185)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform|*Wave-U-Net*|SDR statistics|\n",
    "|[S. Park, T. Kim, K. Lee, and N. Kwak (2018)](https://arxiv.org/abs/1805.08559)|[DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|Stacked Hourglass Network(CNN-based)|Median SDR|\n",
    "|[J.Y. Liu and Y.H. Yang (2018)](https://ieeexplore.ieee.org/abstract/document/8614148)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html), [DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|ARC(Auto-encoder with Recurrent skip Connections) aka *Spect U-Net*|SDR|\n",
    "|[N. Takahashi, N. Goswami, and Y. Mitsufuji (2018)](https://ieeexplore.ieee.org/abstract/document/8521383)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html), [DSD100](https://sigsep.github.io/datasets/dsd100.html)|Spectrogram|*MMDenseLSTM*|SDR|\n",
    "|[F. Lluís, J. Pons, and X. Serra (2018)](https://arxiv.org/abs/1810.12187)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform|*Wave-Net*|SAR, SDR, SIR|\n",
    "|[J.Y. Liu and Y.H. Yang (2019)](https://arxiv.org/abs/1906.01203)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|Dilated GRU|SDR|\n",
    "|[F. Stöter, S. Uhlich, A. Liutkus, and Y. Mitsufuji (2019)](https://hal.inria.fr/hal-02293689/)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html), MUSDB18-HQ|Spectrogram|*Open-Unmix* (based on [S. Uhlich, *et al.* (2017)](https://ieeexplore.ieee.org/abstract/document/7952158))|SDR|\n",
    "|[L. Prétet, *et al.* (2019)](https://ieeexplore.ieee.org/abstract/document/8683555)|*Bean* + [MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|U-Net|SAR, SDR, SIR|\n",
    "|[Y. Luo and N. Mesgarani (2019)](https://ieeexplore.ieee.org/abstract/document/8707065)|WSJ0-2MIX (speech)|Waveform|Conv-TasNet|SI-SNR, SDR|\n",
    "|[A. Défossez, *et al.*(2019)](https://arxiv.org/abs/1911.13254)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform|*Demucs*|SDR|\n",
    "|[R. Hennequin, *et al.* (2020)](https://joss.theoj.org/papers/10.21105/joss.02154)|Train: *Bean* + Extra , Test: [MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*Spleeter* (based on [L. Prétet, *et al.* (2019)](https://ieeexplore.ieee.org/abstract/document/8683555))|SAR, SDR, SIR, ISR|\n",
    "|[E. Nachmani, Y. Adi, and L. Wolf (2020)](http://proceedings.mlr.press/v119/nachmani20a.html)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html), WSJ0-2MIX (speech)|Spectrogram|DP(Dual-Path)RNN|SDR|\n",
    "|[D. Samuel and A. Ganeshan (2020)](https://ieeexplore.ieee.org/abstract/document/9053513)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform + Spectrogram|*Meta-TasNet* (meta-learning of ConvTasNet)|SI-SNR, SDR|\n",
    "|[N. Takahashi and Y. Mitsufuji (2020)](https://arxiv.org/abs/2010.01733)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*D3Net* (multidilated convolution)|SDR|\n",
    "|[E. Lancaster, and N. Souviraà-Labastie (2020)](https://hal.science/hal-02986241/)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)+ Extra 30|Waveform|TasNet|SI-SNR, SDR|\n",
    "|[W. Choi, *et al.* (2020)](https://arxiv.org/abs/2010.11631)|[MUSDB18-HQ](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*LaSAFT-GPoCM* (Latent Source Attentive Frequency Transformation Gated Point-wise Convolutional Modulation)|SDR|\n",
    "|[T. Li, *et al.* (2021)](https://ieeexplore.ieee.org/abstract/document/9362081)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*Sams-Net* (Sliced Attention-based Neural Network)|SDR|\n",
    "|[Q. Kong, *et al.* (2021)](https://arxiv.org/abs/2109.05418)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*ResUNet* (Residual UNet)|SDR|\n",
    "|[R. Sawata, *et al.* (2021)](https://ieeexplore.ieee.org/abstract/document/9414044)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform + Spectrogram|*CrossNet-UnMiX (X-UMX)* (multi-domain loss, combination loss)|SDR|\n",
    "|[H. Liu, Q. Kong, and J. Liu (2021)](https://arxiv.org/abs/2112.04685)|[MUSDB18-HQ](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|*CWS-PResUNet* (channel-wise subband phase-aware ResUNet), *ByteMSS* (CWS-PResUNet+DeMucs)|SDR|\n",
    "|[A. Défossez (2021)](https://arxiv.org/abs/2111.03600)|[MUSDB18-HQ](https://sigsep.github.io/datasets/musdb.html)|Waveform + Spectrogram|Hybrid *Demucs*|nSDR|\n",
    "|[M. Kim, *et al.* (2021)](https://arxiv.org/abs/2111.12203)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform + Spectrogram|*KUIELab-MDX-Net* (two-stream neural network)|SDR|\n",
    "|[Y. Luo and J. Yu (2022)](https://arxiv.org/abs/2209.15174)|[MUSDB18, MUSDB18-HQ](https://sigsep.github.io/datasets/musdb.html)|Spectrogram|Band-Split RNN|uSDR, cSDR|\n",
    "|[Y. Hu, *et al.* (2022)](https://ieeexplore.ieee.org/abstract/document/9812509)|[MUSDB18](https://sigsep.github.io/datasets/musdb.html)|Waveform + Spectrogram|*CDE-HTCN* (cross-domain encoder hierarchic temporal convolutional network)|SDR|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c8e8d",
   "metadata": {},
   "source": [
    "# 추가 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfcb1b",
   "metadata": {},
   "source": [
    "## 피쳐, \n",
    "- Magnitude Spectrogram\n",
    "    - STFT로 계산 (주로 Hanning window, window size = 2048, hop size = 512) 후 mel-filterbank, masking 등 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3ae57",
   "metadata": {},
   "source": [
    "## 전처리, 후처리\n",
    "- Wiener filtering\n",
    "    - *MMDenseLSTM, D3Net, Spleeter, Open Unmix, Demucs* 등의 모형에서 마지막 후처리 작업으로 **Multi-Channel Wiener filtering**을 사용했다. ([A.A. Nugraha, A. Liutkus, and E. Vincent (2016)](https://ieeexplore.ieee.org/abstract/document/7760548) 이후)\n",
    "- Data Augmentation\n",
    "    - 작은 데이터세트를 다룰 때는 Spectrogram의 **Data Augmentation**로 input을 강화했다. ([S. Uhlich, *et al.* (2017)](https://ieeexplore.ieee.org/abstract/document/7952158) 이후)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8ffab",
   "metadata": {},
   "source": [
    "## 모형\n",
    "- DenseNet\n",
    "- UNet:\n",
    "- *Open-Unmix* \n",
    "- *Spleeter*\n",
    "- *TasNet*: \"Time-domain Audio Separation NETwork\"\n",
    "- *Demucs*: \"encoder/decoder\" 구조로 convolutional encoder, bidirectional LSTM, convolutional decoder로 구성되며 encoder와 decoder는  skip U-Net connections으로 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf5ff4",
   "metadata": {},
   "source": [
    "## 데이터\n",
    "    - MUSDB18: 여러 장르가 섞인 음악 데이터 세트. 각 트랙은 보컬, 드럼, 베이스, 기타로 분류되어 주석이 달림."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10e1c8",
   "metadata": {},
   "source": [
    "## 기타 사항\n",
    "++ 추가로 논문 저자들을 보면 어느 회사의 연구원들을 위주로 모형을 발달시켜가는 경우를 볼 수 있다. 유명한 오픈소스 모형인 *Open-Unmix*의 경우 Sony, *Demucs*는 Facebook, *Spleeter*는 Deezer의 연구원들이 참여하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3829c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
