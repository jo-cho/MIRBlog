[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "음악정보검색(Music Information Retrieval)에 대한 포스트를 올리는 블로그입니다. 음악정보검색을 독학하며 배운 내용을 기록하는 초보자의 입문기라고 생각해주세요."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Music Information Retrieval",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n2.1. 악보 표현\n\n\nSheet Music\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n2.2. 기호 표현\n\n\nSymbolic Representation\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n2.3. 오디오 표현\n\n\nAudio Representation\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 14, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n3.1. 수학리뷰 - 복소수와 지수함수\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)\n\n\nDiscrete Fourier Transform & Fast Fourier Transform\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n3.3. 단기 푸리에 변환 (STFT) (1)\n\n\nShort-Term Fourier Transform (1)\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n3.4. 단기 푸리에 변환 (STFT) (2)\n\n\nShort-Term Fourier Transform (2)\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n3.5. 디지털 신호\n\n\nDigital Signals\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n4.1. 오디오 동기화 피쳐\n\n\nAudio Synchronization Features\n\n\n\n\n음악동기화\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n4.2. 동적 시간 워핑 (DTW)\n\n\nDynamic Time Warping\n\n\n\n\n음악동기화\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n5.1. 음악 구조와 분할\n\n\nMusic Structure and Segmentation\n\n\n\n\n음악구조분석\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n5.2. 자기 유사성 행렬 (SSM)\n\n\nSelf Similarity Matrix\n\n\n\n\n음악구조분석\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n5.3. 오디오 썸네일\n\n\nAudio Thumbnail\n\n\n\n\n음악구조분석\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n5.4. 노벨티 기반 분할\n\n\nNovelty-based Segmentation\n\n\n\n\n음악구조분석\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n5.5. 음악 처리의 평가 방법\n\n\nEvaluation of Music Processing\n\n\n\n\n음악구조분석\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "title": "2.1. 악보 표현",
    "section": "",
    "text": "음악의 표현 방법 중 악보(sheet)와 기보법(notation), 음(note), 피치(pitch), 크로마(chroma) 등에 대해 다룬다."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "title": "2.1. 악보 표현",
    "section": "악보",
    "text": "악보\nFull Score (전체 악보) - 위에서부터 악기별로 악보가 정렬되어 있다.\n\nImage(\"../img/2.music_representation/FMP_C1_F10.png\", width=400, height=400)\n\n\n\n\n\n예전에는 고품질의 표기를 그리는 것이 중요했으며, 이는 “music engraving”이라고 불렸다.\n하지만 요즘은 컴퓨터 소프트웨어가 악보를 그릴 수 있다. 아래는 위의 악보를 컴퓨터가 똑같이 제작한 버전의 악보이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "title": "2.1. 악보 표현",
    "section": "기보법 (Music Notation)",
    "text": "기보법 (Music Notation)\n\n오선보(staff)는 5개의 수평선들과 네 개의 공백의 집합으로, 각기 다른 음 높낮이를 표현한다.\n5선 만으로는 음의 높이를 알 수 없다. 따라서, 음의 자리를 정해주는 음자리표(clef)를 5선의 맨 앞에 그려 넣는데, 이렇게 음자리표까지 그려져 음의 자리가 정해져야 비로소 보표가 된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F04.png\", width=500)\n\n\n\n\n\n조표(key signature)란 악보에서 음자리표와 박자표 사이에 붙는 올림표나 내림표를 말하며, 음표 앞에 표기하는 임시표와는 달리 보통의 음표보다 반음이 지속적으로 높거나 낮은 상태를 나타내기 위해 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F05.png\", width=500)\n\n\n\n\n\n악보는 음표(note), 쉼표(rest)로 형성되어 있다. (음표에 대한 자세한 설명은 생략한다.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_F07.png\", width=500)\n\n\n\n\n\n박자표(time signature)는 악곡의 박자 종류를 가리킨다. 박자표는 모두 분수의 꼴로 쓴다\n\n\nImage(\"../img/2.music_representation/FMP_C1_F06.png\", width=500)\n\n\n\n\n\n여러 오선을 합쳐 staff system을 만들 수 있다. 다양한 악기를 동시에 연주할 때 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F08.png\", width=500)\n\n\n\n\n\n템포, 다이나믹, 표현 등을 위한 설명으로 아티큘레이션(articulation)을 쓸 수 있다. 아래의 그림에 나와있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F09.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "title": "2.1. 악보 표현",
    "section": "음과 피치",
    "text": "음과 피치\n\n피치(=음고, 음높낮이)(pitch)란 음(note)이 얼마나 높은지 낮은지를 다루는 속성이다. 피치는 음파의 기본 주파수(fundamental frequency)와 긴밀히 연관되어 있다.\n옥타브(ocatve)는 두 음의 간격을 의미하는데, 한 옥타브 높은 음은 낮은 음은 두배의 기본 주파수이다. 예를 들어 440Hz의 A와 880Hz의 A는 한 옥타브를 사이에 두고 나눠진다.\n피치 클래스(pitch class)란 옥타브를 간격으로 있는 모든 음의 집합이다. 예를 들어 C {…, C1, C2, …}는 하나의 피치 클래스, D {…, D1, D2, …}는 또다른 피치 클래스이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_PitchClassC.png\", width=500)\n\n\n\n\n\nimport numpy as np\n\ndef generate_sinusoid_pitches(pitches=[69], dur=0.5, Fs=4000, amp=0.25):\n    \"\"\"Generation of sinusoids for a given list of MIDI pitches\n\n    Args:\n        pitches (list): List of MIDI pitches (Default value = [69])\n        dur (float): Duration (in seconds) of each sinusoid (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 4000)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = []\n    for p in pitches:\n        freq = 2 ** ((p - 69) / 12) * 440\n        x = np.append(x, np.sin(2 * np.pi * freq * t))\n    x = amp * x / np.max(x)\n    return x, t\n\n\nFs = 22050\n\npitches = [36,48,60,72,84,96,108]\nx, t = generate_sinusoid_pitches(pitches=pitches, Fs=Fs)\nprint('Pitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}', flush=True)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nPitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n음계(scale)는 음악에서 피치(pitch) 순서로 된 음의 집합을 말한다. 악곡을 주로 구성하는 음을 나타내며, 음계의 종류에 따라 곡의 분위기가 달라진다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_MusicalScales.png\", width=500)\n\n\n\n\n\ndur = 0.5\nFs = 22050\n\nx_maj, t = generate_sinusoid_pitches(pitches=[60,62,64,65,67,69,71,72], Fs=Fs)\nx_min, t = generate_sinusoid_pitches(pitches=[60,62,63,65,67,68,70,72], Fs=Fs)\n\nprint('C major scale', flush=True)\nipd.display(ipd.Audio(data=x_maj, rate=Fs))\nprint('C minor scale', flush=True)\nipd.display(ipd.Audio(data=x_min, rate=Fs))\n\nC major scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nC minor scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n평균율(equal temperament)이란 한 옥타브를 12개의 동일한 음계 단계로 나눈 것을 의미한다.\n두 연속된 음계 사이의 차이를 반음(semitone)이라고 하는데, 이는 12음 음계의 가장 작은 간격이다. 음악인들은 이를 ’half-step’이라고도 말한다.\n12음 평균율 음계에는 12개의 피치 클래스가 있다. 서양 음악 표기법에서 이러한 피치 클래스는 알파벳과 임시표(accidental)를 결합하여 표시된다. 7개의 피치 클래스(C 장조에 해당)는 문자 C, D, E, F, G, A 및 B로 표시된다. 이러한 피치 클래스는 피아노 건반의 흰색 건반에 해당된다. 나머지 5개의 피치 등급은 피아노 건반의 검은 건반에 해당하며 알파벳과 임시표(♯ ,♭)의 조합으로 표시된다. 샵(♯)은 음을 반음 올리고 플랫(♭)은 반음 내린 것으로 음 이름 뒤에 표시된다: C♯, D♯, F♯, G♯, A♯ 혹은 D♭, E♭, G♭, A♭, B♭. 이 때 C♯과 D♭는 같은 피치 클래스를 나타낸다. 이는 “enharmonic equivalence”로도 알려져 있다.\n\n과학적 피치 표기\n\n12음 평균율의 음에 이름을 지정하기 위해 피치 클래스를 표시하는 것 외에도 옥타브에 대한 식별자가 필요하다. 과학적 피치 표기법에 따라 각 음은 피치 클래스 이름과 옥타브를 나타내는 숫자로 지정된다. 음 A4는 440Hz의 기본 주파수를 갖는 것으로 결정되어 기준 역할을 한다. 옥타브 수는 피치 클래스 B의 음에서 피치 클래스 C의 음으로 올라갈 때 1씩 증가한다.\n다음 그림은 C3에서 C5까지의 건반과 서양 음악 표기법을 사용하는 해당 음표가 있는 피아노 건반 부분을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F02.png\", width=500)\n\n\n\n\n\ndur = 0.2\nFs = 22050\npitches = range(48,73)\n\nx_chromatic, t = generate_sinusoid_pitches(pitches=pitches, dur=dur, Fs=Fs)\n\nprint('Sinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):', flush=True)\nipd.display(ipd.Audio(data=x_chromatic, rate=Fs))\n\nSinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "title": "2.1. 악보 표현",
    "section": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)",
    "text": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)\n크로마란?\n\n피치에 따라 평균율 음계의 모든 음을 순서대로 배열하면, 음계의 모든 음이 같은 간격으로 배열된 평균율의 크로마틱 음계(chromatic scale)를 얻을 수 있다.\n“Chromatic”이라는 용어는 색을 의미하는 그리스어 “chroma”에서 유래했다.\n음악적 맥락에서 크로마(chroma)라는 용어는 12개의 다른 피치 클래시와 밀접한 관련이 있다. 예를 들어, C2와 C5 음은 모두 같은 크로마 값 C를 가지고 있다.\n즉, 크로마 값이 같은 모든 음은 동일한 피치 클래스에 속한다.\n같은 피치클래스에 속하거나 크로마 값이 같은 음은 유사하게 인식된다. 반면에, 다른 피치 클래스에 속하거나 다른 크로마 값을 갖는 음은 서로 다른 것으로 인식된다.\n크로마 값의 주기적 특성은 아래 그림과 같이 크로마 원에 의해 설명된다.\n이 개념을 확장하면, 로저 셰퍼드(1929)의 이름을 딴 셰퍼드의 피치 나선(Shepard’s helix of pitch)은 선형 피치 공간을 하나의 수직선을 따라 옥타브 관련 피치가 놓이도록 원통을 감싸고 있는 나선으로 표현한다. 실린더가 수평면에 투영되면 크로마원이 생성된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F03.png\", width=500)\n\n\n\n\n셰퍼드 톤\n\nShepard의 피치 나선은 Shepard 톤을 사용하여 음향화할 수 있으며, 각 톤은 옥타브로 구분된 사인파의 가중 중첩이다.\n반음계 위로 올라가는 이 음조를 연주할 때, 계속해서 위로 올라가는 음조의 청각적 환영을 얻는다(펜로즈 계단의 시각적 착시와 유사; 아래 그림).\n\n\nImage(\"../img/2.music_representation/FMP_C1_PenroseStairs.png\", width=200)\n\n\n\n\n\n뒤의 코드 예시에서 인간이 들을 수 있는 사인파 (20~20000헤르츠의 주파수)만 사용해보자. 특정 가중은 사용되지 않는다(모든 사인파는 1의 크기를 가짐).\n마지막으로 셰퍼드 톤은 크로마틱 스케일로 C3 (MIDI pitch 48) 부터 C5 (MIDI pitch 72)까지로 생성된다.\n\n\ndef generate_shepard_tone(freq=440, dur=0.5, Fs=44100, amp=1):\n    \"\"\"Generate Shepard tone\n\n    Args:\n        freq (float): Frequency of Shepard tone (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Shepard tone\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    num_sin = 1\n    x = np.sin(2 * np.pi * freq * t)\n    freq_lower = freq / 2\n    while freq_lower > 20:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_lower * t)\n        freq_lower = freq_lower / 2\n    freq_upper = freq * 2\n    while freq_upper < 20000:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_upper * t)\n        freq_upper = freq_upper * 2\n    x = x / num_sin\n    x = amp * x / np.max(x)\n    return x, t\n\ndef f_pitch(p):\n    F_A4 = 440\n    return F_A4 * 2 ** ((p - 69) / 12)\n    \nFs = 44100\ndur = 0.5\n\npitch_start = 48\npitch_end = 72\nscale = []\nfor p in range(pitch_start, pitch_end + 1):\n    freq = f_pitch(p)    \n    s, t = generate_shepard_tone(freq=freq, dur=dur, Fs=Fs, amp = 0.5)\n    scale = np.concatenate((scale, s))\n    \nipd.display(ipd.Audio(scale, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nShepard–Risset Glissando\n\n이산적인 스케일을 사용하는대신 연속적인 셰퍼든 톤의 등락을 생성할 수 있다.: (Shepard–Risset glissando)\n뒤의 코드 예시는 상승하는 glissando를 생성한다.\n첫 째로 기하급수적으로 상승하는 chirp 신호가 정의된다. 이때 순간 주파수(instantaneous frequency)는 정현파 변수의 미분으로 주어진다.\n생성된 chirp 신호는 정확히 1옥타브를 커버한다. 그런 다음 Shepared 톤과 유사하게, 옥타브로 분리된 처프의 중첩(superposition)이 생성된다. 한 옥타브를 커버하고 Shepard–Risset glissando의 끝 부분은 (지각적으로) 시작 부분과 일치한다. 따라서 여러 glissando를 연결하여 논스톱 버전을 얻는다.\n\n\ndef generate_chirp_exp_octave(freq_start=440, dur=8, Fs=44100, amp=1):\n    \"\"\"Generate one octave of a chirp with exponential frequency increase\n\n    Args:\n        freq_start (float): Start frequency of chirp (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Chirp signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = np.sin(2 * np.pi * freq_start * np.power(2, t / dur) / np.log(2) * dur)\n    x = amp * x / np.max(x)\n    return x, t\n\n\ndef generate_shepard_glissando(num_octaves=3, dur_octave=8, Fs=44100):\n    \"\"\"Generate several ocatves of a Shepared glissando\n\n    Args:\n        num_octaves (int): Number of octaves (Default value = 3)\n        dur_octave (int): Duration (in seconds) per octave (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n\n    Returns:\n        x (np.ndarray): Shepared glissando\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    freqs_start = 10 * 2**np.arange(0, 11)\n    # Generate Shepard glissando by superimposing chirps that differ by octaves\n    for freq in freqs_start:\n        if freq == 10:\n            x, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n        else:\n            chirp, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n            x = x + chirp\n    x = x / len(freqs_start)\n    # Concatenate several octaves\n    x = np.tile(x, num_octaves)\n    N = len(x)\n    t = np.arange(N) / Fs\n    return x, t\n    \nglissando, t = generate_shepard_glissando(num_octaves=3, dur_octave=8)\nipd.display(ipd.Audio(glissando, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_SheetMusic.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_MusicalNotesPitches.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_ChromaShepard.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "title": "2.2. 기호 표현",
    "section": "",
    "text": "음악의 표현 방법 중 기호(심볼릭) 표현에 대해 알아본다. 피아노-롤(piano-roll), 미디(MIDI) 등이 있다."
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "title": "2.2. 기호 표현",
    "section": "피아노-롤(piano-roll) 표현",
    "text": "피아노-롤(piano-roll) 표현\n\n피아노-롤은 피아노와 관련된 음 정보들을 모아 가시화한 것을 일반적으로 말한다.\n드뷔시와 베토벤 음악의 피아노롤을 아래 영상과 같이 표현할 수 있다.\n\n\nipd.display( ipd.YouTubeVideo(\"LlvUepMa31o\", start=15) )\n\n\n        \n        \n\n\n\nipd.display( ipd.YouTubeVideo(\"Kri2jWr08S4\", start=11) )"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "title": "2.2. 기호 표현",
    "section": "미디 (MIDI) 표현",
    "text": "미디 (MIDI) 표현\n\n또다른 기호 표현으로는 MIDI(Musical Instrument Digital Interface) 스탠다드가 있다. MIDI는 1980년대 초반 전자 음악 악기 시장의 급성장과 함께 출현했다.\nMIDI 메시지는 음(note) 온셋, 음 오프셋, 강도(intensity or “velocity”)와 같은 정보를 인코딩한다. 컴퓨터에서 MIDI 파일은 MIDI 메시지들과 다른 메타데이터를 보관한다.\nMIDI 노트넘버(MIDI note number)는 0과 127 사이의 정수로 노트의 피치를 인코딩한다. 가장 중요한 것으로는 C4(중간 C)는 MIDI 노트넘버 60이고, A4(concert A440)은 MIDI 노트넘버 69이다. MIDI 노트넘버는 12개로 나누어져있으며 한 옥타브씩 나누어진다 (e.g. 72 = C5, 84 = C6, etc.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_MIDI-NoteNumbers.png\", width=500)\n\n\n\n\n\n키 벨로시티(key velocity)는 0과 127 사이의 정수로 소리의 강도를 조정한다.\nMIDI 채널은 0과 15 사이의 정수로 신디사이저가 특정 악기를 사용하도록 안내한다.\nMIDI는 사분음표를 clock pulses 또는 틱으로 세분화한다. 예를 들어, 분기 음 당 펄스 수(PPQN)를 120으로 정의하면 60개의 틱이 8번째 음의 길이를 나타낸다.\n또한 MIDI는 템포를 BPM으로 인코딩하여 절대적인 시간 정보를 알려준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F13.png\", width=600)\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.mid\")\nmidi_list = []\n\nfor instrument in midi_data.instruments:\n    for note in instrument.notes:\n        start = note.start\n        end = note.end\n        pitch = note.pitch\n        velocity = note.velocity\n        midi_list.append([start, end, pitch, velocity, instrument.name])\n        \nmidi_list = sorted(midi_list, key=lambda x: (x[0], x[2]))\n\ndf = pd.DataFrame(midi_list, columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.25\n      0.50\n      43\n      113\n      Piano\n    \n    \n      0.25\n      0.50\n      55\n      76\n      Piano\n    \n    \n      0.25\n      0.50\n      67\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      43\n      113\n      Piano\n    \n    \n      0.50\n      0.75\n      55\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      67\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      43\n      113\n      Piano\n    \n    \n      0.75\n      1.00\n      55\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      67\n      76\n      Piano\n    \n    \n      1.00\n      2.00\n      39\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      51\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      63\n      70\n      Piano\n    \n    \n      2.25\n      2.50\n      41\n      113\n      Piano\n    \n    \n      2.25\n      2.50\n      53\n      76\n      Piano\n    \n    \n      2.25\n      2.50\n      65\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      41\n      113\n      Piano\n    \n    \n      2.50\n      2.75\n      53\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      65\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      41\n      113\n      Piano\n    \n    \n      2.75\n      3.00\n      53\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      65\n      76\n      Piano\n    \n    \n      3.00\n      5.00\n      38\n      112\n      Piano\n    \n    \n      3.00\n      5.00\n      50\n      126\n      Piano\n    \n    \n      3.00\n      5.00\n      62\n      71\n      Piano\n    \n  \n\n\n\n\nFs = 22050\naudio_data = midi_data.synthesize(fs=Fs)\nipd.Audio(audio_data, rate=Fs)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\ndef midi_to_list(midi):\n    \"\"\"Convert a midi file to a list of note events\n\n    Args:\n        midi (str or pretty_midi.pretty_midi.PrettyMIDI): Either a path to a midi file or PrettyMIDI object\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(midi, str):\n        midi_data = pretty_midi.pretty_midi.PrettyMIDI(midi)\n    elif isinstance(midi, pretty_midi.pretty_midi.PrettyMIDI):\n        midi_data = midi\n    else:\n        raise RuntimeError('midi must be a path to a midi file or pretty_midi.PrettyMIDI')\n\n    score = []\n\n    for instrument in midi_data.instruments:\n        for note in instrument.notes:\n            start = note.start\n            duration = note.end - start\n            pitch = note.pitch\n            velocity = note.velocity / 128.\n            score.append([start, duration, pitch, velocity, instrument.name])\n    return score\n\n\ndef visualize_piano_roll(score, xlabel='Time (seconds)', ylabel='Pitch', colors='FMP_1', velocity_alpha=False,\n                         figsize=(12, 4), ax=None, dpi=72):\n    \"\"\"Plot a pianoroll visualization\n    Args:\n        score: List of note events\n        xlabel: Label for x axis (Default value = 'Time (seconds)')\n        ylabel: Label for y axis (Default value = 'Pitch')\n        colors: Several options: 1. string of FMP_COLORMAPS, 2. string of matplotlib colormap,\n            3. list or np.ndarray of matplotlib color specifications,\n            4. dict that assigns labels  to colors (Default value = 'FMP_1')\n        velocity_alpha: Use the velocity value for the alpha value of the corresponding rectangle\n            (Default value = False)\n        figsize: Width, height in inches (Default value = (12)\n        ax: The Axes instance to plot on (Default value = None)\n        dpi: Dots per inch (Default value = 72)\n    Returns:\n        fig: The created matplotlib figure or None if ax was given.\n        ax: The used axes\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize, dpi=dpi)\n        ax = plt.subplot(1, 1, 1)\n\n    labels_set = sorted(set([note[4] for note in score]))\n    colors = color_argument_to_dict(colors, labels_set)\n\n    pitch_min = min(note[2] for note in score)\n    pitch_max = max(note[2] for note in score)\n    time_min = min(note[0] for note in score)\n    time_max = max(note[0] + note[1] for note in score)\n\n    for start, duration, pitch, velocity, label in score:\n        if velocity_alpha is False:\n            velocity = None\n        rect = patches.Rectangle((start, pitch - 0.5), duration, 1, linewidth=1,\n                                 edgecolor='k', facecolor=colors[label], alpha=velocity)\n        ax.add_patch(rect)\n\n    ax.set_ylim([pitch_min - 1.5, pitch_max + 1.5])\n    ax.set_xlim([min(time_min, 0), time_max + 0.5])\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.grid()\n    ax.set_axisbelow(True)\n    ax.legend([patches.Patch(linewidth=1, edgecolor='k', facecolor=colors[key]) for key in labels_set],\n              labels_set, loc='upper right', framealpha=1)\n\n    if fig is not None:\n        plt.tight_layout()\n\n    return fig, \n\n\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nimport music21 as m21\n\ns = m21.converter.parse(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\ns.plot('pianoroll', figureSize=(10, 3))"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "title": "2.2. 기호 표현",
    "section": "악보적(score) 표현",
    "text": "악보적(score) 표현\n\n기호적 악보 표현은 “2.1.Sheet_Music.ipynb”에서 설명한 음악적 기호들을 인코딩한다. (음자리표, 조표 등등) 하지만 이를 악보로 가시화하는 것이 아니라 저장하는데, MusicXML같은 파일로 저장한다.\n아래 그 예시가 있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F15.png\", width=400)\n\n\n\n\n\ndef xml_to_list(xml):\n    \"\"\"Convert a music xml file to a list of note events\n\n    Args:\n        xml (str or music21.stream.Score): Either a path to a music xml file or a music21.stream.Score\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(xml, str):\n        xml_data = m21.converter.parse(xml)\n    elif isinstance(xml, m21.stream.Score):\n        xml_data = xml\n    else:\n        raise RuntimeError('midi must be a path to a midi file or music21.stream.Score')\n\n    score = []\n\n    for part in xml_data.parts:\n        instrument = part.getInstrument().instrumentName\n\n        for note in part.flat.notes:\n\n            if note.isChord:\n                start = note.offset\n                duration = note.quarterLength\n\n                for chord_note in note.pitches:\n                    pitch = chord_note.ps\n                    volume = note.volume.realized\n                    score.append([start, duration, pitch, volume, instrument])\n\n            else:\n                start = note.offset\n                duration = note.quarterLength\n                pitch = note.pitch.ps\n                volume = note.volume.realized\n                score.append([start, duration, pitch, volume, instrument])\n\n    score = sorted(score, key=lambda x: (x[0], x[2]))\n    return score\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.xml\")\nxml_list = xml_to_list(xml_data)\n\ndf = pd.DataFrame(xml_list[:9], columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False, float_format='%.2f', max_rows=8)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.50\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      0.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      2.00\n      2.00\n      63.00\n      0.71\n      Piano (2)\n    \n    \n      2.50\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n    \n      3.00\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n  \n\n\n\n\nvisualize_piano_roll(xml_list, figsize=(8, 3), velocity_alpha=True,\n                               xlabel='Time (quarter lengths)');\n\n\n\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.xml\")\nxml_list = xml_to_list(xml_data)\n\nvisualize_piano_roll(xml_list, figsize=(10, 7), velocity_alpha=False,\n                               colors='gist_rainbow', xlabel='Time (quarter lengths)');\n\n\n\n\n기호 음악 표현법을 사용하는 파이썬 라이브러리\n\nPrettyMIDI: MIDI 읽기, 컨버팅 등\nmusic21: musicxml파일 다루기\npypianoroll: 피아노롤 비주얼\n\n\n출처:\n\nhttps://musicinformationretrieval.com/\nhttps://www.audiolabs-erlangen.de/FMP\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html",
    "title": "2.3. 오디오 표현",
    "section": "",
    "text": "음악의 표현 방법 중 오디오 표현에 대해 알아본다. 음파(wave), 주파수(frequency), 고조파(harmonics), 강도(intensity), 라우드니스(loudness), 음색(timbre) 등의 중요한 개념을 포함한다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#들을-수-있는-주파수-범위",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#들을-수-있는-주파수-범위",
    "title": "2.3. 오디오 표현",
    "section": "들을 수 있는 주파수 범위",
    "text": "들을 수 있는 주파수 범위\n\n정현파(sinusoidal wave)의 주파수가 높을수록 더 높은 소리를 낸다.\n인간의 가청 주파수 범위는 약 20Hz와 20000Hz(20 kHz) 사이이다. 다른 동물들은 다른 청력 범위를 가지고 있다. 예를 들어, 개의 청력 범위의 상단은 약 45kHz이고 고양이의 청력은 64kHz인 반면, 박쥐는 심지어 100kHz 이상의 주파수를 감지할 수 있다. 이는 사람의 청각 능력을 뛰어넘는 초음파를 내는 개 호루라기를 이용해 주변 사람들을 방해하지 않고 동물을 훈련시키고 명령할 수 있는 이유이다.\n다음 실험에서 주파수가 초당 2배(1옥타브) 증가하는 처프(chirp) 신호를 생성한다.\n\n\ndef generate_chirp_exp_octave(freq_start=440, dur=8, Fs=44100, amp=1):\n    \"\"\"Generate one octave of a chirp with exponential frequency increase\n    Args:\n        freq_start (float): Start frequency of chirp (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n    Returns:\n        x (np.ndarray): Chirp signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = np.sin(2 * np.pi * freq_start * np.power(2, t / dur) / np.log(2) * dur)\n    x = amp * x / np.max(x)\n    return x, t\n\n\n# 20Hz부터 시작하여 주파수는 총 10초 동안 20480Hz까지 상승한다.\nFs = 44100\ndur = 1\nfreq_start = 20 * 2**np.arange(10)\nfor f in freq_start:\n    if f==freq_start[0]:\n        chirp, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=.25)\n    else:\n        chirp_oct, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=.25)\n        chirp = np.concatenate((chirp, chirp_oct))\n\nipd.display(ipd.Audio(chirp, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n# 640Hz부터 시작하여 주파수는 총 10초 동안 20Hz까지 하락한다.\n\nFs = 8000\ndur = 2\nfreq_start = 20 * 2**np.arange(5)\nfor f in freq_start:\n    if f==freq_start[0]:\n        chirp, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=1)\n    else:\n        chirp_oct, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=1)\n        chirp = np.concatenate((chirp,chirp_oct))    \n        \nchirp = chirp[::-1]    \nipd.display(ipd.Audio(chirp, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#피치와-중심-주파수center-frequency",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#피치와-중심-주파수center-frequency",
    "title": "2.3. 오디오 표현",
    "section": "피치와 중심 주파수(center frequency)",
    "text": "피치와 중심 주파수(center frequency)\n\n정현파는 음의 음향적 실현의 원형으로 간주될 수 있다. 때때로 정현파에서 나오는 소리를 하모닉 사운드(harmonic sound) 또는 순수 음색(pure tone)이라고 한다.\n주파수의 개념은 소리의 피치를 결정하는 것과 밀접한 관련이 있다. 일반적으로 피치는 소리의 주관적인 속성이다.\n복잡한 혼합음의 경우, 주파수와의 관계가 특히 모호할 수 있다. 그러나 순수 음색의 경우 주파수와 피치의 관계가 명확하다. 예를 들어, 440 Hz의 주파수를 갖는 정현파는 피치 A4에 해당한다. 이 특정한 피치는 콘서트 피치(concert pitch)로 알려져 있으며, 이는 연주를 위해 악기가 튜닝되는 기준 피치로 사용된다.\n주파수의 약간의 변화가 반드시 지각할 수 있는 변화로 이어지는 것은 아니기 때문에, 일반적으로 주파수의 전체 범위를 단일 피치와 연관시킨다.\n두 주파수가 2의 거듭제곱에 의해 차이가 나는 경우, 이는 옥타브의 개념과 연관된다.\n\n예를 들어, 피치 A3(220 Hz)와 피치 A4(440 Hz) 사이의 인식 거리는 피치 A4와 피치 A5(880 Hz) 사이의 인식 거리와 동일하다.\n즉, 피치에 대한 인간의 인식은 본질적으로 로그(logarithm)이다. 이 지각 특성은 이미 로그 주파수 축을 기준으로 옥타브를 12개의 반음으로 세분화하는 평균율(“equal-tempered scale”)을 정의하는 데 사용되었다.\n\n더 공식적으로, MIDI 노트 번호를 사용하여, 다음과 같이 정의된 중심 주파수(center frequency) \\(F_{pitch}(p)\\)(Hz 단위로 측정)를 각 피치 \\(p∈[0:127]\\) 에 연결할 수 있다.\n\n\\(F_{pitch}(p)=2^{(p−69)/12} \\cdot 440\\)\n\nMIDI 노트 번호 \\(p=69\\)는 기준으로 사용되며 피치 A4(440Hz)에 해당된다. 피치 넘버를 12(옥타브) 증가시키면 2배 증가한다. \\(F_{pitch} ( p + 12) = 2 \\cdot F_{pitch} ( p)\\)\n\n\n\n\nImage(\"../img/2.music_representation/FMP_C1_MIDI-NoteNumbers.png\", width=500)\n\n\n\n\n\ndef f_pitch(p):\n    \"\"\"Compute center frequency for (single or array of) MIDI note numbers\n    Args:\n        p (float or np.ndarray): MIDI note numbers\n    Returns:\n        freq_center (float or np.ndarray): Center frequency\n    \"\"\"\n    freq_center = 2 ** ((p - 69) / 12) * 440\n    return freq_center\n\nchroma = ['A ', 'A#', 'B ', 'C ', 'C#', 'D ', 'D#', 'E ', 'F ', 'F#', 'G ', 'G#']\n\nfor p in range(21, 109):\n    print('p = %3d (%2s%1d), freq = %7.2f ' % (p, chroma[(p-69) % 12], (p//12-1), f_pitch(p)))\n\np =  21 (A 0), freq =   27.50 \np =  22 (A#0), freq =   29.14 \np =  23 (B 0), freq =   30.87 \np =  24 (C 1), freq =   32.70 \np =  25 (C#1), freq =   34.65 \np =  26 (D 1), freq =   36.71 \np =  27 (D#1), freq =   38.89 \np =  28 (E 1), freq =   41.20 \np =  29 (F 1), freq =   43.65 \np =  30 (F#1), freq =   46.25 \np =  31 (G 1), freq =   49.00 \np =  32 (G#1), freq =   51.91 \np =  33 (A 1), freq =   55.00 \np =  34 (A#1), freq =   58.27 \np =  35 (B 1), freq =   61.74 \np =  36 (C 2), freq =   65.41 \np =  37 (C#2), freq =   69.30 \np =  38 (D 2), freq =   73.42 \np =  39 (D#2), freq =   77.78 \np =  40 (E 2), freq =   82.41 \np =  41 (F 2), freq =   87.31 \np =  42 (F#2), freq =   92.50 \np =  43 (G 2), freq =   98.00 \np =  44 (G#2), freq =  103.83 \np =  45 (A 2), freq =  110.00 \np =  46 (A#2), freq =  116.54 \np =  47 (B 2), freq =  123.47 \np =  48 (C 3), freq =  130.81 \np =  49 (C#3), freq =  138.59 \np =  50 (D 3), freq =  146.83 \np =  51 (D#3), freq =  155.56 \np =  52 (E 3), freq =  164.81 \np =  53 (F 3), freq =  174.61 \np =  54 (F#3), freq =  185.00 \np =  55 (G 3), freq =  196.00 \np =  56 (G#3), freq =  207.65 \np =  57 (A 3), freq =  220.00 \np =  58 (A#3), freq =  233.08 \np =  59 (B 3), freq =  246.94 \np =  60 (C 4), freq =  261.63 \np =  61 (C#4), freq =  277.18 \np =  62 (D 4), freq =  293.66 \np =  63 (D#4), freq =  311.13 \np =  64 (E 4), freq =  329.63 \np =  65 (F 4), freq =  349.23 \np =  66 (F#4), freq =  369.99 \np =  67 (G 4), freq =  392.00 \np =  68 (G#4), freq =  415.30 \np =  69 (A 4), freq =  440.00 \np =  70 (A#4), freq =  466.16 \np =  71 (B 4), freq =  493.88 \np =  72 (C 5), freq =  523.25 \np =  73 (C#5), freq =  554.37 \np =  74 (D 5), freq =  587.33 \np =  75 (D#5), freq =  622.25 \np =  76 (E 5), freq =  659.26 \np =  77 (F 5), freq =  698.46 \np =  78 (F#5), freq =  739.99 \np =  79 (G 5), freq =  783.99 \np =  80 (G#5), freq =  830.61 \np =  81 (A 5), freq =  880.00 \np =  82 (A#5), freq =  932.33 \np =  83 (B 5), freq =  987.77 \np =  84 (C 6), freq = 1046.50 \np =  85 (C#6), freq = 1108.73 \np =  86 (D 6), freq = 1174.66 \np =  87 (D#6), freq = 1244.51 \np =  88 (E 6), freq = 1318.51 \np =  89 (F 6), freq = 1396.91 \np =  90 (F#6), freq = 1479.98 \np =  91 (G 6), freq = 1567.98 \np =  92 (G#6), freq = 1661.22 \np =  93 (A 6), freq = 1760.00 \np =  94 (A#6), freq = 1864.66 \np =  95 (B 6), freq = 1975.53 \np =  96 (C 7), freq = 2093.00 \np =  97 (C#7), freq = 2217.46 \np =  98 (D 7), freq = 2349.32 \np =  99 (D#7), freq = 2489.02 \np = 100 (E 7), freq = 2637.02 \np = 101 (F 7), freq = 2793.83 \np = 102 (F#7), freq = 2959.96 \np = 103 (G 7), freq = 3135.96 \np = 104 (G#7), freq = 3322.44 \np = 105 (A 7), freq = 3520.00 \np = 106 (A#7), freq = 3729.31 \np = 107 (B 7), freq = 3951.07 \np = 108 (C 8), freq = 4186.01 \n\n\n\n이 공식으로부터, 두 개의 연속된 피치 p+1과 p의 주파수 비율은 일정하다.\n\n\\(F_\\mathrm{pitch}(p+1)/F_\\mathrm{pitch}(p) = 2^{1/12} \\approx 1.059463\\)\n\n반음의 개념을 일반화한 센트(cent)는 음악 간격에 사용되는 로그 단위를 나타낸다. 정의에 따라 옥타브는 \\(1200\\) 센트로 나뉘며, 각 반음은 \\(100\\)센트에 해당한다. 두 주파수(예: \\(\\omega_1\\) 및 \\(\\omega_2\\)) 사이의 센트 차이는 다음과 같다.\n\n\\(\\log_2\\left(\\frac{\\omega_1}{\\omega_2}\\right)\\cdot 1200.\\)\n\n1센트의 간격은 너무 작아서 연속된 음 사이를 지각할 수 없다. 지각할 수 있는 문턱은 사람마다 다르고 음색과 음악적 맥락과 같은 측면에 따라 달라진다.\n경험적으로 일반 성인은 25센트의 작은 피치 차이를 매우 안정적으로 인식할 수 있으며, 10센트의 차이는 훈련된 청취자만이 인식할 수 있다.\n그림에서와 같이, 기준으로 사용되는 \\(440~\\mathrm{Hz}\\)의 정현파와 다양한 차이를 가진 추가 정현파를 생성하여 본다.\n\n\ndef difference_cents(freq_1, freq_2):\n    \"\"\"Difference between two frequency values specified in cents\n\n    Args:\n        freq_1 (float): First frequency\n        freq_2 (float): Second frequency\n\n    Returns:\n        delta (float): Difference in cents\n    \"\"\"\n    delta = np.log2(freq_1 / freq_2) * 1200\n    return delta\n \ndef generate_sinusoid(dur=1, Fs=1000, amp=1, freq=1, phase=0):\n    \"\"\"Generation of sinusoid\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 1)\n        freq (float): Frequency of sinusoid (Default value = 1)\n        phase (float): Phase of sinusoid (Default value = 0)\n\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = amp * np.sin(2*np.pi*(freq*t-phase))\n    return x, t\n\n\ndur = 1\nFs = 4000\npitch = 69\nref = f_pitch(pitch)\nfreq_list = ref + np.array([0,2,5,10,ref])\nfor freq in freq_list:\n    x, t = generate_sinusoid(dur=dur, Fs=Fs, freq=freq)\n    print('freq = %0.1f Hz (MIDI note number 69 + %0.2f cents)' % (freq, difference_cents(freq,ref)))\n    ipd.display(ipd.Audio(data=x, rate=Fs))  \n\nfreq = 440.0 Hz (MIDI note number 69 + 0.00 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 442.0 Hz (MIDI note number 69 + 7.85 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 445.0 Hz (MIDI note number 69 + 19.56 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 450.0 Hz (MIDI note number 69 + 38.91 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 880.0 Hz (MIDI note number 69 + 1200.00 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#데시벨-스케일-decibel-scale",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#데시벨-스케일-decibel-scale",
    "title": "2.3. 오디오 표현",
    "section": "데시벨 스케일 (Decibel Scale)",
    "text": "데시벨 스케일 (Decibel Scale)\n\n음악의 중요한 특성은 음량을 나타내는 음악 기호뿐만 아니라 음량을 나타내는 일반적인 용어인 다이나믹(dynamics)과 관련이 있다.\n물리적 관점에서 소리 힘(sound power)은 공기를 통해 모든 방향으로 흐르는 음원에 의해 단위 시간당 얼마나 많은 에너지가 방출되는지를 나타낸다.\n소리 강도/인텐시티(sound intensity)는 단위 면적당 소리 힘을 나타낸다. 실제로 소리 힘과 소리 강도는 인간 청취자와 연관된 극히 작은 값을 보여줄 수 있다.\n예를 들어, 인간이 들을 수 있는 순수 음색(pure tone)의 최소 소리 강도인 청각의 임계값(threshold of hearing, TOH)은 다음과 같이 작다.\n\n\\(I_\\mathrm{TOH}:=10^{-12}~\\mathrm{W}/\\mathrm{m}^2\\)\n\n게다가, 인간이 지각할 수 있는 강도의 범위는 \\(I_\\mathrm{TOP}:=10~\\mathrm{W}/\\mathrm{m}^2\\) (통증 임계값(threshold of pain, TOP))으로 매우 크다.\n실질적인 이유로, 힘과 강도를 표현하기 위해 로그 척도로 전환한다. 더 정확하게는 두 값 사이의 비율을 나타내는 로그 단위인 데시벨(dB) 척도를 사용한다.\n일반적으로 소리 강도의 경우 \\(I_\\mathrm{TOH}\\) 같은 값이 참조 역할을 한다.\n그런 다음 dB로 측정된 강도는 다음과 같이 정의된다.\n\n$ (I) := 10_{10}()$\n\n위의 정의에서 \\(\\mathrm{dB}(I_\\mathrm{TOH})=0\\)를 얻을 수 있고, 강도가 두배로 증가하면 대략 3dB 증가한다:\n\n\\(\\mathrm{dB}(2\\cdot I) = 10\\cdot \\log_{10}(2) + \\mathrm{dB}(I) \\approx 3 + \\mathrm{dB}(I)\\)\n\n데시벨 단위로 강도 값을 지정할 때 강도 수준(intensity levels)도 같이 언급된다.\n다음 표는 \\(\\mathrm{W}/\\mathrm{m}^2\\) 와 데시벨 단위로 몇 가지 일반적인 강도값(intensity value)을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_T01.png\", width=400)\n\n\n\n\n\n예시로 이를 보자.\n\n베토벤 5번 교항곡 시작 부분\n\n\n\nipd.Audio(\"../audio/beeth5_orch_21bars.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\ndef compute_power_db(x, Fs, win_len_sec=0.1, power_ref=10**(-12)):\n    \"\"\"Computation of the signal power in dB\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        Fs (scalar): Sampling rate\n        win_len_sec (float): Length (seconds) of the window (Default value = 0.1)\n        power_ref (float): Reference power level (0 dB) (Default value = 10**(-12))\n\n    Returns:\n        power_db (np.ndarray): Signal power in dB\n    \"\"\"\n    win_len = round(win_len_sec * Fs)\n    win = np.ones(win_len) / win_len\n    power_db = 10 * np.log10(np.convolve(x**2, win, mode='same') / power_ref)\n    return power_db\n\n\nFs = 22050\nx, Fs = librosa.load(\"../audio/beeth5_orch_21bars.wav\", sr=Fs, mono=True)\n\nwin_len_sec = 0.2\npower_db = compute_power_db(x, win_len_sec=win_len_sec, Fs=Fs)\n\n\nplot_signal(x, Fs, ylabel='Amplitude', color='gray')\nplot_signal(power_db, Fs, ylabel='Power (dB)', color='red')\nplt.show()"
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#라우드니스loudness",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#라우드니스loudness",
    "title": "2.3. 오디오 표현",
    "section": "라우드니스(Loudness)",
    "text": "라우드니스(Loudness)\n\n다이나믹과 소리 강도는 소리가 조용한 것에서 큰 것으로 확장되는 규모로 소리를 정렬할 수 있는 라우드니스(loudness)라고 불리는 지각적 특성과 관련이 있다.\n라우드니스는 주관적인 측정이며, 이는 개별 청취자(예: 나이는 소리에 대한 인간의 귀의 반응에 영향을 미치는 요인 중 하나)뿐만 아니라 지속 시간(duration) 또는 주파수와 같은 다른 소리 특성에도 영향을 미친다.\n\n예를 들어, 사람은 200ms 동안 지속되는 소리가 50ms 동안만 지속되는 유사한 소리보다 더 크게 느껴진다.\n게다가, 강도는 같지만 주파수가 다른 두 소리는 일반적으로 동일한 라우드니스로 인식되지 않는다.\n정상적인 청력을 가진 사람은 2~4kHz 정도의 소리에 가장 민감하며, 낮은 주파수뿐만 아니라 높은 주파수에서도 감도가 감소한다.\n\n정신음향(psychoacoustic) 실험을 바탕으로 주파수에 따른 순수 음색의 라우드니스는 단위 폰(unit phon)으로 결정되고 표현되어 왔다.\n다음 그림은 동일한 음량 윤곽선(equal loudness contours)을 보여준다. 각 윤곽선은 폰(phon)으로 주어진 고정된 음량에 대해 (로그로 간격을 둔) 주파수 축에 대한 소리 강도를 지정한다. 하나의 폰 단위는 1000Hz의 주파수에 대해 정규화되며, 여기서 하나의 폰 값은 dB 단위의 강도 수준과 같다. 0폰의 윤곽선은 주파수에 따라 청각 임계값(threshold of hearing)이 어떻게 달라지는지를 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F21.png\", width=400)\n\n\n\n\n\n윤곽선은 가중치 함수에 의해 대략적으로 설명될 수 있다. 다음 코드 셀에서 동일한 음량 윤곽선에 질적으로 근사하는 함수의 예를 찾을 수 있다.\n\n\ndef compute_equal_loudness_contour(freq_min=30, freq_max=15000, num_points=100):\n    \"\"\"Computation of the equal loudness contour\n\n    Args:\n        freq_min (float): Lowest frequency to be evaluated (Default value = 30)\n        freq_max (float): Highest frequency to be evaluated (Default value = 15000)\n        num_points (int): Number of evaluation points (Default value = 100)\n\n    Returns:\n        equal_loudness_contour (np.ndarray): Equal loudness contour (in dB)\n        freq_range (np.ndarray): Evaluated frequency points\n    \"\"\"\n    freq_range = np.logspace(np.log10(freq_min), np.log10(freq_max), num=num_points)\n    freq = 1000\n    # Function D from https://bar.wikipedia.org/wiki/Datei:Acoustic_weighting_curves.svg\n    h_freq = ((1037918.48 - freq**2)**2 + 1080768.16 * freq**2) / ((9837328 - freq**2)**2 + 11723776 * freq**2)\n    n_freq = (freq / (6.8966888496476 * 10**(-5))) * np.sqrt(h_freq / ((freq**2 + 79919.29) * (freq**2 + 1345600)))\n    h_freq_range = ((1037918.48 - freq_range**2)**2 + 1080768.16 * freq_range**2) / ((9837328 - freq_range**2)**2\n                                                                                     + 11723776 * freq_range**2)\n    n_freq_range = (freq_range / (6.8966888496476 * 10**(-5))) * np.sqrt(h_freq_range / ((freq_range**2 + 79919.29) *\n                                                                         (freq_range**2 + 1345600)))\n    equal_loudness_contour = 20 * np.log10(np.abs(n_freq / n_freq_range))\n    return equal_loudness_contour, freq_range\n\n\nequal_loudness_contour, freq_range = compute_equal_loudness_contour()\n\nplot_signal(equal_loudness_contour, T_coef=freq_range, figsize=(6,3), xlabel='Frequency (Hz)',\n            ylabel='Intensity (dB)', title='Equal loudness contour', color='red')\nplt.xscale('log')\nplt.grid()\nplt.show()\n\n\n\n\n\n동일 힘을 가지는 처프 신호\n\n이제 30Hz에서 시작하여 10000Hz로 끝나는, 주파수가 기하급수적으로 증가하는 차프 신호에 대한 작은 실험을 해보자.\n먼저, 전체 시간 간격에 걸쳐 동일한 강도의 차프 신호를 생성한다. 이 신호를 들을 때는 주파수가 증가함에 따라 신호가 먼저 커지고 약 4000Hz의 주파수를 지나면 다시 부드러워지는 느낌이 든다.\n\n\n\ndef generate_chirp_exp(dur, freq_start, freq_end, Fs=22050):\n    \"\"\"Generation chirp with exponential frequency increase\n\n    Args:\n        dur (float): Length (seconds) of the signal\n        freq_start (float): Start frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    freq = np.exp(np.linspace(np.log(freq_start), np.log(freq_end), N))\n    phases = np.zeros(N)\n    for n in range(1, N):\n        phases[n] = phases[n-1] + 2 * np.pi * freq[n-1] / Fs\n    x = np.sin(phases)\n    return x, t, freq\n\n\nFs = 22050\nfreq_start = 30 \nfreq_end = 10000\ndur = 10\nx, t, freq = generate_chirp_exp(dur, freq_start, freq_end, Fs=Fs)\n\n\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [3, 2]}, figsize=(7, 5))\nN, H = 1024, 512\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, pad_mode='constant')\nplot_matrix(np.log(1+np.abs(X)), Fs=Fs/H, Fs_F=N/Fs, ax=[ax[0,0], ax[0,1]], \n            title='Spectrogram of chirp', colorbar=True)\n\nwin_len_sec = 0.1\npower_db = compute_power_db(x, win_len_sec=win_len_sec, Fs=Fs)\nplot_signal(power_db, Fs=Fs, ax=ax[1,0], title='Sound power level', ylabel='Power (dB)', color='red')\nax[1,0].set_ylim([103, 137])\nax[1,1].set_axis_off()\nplt.tight_layout()\nplt.show()\n\ndisplay(Audio(x, rate=Fs) )\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n동일 라우드니스를 가지는 처프 신호\n\n둘째로, 위에서 생성된 동일 라우드니스 윤곽에 따라 신호의 진폭(amplitude)을 조정한다.\n이 경우 전체 주파수 범위를 통해 스위핑할 때 결과로 발생하는 처프 신호의 라우드니스가 동일한 것으로 보인다.\n\n\n\ndef generate_chirp_exp_equal_loudness(dur, freq_start, freq_end, Fs=22050):\n    \"\"\"Generation chirp with exponential frequency increase and equal loudness\n\n    Args:\n        dur (float): Length (seconds) of the signal\n        freq_start (float): Starting frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n        intensity (np.ndarray): Instant intensity of the signal\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    intensity, freq = compute_equal_loudness_contour(freq_min=freq_start, freq_max=freq_end, num_points=N)\n    amp = 10**(intensity / 20)\n    phases = np.zeros(N)\n    for n in range(1, N):\n        phases[n] = phases[n-1] + 2 * np.pi * freq[n-1] / Fs\n    x = amp * np.sin(phases)\n    return x, t, freq, intensity\n\n\nx_equal_loudness, t, freq, intensity = generate_chirp_exp_equal_loudness(dur, freq_start, freq_end, Fs=Fs)\n\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [3, 2]}, figsize=(7, 5))\nN, H = 1024, 512\nX = librosa.stft(x_equal_loudness, n_fft=N, hop_length=H, win_length=N, pad_mode='constant')\nplot_matrix(np.log(1+np.abs(X)), Fs=Fs/H, Fs_F=N/Fs, ax=[ax[0,0], ax[0,1]], \n                     title='Spectrogram of chirp with equal loudness', colorbar=True)\n\nwin_len_sec = 0.1\npower_db = compute_power_db(x_equal_loudness, win_len_sec=win_len_sec, Fs=Fs)\nplot_signal(power_db, Fs=Fs, ax=ax[1,0], title='Sound power level', ylabel='Power (dB)', color='red')\nax[1,0].set_ylim([103, 137])\nax[1,1].set_axis_off()\nplt.tight_layout()\nplt.show()\n\ndisplay( Audio(x_equal_loudness, rate=Fs) )\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프와-adsr-모형envelope-and-adsr-model",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프와-adsr-모형envelope-and-adsr-model",
    "title": "2.3. 오디오 표현",
    "section": "엔벨로프와 ADSR 모형(Envelope and ADSR Model)",
    "text": "엔벨로프와 ADSR 모형(Envelope and ADSR Model)\n\n소리의 음색에 영향을 미치는 한 가지 소리 특성은 파형의 엔벨로프(envelope)이며, 이는 진폭에서 극단을 나타내는 매끄러운 곡선으로 간주될 수 있다.\n음향 합성에서 생성되는 신호의 엔벨로프는 어택(attack, A), 디케이(decay, D), 서스테인(sustain, S), 릴리스(release, R) 단계로 구성된 ADSR이라는 모델에 의해 종종 설명된다.\n4단계의 상대적 지속 시간과 진폭은 합성된 음색이 어떻게 들릴지에 큰 영향을 미친다.\n다음 그림은 이상적인 ADSR 모델과 피아노와 바이올린 사운드의 엔벨로프(단음 C4 재생)를 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F22a-23.png\", width=800)\n\n\n\n\n\n그림에서 알 수 있듯이, 하나의 음을 연주하면 이미 주기적인 요소뿐만 아니라 비주기적인 요소를 포함하여 시간이 지남에 따라 지속적으로 변화할 수 있는 특성을 가진 복잡한 음향 혼합물이 생성된다.\n어택(attack) 단계 동안, 소리는 보통 넓은 주파수 범위에 걸쳐 소음 같은 구성 요소로 축적된다. 소리가 시작될 때 소음과 같은 짧은 지속 시간의 소리를 과도음/트랜지언트(transient)라고 한다.\n디케이(decay) 단계 동안, 소리는 안정화되고 일정한 주기 패턴에 도달한다.\n서스테인(sustain) 단계 동안, 에너지는 꽤 일정하게 유지된다.\n릴리스(release) 단계에서는 소리가 사라진다.\n다음 코드 셀에서, 이상화된 ADSR 모델을 생성한다.\n\n\ndef compute_adsr(len_A=10, len_D=10, len_S=60, len_R=10, height_A=1.0, height_S=0.5):\n    \"\"\"Computation of idealized ADSR model\n\n    Args:\n        len_A (int): Length (samples) of A phase (Default value = 10)\n        len_D (int): Length (samples) of D phase (Default value = 10)\n        len_S (int): Length (samples) of S phase (Default value = 60)\n        len_R (int): Length (samples) of R phase (Default value = 10)\n        height_A (float): Height of A phase (Default value = 1.0)\n        height_S (float): Height of S phase (Default value = 0.5)\n\n    Returns:\n        curve_ADSR (np.ndarray): ADSR model\n    \"\"\"\n    curve_A = np.arange(len_A) * height_A / len_A\n    curve_D = height_A - np.arange(len_D) * (height_A - height_S) / len_D\n    curve_S = np.ones(len_S) * height_S\n    curve_R = height_S * (1 - np.arange(1, len_R + 1) / len_R)\n    curve_ADSR = np.concatenate((curve_A, curve_D, curve_S, curve_R))\n    return curve_ADSR\n\n\ncurve_ADSR = compute_adsr(len_A=10, len_D=10, len_S=60, len_R=10, height_A=1.0, height_S=0.5)\n\nplot_signal(curve_ADSR, figsize=(4,2.5), ylabel='Amplitude', title='ADSR model', color='red')\nplt.show()\n\ncurve_ADSR = compute_adsr(len_A=20, len_D=2, len_S=60, len_R=1, height_A=2.0, height_S=1.2)\nplot_signal(curve_ADSR, figsize=(4,2.5), ylabel='Amplitude', title='ADSR model', color='red')\nplt.show()\n\n\n\n\n\n\n\n\nADSR 모델은 단순화된 형태이며 특정 악기에서 생성되는 톤의 진폭 엔벨로프에 대한 의미 있는 근사치만 산출한다.\n예를 들어, 위와 같은 바이올린 소리는 ADSR 모델에 의해 잘 근사되지 않는다.\n\n우선 음량을 점차 늘려가며 부드럽게 연주하기 때문에 어택 국면이 퍼진다. 게다가, 디케이 단계가 없는 것처럼 보이고 그 이후의 서스테인 단계는 일정하지 않다; 대신 진폭 엔벨로프는 규칙적인 방식으로 진동한다. 바이올린 연주자가 활로 현을 켜는 것을 멈추면 릴리즈 단계가 시작된다. 그리고 나서 그 소리는 빠르게 사라진다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프-계산",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프-계산",
    "title": "2.3. 오디오 표현",
    "section": "엔벨로프 계산",
    "text": "엔벨로프 계산\n\n파형의 엔벨로프를 계산하는 방법은 여러 가지가 있다. 다음에서는 각 윈도우 섹션에 최대 필터를 적용하여 간단한 슬라이딩 윈도우 방식을 사용한다. 다음 코드 셀에서는 주어진 파형의 상한 엔벨로프와 하한 엔벨로프 및 파형의 크기 엔벨로프를 계산한다.\n\n\ndef compute_envelope(x, win_len_sec=0.01, Fs=4000):\n    \"\"\"Computation of a signal's envelopes\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        win_len_sec (float): Length (seconds) of the window (Default value = 0.01)\n        Fs (scalar): Sampling rate (Default value = 4000)\n\n    Returns:\n        env (np.ndarray): Magnitude envelope\n        env_upper (np.ndarray): Upper envelope\n        env_lower (np.ndarray): Lower envelope\n    \"\"\"\n    win_len_half = round(win_len_sec * Fs * 0.5)\n    N = x.shape[0]\n    env = np.zeros(N)\n    env_upper = np.zeros(N)\n    env_lower = np.zeros(N)\n    for i in range(N):\n        i_start = max(0, i - win_len_half)\n        i_end = min(N, i + win_len_half)\n        env[i] = np.amax(np.abs(x)[i_start:i_end])\n        env_upper[i] = np.amax(x[i_start:i_end])\n        env_lower[i] = np.amin(x[i_start:i_end])\n    return env, env_upper, env_lower\n    \n    \ndef compute_plot_envelope(x, win_len_sec, Fs, figsize=(6, 3), title=''):\n    \"\"\"Computation and subsequent plotting of a signal's envelope\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        win_len_sec (float): Length (seconds) of the window\n        Fs (scalar): Sampling rate\n        figsize (tuple): Size of the figure (Default value = (6, 3))\n        title (str): Title of the figure (Default value = '')\n\n    Returns:\n        fig (mpl.figure.Figure): Generated figure\n    \"\"\"\n    t = np.arange(x.size)/Fs\n    env, env_upper, env_lower = compute_envelope(x, win_len_sec=win_len_sec, Fs=Fs)\n    fig = plt.figure(figsize=figsize)\n    plt.plot(t, x, color='gray', label='Waveform')\n    plt.plot(t, env_upper, linewidth=2, color='cyan', label='Upper envelope')\n    plt.plot(t, env_lower, linewidth=2, color='blue', label='Lower envelope')\n    plt.plot(t, env, linewidth=2, color='red', label='Magnitude envelope')\n    plt.title(title)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.xlim([t[0], t[-1]])\n    #plt.ylim([-0.7, 0.7])\n    plt.legend(loc='lower right')\n    plt.show()\n    ipd.display(ipd.Audio(data=x, rate=Fs))\n    return fig\n\n\nFs = 11025\nwin_len_sec=0.05\n\nx, Fs = librosa.load(\"../audio/piano_c4.wav\", sr=Fs)\nfig = compute_plot_envelope(x, win_len_sec=win_len_sec, Fs=Fs, title='piano sound')\n\nx, Fs = librosa.load(\"../audio/violin_c4.wav\", sr=Fs)\nfig = compute_plot_envelope(x, win_len_sec=win_len_sec, Fs=Fs, title='violin sound')\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#비브라토-트레몰로-vibrato-and-tremolo",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#비브라토-트레몰로-vibrato-and-tremolo",
    "title": "2.3. 오디오 표현",
    "section": "비브라토, 트레몰로 Vibrato and Tremolo",
    "text": "비브라토, 트레몰로 Vibrato and Tremolo\n\n바이올린의 예에서 음색과 관련된 다른 현상들이 나타난다. 예를 들어, 진폭의 주기적인 변화를 관찰할 수 있다. 이러한 진폭 변조는 트레몰로(tremolo)로도 알려져 있다.\n트레몰로의 효과는 진동수의 규칙적인 변화(주파수 변조)로 구성된 음악적 효과인 비브라토와 함께 종종 동반된다.\n현악 이외에도 비브라토는 인간 가수들이 표현을 더하기 위해 주로 사용된다. 트레몰로와 비브라토가 단순히 강도와 주파수의 국소적인 변화라고 할지라도, 그것들이 반드시 전체적인 음조의 음량이나 음조의 지각된 변화를 불러일으키지는 않는다. 오히려, 그것들은 음악적 음색에 영향을 미치는 특징들이다.\n다음 코드 셀에서, 단순한 정현파, 비브라토가 있는 정현파, 트레몰로가 있는 정현파를 생성한다.\n\n\ndef generate_sinusoid_vibrato(dur=5, Fs=1000, amp=0.5, freq=440, vib_amp=1, vib_rate=5):\n    \"\"\"Generation of a sinusoid signal with vibrato\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 0.5)\n        freq (float): Frequency (Hz) of sinusoid (Default value = 440)\n        vib_amp (float): Amplitude (Hz) of the frequency oscillation (Default value = 1)\n        vib_rate (float): Rate (Hz) of the frequency oscillation (Default value = 5)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    freq_vib = freq + vib_amp * np.sin(t * 2 * np.pi * vib_rate)\n    phase_vib = np.zeros(num_samples)\n    for i in range(1, num_samples):\n        phase_vib[i] = phase_vib[i-1] + 2 * np.pi * freq_vib[i-1] / Fs\n    x = amp * np.sin(phase_vib)\n    return x, t\n\ndef generate_sinusoid_tremolo(dur=5, Fs=1000, amp=0.5, freq=440, trem_amp=0.1, trem_rate=5):\n    \"\"\"Generation of a sinusoid signal with tremolo\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 0.5)\n        freq (float): Frequency (Hz) of sinusoid (Default value = 440)\n        trem_amp (float): Amplitude of the amplitude oscillation (Default value = 0.1)\n        trem_rate (float): Rate (Hz) of the amplitude oscillation (Default value = 5)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    amps = amp + trem_amp * np.sin(t * 2 * np.pi * trem_rate)\n    x = amps * np.sin(2*np.pi*(freq*t))\n    return x, t\n\n\nFs = 4000\ndur = 5\nfreq = 220\namp = 0.5\nfigsize = (8,2)\n\nx, t = generate_sinusoid(dur=dur, Fs=Fs, amp=amp, freq=freq)\nx_vib, t = generate_sinusoid_vibrato(dur=dur, Fs=Fs, amp=amp, freq=freq, vib_amp=6, vib_rate=5)\nx_trem, t = generate_sinusoid_tremolo(dur=dur, Fs=Fs, amp=amp, freq=freq, trem_amp=0.3, trem_rate=5)\n\n\nplot_signal(x, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nplot_signal(x_vib, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid with vibrato')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x_vib, rate=Fs))\n\nplot_signal(x_trem, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid with tremolo')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x_trem, rate=Fs))\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#부분음부분파-partials",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#부분음부분파-partials",
    "title": "2.3. 오디오 표현",
    "section": "부분음/부분파 (Partials)",
    "text": "부분음/부분파 (Partials)\n\n아마도 음색을 특징 짓는 가장 중요하고 잘 알려진 속성은 특정 부분파(Partials)의 존재와 그 상대적 강점일 것이다.\n부분파는 음악 톤에서 가장 낮은 부분이 기본 주파수(fundamental frequency) 인 지배적 주파수이다.\n소리의 부분파는 스펙트로그램으로 시각화된다. 스펙트로그램(spectrogram)은 시간 경과에 따른 주파수 성분의 강도를 보여준다\n비조화(inharmonicity)는 가장 가까운 이상고조파(ideal harmonic)에서 벗어나는 부분적 정도를 나타낸다.\n명확하게 인식할 수 있는 음정을 가진 음악적 톤과 같은 소리의 경우, 대부분의 부분파는 고조파(harmonics)에 가깝다. 그러나 모든 부분파가 동일한 강도로 발생할 필요는 없다. 다음 그림은 서로 다른 악기에서 재생되는 단일 노트 C4에 대한 스펙트로그램 표현을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F23_FourInstruments.png\", width=800)\n\n\n\n\n\n음의 기본 주파수(261.6Hz)와 고조파(261.6Hz의 정수 배수) 모두 수평 구조로 보인다.\n음악 톤의 디케이는 각각의 부분파에서 그에 상응하는 디케이에 의해 반영된다.\n톤의 에너지의 대부분은 낮은 부분에 포함되어 있고, 높은 부분에 대한 에너지는 낮은 경향이 있다. 이러한 분포는 많은 악기에서 일반적이다. 현악기의 경우, 소리는 풍부한 부분 스펙트럼을 갖는 경향이 있는데, 여기서 많은 에너지가 상부 고조파(harmonics)에도 포함될 수 있다. 이 그림은 또한 트레몰로(특히 플루트의 경우)와 비브라토(특히 바이올린의 경우)를 보여준다.\n\n다른 예\n\n# pure tone\nT = 2.0 # seconds\nf0 = 1047.0\nsr = 22050\nt = np.linspace(0, T, int(T*sr), endpoint=False) # time variable\nx = 0.1*np.sin(2*np.pi*f0*t)\nipd.Audio(x, rate=sr)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[:4096])\nX_mag = np.absolute(X)        # spectral magnitude\nf = np.linspace(0, sr, 4096)  # frequency variable\nplt.figure(figsize=(6, 2))\nplt.title('pure tone')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n# oboe C6\nx, sr = librosa.load('../audio/oboe_c6.wav')\nprint(x.shape)\nipd.Audio(x, rate=sr)\n\n(23625,)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[10000:14096])\nX_mag = np.absolute(X)\nplt.figure(figsize=(6, 2))\nplt.title('oboe C6')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\nx, sr = librosa.load('../audio/clarinet_c6.wav')\nprint(x.shape)\nipd.Audio(x, rate=sr)\n\n(51386,)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[10000:14096])\nX_mag = np.absolute(X)\nplt.figure(figsize=(6, 2))\nplt.title('clarinet C6')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n부분파의 구성 요소의 상대적 진폭 차이에 주목해보자. 세 신호 모두 거의 동일한 피치와 기본 주파수를 가지고 있지만, 음색은 다르다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#missing-fundamental",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#missing-fundamental",
    "title": "2.3. 오디오 표현",
    "section": "Missing Fundamental",
    "text": "Missing Fundamental\n\n앞서 말했듯이, 소리의 음색은 결정적으로 고조파에 걸친 신호의 에너지 분포에 따라 달라진다. 또한, 인식된 피치의 지각은 기본 주파수뿐만 아니라 더 높은 고조파와 그들의 관계에 따라 달라진다. 예를 들어, 인간은 이 피치와 관련된 기본 주파수가 완전히 누락된 경우에도 톤의 피치를 감지할 수 있다. 이 현상은 “missing fundamental”로 알려져 있다.\n다음 코드 예제에서는 음의 중심 주파수(center frequency)의 정수 배수인 주파수를 가진 (가중된) 정현파를 추가하여 소리를 생성한다. 특히 순수 톤(MIDI 피치 𝑝), 고조파가 있는 톤, missing fundamental의 고조파가 있는 톤, 두번 째 순수 톤(MIDI 피치 𝑝+12)을 생성한다.\n\n\ndef generate_tone(p=60, weight_harmonic=np.ones([16, 1]), Fs=11025, dur=2):\n    \"\"\"Generation of a tone with harmonics\n\n    Args:\n        p (float): MIDI pitch of the tone (Default value = 60)\n        weight_harmonic (np.ndarray): Weights for the different harmonics (Default value = np.ones([16, 1])\n        Fs (scalar): Sampling frequency (Default value = 11025)\n        dur (float): Duration (seconds) of the signal (Default value = 2)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    freq = 2 ** ((p - 69) / 12) * 440\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = np.zeros(t.shape)\n    for h, w in enumerate(weight_harmonic):\n        x = x + w * np.sin(2 * np.pi * freq * (h + 1) * t)\n    return x, t\n\ndef plot_spectrogram(x, Fs=11025, N=4096, H=2048, figsize=(4, 2)):\n    \"\"\"Computation and subsequent plotting of the spectrogram of a signal\n\n    Args:\n        x: Signal (waveform) to be analyzed\n        Fs: Sampling rate (Default value = 11025)\n        N: FFT length (Default value = 4096)\n        H: Hopsize (Default value = 2048)\n        figsize: Size of the figure (Default value = (4, 2))\n\n    \"\"\"\n    N, H = 2048, 1024\n    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann')\n    Y = np.abs(X)\n    plt.figure(figsize=figsize)\n    librosa.display.specshow(librosa.amplitude_to_db(Y, ref=np.max),\n                             y_axis='linear', x_axis='time', sr=Fs, hop_length=H, cmap='gray_r')\n    plt.ylim([0, 3000])\n    # plt.colorbar(format='%+2.0f dB')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.tight_layout()\n    plt.show()\n\n\nFs = 11025\np = 60\n\nprint('Pure tone (p = %s):' % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0.2])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Tone with harmonics (p = %s):' % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Tone with harmonics and missing fundamental (p = %s):'  % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Pure tone (p = %s):' % (p + 12))\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0, 0.2])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nPure tone (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nTone with harmonics (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nTone with harmonics and missing fundamental (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nPure tone (p = 72):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n출처:\n\nhttps://musicinformationretrieval.com/\nhttps://www.audiolabs-erlangen.de/FMP\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "",
    "text": "푸리에 변환(Fourier transform)을 보기 전에 이와 관련한 몇가지 수학적 개념(복소수, 지수함수)을 리뷰해보록 한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-개념",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-개념",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "기본 개념",
    "text": "기본 개념\n\n실수 부분 \\(\\mathrm{Re}(c) = a\\), 허수 부분 \\(\\mathrm{Im}(c) = b\\) 및 허수 단위 \\(i = \\sqrt{-1}\\)로 복소수 \\(c = a + ib\\)를 쓸 수 있다. 파이썬에서 기호 j는 허수의 단위를 나타내기 위해 사용된다. 또한 j 앞의 계수가 필요하다. 복소수를 지정하기 위해 complex라는 생성자를 사용할 수도 있다.\n\n\na = 1.5\nb = 0.8\nc = a + b*1j\nprint(c)\nc2 = complex(a,b)\nprint(c2)\n\n(1.5+0.8j)\n(1.5+0.8j)\n\n\n\nprint(np.real(c))\nprint(np.imag(c))\n\n1.5\n0.8\n\n\n\ndef generate_figure(figsize=(6, 2), xlim=[0, 1], ylim=[0, 1]):\n    \"\"\"Generate figure for plotting complex numbers\n\n    Args:\n        figsize: Figure size (Default value = (2, 2))\n        xlim: Limits of x-axis (Default value = [0, 1])\n        ylim: Limits of y-axis (Default value = [0, 1])\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.grid()\n    plt.xlim(xlim)\n    plt.ylim(ylim)\n    plt.xlabel(r'$\\mathrm{Re}$')\n    plt.ylabel(r'$\\mathrm{Im}$')\n\ndef plot_vector(c, color='k', start=0, linestyle='-'):\n    \"\"\"Plot arrow corresponding to difference of two complex numbers\n\n    Args:\n        c: Complex number\n        color: Color of arrow (Default value = 'k')\n        start: Complex number encoding the start position (Default value = 0)\n        linestyle: Linestyle of arrow (Default value = '-')\n\n    Returns:\n        arrow (matplotlib.patches.FancyArrow): Arrow\n    \"\"\"\n    return plt.arrow(np.real(start), np.imag(start), np.real(c), np.imag(c),\n                     linestyle=linestyle, head_width=0.05, fc=color, ec=color, overhang=0.3,\n                     length_includes_head=True)\n\n\nc = 1.5 + 0.8j\n\ngenerate_figure(xlim=[0, 2.5], ylim=[0, 1])\nv = plot_vector(c, color='k')\n\nplt.text(1.5, 0.8, '$c$', size='16')\nplt.text(0.8, 0.55, '$|c|$', size='16')\nplt.text(0.25, 0.05, '$\\gamma$', size='16');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표-표현-polar-representation",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표-표현-polar-representation",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "극좌표 표현 (Polar Representation)",
    "text": "극좌표 표현 (Polar Representation)\n\n복소수 \\(a+ib\\) 의 절대값 (absolute value or modulus)은 다음과 같이 정의된다.\n\n\\(|c| := \\sqrt{a^2 + b^2}.\\)\n\n(radian으로 주어진) 각도(angle)는 다음과 같다.\n\n\\(\\gamma := \\mathrm{atan2}(b, a).\\)\n\n이는 \\((-\\pi,\\pi]\\) 간격의 숫자를 생성하며, 이 값은 음의 값에 \\(2\\pi\\)를 추가하여 \\([0,2\\pi)\\)에 매핑될 수 있다. 각도(degree 단위)는 다음과 같이 구한다.\n\n\\(360 \\cdot \\frac{\\gamma}{2\\pi}\\)\n\n\n\nprint('Absolute value:', np.abs(c))\nprint('Angle (in radians):', np.angle(c))\nprint('Angle (in degree):', np.rad2deg(np.angle(c)))\nprint('Angle (in degree):', 360 * np.angle(c)/(2*np.pi) )\n\nAbsolute value: 1.7\nAngle (in radians): 0.48995732625372834\nAngle (in degree): 28.07248693585296\nAngle (in degree): 28.07248693585296\n\n\n\n복소수 \\(c=a+ib\\)는 \\((|c|, \\gamma)\\) 쌍에 의해 고유하게 정의되며, 이는 \\(c\\)의 극좌표 표현(polar representation)이라고도 한다. 다음과 같이 극좌표 표현 \\((|c|,\\gamma)\\)에서 데카르트 표현(Cartesian representation) \\((a,b)\\)를 얻는다.\n\n\\[\\begin{eqnarray}\na &=& |c| \\cdot \\cos(\\gamma) \\\\\nb &=& |c| \\cdot \\sin(\\gamma)\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#연산",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#연산",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "연산",
    "text": "연산\n\n두 복소수 \\(c_1=a_1+ib_1\\)와 \\(c_2=a_2+ib_2\\)의 경우, 합은 다음과 같다.\n\n\\[\nc_1 + c_2 = (a_1 + ib_1) + (a_2 + ib_2) := (a_1 + a_2) + i(b_1 + b_2)\n\\]\n\n실수 부분과 허수 부분을 개별적으로 합산하여 정의한다. 덧셈의 기하학적 직관은 평행사변형으로 시각화할 수 있다.\n\n\nc1 = 1.3 - 0.3j\nc2 = 0.3 + 0.5j\nc = c1 + c2\n\ngenerate_figure(xlim=[-0.3, 2.2], ylim=[-0.4, 0.6])\nv1 = plot_vector(c1, color='k')\nv2 = plot_vector(c2, color='b')\nplot_vector(c1, start=c2, linestyle=':', color='lightgray')\nplot_vector(c2, start=c1, linestyle=':', color='lightgray')\nv3 = plot_vector(c, color='r')\n\nplt.legend([v1, v2, v3], ['$c_1$', '$c_2$', '$c_1+c_2$']);\n\n\n\n\n\n두 숫자 \\(c_1=a_1+ib_1\\)와 \\(c_2=a_2+ib_2\\)의 복소수 곱셈은 다음과 같이 정의된다.\n\n\\[c = c_1 \\cdot c_2 = (a_1 + ib_1) \\cdot (a_2 + ib_2) := (a_1a_2 - b_1b_2) + i(a_1b_2 + b_1a_2).\\]\n\n기하학적으로, 이 곱은 각도를 더하고 절대값을 곱함으로써 얻어진다. 다시 말해, \\((|c_1|, \\gamma_1)\\)와 \\((|c_2|, \\gamma_2)\\)가 각각 \\(c_1\\)와 \\(c_1\\)의 극좌표 표현이라면, \\(c\\)의 극좌표 표현 \\((|c|, \\gamma)\\)는 다음과 같이 주어진다.\n\n\\[\\begin{eqnarray}\n\\gamma &=& \\gamma_1 + \\gamma_2 \\\\\n|c| &=& |c_1| \\cdot |c_2|\n\\end{eqnarray}\\]\n\nc1 = 1.0 - 0.5j\nc2 = 2.3 + 0.7j\nc = c1 * c2\n\ngenerate_figure(xlim=[-0.5, 4.0], ylim=[-0.75, 0.75])\nv1 = plot_vector(c1, color='k')\nv2 = plot_vector(c2, color='b')\nv3 = plot_vector(c, color='r')\nplt.legend([v1, v2, v3], ['$c_1$', '$c_2$', '$c_1 \\cdot c_2$']);"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표계-polar-coordinate-plot",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표계-polar-coordinate-plot",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "극좌표계 (Polar Coordinate Plot)",
    "text": "극좌표계 (Polar Coordinate Plot)\n\ndef plot_polar_vector(c, label=None, color=None, start=0, linestyle='-'):\n    # plot line in polar plane\n    line = plt.polar([np.angle(start), np.angle(c)], [np.abs(start), np.abs(c)], label=label, \n                     color=color, linestyle=linestyle)\n    # plot arrow in same color\n    this_color = line[0].get_color() if color is None else color\n    plt.annotate('', xytext=(np.angle(start), np.abs(start)), xy=(np.angle(c), np.abs(c)),\n                 arrowprops=dict(facecolor=this_color, edgecolor='none', \n                                 headlength=12, headwidth=10, shrink=1, width=0))\n\n\n#head_width=0.05, fc=color, ec=color, overhang=0.3, length_includes_head=True    \n    \nc_abs = 1.5\nc_angle = 45  # in degree\nc_angle_rad = np.deg2rad(c_angle) \na = c_abs * np.cos(c_angle_rad)\nb = c_abs * np.sin(c_angle_rad)\nc1 = a + b*1j    \nc2 = -0.5 + 0.75*1j\n\nplt.figure(figsize=(6, 6))\nplot_polar_vector(c1, label='$c_1$', color='k')\nplot_polar_vector(np.conj(c1), label='$\\overline{c}_1$', color='gray')\nplot_polar_vector(c2, label='$c_2$', color='b')\nplot_polar_vector(c1*c2, label='$c_1\\cdot c_2$', color='r')\nplot_polar_vector(c1/c2, label='$c_1/c_2$', color='g')\n\nplt.ylim([0, 1.8]);\nplt.legend(framealpha=1);"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#power-series-멱급수",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#power-series-멱급수",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "Power Series (멱급수)",
    "text": "Power Series (멱급수)\n\n실 지수 함수(real exponential function) \\(\\exp:\\mathbb{R}\\to \\mathbb{R}\\)는 많은 수학 응용에서 볼 수 있다. 그리고 이 함수는 많은 다른 방식으로 특성화될 수 있다.\n역사적으로 지수 함수는 금리를 고려할 때 \\(17^\\mathrm{th}\\) 세기에 Johann Bernoulli에 의해 연구된 바 있다.\n\n\\(1\\)의 이자를 매월 복합된 연간 금리로 이자 \\(a\\)를 얻는다고 가정하자. 그런 다음 매달 얻은 이자는 현재 값의 \\(\\frac{a}{12}\\)배이므로, 매달 총 값에 \\(\\left(1+\\frac{a}{12}\\right)\\)를 곱하고 연말의 값은 \\(\\left(1+\\frac{a}{12}\\right)^{12}\\)이다. 매일 이자가 복합되는 경우 \\(\\left(1+\\frac{a}{365}\\right)^{365}\\)가 된다.\n\n시간 간격을 더 짧게 함으로써 매년 증가하도록 하는 것은 지수 함수의 limit 정의로 이어진다.\n\n\\(\\exp(a) = \\mathrm{lim}_{n\\to\\infty} \\left(1+\\frac{a}{n}\\right)^{n},\\)\n\n상수 \\(e:=\\exp(1)\\approx 2.71828 \\ldots\\)는 Euler의 숫자로도 알려져 있다. 위의 정의에서 \\(n\\)-fold 곱을 확장하면 지수 함수가 다음과 같은 멱급수로 표현될 수 있음을 보여줄 수 있다. \\[\\exp(a) := \\sum_{n=0}^{\\infty} \\frac{a^n}{n!} = 1 + a + \\frac{a^2}{1 \\cdot 2} + \\frac{a^3}{1 \\cdot 2 \\cdot 3} + \\cdot\\]\n멱급수에서 실수값 변수 \\(a\\in\\mathbb{R}\\)를 복소수 값 변수 \\(c\\in\\mathbb{C}\\)로 바꾸면, 여전히 다음과 같이 주어진 복소수 지수 함수 \\(\\exp:\\mathbb{C}\\to \\mathbb{C}\\)를 얻는다.\n\n\\[\\exp(c) := \\sum_{n=0}^{\\infty} \\frac{c^n}{n!} = 1 + c + \\frac{c^2}{1 \\cdot 2} + \\frac{c^3}{1 \\cdot 2 \\cdot 3} + \\cdot\\]\n\n복소수 지수 함수의 정의를 기반으로 삼각 함수(예: \\(\\sin\\) 및 \\(\\cos\\))의 정의를 복소 인수로 확장할 수도 있다.\n다음 구현은 매개 변수 \\(N\\in\\mathbb{N}\\)에 의해 지정된 첫 번째 \\(N\\) 항만 고려하여 멱급수의 근사치를 산출한다. \\(c=1\\)의 경우, 숫자 \\(e\\)에 대한 근사치를 산출한다.\n\n\ndef exp_power_series(c, N):\n    \"\"\"Compute power series for exponential function\n\n    Args:\n        c: Complex number\n        N: Number of summands used for approximation\n\n    Returns:\n        exp_c: Approximation of exp(c)\n    \"\"\"    \n    exp_c = 1\n    c_power = 1\n    nfac = 1\n    for n in range(1, N):\n        nfac *= n\n        c_power *= c \n        exp_c += c_power / nfac\n    return exp_c\n\n\nc=1\nprint('Approximation (N =  1):', exp_power_series(c, 1))\nprint('Approximation (N =  2):', exp_power_series(c, 2))\nprint('Approximation (N =  4):', exp_power_series(c, 4))\nprint('Approximation (N =  8):', exp_power_series(c, 8))\nprint('Approximation (N = 12):', exp_power_series(c, 12))\nprint('Numpy:                 ', np.exp(c))\n\nApproximation (N =  1): 1\nApproximation (N =  2): 2.0\nApproximation (N =  4): 2.6666666666666665\nApproximation (N =  8): 2.7182539682539684\nApproximation (N = 12): 2.718281826198493\nNumpy:                  2.718281828459045"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#지수-항등식과-오일러-공식-exponentiation-identity-and-eulers-formula",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#지수-항등식과-오일러-공식-exponentiation-identity-and-eulers-formula",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "지수 항등식과 오일러 공식 (Exponentiation Identity and Euler’s Formula )",
    "text": "지수 항등식과 오일러 공식 (Exponentiation Identity and Euler’s Formula )\n\n멱급수 정의에 기초하여, 많은 속성을 설명하는 지수 함수의 두 가지 유명한 공식을 증명할 수 있다.\n첫 번째 공식은 지수 항등식 exponentation identity로 알려져 있으며 다음과 같다.\n\n\\[\n  \\exp(c_1 + c_2) = \\exp(c_1)\\cdot \\exp(c_2)\n\\]\nfor any complex numbers \\(c_1, c_2\\in\\mathbb{C}\\).\n\n특히, 이 속성은 실수 인수의 기하급수적인 증가를 설명한다. 예를들면,\n\n\\[\n  \\exp(n) = \\exp(1+1+\\ldots +1) = \\exp(1)^n = e^n\n\\]\nfor \\(n\\in\\mathbb{N}\\).\n\n오일러 공식 Euler’s formula로 알려진 두 번째 공식은 순 허수(pure imaginary)의 인수에서 지수 함수의 값을 삼각 함수와 연관시킨다. 이는 일부 실수 값 \\(\\beta\\in\\mathbb{R}\\)와 함께 복소수 \\(c = i\\gamma\\)에 대해, 다음의 항등식을 가진다.\n\n\\[\\mathrm{exp}(i\\gamma) = \\cos(\\gamma) + i\\sin(\\gamma)\\]\n\n실제로 실수 사인 및 코사인 함수를 시작으로 오일러 공식을 사용하여 \\(\\mathrm{exp}(i\\gamma)\\)를 정의하는 경우가 많다.\n다음 그림에 나온 것처럼 허수(수직) 축을 따라 \\(\\exp\\)의 실수 및 허수 부분의 주기적인 행동을 설명한다.\n\n\nA, B = np.meshgrid(np.arange(-2, 2, 0.1), np.arange(-12, 12, 0.1))\nC = A + B*1j\nf_exp = np.exp(C)\n\nplt.figure(figsize=(12, 4))\nextent = [-2, 2, -12, 12]\nplt.subplot(1, 3, 1)\nplt.imshow(np.real(f_exp),  aspect='auto', cmap='seismic', origin='lower', extent=extent)\nplt.title('Real part Re(exp(c))')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.subplot(1, 3, 2)\nplt.imshow(np.imag(f_exp),  aspect='auto', cmap='seismic', origin='lower', extent=extent)\nplt.title('Imaginary part Im(exp(c))')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.subplot(1, 3, 3)\nplt.imshow(np.abs(f_exp),  aspect='auto', cmap='gray_r', origin='lower', extent=extent)\nplt.title('Absolute value |exp(c)|')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-속성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-속성",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "기본 속성",
    "text": "기본 속성\n\n지수 함수에는 여러 가지 흥미로운 속성이 있다:\n\n\\(\\exp(i\\gamma) = \\exp(i(\\gamma+2\\pi))\\)\n\\(|\\exp(i\\gamma)| = 1\\)\n\\(\\overline{\\exp(i\\gamma)} = \\exp(-i\\gamma)\\)\n\\(\\exp(i(\\gamma_1+\\gamma_2)) = \\exp(i\\gamma_1) \\exp(i\\gamma_2)\\)\n\\(\\frac{d\\exp(i\\gamma)}{d\\gamma} = i\\exp(i\\gamma)\\)\n\n특히, 복소수 값 \\(\\mathrm{exp}(i\\gamma)\\)은 모든 \\(\\gamma\\in\\mathbb{R}\\)에 대해 복소수 평면의 단위 원(unit circle)에 있다. 또한 주기성(periodicity)으로 인해 \\(\\gamma\\in[0,2\\pi)\\)을 고려하기에 충분하다.\n실제로 \\(\\gamma\\)는 복소수 \\(c = \\mathrm{exp}(i\\gamma)\\)의 각도(라디안 단위)를 인코딩한다.(\\(|c|=1\\))\n다음 그림은 각도 \\(\\gamma\\)를 \\(0\\)에서 \\(2\\pi\\)로 증가시킬 때 값 \\(\\mathrm{exp}(i\\gamma)\\)이 어떻게 변하는지 보여준다.\n\n\nfrom matplotlib import ticker \n%matplotlib inline\n\ncmap = plt.cm.get_cmap('hsv') # hsv is nice because it is a circular color map\n\nN = 64\n\nfig = plt.figure(figsize=(5 * 3, 5))\nax1 = fig.add_subplot(1, 3, 1, projection='polar')\nax2 = fig.add_subplot(1, 3, 2)\nax3 = fig.add_subplot(1, 3, 3)\n\nfor i in range(N):\n    gamma = 2 * np.pi * i / N\n    c = np.exp(1j * gamma)\n    color = cmap(i / N)\n    ax1.plot([0, np.angle(c)], [0, np.abs(c)], color=color)\n    ax1.plot(np.angle(c), np.abs(c), 'o', color=color)\n    ax2.plot(gamma, np.real(c), 'o', color=color)\n    ax3.plot(gamma, np.imag(c), 'o', color=color)\n    \nax2.grid()\nax2.set_xlabel('$\\gamma$ [radians]')\nax2.set_ylabel('$\\mathrm{Re}(\\exp(i \\gamma))$')\nax2.xaxis.set_major_formatter(ticker.FormatStrFormatter('$%s$')) \n\nax3.grid()\nax3.set_xlabel('$\\gamma$ [radians]')\nax3.set_ylabel('$\\mathrm{Im}(\\exp(i \\gamma))$')\nax3.xaxis.set_major_formatter(ticker.FormatStrFormatter('$%s$')) \nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#의-거듭제곱근-roots-of-unity",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#의-거듭제곱근-roots-of-unity",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "1의 거듭제곱근 (Roots of Unity)",
    "text": "1의 거듭제곱근 (Roots of Unity)\n\n\\(N \\in \\mathbb{N}_{>0}\\)를 양의 정수라고 하자. 복소수 \\(\\rho \\in \\mathbb{C}\\)는 \\(\\rho^N = 1\\)인 경우 \\(N^\\mathrm{th}\\) 1의 거듭제곱근(root of unity)라고 한다. 다시말해 1의 거듭제곱근은 거듭제곱하여 1이 되는 복소수이다. 정확히 \\(N\\)개의 뚜렷한 \\(N^\\mathrm{th}\\) root of unity가 있다는 것을 보이는 것은 어렵지 않다.\n또한, 모든 \\(n\\in [1:N-1]\\)에 대해 \\(\\rho^n \\neq 1\\)인 경우, 단위 n승근(primitive \\(N^\\mathrm{th}\\) root of unity)라고 한다.\n위에서 언급한 속성을 통해 \\(\\rho_N:=\\exp(2 \\pi i / N)\\) 이 단위 n승근임을 쉽게 알 수 있다.\n모든 \\(N^\\mathrm{th}\\) root of unity는 \\(\\rho_N\\)의 power을 고려하여 생성될 수 있다.:\n\n\\[1=\\rho_N^0, \\quad \\rho_N^1, \\quad \\rho_N^2, \\quad ...,\\quad \\rho_N^{N-1}\\]\n\n다음 그림은 서로 다른 정수 \\(N \\in \\mathbb{N}_{>0}\\)에 대한 모든 root of unity를 보여준다. primitive root는 빨간색으로 표시되어 있다.\n\n\ndef plot_root_unity(N, figsize=(5, 5)): \n    root_unity = np.exp(2j * np.pi / N)\n    root_unity_power = 1\n\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.grid()  \n    plt.xlim([-1.4, 1.4])\n    plt.ylim([-1.4, 1.4])\n    plt.xlabel('$\\mathrm{Re}$')\n    plt.ylabel('$\\mathrm{Im}$')\n    plt.title('Roots of unity for $N=%d$'%N)\n\n    for n in range(0, N):\n        colorPlot = 'r' if gcd(n, N) == 1 else 'k'\n        plot_vector(root_unity_power, color=colorPlot)\n        plt.text(np.real(1.2*root_unity_power), np.imag(1.2*root_unity_power), \n                 r'$\\rho_{%s}^{%s}$' % (N, n), size='18', \n                 color=colorPlot, ha='center', va='center')\n        root_unity_power *= root_unity\n\n    circle_unit = plt.Circle((0, 0), 1, color='lightgray', fill=0)   \n    ax.add_artist(circle_unit)\n\n\nplot_root_unity(N=8)    \nplot_root_unity(N=11)\nplot_root_unity(N=12)\n\n\n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "",
    "text": "이산 푸리에 변환(DFT)과 그 기본 속성과 함께, DFT를 평가하는 효율적인 알고리즘인 고속 푸리에 변환(FFT)을 소개한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#내적-inner-product",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#내적-inner-product",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "내적 (Inner Product)",
    "text": "내적 (Inner Product)\n\n푸리에 변환(Fourier transform)을 이해하기 위한 중요한 개념으로 \\(N \\in \\mathbb{N}\\)에 대한 복소(complex) 벡터 공간 \\(\\mathbb{C}^N\\)에 대한 내적(inner product) 이 있다.\n두 개의 복소수 벡터 \\(x, y \\in \\mathbb{C}^N\\)가 주어지면, \\(x\\)와 \\(y\\) 사이의 내적은 다음과 같이 정의된다. \\[\\langle x | y \\rangle := \\sum_{n=0}^{N-1} x(n) \\overline{y(n)}.\\]\n내적의 절대값은 \\(x\\)와 \\(y\\) 사이의 유사성의 척도로 해석될 수 있다.\n\n\\(x\\)와 \\(y\\)가 동일한 방향을 가리키면(즉, \\(x\\)와 \\(y\\)가 유사함), 내적 \\(|\\langle x | y \\rangle|\\)이 크다.\n\\(x\\)와 \\(y\\)가 직교하면(즉, \\(x\\)와 \\(y\\)가 서로 다른 경우), 내적 \\(|\\langle x | y \\rangle|\\)는 0이다.\n\n함수 np.vdot을 사용하여 내적을 계산할 때 첫 번째 인수에 대해 복소 켤레(complex conjugate)가 수행된다는 점에 유의하자.\n따라서, 위에서 정의된 \\(\\langle x | y \\rangle\\)를 계산하려면, np.vdot(y, x)를 사용해야 한다.\n\n\nx = np.array([ 1.0, 1j, 1.0 + 1.0j ])\ny = np.array([ 1.1, 1j, 0.9 + 1.1j ])\nprint('Vectors of high similarity:', np.abs(np.vdot(y, x)))\n\nx = np.array([ 1.0,   1j, 1.0 + 1j ])\ny = np.array([ 1.1, -1j, 0.1      ])\nprint('Vectors of low similarity:', np.abs(np.vdot(y, x)))\n\nVectors of high similarity: 4.104875150354758\nVectors of low similarity: 0.22360679774997913"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft의-정의",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft의-정의",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "DFT의 정의",
    "text": "DFT의 정의\n\n\\(x\\in \\mathbb{C}^N\\)을 길이가 \\(N\\in\\mathbb{N}\\)인 벡터라고 하자. 음악 신호의 맥락에서 \\(x\\)는 샘플 \\(x(0), x(1), ..., x(N-1)\\)가 있는 이산(discrete) 신호로 해석될 수 있다.\n이산 푸리에 변환(DFT)은 다음과 같이 정의된다. \\[ X(k) := \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N) \\] for \\(k \\in [0:N-1]\\).\n벡터 \\(X\\in\\mathbb{C}^N\\)는 시간 영역(time-domain) 신호 \\(x\\)의 주파수 표현(frequency representation)으로 해석될 수 있다.\nDFT의 기하학적 해석을 얻기 위해 벡터 \\(\\mathbf{u}_k\\in\\mathbb{C}^N\\)를 다음과 같이 정의한다. \\[\\mathbf{u}_k(n) :=  \\exp(2 \\pi i k n / N) = \\cos(2 \\pi k n / N) + i \\sin(2 \\pi k n / N)\\] for \\(k \\in [0:N-1]\\).\n이 벡터는 주파수 \\(k/N\\)의 지수 함수의 샘플링된 버전으로 볼 수 있다. 그러면 DFT는 신호 \\(x\\) 및 샘플링된 지수 함수 \\(\\mathbf{u}_k\\)의 내적으로 표현될 수 있다. \\[ X(k) := \\sum_{n=0}^{N-1} x(n) \\overline{\\mathbf{u}_k} = \\langle x | \\mathbf{u}_k \\rangle\\]\n절대값 \\(|X(k)|\\)는 신호 \\(x\\)와 \\(\\mathbf{u}_k\\) 사이의 유사도를 나타낸다.\n\\(x\\in \\mathbb{R}^N\\)이 실수 값 벡터(음악 신호 시나리오의 경우, 항상 해당)인 경우 다음을 얻는다.\n\n\\[ X(k) := \\langle x |\\mathrm{Re}(\\mathbf{u}_k) \\rangle - i\\langle x | \\mathrm{Im}(\\mathbf{u}_k) \\rangle \\]\n\n다음 그림은 두 개의 서로 다른 주파수 파라미터 \\(k\\)에 대한 함수 \\(\\overline{\\mathbf{u}_k}\\)와 비교한 신호 \\(x\\)의 예를 보여준다.\n\n\\(\\overline{\\mathbf{u}_k}\\)의 실수부와 허수부는 각각  빨간색 및  파란색으로 표시된다.\n\n\n\nN = 64\nn = np.arange(N)\nk = 3\nx = np.cos(2 * np.pi * (k * n / N) + (1.2*np.random.rand(N) - 0.0))\n\nplt.figure(figsize=(6, 4))\n\nplt.subplot(2, 1, 1)\nplt.plot(n, x, 'k', marker='.', markersize='5', linewidth=2.0, label='$x$')\nplt.xlabel('Time (samples)')\nk = 3\nu_k_real = np.cos(2 * np.pi * k * n / N)\nu_k_imag = -np.sin(2 * np.pi * k * n / N)\nu_k = u_k_real + u_k_imag*1j\nsim_complex = np.vdot(u_k, x)\nsim_abs = np.abs(sim_complex)\nplt.title(r'Signal $x$ and some $u_k$ (k=3) having high similarity: Re($X(k)$) = %0.2f, Im($X(k)$) = %0.2f,  $|X(k)|$=%0.2f'%(sim_complex.real,sim_complex.imag,sim_abs))\nplt.plot(n, u_k_real, 'r', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Re}(\\overline{\\mathbf{u}}_k)$');\nplt.plot(n, u_k_imag, 'b', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Im}(\\overline{\\mathbf{u}}_k)$');\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(n, x, 'k', marker='.', markersize='5', linewidth=2.0, label='$x$')\nplt.xlabel('Time (samples)')\nk = 5\nu_k_real = np.cos(2 * np.pi * k * n / N)\nu_k_imag = -np.sin(2 * np.pi * k * n / N)\nu_k = u_k_real + u_k_imag*1j\nsim_complex = np.vdot(u_k, x)\nsim_abs = np.abs(sim_complex)\nplt.title(r'Signal $x$ and some $u_k$ (k=5) having low similarity: Re($X(k)$) = %0.2f, Im($X(k)$) = %0.2f,  $|X(k)|$=%0.2f'%(sim_complex.real,sim_complex.imag,sim_abs))\nplt.plot(n, u_k_real, 'r', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Re}(\\overline{\\mathbf{u}}_k)$');\nplt.plot(n, u_k_imag, 'b', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Im}(\\overline{\\mathbf{u}}_k)$');\nplt.legend()\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft-행렬-dft-matrix",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft-행렬-dft-matrix",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "DFT 행렬 (DFT Matrix)",
    "text": "DFT 행렬 (DFT Matrix)\n\n선형 연산자 \\(\\mathbb{C}^N \\to \\mathbb{C}^N\\)이면, DFT는 \\(N\\times N\\)-행렬로 표현할 수 있다. 이는 다음과 같은 유명한 DFT 행렬 \\(\\mathrm{DFT}_N \\in \\mathbb{C}^{N\\times N}\\) 행렬로 이어진다. \\[\\mathrm{DFT}_N(n, k) = \\mathrm{exp}(-2 \\pi i k n / N)\\] for \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\\(\\rho_N:=\\exp(2 \\pi i / N)\\)를 단위 N승근 (primitive Nth roots of unity)이라고 한다. 또한 단위 N승근을 다음과 같이 정의한다.\n\n\\(\\sigma_N:= \\overline{\\rho_N} = \\mathrm{exp}(-2 \\pi i / N)\\)\n\n지수 함수의 속성으로부터 다음을 얻을 수 있다.\n\n\\(\\sigma_N^{kn} = \\mathrm{exp}(-2 \\pi i / N)^{kn} = \\mathrm{exp}(-2 \\pi i k n / N)\\)\n\n이로부터 다음의 행렬을 얻는다. \\[\n\\mathrm{DFT}_N =\n\\begin{pmatrix}\n  1 & 1 & 1 & \\dots  & 1 \\\\\n  1 & \\sigma_N & \\sigma_N^2 & \\dots  & \\sigma_N^{N-1} \\\\\n  1 & \\sigma_N^2 & \\sigma_N^4 & \\dots  & \\sigma_N^{2(N-1)} \\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n  1 & \\sigma_N^{N-1} & \\sigma_N^{2(N-1)} & \\dots  & \\sigma_N^{(N-1)(N-1)} \\\\\n\\end{pmatrix}\n\\]\n다음 그림에서 \\(\\mathrm{DFT}_N\\)의 실수 및 허수 부분이 표시되며, 값은 적절한 색상으로 인코딩된다. \\(\\mathrm{DFT}_N\\)의 \\(k^\\mathrm{th}\\) 행은 위에 정의된 벡터 \\(\\mathbf{u}_k\\)에 해당한다.\n\n\ndef generate_matrix_dft(N, K):\n    \"\"\"Generates a DFT (discrete Fourier transfrom) matrix\n\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n\n    Returns:\n        dft (np.ndarray): The DFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(-2j * np.pi * k * n / N)\n    return dft\n\ndef dft(x):\n    \"\"\"Compute the disrcete Fourier transfrom (DFT)\n\n    Args:\n        x (np.ndarray): Signal to be transformed\n\n    Returns:\n        X (np.ndarray): Fourier transform of x\n    \"\"\"\n    x = x.astype(np.complex128)\n    N = len(x)\n    dft_mat = generate_matrix_dft(N, N)\n    return np.dot(dft_mat, x)\n\n\nN = 32\ndft_mat = generate_matrix_dft(N, N)\n\nplt.figure(figsize=(10, 3))\n\nplt.subplot(1, 2, 1)\nplt.title('$\\mathrm{Re}(\\mathrm{DFT}_N)$')\nplt.imshow(np.real(dft_mat), origin='lower', cmap='seismic', aspect='equal')\nplt.xlabel('Time index $n$')\nplt.ylabel('Frequency index $k$')\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\nplt.title('$\\mathrm{Im}(\\mathrm{DFT}_N)$')\nplt.imshow(np.imag(dft_mat), origin='lower', cmap='seismic', aspect='equal')\nplt.xlabel('Time index $n$')\nplt.ylabel('Frequency index $k$')\nplt.colorbar()\nplt.tight_layout()\n\n\n\n\n\nN = 128\nn = np.arange(N)\nk = 10\nx = np.cos(2 * np.pi * (k * n / N) + 2 * (np.random.rand(N) - 0.5)) \nX = dft(x)\n\nplt.figure(figsize=(8, 3))\n\nplt.subplot(1, 2, 1)\nplt.title('$x$')\nplt.plot(x)\nplt.xlabel('Time (index $n$)')\n\nplt.subplot(1, 2, 2)\nplt.title('$|X|$')\nplt.plot(np.abs(X))\nplt.xlabel('Frequency (index $k$)')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#계산-복잡성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#계산-복잡성",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "계산 복잡성",
    "text": "계산 복잡성\n\nFFT는 전체 작업 수를 \\(N^2\\)(일반적인 행렬-벡터 곱 \\(\\mathrm{DFT}_N \\cdot x\\)를 계산할 때 필요함)에서 \\(N\\log_2N\\) 정도로 줄인다. 예를 들어 \\(N=2^{10}=1024\\)를 사용하면 원래의 접근 방식의 \\(N^2=1048576\\) 작업 대신 FFT에 대략 \\(N\\log_2N=10240\\)가 필요하다.\nPython 코드의 작은 비트의 시간을 측정하는 간단한 방법을 제공하는 timeit 모듈을 사용하여 실행 시간을 비교한다.\n\n\nN = 512\nn = np.arange(N)\nx = np.sin(2 * np.pi * 5 * n / N )\n\nprint('Timing for DFT: ', end='')\n%timeit dft(x)\nprint('Timing for FFT: ', end='')\n%timeit fft(x)\n\nTiming for DFT: 284 ms ± 6.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\nTiming for FFT: 9.31 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nimport timeit\n\nNs = [2 ** n for n in range(5, 11)]\ntimes_dft = []\ntimes_fft = []\nexecuctions = 5\n\nfor N in Ns:\n    n = np.arange(N)\n    x = np.sin(2 * np.pi * 5 * n / N )\n    \n    time_dft = timeit.timeit(lambda: dft(x), number=execuctions) / execuctions\n    time_fft = timeit.timeit(lambda: fft(x), number=execuctions) / execuctions\n    times_dft.append(time_dft)\n    times_fft.append(time_fft)\n    \nplt.figure(figsize=(6, 3))\n    \nplt.plot(Ns, times_dft, '-xk', label='DFT')\nplt.plot(Ns, times_fft, '-xr', label='FFT')\nplt.xticks(Ns)\nplt.legend()\nplt.grid()\nplt.xlabel('$N$')\nplt.ylabel('Runtime (seconds)');\n\n\n\n\n\nFFT의 경우 계산이 훨씬 빠른 것을 볼 수 있다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#fft-예시",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#fft-예시",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "FFT 예시",
    "text": "FFT 예시\n\nlibrosa\n\n\nx, sr = librosa.load(\"../audio/c_strum.wav\")\nprint(x.shape)\nprint(sr)\nipd.Audio(x, rate=sr)\n\n(102400,)\n22050\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x)\nX_mag = np.absolute(X)\nf = np.linspace(0, sr, len(X_mag)) # frequency variable\n\n\nplt.figure(figsize=(6, 2))\nplt.plot(f, X_mag) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\nplt.show()\n\n\n\n\n\n# zoom in\nplt.figure(figsize=(6, 2))\nplt.plot(f[:5000], X_mag[:5000])\nplt.xlabel('Frequency (Hz)')\nplt.show()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#푸리에-계수의-극좌표-표현-polar-representation-of-fourier-coefficients",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#푸리에-계수의-극좌표-표현-polar-representation-of-fourier-coefficients",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "푸리에 계수의 극좌표 표현 (Polar Representation of Fourier Coefficients)",
    "text": "푸리에 계수의 극좌표 표현 (Polar Representation of Fourier Coefficients)\n\n\\(x=(x(0), x(1), ..., x(N-1))\\)을 샘플 \\(x(n)\\in\\mathbb{R}\\) for \\(n\\in[0:N-1]\\)을 가지는 시그널이라고 하자. 복소 푸리에 계수 \\(c_k:=X(k)\\in\\mathbb{C}\\) for \\(k\\in[0:N-1]\\)는 DFT에 계산되어 다음과 같다. \\[\nc_k :=X(k) = \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N).\n\\]\n\\(c_k = a_k + i b_k\\)를 실수부 \\(a_k\\in\\mathbb{R}\\)와 허수부 \\(b_k\\in\\mathbb{R}\\)로 구성된 복소수라고 할 때,\n절대값은 \\(|c_k| := \\sqrt{a_k^2 + b_k^2}\\)이고,\n각도(래디안 단위)는 \\(\\gamma_k := \\mathrm{angle}(c_k) := \\mathrm{atan2}(b_k, a_k) \\in [0,2\\pi)\\)이다.\n지수 함수를 쓰면, 다음의 극좌표 표현을 얻는다. \\[\n  c_k = |c_k| \\cdot \\mathrm{exp}(i \\gamma_k).\n\\]"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#최적화-optimality-속성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#최적화-optimality-속성",
    "title": "3.2. 이산 푸리에 변환 & 고속 푸리에 변환 (DFT & FFT)",
    "section": "최적화 Optimality 속성",
    "text": "최적화 Optimality 속성\n\n\\(\\mathbf{cos}_{k,\\varphi}:[0:N-1]\\to\\mathbb{R}\\)를 주파수 파라미터 \\(k\\) 및 위상 \\(\\varphi\\in[0 ,1)\\)와 함께 샘플 정현파(sinusoid)라고 하면 다음과 같이 정의된다. \\[\n  \\mathbf{cos}_{k,\\varphi}(n) = \\sqrt{2}\\mathrm{cos}\\big( 2\\pi (kn/N - \\varphi) \\big)\n\\] for \\(n\\in[0,N-1]\\)\n직관적으로 말하자면, 길이 \\(N\\)의 이산 신호 \\(x\\)와 주파수 파라미터 \\(k\\)에 대한 푸리에 변환을 계산할 때 신호 \\(x\\)와 정현파 \\(\\mathbf{cos}_{k,\\varphi_k}\\)의 내적(일종의 상관 관계)을 계산한다.\n\\(\\varphi_k\\) 위상은 \\(\\varphi\\in[0,1)\\)로 \\(x\\)와 모든 가능한 정현파 \\(\\mathbf{cos}_{k,\\varphi}\\) 사이의 상관관계를 최대화한다는 속성을 가지고 있다.\n\n\\[\n      \\varphi_k = \\mathrm{argmax}_{\\varphi\\in[0,1)} \\langle x | \\mathbf{cos}_{k,\\varphi} \\rangle.\n\\]\n\n복소 푸리에 계수 \\(X(k)\\)는 기본적으로 복소수의 각도로 주어지는 이 최적 위상을 인코딩한다. 보다 정확하게 \\(\\gamma_k\\)를 \\(X(k)\\)의 각도라고 하면, 최적 위상 \\(\\varphi_k\\)가 다음과 같이 주어진다는 것을 알 수 있다.\n\n\\[\n       \\varphi_k := - \\frac{\\gamma_k}{2 \\pi}.\n\\]\n\n# Generate a chirp-like test signal (details not important)\nN = 256\nt_index = np.arange(N)\nx = 1.8 * np.cos(2 * np.pi * (3 * (t_index * (1 + t_index / (4 * N))) / N))\n\nk = 4\nexponential = np.exp(-2 * np.pi * 1j * k * t_index / N)\nX_k = np.sum(x * exponential)\nphase_k = - np.angle(X_k) / (2 * np.pi)\n\ndef compute_plot_correlation(x, N, k, phase):\n    sinusoid = np.cos(2 * np.pi * (k * t_index / N - phase)) \n    d_k = np.sum(x * sinusoid)\n    plt.figure(figsize=(6,1.5))\n    plt.plot(t_index, x, 'k')\n    plt.plot(sinusoid, 'r')\n    plt.title('Phase = %0.2f; correlation = %0.2f (optimal  = %0.2f)' % (phase, d_k, np.abs(X_k)))\n    plt.tight_layout()\n    plt.show()\n\nprint('Sinusoid with phase from Fourier coefficient resulting in an optimal correlation.')    \ncompute_plot_correlation(x, N, k, phase=phase_k)\n\nprint('Sinusoid with an arbitrary phase resulting in a medium correlation.')  \ncompute_plot_correlation(x, N, k, phase=0.4)\n\nprint('Sinusoid with a phase that yields a correlation close to zero.')  \ncompute_plot_correlation(x, N, k, phase=0.51)\n\nSinusoid with phase from Fourier coefficient resulting in an optimal correlation.\n\n\n\n\n\nSinusoid with an arbitrary phase resulting in a medium correlation.\n\n\n\n\n\nSinusoid with a phase that yields a correlation close to zero.\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "",
    "text": "단기 푸리에 변환(STFT)를 소개하고, 이와 관련된 윈도우(window), 스펙트로그램(spectrogram), 패딩(padding) 전략 등을 살펴본다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#missing-time-localization",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#missing-time-localization",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "“Missing Time Localization”",
    "text": "“Missing Time Localization”\n\n기존 푸리에 변환은 전체 시간 영역에서 평균화되는 주파수 정보를 생성한다. 그러나 이러한 주파수가 언제 벌생하는지에 대한 정보는 변환에 숨겨져 있다. 이 현상은 다음 그림을 보면 알 수 있다.\n\n\nFs = 128\nduration = 10\nomega1 = 1\nomega2 = 5\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * omega1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * omega2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(8, 2))\nplt.subplot(1, 2, 1)\nplt.plot(t, x)\nplt.xlim([min(t), max(t)])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(1, 2, 2)\nX = np.abs(np.fft.fft(x)) / Fs\nfreq = np.fft.fftfreq(N, d=1/Fs)\nX = X[:N//2]\nfreq = freq[:N//2]\nplt.plot(freq, X)\nplt.xlim([0, 7])\nplt.ylim([0, 3])\nplt.xlabel('Frequency (Hz)')\nplt.tight_layout()\n\n\n\n\n\nImage(\"../img/3.fourier_analysis/f.2.6.PNG\", width=600)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#기본-개념",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#기본-개념",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "기본 개념",
    "text": "기본 개념\n\n숨겨진 시간 정보를 복구하기 위해 Dennis Gabor는 1946년에 단시간 푸리에 변환(STFT)을 도입했다.\n전체 신호를 고려하는 대신 STFT는 신호의 작은 부분만 고려한다. 이를 위해 짧은 시간 동안의 non-zero 함수, 소위 윈도우 함수(window function)를 고정한다. 그런 다음 원래 신호에 윈도우 함수를 곱하여 윈도우(windowed) 신호를 생성한다.\n서로 다른 시간 인스턴스에서 주파수 정보를 얻으려면 시간에 따라 윈도우 함수를 이동하고, 각 결과 윈도우 신호에 대해 푸리에 변환을 계산해야 한다.\n\n\ndef windowed_ft(t, x, Fs, w_pos_sec, w_len):\n    N = len(x)\n    w_pos = int(Fs * w_pos_sec)\n    w_padded = np.zeros(N)\n    w_padded[w_pos:w_pos + w_len] = 1\n    x = x * w_padded\n    \n    X = np.abs(np.fft.fft(x)) / Fs\n    freq = np.fft.fftfreq(N, d=1/Fs)\n    X = X[:N//2]\n    freq = freq[:N//2]\n    \n    plt.figure(figsize=(8, 2))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(t, x, c='k')\n    plt.plot(t, w_padded, c='r')\n    plt.xlim([min(t), max(t)])\n    plt.ylim([-1.1, 1.1])\n    plt.xlabel('Time (seconds)')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(freq, X, c='k')\n    plt.xlim([0, 7])\n    plt.ylim([0, 3])\n    plt.xlabel('Frequency (Hz)')\n    plt.tight_layout()\n    \nprint('서로다른 window 변화에 대한 실험:')\n\nw_len = 4 * Fs\nwindowed_ft(t, x, Fs, w_pos_sec=1, w_len=w_len) # 윈도우 신호 t=1 중심\nwindowed_ft(t, x, Fs, w_pos_sec=3, w_len=w_len) # t=3\nwindowed_ft(t, x, Fs, w_pos_sec=5, w_len=w_len) # t=5\nplt.show()\n\n서로다른 window 변화에 대한 실험:"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#윈도우window",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#윈도우window",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "윈도우(window)",
    "text": "윈도우(window)\n\nSTFT는 원래 신호의 속성뿐만 아니라 윈도우 함수의 속성도 반영한다는 점에 유의해야 한다.\n우선 STFT는 섹션의 크기를 결정하는 윈도우의 길이에 따라 달라진다. 그리고 STFT는 윈도우 모양의 영향을 받는다. 예를 들어 직사각형 윈도우를 사용하면 일반적으로 단면 경계에서 불연속성이 발생하기 때문에 큰 단점이 있다. 이러한 급격한 변화는 전체 주파수 스펙트럼에 걸쳐 전파되는 간섭으로 인해 부작용을 발생시킨다: ripple artifacts.\n\n윈도우 유형\n\n이러한 경계 효과를 줄이기 위해 원하는 섹션 내에서 섹션의 경계를 향해 연속적으로 0으로 떨어지는 음이 아닌 윈도우를 사용한다. 그러한 예 중 하나는 훨씬 더 작은 ripple artifact를 초래하는 삼각형 윈도우(triangular winow) 이다.\n신호 처리에 자주 사용되는 윈도우는 Hann 윈도우(기상학자 Julius von Hann의 이름을 따서 명명됨, 1839~1921)이다. Hann 윈도우는 상승하는 코사인 윈도우로, 섹션 경계에서 스무스(smoothly)하게 0으로 떨어진다. 이는 윈도우 신호의 푸리에 변환에서 부작용을 완화한다. 그러나 단점은 Hann 윈도우가 약간의 주파수 번짐을 유발한다는 것이다.\n결과적으로 신호의 윈도우 영역의 푸리에 변환은 신호의 속성이 제안하는 것보다 더 스무스해 보일 수 있다. 즉, ripple artifact의 감소는 더 안좋은 spectral localization을 통해 달성된다 (trade-off 관계).\n\n\ndef windowed_ft2(t, x, Fs, w_pos_sec, w_len, w_type, upper_y=1.0):\n    \n    N = len(x)\n    w_pos = int(Fs * w_pos_sec)\n    w = np.zeros(N)\n    w[w_pos:w_pos + w_len] = scipy.signal.get_window(w_type, w_len)\n    x = x * w\n    \n    plt.figure(figsize=(8, 2))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(t, x, c='k')\n    plt.plot(t, w, c='r')\n    plt.xlim([min(t), max(t)])\n    plt.ylim([-1.1, 1.1])\n    plt.xlabel('Time (seconds)')\n\n    plt.subplot(1, 2, 2)\n    X = np.abs(np.fft.fft(x)) / N * 2\n    freq = np.fft.fftfreq(N, d=1/Fs)\n    X = X[:N//2]\n    freq = freq[:N//2]\n    plt.plot(freq, X, c='k')\n    plt.xlim([0, 50])\n    plt.ylim([0, upper_y])\n    plt.xlabel('Frequency (Hz)')\n    plt.tight_layout()\n    plt.show()\n\n\nduration = 2.0\nFs = 2000\nomega = 10\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nx = 0.9 * np.sin(2 * np.pi * omega * t * t)\n\nplt.figure(figsize=(8, 2))\n\nplt.subplot(1, 2, 1)\nplt.plot(t, x, c='k')\nplt.xlim([t[0], t[-1]])\nplt.ylim([-1.1, 1.1])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(1, 2, 2)\nX = np.abs(np.fft.fft(x)) / N * 2\nfreq = np.fft.fftfreq(N, d=1/Fs)\nX = X[:N//2]\nfreq = freq[:N//2]\nplt.plot(freq, X, c='k')\nplt.xlim([0, 50])\nplt.ylim(bottom=0)\nplt.xlabel('Frequency (Hz)');\nplt.tight_layout()\n\n\n\n\n\nw_len = 1024\nw_pos = 1280\nprint('Rectangular window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'boxcar', upper_y=0.15)\nprint('Triangular window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'triang', upper_y=0.15)\nprint('Hann window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'hann', upper_y=0.15)\n\nRectangular window:\n\n\n\n\n\nTriangular window:\n\n\n\n\n\nHann window:"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#discrete-stft의-정의",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#discrete-stft의-정의",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "Discrete-STFT의 정의",
    "text": "Discrete-STFT의 정의\n\n이제 STFT의 이산적 사례를 고려하고 실제 적용에 필요한 가장 중요한 수학 공식을 구체화해보자.\n\\(x:[0:L-1]:=\\{0,1,\\ldots,L-1\\}\\to{\\mathbb R}\\)가 길이 \\(L\\)의 실수 값 이산 시간(DT) 신호라고 가정하자. 이는 헤르츠(Hertz)로 주어진 고정 샘플링 비율 \\(F_\\mathrm{s}\\)에 대해 등거리(equidistant) 샘플링에 의해 얻어진다.\n\\(w:[0:N-1]\\to\\mathbb{R}\\)를 길이 \\(N\\in\\mathbb{N}\\)의 표본 윈도우 함수라고 하자. 예를 들어 직사각형 윈도우의 경우 \\(w(n)=1\\) for \\(n\\in[0:N-1]\\)이다. 길이 파라미터 \\(N\\)는 해당 섹션의 기간을 결정하며 이는 \\(N/F_\\mathrm{s}\\)초에 해당된다.\n홉 크기(hop size)라고 하는 추가 파라미터 \\(H\\in\\mathbb{N}\\)를 도입한다. 홉 크기 파라미터는 샘플에 지정되며 신호에서 윈도우가 이동하는 단계 크기(step size)를 결정한다. 이러한 파라미터와 관련하여 신호 \\(x\\)의 이산 STFT \\(\\mathcal{X}\\)는 다음과 같다. \\[ \\mathcal{X}(m,k):= \\sum_{n=0}^{N-1} x(n+mH)w(n)\\mathrm{exp}(-2\\pi ikn/N) \\] with \\(m\\in[0:M]\\) and \\(k\\in[0:K]\\)\n\\(M:=\\lfloor \\frac{L-N}{H} \\rfloor\\)는 윈도우 시간 범위가 신호의 시간 범위에 완전히 포함되도록 하는 최대 프레임 인덱스(maximal frame index)이다(나중에 패딩(padding) 전략을 사용하는 일부 변형을 볼 것).\n또한 \\(K=N/2\\)(\\(N\\)이 짝수라고 가정)는 Nyquist 주파수에 해당하는 주파수 인덱스이다.\n복소수 $ (m,k)$는 \\(m^{\\mathrm{th}}\\) 시간 프레임에 대한 \\(k^{\\mathrm{th}}\\) 푸리에 계수를 나타낸다.\n각 고정 시간 프레임 \\(m\\)에 대해, 0에 대한 계수 \\(\\mathcal{X}(m,k)\\) for \\(k\\in[0:K]\\)에 의해 주어진 크기 \\(K+1\\)의 스펙트럼 벡터(spectral vector) 를 얻는다.\n이러한 각 스펙트럼 벡터의 계산은 \\(N\\) 크기의 DFT에 해당하며 FFT를 사용하여 효율적으로 수행될 수 있다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#시간-및-주파수-인덱스에-대한-해석",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#시간-및-주파수-인덱스에-대한-해석",
    "title": "3.3. 단기 푸리에 변환 (STFT) (1)",
    "section": "시간 및 주파수 인덱스에 대한 해석",
    "text": "시간 및 주파수 인덱스에 대한 해석\n\n시간 차원의 경우, 각 푸리에 계수 \\(\\mathcal{X}(m,k)\\)는 초 단위로 주어진 물리적 시간 위치와 연관된다. \\[\\begin{equation}\n       T_\\mathrm{coef}(m) := \\frac{m\\cdot H}{F_\\mathrm{s}}\n\\end{equation}\\]\n예를 들어 가능한 가장 작은 홉 크기 \\(H=1\\)의 경우 \\(T_\\mathrm{coef}(m)=m/F_\\mathrm{s}=m\\cdot T~\\sec\\)를 얻는다. 이 경우 DT 신호 \\(x\\)의 각 샘플에 대한 스펙트럼 벡터를 얻으므로 데이터 양이 크게 증가한다.\n또한, 하나의 샘플에 의해서만 이동된 섹션을 고려하면 일반적으로 매우 유사한 스펙트럼 벡터가 생성된다. 이러한 유형의 중복성을 줄이기 위해 일반적으로 홉 크기를 윈도우 길이 \\(N\\)에 연관시킨다. 예를 들어, \\(H=N/2\\)를 선택하는 경우가 많으며, 이는 생성된 모든 스펙트럼 계수를 포함하는 데이터 크기와 합리적인 시간의 분해 사이의 좋은 trade-off이다.\n주파수 차원의 경우 \\(\\mathcal{X}(m,k)\\)의 인덱스 \\(k\\)는 물리적 주파수에 해당된다.\n\n\\[\\begin{equation}\n         F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n\nT_coef = np.arange(X.shape[1]) * H / Fs\nF_coef = np.arange(X.shape[0]) * Fs / N\n\nplt.figure(figsize=(3, 4))\n\nplt.subplot(2, 1, 1)\nplt.plot(t, x, c='k')\nplt.xlim([min(t), max(t)])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(2, 1, 2)\nleft = min(T_coef)\nright = max(T_coef) + N / Fs\nlower = min(F_coef)\nupper = max(F_coef)\nplt.imshow(Y, origin='lower', aspect='auto', cmap='gray_r', \n           extent=[left, right, lower, upper])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "",
    "text": "단기 푸리에 변환(SFTF)의 변형을 다룬다. 주파수 그리드 밀도(density), 보간법(interpolation), 그리고 역(inverse) 푸리에 변환 등을 소개한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#dft-주파수-그리드",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#dft-주파수-그리드",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "DFT 주파수 그리드",
    "text": "DFT 주파수 그리드\n\n\\(x\\in \\mathbb{R}^N\\) 를 길이 \\(N\\in\\mathbb{N}\\)의 샘플 \\(x(0), x(1), \\ldots, x(N-1)\\)의 이산 신호라고 하자.\n샘플링 레이트 \\(F_\\mathrm{s}\\)가 주어졌을 때, \\(x\\)는 연속 시간 신호 \\(f:\\mathbb{R}\\to\\mathbb{R}\\)를 샘플링하여 얻는다고 가정한다.\n그러면 이산 푸리에 변환(DFT) \\(X := \\mathrm{DFT}_N \\cdot x\\)은 특정 주파수에 대한 연속 푸리에 변환 \\(\\hat{f}\\)의 근사치로 해석될 수 있다. \\[\nX(k) := \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N)\n\\approx {F_\\mathrm{s}} \\cdot \\hat{f} \\left(k \\cdot \\frac{F_\\mathrm{s}}{N}\\right)\n\\] for \\(k\\in[0:N-1]\\).\n따라서 \\(X(k)\\)의 인덱스 \\(k\\)는 다음의 물리적 주파수(헤르츠단위)에 해당된다. \\[\\begin{equation}\n       F_\\mathrm{coef}^N(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n즉, 이산 푸리에 변환은 \\(\\mathrm{DFT}_N\\)의 크기 \\(N\\)에 따라 달라지는, 해상도 \\(F_\\mathrm{s}/N\\)의 선형 주파수 그리드(frequency grid)를 얻는다.\n주파수 그리드의 밀도를 높이기 위한 한 가지 아이디어는 인위적으로 신호에 0을 추가하여 DFT의 크기를 늘리는 것이다.\n이를 위해 \\(L\\in\\mathbb{N}\\) with \\(L\\geq N\\)라고 하자. 그런 다음 \\(\\tilde{x}\\in \\mathbb{R}^L\\) 신호를 얻기 위해 \\(x\\) 신호 오른쪽에 제로 패딩(zero padding)을 적용한다.\n\n\\[\\tilde{x}(n) :=\\left\\{\\begin{array}{ll}\n    x(n) , \\,\\,\\mbox{for}\\,\\, n \\in[0:N-1]\\\\\n    0,     \\,\\,\\mbox{for}\\,\\, n \\in[N:L-1]\n\\end{array}\\right.\\]\n\n\\(\\mathrm{DFT}_L\\)을 적용하면 다음을 얻는다. \\[\n\\tilde{X}(k) = \\mathrm{DFT}_L \\cdot \\tilde{x}\n= \\sum_{n=0}^{L-1} \\tilde{x}(n) \\exp(-2 \\pi i k n / L)\n= \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / L)\n\\approx {F_\\mathrm{s}} \\cdot \\hat{f} \\left(k \\cdot \\frac{F_\\mathrm{s}}{L}\\right)\n\\] for \\(k\\in[0:L-1]\\).\n이제 계수 \\(\\tilde{X}(k)\\)는 다음의 물리적 주파수에 대응된다. \\[\\begin{equation}\n       F_\\mathrm{coef}^L(k) := \\frac{k\\cdot F_\\mathrm{s}}{L},\n\\end{equation}\\]\n이는 선형 주파수 해상도 \\(F_\\mathrm{s}/L\\)를 보인다.\n예를 들어, \\(L=2N\\)인 경우 주파수 그리드 해상도는 2배 증가한다. 즉, DFT가 길수록 간격이 더 가까운 주파수 빈(bin)이 더 많아진다.\n그러나 이 트릭은 DFT의 근사 품질을 개선하지 않는다는 점에 유의해야 한다(리만(Riemann) 근사의 합계 수는 여전히 \\(N\\)임에 유의하자).\n단, \\(L\\geq N\\) 및 제로 패딩을 사용할 때 주파수 축의 선형 샘플링이 정제(refine)된다.\n다음 예는 \\(\\mathrm{DFT}_N \\cdot x\\)를 \\(\\mathrm{DFT}_L \\cdot \\tilde{x}\\)와 비교한다.\n\n\nFs = 32\nduration = 2\nfreq1 = 5\nfreq2 = 15\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * freq1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * freq2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(8, 2))\n\nax1 = plt.subplot(1, 2, 1)\nplt.plot(x)\nplt.title('Orginal signal ($N$=%d)' % N)\nplt.xlabel('Time (samples)')\nplt.xlim([0, N - 1])\nplt.subplot(1, 2, 2)\nY = np.abs(np.fft.fft(x)) / Fs\nplt.plot(Y)\nplt.title('Magnitude DFT of original signal ($N$=%d)' % N)\nplt.xlabel('Frequency (bins)')\nplt.xlim([0, N - 1])\nplt.tight_layout()\n\nL = 2 * N\npad_len = L - N\nt_tilde = np.concatenate((t, np.arange(len(x), len(x) + pad_len) / Fs))\nx_tilde = np.concatenate((x, np.zeros(pad_len)))\n                         \nplt.figure(figsize=(8, 2))\nax1 = plt.subplot(1, 2, 1)\nplt.plot(x_tilde)\nplt.title('Padded signal ($L$=%d)' % L)\nplt.xlabel('Time (samples)')\nplt.xlim([0, L - 1])\nplt.subplot(1, 2, 2)\nY_tilde = np.abs(np.fft.fft(x_tilde)) / Fs\nplt.plot(Y_tilde)\nplt.title('Magnitude DFT of padded signal ($L$=%d)' % L)\nplt.xlabel('Frequency (bins)')\nplt.xlim([0, L - 1])\n\nplt.tight_layout()                       \n\n\n\n\n\n\n\n\n다음 코드 예제는 증가된 주파수 그리드 해상도로 DFT를 계산하는 함수를 구현한다.\n여기에서 모든 파라미터는 물리적 방식으로 해석된다(초 및 헤르츠 기준).\n\n\ndef compute_plot_DFT_extended(t, x, Fs, L):\n    N = len(x)\n    pad_len = L - N\n    t_tilde = np.concatenate((t, np.arange(len(x), len(x) + pad_len) / Fs))\n    x_tilde = np.concatenate((x, np.zeros(pad_len)))\n    Y = np.abs(np.fft.fft(x_tilde)) / Fs    \n    Y = Y[:L//2]\n    freq = np.arange(L//2)*Fs/L\n    # freq = np.fft.fftfreq(L, d=1/Fs)\n    # freq = freq[:L//2]\n    plt.figure(figsize=(10, 2))\n    \n    ax1 = plt.subplot(1, 3, 1)\n    plt.plot(t_tilde, x_tilde)\n    plt.title('Signal ($N$=%d)' % N)\n    plt.xlabel('Time (seconds)')\n    plt.xlim([t[0], t[-1]])\n    \n    ax2 = plt.subplot(1, 3, 2)\n    plt.plot(t_tilde, x_tilde)\n    plt.title('Padded signal (of size $L$=%d)' % L)\n    plt.xlabel('Time (seconds)')\n    plt.xlim([t_tilde[0], t_tilde[-1]])    \n    \n    ax3 = plt.subplot(1, 3, 3)\n    plt.plot(freq, Y)\n    plt.title('Magnitude DFT of padded signal ($L$=%d)' % L)\n    plt.xlabel('Frequency (Hz)')\n    plt.xlim([freq[0], freq[-1]])\n    plt.tight_layout()           \n\n    return ax1, ax2, ax3\n\n\nN = len(x)\n\nL = N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)\n\nL = 2 * N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)\n\nL = 4 * N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-그리드-해상도가-증가된-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-그리드-해상도가-증가된-stft",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "주파수 그리드 해상도가 증가된 STFT",
    "text": "주파수 그리드 해상도가 증가된 STFT\n\n이제 동일한 제로-패딩 전략을 사용하여 STFT의 주파수 그리드 해상도를 높이는 방법을 보자. librosa 함수 librosa.stft는 두 개의 파라미터 n_fft(\\(L\\)에 해당) 및 win_length(\\(N\\)에 해당)를 통해 이 아이디어를 구현한다. 파라미터를 물리적 도메인으로 변환할 때 주의해야 한다.\n바이올린이 연주하는 음 C4의 예를 보자\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\nt_wav = np.arange(0, x.shape[0]) * 1 / Fs\nplt.figure(figsize=(5, 1.5))\nplt.plot(t_wav, x, c='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)')\nplt.tight_layout()\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n이제 제로 패딩으로 STFT를 계산한다. 그림에서 축은 시간 프레임 및 주파수 빈으로 표시된다.\n\n\ndef compute_stft(x, Fs, N, H, L=N, pad_mode='constant', center=True):    \n    X = librosa.stft(x, n_fft=L, hop_length=H, win_length=N, \n                     window='hann', pad_mode=pad_mode, center=center)\n    Y = np.log(1 + 100 * np.abs(X) ** 2)\n    F_coef = librosa.fft_frequencies(sr=Fs, n_fft=L)\n    T_coef = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H) \n    return Y, F_coef, T_coef\n\ndef plot_compute_spectrogram(x, Fs, N, H, L, color='gray_r'):\n    Y, F_coef, T_coef = compute_stft(x, Fs, N, H, L)\n    plt.imshow(Y, cmap=color, aspect='auto', origin='lower')\n    plt.xlabel('Time (frames)')\n    plt.ylabel('Frequency (bins)')\n    plt.title('L=%d' % L)\n    plt.colorbar()\n\n\nN = 256\nH = 64\ncolor = 'gray_r' \nplt.figure(figsize=(8, 3))\n\nL = N\nplt.subplot(1,3,1)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nL = 2 * N\nplt.subplot(1,3,2)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nL = 4 * N\nplt.subplot(1,3,3)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nplt.tight_layout()\n\n\n\n\n\n다음으로 동일한 계산을 반복한다. 여기서 축은 이제 초와 헤르츠로 지정된 물리적 단위를 표시하도록 변환된다. 또한 시간-주파수 평면을 확대하여 밀도가 높은 주파수 그리드 밀도의 효과를 강조한다.\n\n\ndef plot_compute_spectrogram_physical(x, Fs, N, H, L, xlim, ylim, color='gray_r'):\n    Y, F_coef, T_coef = compute_stft(x, Fs, N, H, L)\n    extent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\n    plt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title('L=%d' % L)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.colorbar()\n\n\nxlim_sec = [1, 2]\nylim_hz = [2000, 3000]\n\nplt.figure(figsize=(8, 3))\n\nL = N\nplt.subplot(1,3,1)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nL = 2 * N\nplt.subplot(1,3,2)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nL = 4 * N\nplt.subplot(1,3,3)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nplt.tight_layout()\n\n\n\n\n\nlibrosa 함수 librosa.stft는 두 개의 파라미터 n_fft(패딩된 섹션의 크기 \\(L\\)에 해당) 및 win_length(\\(N\\)에 해당, 윈도우 부분)가 있다. 이 패딩 변형을 \\(L\\)(\\(N\\) 대신)와 함께 사용하면, 함수 \\(F_\\mathrm{coef}\\)의 계산을 다음과 같이 조정해야 한다. \\[\\begin{equation}\n       F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{L}\n\\end{equation}\\] for \\(k\\in [0:K]\\) with \\(K=L/2\\).\n반올림 문제를 방지하려면 짝수 \\(L\\)(아마도 2의 거듭제곱)를 선택하는 것이 좋다.\n\n\nN = 256\nL = 512\nH = 64\ncolor = 'gray_r' \n\nX = librosa.stft(x, n_fft=L, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True) # center에 대해서는 밑에서 다루기로 한다\nY = np.log(1 + 100 * np.abs(X) ** 2)\n\nT_coef = np.arange(0, X.shape[1]) * H / Fs\n\nK = L // 2\nF_coef = np.arange(K + 1) * Fs / L # 공식에 따라\nF_coef_librosa = librosa.fft_frequencies(sr=Fs, n_fft=L) # librosa 내장\nprint('F_coef 결과가 같은가:', np.allclose(F_coef, F_coef_librosa))\nprint('Y.shape = (%d,%d)'%(Y.shape[0],Y.shape[1]))\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\n\nF_coef 결과가 같은가: True\nY.shape = (257,1034)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#보간법-interpolation",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#보간법-interpolation",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "보간법 (Interpolation)",
    "text": "보간법 (Interpolation)\n\n데이터 포인트 시퀀스가 주어지면 보간법 interpolation의 목표는 의미 있는 방식으로 시퀀스를 정제(refine)하는 중간(intermediate) 데이터 포인트를 계산하는 것이다.\n보다 구체적으로, 파라미터 \\(t\\in\\mathbb{R}\\)를 \\(f(t)\\in\\mathbb{R}\\)로 매핑하는 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\) 함수를 고려해보자.\n\\(n\\in\\mathbb{Z}\\)에 대한 파라미터 \\(t_n\\in\\mathbb{R}\\)의 이산 집합에 대해서만 \\(f(t_n)\\) 값이 있다고 가정하자. \\(t_{n} > t_ {n-1}\\).\n그런 다음 보간법의 목표는 \\(f^\\ast(t)\\) 값을 추정하는 것이다. \\(f(t_n)\\)는 다음과 같이 주어진다.\n\n\\[f^\\ast(t) \\approx f(t)\\] for any \\(t\\in\\mathbb{R}\\)\n\n실제로는 \\(f\\) 함수는 알 수 없지만, 종종 \\(f\\)의 연속성, 평활성, 미분 가능성 등과 같은 특정 속성을 가정한다.\n가장 간단한 보간법 방법은 조각 상수 보간(piecewise constant interpolation)(또는 최근접 이웃(nearest neighbor) 보간법)이다. 파라미터 \\(t\\in\\mathbb{R}\\)가 주어지면, 가장 가까운 파라미터 \\(t_n\\)을 취하여 다음을 정의한다.\n\n\\(f^\\ast(t)=f(t_n).\\)\n\n\n\n# Simulates the original function\nt = np.arange(-0.5, 10.5, 0.01)\nf = np.sin(2 * t)\n\n# Known funcion values\nt_n = np.arange(0, 11)\nf_n = np.sin(2 * t_n)\n\n# Interpolation\nf_interpol_nearest = interp1d(t_n, f_n, kind='nearest', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_nearest, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Piecewise constant interpolation')\nplt.tight_layout()\n\n\n\n\n\n최근접 이웃 보간법은 일반적으로 이산 함수를 생성한다. 연속적인 보간법 함수를 얻기 위한 간단한 대안으로는 선형 보간법(linear interpolation)이 있다.\n\\(t_{n-1}\\)와 \\(t_n\\) 사이에 있는 파라미터 \\(t\\)가 주어지면, 다음과 같이 정의할 수 있다. \\[\nf^\\ast(t)=f(t_{n-1}) + (f(t_{n})-f(t_{n-1}))\\cdot\\frac{t-t_{n-1}}{t_{n} - t_{n-1}}.\n\\]\n\n\nf_interpol_linear = interp1d(t_n, f_n, kind='linear', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_linear, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Linear interpolation')\nplt.tight_layout()\n\n\n\n\n\nPython 클래스 scipy.inperploate.interp1d는 Nearest-neighbor, 선형 및 다양한 차수의 spline 보간을 포함하여 여러 종류의 보간 방법을 제공한다. 또 다른 예로, 3차 보간(3차 스플라인)에 대한 결과를 보자.\n\n\nf_interpol_cubic = interp1d(t_n, f_n, kind='cubic', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_cubic, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Cubic interpolation')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-보간법",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-보간법",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "주파수 보간법",
    "text": "주파수 보간법\n\n선형 주파수 그리드의 밀도를 증가시키기 위해 제로 패딩을 기반으로 더 큰 DFT를 사용할 수 있었다. 이제 주파수 영역에서 보간법을 적용하여 대안을 소개한다.\n\\(x\\in \\mathbb{R}^N\\)를 길이 \\(N\\in\\mathbb{N}\\), 샘플링 레이트 \\(F_\\mathrm{s}\\), DFT \\(X = \\mathrm{DFT} _N \\cdot x\\), 및 DFT 크기 \\(Y=|X|\\)의 이산 신호라고 하자. 그러면 \\(Y(k)\\)의 인덱스 \\(k\\)는 다음의 헤르츠로 주어진 물리적 주파수에 해당한다.\n\n\\[\\begin{equation}\n         F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n\n즉, 주파수 그리드 결과의 해상도는 \\(F_\\mathrm{s}/N\\)이다. 팩터 \\(\\rho\\in\\mathbb{N}\\)를 도입하여, 해상도 \\(F_\\mathrm{s}/(\\rho\\cdot N)\\)를 고려하여 주파수 그리드를 정제(refine)한다. 이 주파수 그리드를 기반으로 보간 기술을 사용하여 크기 주파수 계수(magnitude frequency coefficient)를 계산한다.\n\n\nFs = 32\nduration = 2\nomega1 = 5\nomega2 = 15\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * omega1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * omega2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(6, 2))\nplt.plot(t, x)\nplt.title('Orginal signal ($N$=%d)' % N)\nplt.xlabel('Time (seconds)')\nplt.xlim([t[0], t[-1]])   \nplt.tight_layout()\n\nY = np.abs(np.fft.fft(x)) / Fs\nY = Y[:N//2+1]\nF_coef = np.arange(N//2+1)*Fs/N\nplt.figure(figsize=(6, 2))\nplt.plot(F_coef,Y)\nplt.title('Magnitude DFT ($N$=%d)' % N)\nplt.xlabel('Frequency (Hz)')\nplt.xlim([F_coef[0], F_coef[-1]])     \nplt.tight_layout()\n\n\n\n\n\n\n\n\ndef interpolate_plot_DFT(N, Fs, F_coef, rho, int_method):\n    F_coef_interpol = np.arange(F_coef[0], F_coef[-1], Fs/(rho*N))\n    Y_interpol = interp1d(F_coef, Y, kind=int_method)(F_coef_interpol)\n    plt.figure(figsize=(6, 2))\n    plt.plot(F_coef_interpol, Y_interpol)\n    plt.title(r'Magnitude DFT (interpolation: %s, $\\rho$=%d)'%(int_method,rho))\n    plt.xlabel('Frequency (Hz)')\n    plt.xlim([F_coef[0], F_coef[-1]])\n    plt.tight_layout()\n\n\nrho = 4\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='nearest')\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='linear')\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='cubic')"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#stft를-위한-보간법",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#stft를-위한-보간법",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "STFT를 위한 보간법",
    "text": "STFT를 위한 보간법\n\nSTFT의 주파수 그리드를 정제하기 위해서 주파수 방향을 따라 보간법을 적용할 수 있다.\n이전과 같은 바이올린(C4)의 예로 보자.\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\nt_wav = np.arange(0, x.shape[0]) * 1 / Fs\nplt.figure(figsize=(6, 1))\nplt.plot(t_wav, x, c='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)');\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\ndef stft_convention_fmp(x, Fs, N, H, pad_mode='constant', center=True, mag=False, gamma=0):\n    \"\"\"Compute the discrete short-time Fourier transform (STFT)\n\n    Args:\n        x (np.ndarray): Signal to be transformed\n        Fs (scalar): Sampling rate\n        N (int): Window size\n        H (int): Hopsize\n        pad_mode (str): Padding strategy is used in librosa (Default value = 'constant')\n        center (bool): Centric view as used in librosa (Default value = True)\n        mag (bool): Computes magnitude STFT if mag==True (Default value = False)\n        gamma (float): Constant for logarithmic compression (only applied when mag==True) (Default value = 0)\n\n    Returns:\n        X (np.ndarray): Discrete (magnitude) short-time Fourier transform\n    \"\"\"\n    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N,\n                     window='hann', pad_mode=pad_mode, center=center)\n    if mag:\n        X = np.abs(X)**2\n        if gamma > 0:\n            X = np.log(1 + gamma * X)\n    F_coef = librosa.fft_frequencies(sr=Fs, n_fft=N)\n    T_coef = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H)\n    # T_coef = np.arange(X.shape[1]) * H/Fs\n    # F_coef = np.arange(N//2+1) * Fs/N\n    return X, T_coef, F_coef\n\n\ndef compute_f_coef_linear(N, Fs, rho=1):\n    \"\"\"Refines the frequency vector by factor of rho\n\n    Args:\n        N (int): Window size\n        Fs (scalar): Sampling rate\n        rho (int): Factor for refinement (Default value = 1)\n\n    Returns:\n        F_coef_new (np.ndarray): Refined frequency vector\n    \"\"\"\n    L = rho * N\n    F_coef_new = np.arange(0, L//2+1) * Fs / L\n    return F_coef_new\n\n\ndef interpolate_freq_stft(Y, F_coef, F_coef_new):\n    \"\"\"Interpolation of STFT along frequency axis\n\n    Args:\n        Y (np.ndarray): Magnitude STFT\n        F_coef (np.ndarray): Vector of frequency values\n        F_coef_new (np.ndarray): Vector of new frequency values\n\n    Returns:\n        Y_interpol (np.ndarray): Interploated magnitude STFT\n    \"\"\"\n    compute_Y_interpol = interp1d(F_coef, Y, kind='cubic', axis=0)\n    Y_interpol = compute_Y_interpol(F_coef_new)\n    return Y_interpol\n\n\ndef plot_compute_spectrogram_physical(x, Fs, N, H, xlim, ylim, rho=1, color='gray_r'):\n    Y, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H, mag=True, gamma=100)\n    F_coef_new = compute_f_coef_linear(N, Fs, rho=rho)\n    Y_interpol = interpolate_freq_stft(Y, F_coef, F_coef_new)    \n    extent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\n    plt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(r'$\\rho$=%d' % rho)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.colorbar()\n\n\nxlim_sec = [1, 2]\nylim_hz = [2000, 3000]\n\nN = 256\nH = 64\nplt.figure(figsize=(10, 4))\n \nplt.subplot(1, 3, 1)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=1)\n\nplt.subplot(1, 3, 2)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=2)\n\nplt.subplot(1, 3, 3)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=4)\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#로그-주파수-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#로그-주파수-stft",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "로그-주파수 STFT",
    "text": "로그-주파수 STFT\n\n이 보간법은 주파수 그리드의 비선형 변형에 사용될 수 있다. 예를 들어 선형 간격의 주파수 축(헤르츠로 측정)을 로그 간격의 주파수 축(피치 또는 센트로 측정)으로 변환할 수 있다.\n로그 간격의 주파수 그리드를 정의하는 것이 주요 단계이다. 이때 음정에 사용되는 대수 측정 단위인 센트라는 개념을 사용한다. 참조 주파수 \\(\\omega_0\\)가 주어지면 임의의 주파수 \\(\\omega\\)와 \\(\\omega_0\\) 사이의 거리는 다음과 같이 지정된다. \\[\n    \\log_2\\left(\\frac{\\omega}{\\omega_0}\\right)\\cdot 1200\n\\]\n다음 함수에서는 최소 주파수 값(매개변수 F_min이 기준 주파수 \\(\\omega_0\\)로 사용되므로 \\(0\\) cents에 해당함)에서 시작하여 로그 간격의 주파수 축을 계산한다.\n또한 이 함수에는 로그 해상도를 센트 단위로 지정하는 파라미터 R이 있다. 즉, 로그 주파수 축에서 두 개의 연속된 주파수 빈은 R 센트 떨어져 있다.\n최대 주파수는 다른 매개변수 F_max에 의해 지정된다.\n다음 예에서 주파수 F_min = 100(\\(0\\) 센트에 해당) 및 F_max = 3200(\\(6000\\) 센트에 해당)을 사용한다. 또한 해상도는 R=20(옥타브당 \\(60\\) 주파수 빈에 해당)으로 설정한다.\n\n\ndef compute_f_coef_log(R, F_min, F_max):\n    \"\"\"Adapts the frequency vector in a logarithmic fashion\n\n    Args:\n        R (scalar): Resolution (cents)\n        F_min (float): Minimum frequency\n        F_max (float): Maximum frequency (not included)\n\n    Returns:\n        F_coef_log (np.ndarray): Refined frequency vector with values given in Hz)\n        F_coef_cents (np.ndarray): Refined frequency vector with values given in cents.\n            Note: F_min serves as reference (0 cents)\n    \"\"\"\n    n_bins = np.ceil(1200 * np.log2(F_max / F_min) / R).astype(int)\n    F_coef_log = 2 ** (np.arange(0, n_bins) * R / 1200) * F_min\n    F_coef_cents = 1200 * np.log2(F_coef_log / F_min)\n    return F_coef_log, F_coef_cents\n\n\nN = 1024\nH = 256\nY, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H, mag=True, gamma=100)\n\nF_min = 100\nF_max = 3200\nR = 20\nF_coef_log, F_coef_cents = compute_f_coef_log(R, F_min, F_max)\n\nprint('#bins=%3d, F_coef[0]      =%6.2f, F_coef[1]      =%6.2f, F_coef[-1]      =%6.2f'%(len(F_coef),F_coef[0], F_coef[1], F_coef[-1]))\nprint('#bins=%3d, F_coef_log[0]  =%6.2f, F_coef_log[1]  =%6.2f, F_coef_log[-1]  =%6.2f'%(len(F_coef_log),F_coef_log[0], F_coef_log[1], F_coef_log[-1]))\nprint('#bins=%3d, F_coef_cents[0]=%6.2f, F_coef_cents[1]=%6.2f, F_coef_cents[-1]=%6.2f'%(len(F_coef_cents),F_coef_cents[0], F_coef_cents[1], F_coef_cents[-1]))\n\n#bins=513, F_coef[0]      =  0.00, F_coef[1]      = 21.53, F_coef[-1]      =11025.00\n#bins=300, F_coef_log[0]  =100.00, F_coef_log[1]  =101.16, F_coef_log[-1]  =3163.24\n#bins=300, F_coef_cents[0]=  0.00, F_coef_cents[1]= 20.00, F_coef_cents[-1]=5980.00\n\n\n\nY_interpol = interpolate_freq_stft(Y, F_coef, F_coef_log)\ncolor = 'gray_r' \n\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 3, 1)\nextent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_ticks_freq = np.array([100, 400, 800, 1200, 1600, 2000, 2400, 2800, 3200])\nplt.yticks(y_ticks_freq)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.title('Linear frequency axis')\nplt.ylim([F_min, F_max])\nplt.colorbar()\n\nplt.subplot(1, 3, 2)\nextent=[T_coef[0], T_coef[-1], F_coef_cents[0], F_coef_cents[-1]]\nplt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_tick_freq_cents = 1200 * np.log2(y_ticks_freq / F_min)\nplt.yticks(y_tick_freq_cents, y_ticks_freq)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.title('Log-frequency axis')\nplt.title('Log-frequency axis with R=%d' % R)\nplt.colorbar()\n\nplt.subplot(1, 3, 3)\nextent=[T_coef[0], T_coef[-1], F_coef_cents[0], F_coef_cents[-1]]\nplt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_ticks_cents = np.array([0, 1200, 2400, 3600, 4800, 6000])\nplt.yticks(y_ticks_cents)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (cents)')\nplt.title('Log-frequency axis')\nplt.title('Log-frequency axis with R=%d' % R)\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#샘플-신호에-대한-시간-축",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#샘플-신호에-대한-시간-축",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "샘플 신호에 대한 시간 축",
    "text": "샘플 신호에 대한 시간 축\n\n\\(x=(x(0),x(1), \\ldots x(L-1))^\\top \\in \\mathbb{R}^L\\)을 길이가 \\(L\\in\\mathbb{N}\\)인 이산-시간 신호라고 가정하자. 또한 \\(F_\\mathrm{s}\\)를 샘플 레이트라고 하자.\n그런 다음 물리적 시간 위치(초 단위로 표시)의 벡터 \\(t=(t(0),t(1), \\ldots t(L-1))^\\top \\in \\mathbb{R}^L\\)을 \\(x\\)에 대입하면 다음과 같이 정의된다. \\[\n   t(n) = \\frac{n}{F_\\mathrm{s}}\n\\] for \\(n\\in[0:L-1]\\)\n다시 말해,\n\n샘플 \\(x(0)\\)는 물리적 시간 \\(t(0)=0\\)(초 단위로 표시됨)와 연관된다.\n신호 \\(x\\)의 기간(duration)(초 단위)은 샘플 수를 샘플링 속도로 나눈 것이다: \\(L/F_\\mathrm{s}\\). 단, 이것은 \\(t(L-1)=(L-1)/F_\\mathrm{s}\\)와 동일하지 않다.\n두 샘플 \\(x(n-1)\\) 및 \\(x(n)\\) 사이의 거리(샘플링 기간 sampling period이라고 함)는 \\(1/F_\\mathrm{s}\\)이다.\n\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.Audio(x, rate=Fs)\nL = x.shape[0] #샘플 수\nt_wav = np.arange(L) / Fs\nx_duration = L / Fs #듀레이션\n\nprint('t[0] = %0.4f, t[-1] = (L-1)/Fs = %0.4f, Fs = %0.0f, L = %0.0f, dur_x=%0.4f'\n      % (t_wav[0], t_wav[-1], Fs, L, x_duration))\nipd.display(ipd.Audio(x, rate=Fs))\n\nplt.figure(figsize=(6, 2))\nplt.plot(t_wav, x, color='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)')\nplt.tight_layout()\n\nt[0] = 0.0000, t[-1] = (L-1)/Fs = 3.0000, Fs = 22050, L = 66150, dur_x=3.0000\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n# librosa를 이용한 plot\n# 단 librosa는 파형의 샘플이 아닌 symmetric amplitude envelope를 그림\n\nplt.figure(figsize=(6, 2))\nlibrosa.display.waveshow(x, color='gray')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#중심-윈도우잉과-시간-변환-centered-windowing-and-time-conversion",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#중심-윈도우잉과-시간-변환-centered-windowing-and-time-conversion",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "중심 윈도우잉과 시간 변환 (Centered Windowing and Time Conversion)",
    "text": "중심 윈도우잉과 시간 변환 (Centered Windowing and Time Conversion)\n\n신호의 윈도우 부분을 고려할 때 중앙 (centered) 시점을 채택한다. 여기서 윈도우의 중심이란 물리적 도메인과 관련된 참조로 사용된다.\n특히 STFT를 계산할 때, 윈도우 길이의 절반의 제로-패딩을 적용하여 신호를 왼쪽으로 확장한다.\n보다 정확히 말하면, \\(w:[0:N-1]\\to\\mathbb{R}\\)를 짝수 윈도우 길이 \\(N\\in\\mathbb{N}\\)의 윈도우 함수라고 하고 \\(H\\in\\mathbb{ N}\\)를 홉(hop) 크기라고 하자. 그리고 \\(N/2\\)개 0값을 앞에 넣는다.\n\n\\[\n\\tilde{x}=(0,\\ldots,0,x(0),x(1), \\ldots x(L-1))^\\top \\in \\mathbb{R}^{L+N/2}\n\\]\n\\[\n   \\mathcal{X}(m,k):= \\sum_{n=0}^{N-1} \\tilde{x}(n+mH)w(n)\\mathrm{exp}(-2\\pi ikn/N).\n\\]\n\n또한 프레임 인덱스 \\(m\\)이 물리적 시간 위치와 연관되어 있는 규칙을 사용한다.\n\n\\(T_\\mathrm{coef}(m) := \\frac{m\\cdot H}{F_\\mathrm{s}}\\)\n\n특히 다음이 성립한다.\n\n프레임 인덱스 \\(m=0\\)는 물리적 시간 \\(T_\\mathrm{coef}(0)=0\\)(초 단위)에 해당한다.\n시간 해상도(즉, 연속되는 두 프레임 사이의 거리)은 \\(\\Delta t = H/F_\\mathrm{s}\\)(초 단위)이다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-변환-frequency-conversion",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-변환-frequency-conversion",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "주파수 변환 (Frequency Conversion)",
    "text": "주파수 변환 (Frequency Conversion)\n\n\\(x\\) 및 \\(w\\)가 실수이면 주파수 계수의 상위 절반이 중복된다. 따라서 계수 \\(k\\in[0:K]\\) (\\(K=N/2\\))만 사용된다.\n특히 인덱스 \\(k=N/2\\)는 나이퀴스트(Nyquist) 주파수 \\(\\omega=F_\\mathrm{s}/2\\)에 해당한다.\n또한 인덱스 \\(k\\)는 다음의 주파수에 해당한다(헤르츠 단위).\n\n\\(F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\\)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#스펙트로그램-시각화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#스펙트로그램-시각화",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "스펙트로그램 시각화",
    "text": "스펙트로그램 시각화\n\n다음 코드는 이러한 규칙을 구현하기 위해 librosa 함수 librosa.stft를 사용하는 방법을 보여준다. 파라미터 설정 center=True는 centered view를 활성화하고 pad_mode='constant'는 제로-패딩 모드로 전환한다.\n또한 이 코드는 변환 함수 \\(T_\\mathrm{coef}\\) 및 \\(F_\\mathrm{coef}\\)를 한 번은 위의 공식을 사용하고 한 번은 librosa 내장 함수를 사용하여 구현하는 방법을 보여준다. 홀수 윈도우 크기 \\(N\\)의 경우 반올림에 대한 다른 규칙이 있을 수 있다. 실제로는 일반적으로 짝수 윈도우 크기를 사용한다(특히 FFT algorithm 관점에서 2의 거듭제곱임).\n\n\nN = 256\nH = 64\ncolor = 'gray_r' \n\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nY = np.log(1 + 100 * np.abs(X) ** 2)\n\nT_coef = np.arange(X.shape[1]) * H / Fs #위의 공식\nT_coef_librosa = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H) #librosa 내장\nprint('T_coef 계산 결과가 같은가:', np.allclose(T_coef, T_coef_librosa))\n\nK = N // 2\nF_coef = np.arange(K+1) * Fs / N #위의 공식\nF_coef_librosa = librosa.fft_frequencies(sr=Fs, n_fft=N) #librosa 내장\nprint('F_coef 계산 결과가 같은가:', np.allclose(F_coef, F_coef_librosa))\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\nplt.show()\n\nT_coef 계산 결과가 같은가: True\nF_coef 계산 결과가 같은가: True\n\n\n\n\n\n\n시각화에서 centered view를 채택하려면 프레임 길이의 절반만큼 왼쪽 및 오른쪽 여백을 조정하고, 빈(bin) 너비의 절반만큼 아래쪽 및 위쪽 여백을 조정해야 한다.\n그러나 큰 스펙트로그램의 경우 시각화의 이러한 작은 조정은 상관 없다.\n\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0] - (H / 2) / Fs, T_coef[-1] + (H / 2) / Fs,\n          F_coef[0] - (Fs / N) / 2, F_coef[-1] + (Fs / N) / 2]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlim([T_coef[0], T_coef[-1]])\nplt.ylim([F_coef[0], F_coef[-1]])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\n\n\n\n\n\n# librosa의 내장 함수로 결과를 비교하자\n\nplt.figure(figsize=(6, 3))\nlibrosa.display.specshow(Y, y_axis='linear', x_axis='time', sr=Fs, hop_length=H, cmap=color)\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-dft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-dft",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "역(Inverse) DFT",
    "text": "역(Inverse) DFT\n\n\\(N\\in\\mathbb{N}\\) 길이의 벡터 \\(x\\in \\mathbb{C}^N\\)가 주어지면 DFT은 행렬-벡터 곱으로 정의된다. \\[X = \\mathrm{DFT}_N \\cdot x\\]\n\nwith \\(\\mathrm{DFT}_N \\in \\mathbb{C}^{N\\times N}\\)\ngiven by \\(\\mathrm{DFT}_N(n, k) = \\mathrm{exp}(-2 \\pi i k n / N)\\)\nfor \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\nDFT는 벡터 \\(x\\)를 스펙트럼 벡터 \\(X\\)에서 복구할 수 있다는 점에서 invertible하다. 역 DFT는 행렬-벡터 곱으로 다시 지정된다. \\[ x = \\mathrm{DFT}_N^{-1} \\cdot X, \\]\n여기서 \\(\\mathrm{DFT}_N^{-1}\\)는 DFT 행렬 \\(\\mathrm{DFT}_N\\)의 역을 나타낸다.\n\n\\(\\mathrm{DFT}_N^{-1}(n, k) = \\frac{1}{N}\\mathrm{exp}(2 \\pi i k n / N)\\)\nfor \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\n즉, 역함수는 본질적으로 일부 정규화 인자(normalizing factor) 및 켤레 복소수(complex conjugation)까지 DFT 행렬과 일치한다.\n다음 코드 셀에서 DFT 행렬과 그 역행렬을 생성한다. 또한 두 행렬이 실제로 서로 역임을 보여준다.\n\n이를 위해 \\(\\mathrm{DFT}_N \\cdot \\mathrm{DFT}_N^{-1}\\)와 항등 행렬 \\(I_N\\in \\mathbb{R}^{N\\times N}\\)의 차이, 그리고 \\(\\mathrm{DFT}_N^{-1} \\cdot\\mathrm{DFT}_N\\)와 \\(I_N\\)의 차이를 측정한다.\n\n\n\ndef generate_matrix_dft(N, K):\n    \"\"\"Generates a DFT (discrete Fourier transfrom) matrix\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n    Returns:\n        dft (np.ndarray): The DFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(-2j * np.pi * k * n / N)\n    return dft\n\ndef generate_matrix_dft_inv(N, K):\n    \"\"\"Generates an IDFT (inverse discrete Fourier transfrom) matrix\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n    Returns:\n        dft (np.ndarray): The IDFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(2j * np.pi * k * n / N) / N\n    return dft\n\n\nN = 32\ndft_mat = generate_matrix_dft(N, N)\ndft_mat_inv = generate_matrix_dft_inv(N, N)\n\nI = np.eye(N)\nA =  np.dot(dft_mat, dft_mat_inv)\nB =  np.dot(dft_mat_inv, dft_mat)\n\nplt.figure(figsize=(11, 3))\n\nplt.subplot(1, 3, 1)\nplt.title(r'$I_N$ for $N = %d$'%N)\nplt.imshow(I, origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar()\n\nplt.subplot(1, 3, 2)\nplt.title(r'$|I_N - \\mathrm{DFT}_N \\cdot \\mathrm{DFT}_N^{-1}|$')\nplt.imshow(np.abs(I-A), origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar()\n\nplt.subplot(1, 3, 3)\nplt.title(r'$|I_N - \\mathrm{DFT}_N^{-1} \\cdot \\mathrm{DFT}_N|$')\nplt.imshow(np.abs(I-B), origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar();\n\nplt.tight_layout()\n\n\n\n\n\nDFT는 FFT 알고리즘을 사용하여 효율적으로 계산할 수 있다. 역 DFT 계산에도 적용할 수 있다. 다음에서는 numpy.fft.fft 및 numpy.fft.ifft를 사용해 구현한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-stft",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "역(Inverse) STFT",
    "text": "역(Inverse) STFT\n\n다음으로 이산 STFT을 inverting하는 법을 보자.\n\\(x:\\mathbb{Z}\\to\\mathbb{R}\\)를 이산-시간 신호라고 하고, \\(\\mathcal{X}\\)를 그것의 STFT라고 하자.\n또한 \\(w:[0:N-1]\\to\\mathbb{R}\\)를 길이 \\(N\\in\\mathbb{N}\\) 및 홉 크기 파라미터 \\(H\\in\\mathbb{N}\\)의 실수 값 이산 윈도우 함수를 나타낸다고 하자.\n표기상 편의를 위해 제로-패딩을 사용하여 윈도우 함수를 \\(w:\\mathbb{Z}\\to\\mathbb{R}\\)로 확장한다.\n\\(x_n:\\mathbb{Z}\\to\\mathbb{R}\\)를 다음에 의해 정의된 윈도우 신호라고 하자.\n\n\\(x_n(r):=x(r+nH)w(r)\\) for \\(r\\in\\mathbb{Z}\\).\n\n그러면 STFT 계수 \\(\\mathcal{X}(n,k)\\) for \\(k\\in[0:N-1]\\)가 다음에 의해 얻어진다.\n\n\\((\\mathcal{X}(n,0),\\ldots, \\mathcal{X}(n,N-1))^\\top = \\mathrm{DFT}_N \\cdot (x_n(0),\\ldots, x_n(N-1))^\\top.\\)\n\n\\(\\mathrm{DFT}_N\\)가 invertible 행렬이기 때문에 STFT에서의 윈도우 신호 \\(x_n\\)를 다음과 같이 재구성할 수 있다. \\[(x_n(0),\\ldots x_n(N-1))^\\top = \\mathrm{DFT}_N^{-1} \\cdot (\\mathcal{X}(n,0),\\ldots, \\mathcal{X}(n,N-1))^\\top\\]\n원래 신호의 샘플 \\(x(r)\\)을 얻으려면 윈도우 프로세스를 반대로 해야 한다. 이것은 윈도우 프로세스에서 상대적으로 약한 조건에서 가능하다는 것을 볼 수 있다. 신호의 윈도우 섹션의 적절하게 이동된 모든 버전에 대한 중첩(superposition)을 고려해 보자. \\[\\sum_{n\\in\\mathbb{Z}} x_n(r-nH)\n  = \\sum_{n\\in\\mathbb{Z}} x(r-nH+nH)w(r-nH)\n  = x(r)\\sum_{n\\in\\mathbb{Z}} w(r-nH)\\]\n따라서 샘플 \\(x(r)\\)를 다음을 통해 복구할 수 있다. \\[x(r) = \\frac{\\sum_{n\\in\\mathbb{Z}} x_n(r-nH)}{\\sum_{n\\in\\mathbb{Z}} w(r-nH)}\\]\n\n\\(\\sum_{n\\in\\mathbb{Z}} w(r-nH)\\not= 0\\)\n\n이 전반적인 접근 방식은 소위 overlap–add technique을 기반으로 한다. 이 기술에서는 겹치는 재구성된 윈도우 섹션이 단순히 오버레이되고 합산된다(그런 다음 windowing을 보상하기 위해 정규화됨)."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#단위-분할-partition-of-unity",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#단위-분할-partition-of-unity",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "단위 분할 (Partition of Unity)",
    "text": "단위 분할 (Partition of Unity)\n\n위의 조건을 만족하는 홉 크기와 함께 윈도우 함수를 찾는 것은 어렵지 않다. 예를 들어 윈도우 함수 \\(w:[0:N-1]\\to\\mathbb{R}\\)가 양수이고 홉 크기가 윈도우 길이보다 작거나 같을 때 time-shifted 윈도우에 대한 합계는 항상 양수이다.\n종종 윈도우 함수와 홉 크기를 다음의 더 강한 조건으로 선택할 수도 있다.\n\n\\(\\sum_{n\\in\\mathbb{Z}} w(r-nH) = 1\\) (for all \\(r\\in\\mathbb{Z}\\) is fulfilled.)\n\n이 경우, time-shifted 윈도우 함수는 이산 시간 축 \\(\\mathbb{Z}\\)의 단위 분할 (partition of unity)을 정의한다고 한다.\n예를 들어, 다음과 같이 정의된 윈도우 \\(w:\\mathbb{Z}\\to\\mathbb{R}\\)로 squared sinusoidal을 사용할 때 단위 분할을 얻는다.\n\n\\(w(r):= \\left\\{ \\begin{array}{cl}  \\sin(\\pi r/N)^2 \\quad \\mbox{if}\\,\\,\\, r\\in[0:N-1] \\\\  0 \\quad \\mbox{otherwise}  \\end{array} \\right.\\)\n홉 사이즈는 \\(H=N/2\\)\n\n단위 분할이 되는 속성은 윈도우 함수 자체뿐만 아니라 홉 크기 파라미터에도 의존한다는 점에 유의해야 한다.\n다음 그림은 \\(N\\) 길이의 다양한 윈도우 함수와 홉 크기 \\(H\\)를 사용하는 time-shifted 버전을 보여준다. time-shifted 버전의 합은 두꺼운 빨간색 곡선으로 표시된다.\n\n\ndef plot_sum_window(w, H, L, title='', figsize=(6, 2)):\n    N = len(w)\n    M = np.floor((L - N) / H).astype(int) + 1\n    w_sum = np.zeros(L)\n    plt.figure(figsize=figsize)\n    for m in range(M):\n        w_shifted = np.zeros(L)\n        w_shifted[m * H:m * H + N] = w\n        plt.plot(w_shifted, 'k')\n        w_sum = w_sum + w_shifted\n    plt.plot(w_sum, 'r', linewidth=3)\n    plt.xlim([0, L-1])\n    plt.ylim([0, 1.1*np.max(w_sum)])\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n    return w_sum\n\n\nL = 256\nN = 64\n\nH = N//2\nw_type = 'triang'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Triangular window, H = N/2');\n\nH = N//2\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Hann window, H = N/2');\n\nH = 3*N//8\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Hann window, H = 3N/8');\n\nH = N//4\nw = scipy.signal.gaussian(N, std=8)\nplot_sum_window(w, H, L, title='Gaussian window, H = N/4');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#구현",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#구현",
    "title": "3.4. 단기 푸리에 변환 (STFT) (2)",
    "section": "구현",
    "text": "구현\n\n역 DFT에서 작은 허수값을 피하기 위해 재구성된 윈도우 신호의 실수 부분만 유지하는게 이득일 수 있다.\n역 DFT를 적용한 후에는 윈도잉을 보상해야 한다. 프레임 기반 레벨에서(즉, 각 윈도우 섹션에 대해 개별적으로) 이 작업을 수행하는 것 보다는 모든 윈도우 신호와 이동된 모든 윈도우를 개별적으로 누적하여 전역적으로(globally) 보상을 수행해야 한다. 전역 보상이 가능한 이유는 DFT의 선형성에 있다. 또한 보상에서 0으로 나누기를 피해야 한다.\n주어진 홉 크기에 대해 이동된 윈도우가 단위 분할(a partition of unity)을 형성하는 경우, 보상을 수행할 필요가 없다.\nSTFT 계산에서 패딩이 적용된 경우 역 STFT 계산 시 이를 고려해야 한다.\n\n\ndef stft_basic(x, w, H=8, only_positive_frequencies=False):\n    \"\"\"Compute a basic version of the discrete short-time Fourier transform (STFT)\n    Args:\n        x (np.ndarray): Signal to be transformed\n        w (np.ndarray): Window function\n        H (int): Hopsize (Default value = 8)\n        only_positive_frequencies (bool): Return only positive frequency part of spectrum (non-invertible)\n            (Default value = False)\n    Returns:\n        X (np.ndarray): The discrete short-time Fourier transform\n    \"\"\"\n    N = len(w)\n    L = len(x)\n    M = np.floor((L - N) / H).astype(int) + 1\n    X = np.zeros((N, M), dtype='complex')\n    for m in range(M):\n        x_win = x[m * H:m * H + N] * w\n        X_win = np.fft.fft(x_win)\n        X[:, m] = X_win\n\n    if only_positive_frequencies:\n        K = 1 + N // 2\n        X = X[0:K, :]\n    return X\n\ndef istft_basic(X, w, H, L):\n    \"\"\"Compute the inverse of the basic discrete short-time Fourier transform (ISTFT)\n    Args:\n        X (np.ndarray): The discrete short-time Fourier transform\n        w (np.ndarray): Window function\n        H (int): Hopsize\n        L (int): Length of time signal\n    Returns:\n        x (np.ndarray): Time signal\n    \"\"\"\n    N = len(w)\n    M = X.shape[1]\n    x_win_sum = np.zeros(L)\n    w_sum = np.zeros(L)\n    for m in range(M):\n        x_win = np.fft.ifft(X[:, m])\n        # Avoid imaginary values (due to floating point arithmetic)\n        x_win = np.real(x_win)\n        x_win_sum[m * H:m * H + N] = x_win_sum[m * H:m * H + N] + x_win\n        w_shifted = np.zeros(L)\n        w_shifted[m * H:m * H + N] = w\n        w_sum = w_sum + w_shifted\n    # Avoid division by zero\n    w_sum[w_sum == 0] = np.finfo(np.float32).eps\n    x_rec = x_win_sum / w_sum\n    return x_rec, x_win_sum, w_sum\n\n\nL = 256\nt = np.arange(L) / L\nomega = 4\nx = np.sin(2 * np.pi * omega * t * t)\n\nN = 64\nH = 3 * N // 8\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nX = stft_basic(x, w=w, H=H)\nx_rec, x_win_sum, w_sum = istft_basic(X, w=w, H=H, L=L)\n\nplt.figure(figsize=(8, 3))\nplt.plot(x, color=[0, 0, 0], linewidth=4, label='Original signal')\nplt.plot(x_win_sum, 'b', label='Summed windowed signals')\nplt.plot(w_sum, 'r', label='Summed windows')\nplt.plot(x_rec, color=[0.8, 0.8, 0.8], linestyle=':', linewidth=4, label='Reconstructed signal')\nplt.xlim([0,L-1])\nplt.legend(loc='lower left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nlibrosa 예제\n\n단, librosa.istft에서는 다른 윈도우 보상 방법을 사용한다. \\[x(r) = \\frac{\\sum_{n\\in\\mathbb{Z}} w(r-nH)x_n(r-nH)}{\\sum_{n\\in\\mathbb{Z}} w(r-nH)^2}\\]\n\n\ndef print_plot(x, x_rec):\n    print('Number of samples of x:    ', x.shape[0])\n    print('Number of samples of x_rec:', x_rec.shape[0])\n    if x.shape[0] == x_rec.shape[0]:\n        print('Signals x and x_inv agree:', np.allclose(x, x_rec))\n        plt.figure(figsize=(6, 2))\n        plt.plot(x-x_rec, color='red')\n        plt.xlim([0, x.shape[0]])\n        plt.title('Differences between x and x_rec')\n        plt.xlabel('Time (samples)');\n        plt.tight_layout()\n        plt.show()\n    else:\n        print('Number of samples of x and x_rec does not agree.')\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")        \n        \nN = 4096\nH = 2048\nL = x.shape[0]\n\nprint('=== Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=True, length=L)\nprint('stft: center=True; istft: center=True')\nprint_plot(x, x_rec)\n\nprint('=== Non-Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=False)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=False, length=L)\nprint('stft: center=False; istft: center=False')\nprint_plot(x, x_rec)\n\nprint('=== Centered vs. Non-Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=False, length=L)\nprint('stft: center=True; istft: center=False')\nprint_plot(x, x_rec)\n\nplt.figure(figsize=(6, 2))\nplt.plot(x, color='black')\nplt.xlim([0, x.shape[0]])\nplt.plot(x_rec, color='gray')\nplt.title('Signal x (black) and x_rec (gray)')\nplt.xlabel('Time (samples)');\nplt.tight_layout()\nplt.show()\n\n=== Centered Case ===\nstft: center=True; istft: center=True\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: True\n\n\n\n\n\n=== Non-Centered Case ===\nstft: center=False; istft: center=False\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: False\n\n\n\n\n\n=== Centered vs. Non-Centered Case ===\nstft: center=True; istft: center=False\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: False\n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\nhttps://musicinformationretrieval.com/\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html",
    "title": "3.5. 디지털 신호",
    "section": "",
    "text": "오디오 신호(signal)의 디지털화에 필요한 샘플링(sampling)과 양자화(quantization)에 대해 소개하며, 또한 간섭(interference) 및 비팅(beating) 현상을 다룬다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링sampling",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링sampling",
    "title": "3.5. 디지털 신호",
    "section": "샘플링(Sampling)",
    "text": "샘플링(Sampling)\n\n신호 처리(signal processing)에서, 샘플링이란 연속 신호를 시간 축의 이산적 부분집합으로만 정의된 이산 신호로 축소시키는 것을 말한다.\n적절한 인코딩을 통해 이산 집합이 정수 집합 \\(\\mathbb{Z}\\)의 하위 집합 \\(I\\)라고 가정하고는 한다. 그런 다음 이산시간(discrete time, DT)-신호는 함수 \\(x\\colon I\\to\\mathbb{R}\\)로 정의되며 여기서 도메인 \\(I\\)는 시점에 해당한다.\n\\(\\mathbb{Z}\\setminus I\\)의 포인트에 대해 모든 값을 0으로 설정하는 것만으로 도메인 \\(I\\)에서 도메인 \\(\\mathbb{Z}\\)로 모든 DT 신호를 확장할 수 있으므로 \\(I=\\mathbb{Z}\\)를 가정할 수 있다.\n연속시간(continuous time, CT)-신호 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\)를 DT-신호 \\(x\\colon\\mathbb{Z}\\to\\mathbb{R}\\)로 변환하는 가장 일반적인 샘플링 절차는 등거리 샘플링(equidistant sampling)이라고 한다.\n양의 실수 \\(T>0\\)를 고정하면, DT-신호 \\(x\\)는 다음과 같이 설정하여 얻는다.\n\n\\(x(n):= f(n \\cdot T)\\) for \\(n\\in\\mathbb{Z}\\)\n\n\\(x(n)\\) 값은 원래 아날로그 신호 \\(f\\)의 시간 \\(t=n\\cdot T\\)에서 가져온 샘플이라고 한다. 간단히 말해서 이 절차를 \\(T\\)-샘플링 이라고도 한다.\n숫자 \\(T\\)는 샘플링 주기 (sampling period) 라고 하고 역(inverse) \\(F_\\mathrm{s}:=1/T\\)는 샘플링 레이트/속도 (sampling rate) 라고 한다. 샘플링 레이트는 초당 샘플 수를 지정하며 헤르츠(Hz) 단위로 측정된다.\n다음 코드 셀에서 높은 샘플링 속도로 샘플링된 DT-신호의 선형 보간법을 통해 정의된 CT-신호 \\(f\\)로 시작한다. 그림에서 이 CT-신호는 검은색 곡선으로 표시된다. 등거리 샘플링을 적용하여 빨간색 줄기 플롯으로 시각화된 DT 신호 \\(x\\)를 얻는다.\n\n\ndef generate_function(Fs, dur=1):\n    \"\"\"Generate example function\n    \n    Args:\n        Fs (scalar): Sampling rate\n        dur (float): Duration (in seconds) of signal to be generated (Default value = 1)\n        \n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(Fs * dur)\n    t = np.arange(N) / Fs\n    x = 1 * np.sin(2 * np.pi * (2 * t - 0))\n    x += 0.5 * np.sin(2 * np.pi * (6 * t - 0.1))\n    x += 0.1 * np.sin(2 * np.pi * (20 * t - 0.2))\n    return x, t\n\n\ndef sampling_equidistant(x_1, t_1, Fs_2, dur=None):\n    \"\"\"Equidistant sampling of interpolated signal\n\n    Args:\n        x_1 (np.ndarray): Signal to be interpolated and sampled\n        t_1 (np.ndarray): Time axis (in seconds) of x_1\n        Fs_2 (scalar): Sampling rate used for equidistant sampling\n        dur (float): Duration (in seconds) of sampled signal (Default value = None)\n        \n    Returns:\n        x (np.ndarray): Sampled signal\n        t (np.ndarray): Time axis (in seconds) of sampled signal\n    \"\"\"\n    if dur is None:\n        dur = len(t_1) * t_1[1]\n    N = int(Fs_2 * dur)\n    t_2 = np.arange(N) / Fs_2\n    x_2 = interp1d(t_1, x_1, kind='linear', fill_value='extrapolate')(t_2)\n    return x_2, t_2\n\n\nFs_1 = 100\nx_1, t_1 = generate_function(Fs=Fs_1, dur=2)\n\nFs_2 = 20\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\n    \nplt.figure(figsize=(6, 2))\nplt.plot(t_1, x_1, 'k')\nplt.title('Original CT-signal')\nplt.xlabel('Time (seconds)')\nplt.ylim([-1.5, 1.5])\nplt.xlim([t_1[0], t_1[-1]])\nplt.tight_layout()\n\nplt.figure(figsize=(6, 2))\nplt.stem(t_2, x_2, linefmt='r', markerfmt='ro', basefmt='None')\nplt.plot(t_1, x_1, 'k', linewidth=1, linestyle='dotted')\nplt.title(r'Sampling rate $F_\\mathrm{s} = %.0f$'%Fs_2)\nplt.xlabel('Time (seconds)')\nplt.ylim([-1.5, 1.5])\nplt.xlim([t_1[0], t_1[-1]])\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#에일리어싱-aliasing",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#에일리어싱-aliasing",
    "title": "3.5. 디지털 신호",
    "section": "에일리어싱 (Aliasing)",
    "text": "에일리어싱 (Aliasing)\n또는 위신호현상\n\n일반적으로 샘플링은 처리 과정에서 정보가 손실되고 원본 CT-신호를 샘플링된 버전으로부터 복구할 수 없다는 점에서 손실적인(lossy) 작업이다.\nCT-신호에 주파수 스펙트럼 측면(대역 제한(bandlimited) 필요)에서 추가 속성이 있는 경우에만 완벽한 재구성이 가능하다. 이것이 유명한 샘플링 정리(sampling theorem)의 주장이다. 샘플링 이론은 또한 DT-신호의 샘플에 의해 가중된 적절하게 이동된 \\(\\mathrm{sinc}\\)-함수를 중첩하여 원래 CT-신호가 어떻게 재구성될 수 있는지 보여준다.\n추가적인 속성이 없다면 샘플링으로 인해 신호의 특정 주파수 구성 요소를 구분할 수 없게 되는 에일리어싱(aliasing)이라는 현상이 발생할 수 있다.\n이 효과는 다음 그림에 설명되어 있다. 높은 샘플링 속도를 사용하면 원본 CT-신호를 높은 정확도로 재구성할 수 있다. 그러나 샘플링 속도를 낮추면 더 높은 주파수 구성 요소가 잘 캡처되지 않고 원래 신호의 대략적인 근사치만 남는다.\n\n\ndef reconstruction_sinc(x, t, t_sinc):\n    \"\"\"Reconstruction from sampled signal using sinc-functions\n\n    Args:\n        x (np.ndarray): Sampled signal\n        t (np.ndarray): Equidistant discrete time axis (in seconds) of x\n        t_sinc (np.ndarray): Equidistant discrete time axis (in seconds) of signal to be reconstructed\n\n    Returns:\n        x_sinc (np.ndarray): Reconstructed signal having time axis t_sinc\n    \"\"\"\n    Fs = 1 / t[1]\n    x_sinc = np.zeros(len(t_sinc))\n    for n in range(0, len(t)):\n        x_sinc += x[n] * np.sinc(Fs * t_sinc - n)\n    return x_sinc\n\ndef plot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc):\n    plt.figure(figsize=(6, 2))\n    plt.plot(t_1, x_1, 'k', linewidth=1, linestyle='dotted', label='Orignal signal')\n    plt.stem(t_2, x_2, linefmt='r:', markerfmt='r.', basefmt='None', label='Samples')\n    plt.plot(t_1, x_sinc, 'b', label='Reconstructed signal')\n    plt.title(r'Sampling rate $F_\\mathrm{s} = %.0f$'%(1/t_2[1]))\n    plt.xlabel('Time (seconds)')\n    plt.ylim([-1.5, 1.5])\n    plt.xlim([t_1[0], t_1[-1]])\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.show()\n\n\nFs_2 = 40\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\nFs_2 = 20\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\nFs_2 = 10\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\n\n\n\n\n\n\n\n\n\n\n다음 예는 에일리어싱이 음질에 미치는 영향을 나타낸다. 높은 샘플링 속도(\\(F_s=8192Hz\\))의 음악 신호로 시작한 다음 두배씩 줄여나가보자.\n\n\nx, Fs = librosa.load('../audio/piano_c_scale.wav', sr=8000)\nFs_orig = Fs\nlen_orig = len(x)\nfor i in range(5):\n    print('Sampling rate Fs = %s; Number of samples = %s' % (Fs, len(x)))\n    x_play = scipy.signal.resample(x, len_orig)\n    ipd.display(ipd.Audio(data=x_play, rate=Fs_orig))\n    Fs = Fs // 2\n    x = x[::2]\n\nSampling rate Fs = 8000; Number of samples = 54001\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 4000; Number of samples = 27001\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 2000; Number of samples = 13501\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 1000; Number of samples = 6751\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 500; Number of samples = 3376\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링-정리-sampling-theorem",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링-정리-sampling-theorem",
    "title": "3.5. 디지털 신호",
    "section": "샘플링 정리 (Sampling Theorem)",
    "text": "샘플링 정리 (Sampling Theorem)\n\n샘플링 정리 (sampling theorem)는 대역 제한이 있는(bandlimited) 연속 시간(CT) 신호를 특정 조건에서 완벽하게 재구성할 수 있다고 말한다.\n보다 정확하게는 \\(|\\omega|>\\Omega\\) 에 대해 푸리에 변환 \\(\\hat{f}\\)가 사라지면 CT 신호 \\(f\\in L^2(\\mathbb{R})\\)를 \\(\\Omega\\)-bandlimited 라고 한다 (즉, \\(\\hat{f}(\\omega) = 0\\) for \\(|\\omega|>\\Omega\\)).\n\\(f\\in L^2(\\mathbb{R})\\)를 \\(\\Omega\\)-bandlimited 함수라고 하고, \\(x\\)를 \\(f\\)의 (with \\(T:=1/(2\\Omega)\\)) \\(T\\)-샘플 버전이라고 하자 (즉, \\(x(n)=f(nT)\\), \\(n\\in\\mathbb{Z}\\)).\n그러면 \\(f\\)는 다음과 같이 \\(x\\)로부터 재구성될 수 있다.\n\n\\[\nf(t)=\\sum_{n\\in\\mathbb{Z}}x(n)\\mathrm{sinc}\\left(\\frac{t-nT}{T}\\right)\n=\\sum_{n\\in\\mathbb{Z}}f\\left(\\frac{n}{2\\Omega}\\right) \\mathrm{sinc}\\left(2\\Omega t-n\\right),\n\\]\nwhere the \\(\\mathrm{sinc}\\)-function is defined as\n\\[\\begin{equation}\n    \\mathrm{sinc}(t):=\\left\\{\\begin{array}{ll}\n    \\frac{\\sin \\pi t}{\\pi t},&\\mbox{ if $t\\not= 0$,}\\\\\n    1,&\\mbox{ if $t= 0$.}\n\\end{array}\\right.\n\\end{equation}\\]\n\n즉, 대역 제한이 샘플링 속도의 절반 이하인 경우, 등거리 샘플링으로 얻은 DT 신호에서 CT 신호 \\(f\\)를 완벽하게 재구성할 수 있다.\n\\(\\mathrm{sinc}\\) 함수를 기반으로 한 이 재구성은 reconstruction_sinc 함수에서 사용되었다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#이산화-discretization",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#이산화-discretization",
    "title": "3.5. 디지털 신호",
    "section": "이산화 (Discretization)",
    "text": "이산화 (Discretization)\n\n위에서 연속-시간 축을 이산-시간 축으로 변환하는 과정으로서의 샘플링을 보았다. 이것은 아날로그-to-디지털의 첫번째 단계였다.\n두 번째 단계에서는 가능한 진폭(amplitude)의 연속 범위(\\(\\mathbb{R}\\)로 인코딩됨)를 가능한 값의 이산 범위(이산 집합 \\(\\Gamma\\subset \\mathbb{R}\\)로 인코딩됨)로 대체해야 한다. 이 프로세스를 일반적으로 양자화(quantization) 라고 한다.\n\n\nImage('../img/3.fourier_analysis/f.2.13.PNG', width=500)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#균일uniform-양자화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#균일uniform-양자화",
    "title": "3.5. 디지털 신호",
    "section": "균일(Uniform) 양자화",
    "text": "균일(Uniform) 양자화\n\n양자화는 각 진폭 값 \\(a\\in\\mathbb{R}\\)에 값 \\(Q(a)\\in\\Gamma\\)을 할당하는 quantizer라고 하는 함수 \\(Q:\\mathbb{R}\\to\\Gamma\\)로 모델링할 수 있다.\n사용되는 많은 quantizer는 단순히 아날로그 값을 일부 정밀도 단위로 반올림하거나 자른다(truncate). 예를 들어 어떤 값 \\(\\Delta\\)와 동일한 quantization step size를 갖는 일반적인 uniform quantizer는 양자화 수준을 균일하게 배치한다.\n\n\\(Q(a) := \\mathrm{sgn}(a) \\cdot \\Delta \\cdot \\left\\lfloor \\frac{|a|}{\\Delta} + \\frac{1}{2} \\right\\rfloor\\) for \\(a\\in\\mathbb{R}\\),\n\\(\\mathrm{sgn}(\\cdot)\\)는 실수의 부호를 생성하는 signum 함수이며, 대괄호 \\(\\lfloor \\cdot \\rfloor\\)는 실수를 잘라(truncate) 이 숫자 아래에서 가장 큰 정수를 생성하는 것이다.\n\\(\\Delta=1\\)의 경우 quantizer \\(Q\\)는 가장 가까운 정수로 간단히 반올림된다.\n\n\n\n양자화 오류 (Quantization Error)\n\n샘플링과 마찬가지로 양자화는 일반적으로 손실이 많은 작업이다. 다른 아날로그 값이 동일한 디지털 값에 매핑될 수 있기 때문이다. 실제 아날로그 값과 양자화된 값의 차이를 양자화 오류라고 한다.\n양자화 step size \\(\\Delta\\)를 줄이면 일반적으로 양자화 오류가 더 작아진다. 그러나 동시에 양자화된 값의 수(따라서 이러한 값을 인코딩하는 데 필요한 비트 수)도 증가한다.\n예를 들어 양자화 단계 크기 \\(\\Delta=1/3\\)가 사용되면 주어진 신호에 대해 \\(8\\)의 서로 다른 양자화 값이 생성된다. 따라서 \\(3\\) 비트 코딩 방식을 사용하여 양자화된 값을 나타낼 수 있다. CD 녹음의 경우 \\(65536\\) 가능한 값을 표현할 수 있는 \\(16\\) 비트 코딩 체계가 사용된다.\n\n\n\n균일 양자화 구현\n\n다음에서 모든 아날로그 값이 \\(s,t\\in\\mathbb{R}\\)에 대해 \\([s,t]\\) 범위 내에 있다고 가정한다. 또한 여러 양자화 수준이 \\(\\lambda\\in\\mathbb{N}\\)인 경우, 양자화 step size를 \\(\\Delta=|t-s|/(\\lambda-1)\\)로 정의한다. 이는 \\(\\lambda\\) 양자화 레벨로 구성되는 (\\(s\\) 값으로 시작하여 \\(t\\) 값으로 끝남), 값 \\(s\\)와 \\(t\\) 사이의 uniform 양자화로 정의한다.\n예를 들어 파형 기반 오디오 신호는 일반적으로 \\([-1,1]\\) 범위에 있다.\n\\(s=-1\\), \\(t=1\\) 및 \\(\\lambda=9\\)의 경우 결과는 \\(\\Delta=1/4\\)이다. 이 경우 결과 양자화 오류는 최대 1/8입니다. 다음 코드 셀에서 서로 다른 매개변수 \\(s\\), \\(t\\) 및 \\(\\lambda\\)에 대해 균일한 양자화를 산출하는 quantize_uniform 함수를 정의해보자.\n\n\ndef quantize_uniform(x, quant_min=-1.0, quant_max=1.0, quant_level=5):\n    \"\"\"Uniform quantization approach\n\n    Args:\n        x (np.ndarray): Original signal\n        quant_min (float): Minimum quantization level (Default value = -1.0)\n        quant_max (float): Maximum quantization level (Default value = 1.0)\n        quant_level (int): Number of quantization levels (Default value = 5)\n\n    Returns:\n        x_quant (np.ndarray): Quantized signal\n    \"\"\"\n    x_normalize = (x-quant_min) * (quant_level-1) / (quant_max-quant_min)\n    x_normalize[x_normalize > quant_level - 1] = quant_level - 1\n    x_normalize[x_normalize < 0] = 0\n    x_normalize_quant = np.around(x_normalize)\n    x_quant = (x_normalize_quant) * (quant_max-quant_min) / (quant_level-1) + quant_min\n    return x_quant\n\n\ndef plot_graph_quant_function(ax, quant_min=-1.0, quant_max=1.0, quant_level=256, mu=255.0, quant='uniform'):\n    \"\"\"Helper function for plotting a graph of quantization function and quantization error\n\n    Args:\n        ax (mpl.axes.Axes): Axis\n        quant_min (float): Minimum quantization level (Default value = -1.0)\n        quant_max (float): Maximum quantization level (Default value = 1.0)\n        quant_level (int): Number of quantization levels (Default value = 256)\n        mu (float): Encoding parameter (Default value = 255.0)\n        quant (str): Type of quantization (Default value = 'uniform')\n    \"\"\"\n    x = np.linspace(quant_min, quant_max, 1000)\n    if quant == 'uniform':\n        x_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, quant_level=quant_level)\n        quant_stepsize = (quant_max - quant_min) / (quant_level-1)\n        title = r'$\\lambda = %d, \\Delta=%0.2f$' % (quant_level, quant_stepsize)\n    if quant == 'nonuniform':\n        x_quant = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\n        title = r'$\\lambda = %d, \\mu=%0.1f$' % (quant_level, mu)\n    error = np.abs(x_quant - x)\n    ax.plot(x, x, color='k', label='Original amplitude')\n    ax.plot(x, x_quant, color='b', label='Quantized amplitude')\n    ax.plot(x, error, 'r--', label='Quantization error')\n    ax.set_title(title)\n    ax.set_xlabel('Amplitude')\n    ax.set_ylabel('Quantized amplitude/error')\n    ax.set_xlim([quant_min, quant_max])\n    ax.set_ylim([quant_min, quant_max])\n    ax.grid('on')\n    ax.legend()\n\n\nplt.figure(figsize=(12,4))\nax = plt.subplot(1, 3, 1)\nplot_graph_quant_function(ax, quant_min=-1, quant_max=4, quant_level=3)\nax = plt.subplot(1, 3, 2)\nplot_graph_quant_function(ax, quant_min=-2, quant_max=2, quant_level=4)\nax = plt.subplot(1, 3, 3)\nplot_graph_quant_function(ax, quant_min=-1, quant_max=1, quant_level=9)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n다음 코드 셀에서는 정현파를 신호로 사용하여 다양한 파라미터 설정에 대한 균일(uniform) 양자화 결과를 본다.\n\n\ndef generate_sinusoid(dur=5, Fs=1000, amp=1, freq=1, phase=0):\n    \"\"\"Generation of sinusoid\n    \n    2.3.Audio_Represenation에 쓰인 바 있음\n    \n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 1)\n        freq (float): Frequency of sinusoid (Default value = 1)\n        phase (float): Phase of sinusoid (Default value = 0)\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = amp * np.sin(2*np.pi*(freq*t-phase))\n    return x, t\n\n\ndef plot_signal_quant(x, t, x_quant, figsize=(6, 2), xlim=None, ylim=None, title=''):\n    \"\"\"Helper function for plotting a signal and its quantized version\n\n    Args:\n        x: Original Signal\n        t: Time\n        x_quant: Quantized signal\n        figsize: Figure size (Default value = (8, 2))\n        xlim: Limits for x-axis (Default value = None)\n        ylim: Limits for y-axis (Default value = None)\n        title: Title of figure (Default value = '')\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.plot(t, x, color='gray', linewidth=1.0, linestyle='-', label='Original signal')\n    plt.plot(t, x_quant, color='red', linewidth=2.0, linestyle='-', label='Quantized signal')\n    if xlim is None:\n        plt.xlim([0, t[-1]])\n    else:\n        plt.xlim(xlim)\n    if ylim is not None:\n        plt.ylim(ylim)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.title(title)\n    plt.legend(loc='upper right', framealpha=1)\n    plt.tight_layout()\n    plt.show()\n\n\ndur = 5\nx, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1, phase=0.0)\n\nquant_min = -1\nquant_max = 1\nquant_level = 5\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));\n\nquant_min = -0.5\nquant_max = 1\nquant_level = 3\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));\n\nquant_min = -1.2\nquant_max = 1.2\nquant_level = 4\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비균일nonuniform-양자화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비균일nonuniform-양자화",
    "title": "3.5. 디지털 신호",
    "section": "비균일(Nonuniform) 양자화",
    "text": "비균일(Nonuniform) 양자화\n\n균일 양자화에서 양자화 수준은 등거리(equidistant) 방식으로 배치(spaced)된다. 그렇지 않은 경우 비균일(nonuniform) 양자화라고 한다. 예를 들어 오디오 신호의 경우 로그 방식으로 간격을 둔 양자화 수준을 선택하는 경우가 많다. 소리 강도에 대한 인간의 인식이 본질적으로 대수적이기 때문이다.\n따라서 인지적 관점에서 보면 높은 진폭 값을 인코딩하는 것보다 낮은 진폭 값을 인코딩하는 데 더 많은 비트를 활용하는 것이 유리할 수 있다(낮은 진폭 값에서 인간은 소리 강도의 변화에 더 민감함).\n로그 양자화에 대한 한 가지 접근 방식으로 다음과 같이 정의되는 \\(\\mu\\)-law 인코딩이 있다. \\[F_\\mu(v) = \\mathrm{sgn}(v) \\frac{\\ln(1+ \\mu |v|)}{\\ln(1+\\mu)}\\] for values \\(v\\in[-1,1]\\), where \\(\\mathrm{sgn}\\) denotes the signum function\n파라미터 \\(\\mu\\in\\mathbb{R}_{>0}\\)는 적용되는 compression 정도를 결정하는 정수이다.\n실제로는 비균일 \\(8\\)비트 양자화 체계를 도출하기 위해 \\(\\mu=255\\)를 자주 사용한다. 인코딩 \\(F_\\mu\\)는 strictly 증가 단조 함수로, \\([-1,1]\\) 간격을 낮은 값은 확장되고 높은 값은 압축되도록 자기 자체에 매핑한다.\n그 역인 \\(\\mu\\)-law 디코딩(decoding) 은 다음과 같다. \\[F_\\mu^{-1}(v) = \\mathrm{sgn}(v) \\frac{(1 + \\mu)^{|v|}- 1}{\\mu}\\] for values \\(v\\in[-1,1]\\)\n다음 코드 셀에서 \\(F_\\mu\\) 함수와 그 역 \\(F_\\mu^{-1}\\)를 구현하고 다른 파라미터 \\(\\mu\\)에 대한 결과를 설명한다.\n\n\ndef encoding_mu_law(v, mu=255.0):\n    \"\"\"mu-law encoding\n\n    Args:\n        v (float): Value between -1 and 1\n        mu (float): Encoding parameter (Default value = 255.0)\n\n    Returns:\n        v_encode (float): Encoded value\n    \"\"\"\n    v_encode = np.sign(v) * (np.log(1.0 + mu * np.abs(v)) / np.log(1.0 + mu))\n    return v_encode\n\n\ndef decoding_mu_law(v, mu=255.0):\n    \"\"\"mu-law decoding\n\n    Args:\n        v (float): Value between -1 and 1\n        mu (float): Dencoding parameter (Default value = 255.0)\n\n    Returns:\n        v_decode (float): Decoded value\n    \"\"\"\n    v_decode = np.sign(v) * (1.0 / mu) * ((1.0 + mu)**np.abs(v) - 1.0)\n    return v_decode\n\n\ndef plot_mu_law(mu=255.0, figsize=(8, 3)):\n    \"\"\"Helper function for plotting a signal and its quantized version\n\n    Args:\n        mu (float): Dencoding parameter (Default value = 255.0)\n        figsize (tuple): Figure size (Default value = (8.5, 2))\n    \"\"\"\n    values = np.linspace(-1, 1, 1000)\n    values_encoded = encoding_mu_law(values, mu=mu)\n    values_decoded = encoding_mu_law(values, mu=mu)\n\n    plt.figure(figsize=figsize)\n    ax = plt.subplot(1, 2, 1)\n    ax.plot(values, values, color='k', label='Original values')\n    ax.plot(values, values_encoded, color='b', label='Encoded values')\n    ax.set_title(r'$\\mu$-law encoding with $\\mu=%.0f$' % mu)\n    ax.set_xlabel('$v$')\n    ax.set_ylabel(r'$F_\\mu(v)$')\n    ax.set_xlim([-1, 1])\n    ax.set_ylim([-1, 1])\n    ax.grid('on')\n    ax.legend()\n\n    ax = plt.subplot(1, 2, 2)\n    ax.plot(values, values, color='k', label='Original values')\n    ax.plot(values, values_decoded, color='b', label='Decoded values')\n    ax.set_title(r'$\\mu$-law decoding with $\\mu=%.0f$' % mu)\n    ax.set_xlabel('$v$')\n    ax.set_ylabel(r'$F_\\mu^{-1}(v)$')\n    ax.set_xlim([-1, 1])\n    ax.set_ylim([-1, 1])\n    ax.grid('on')\n    ax.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\nplot_mu_law(mu=255.0)\nplot_mu_law(mu=7.0)\n\n\n\n\n\n\n\n\n비균일 양자화 구현\n\n먼저 주어진 신호를 \\(F_\\mu\\)를 사용하여 인코딩한 다음, 균일 양자화를 적용하고, 마지막으로 \\(F_\\mu^{-1}\\)를 사용하여 양자화된 신호를 디코딩해보자. 다음 코드에서 신호 샘플을 \\([-1,1]\\) 범위에 있는 경우로 제한한다. 뒤의 그림은 위의 정현파 예제 형식을 따르는 균일 양자화와 비균일 양자화의 차이를 보여준다.\n\n\ndef quantize_nonuniform_mu(x, mu=255.0, quant_level=256):\n    \"\"\"Nonuniform quantization approach using mu-encoding\n\n    Args:\n        x (np.ndarray): Original signal\n        mu (float): Encoding parameter (Default value = 255.0)\n        quant_level (int): Number of quantization levels (Default value = 256)\n\n    Returns:\n        x_quant (np.ndarray): Quantized signal\n    \"\"\"\n    x_en = encoding_mu_law(x, mu=mu)\n    x_en_quant = quantize_uniform(x_en, quant_min=-1, quant_max=1, quant_level=quant_level)\n    x_quant = decoding_mu_law(x_en_quant, mu=mu)\n    return x_quant\n\n\ndur = 5\nx, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1, phase=0.0)\n\nquant_level = 8\nx_quant = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \ntitle=r'Uniform quantization with $\\lambda$=$%d$'%(quant_level));\n\nmu = 7\nx_quant = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \ntitle=r'Nonuniform quantization with $\\mu$=$%d$ and $\\lambda$=$%d$'%(mu, quant_level));\n\n\n\n\n\n\n\n\n위의 접근 방식은 두 개의 파라미터, \\(\\mu\\)(인코딩 파라미타) 및 \\(\\lambda\\)(간격 \\([-1,1]\\)의 양자화 레벨 수)에 따라 달라지는 비균일 양자화 함수를 생성한다. 다음 코드 셀에서는 다양한 파라미터 설정에 대한 양자화 오류(quantization error)와 양자화 함수의 그래프를 보여준다. 양자화 오류는 \\(|v|\\approx 1\\)인 \\(v\\) 값보다 \\(|v|\\approx 0\\)인 \\(v\\) 값에서 훨씬 더 낮다.\n\n\nplt.figure(figsize=(12,3))\nax = plt.subplot(1, 3, 1)\nplot_graph_quant_function(ax, mu=3, quant_level=4, quant='nonuniform')\nax = plt.subplot(1, 3, 2)\nplot_graph_quant_function(ax, mu=7, quant_level=8, quant='nonuniform')\nax = plt.subplot(1, 3, 3)\nplot_graph_quant_function(ax, mu=15, quant_level=16, quant='nonuniform')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#양자화-잡음-quantization-noise",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#양자화-잡음-quantization-noise",
    "title": "3.5. 디지털 신호",
    "section": "양자화 잡음 (Quantization Noise)",
    "text": "양자화 잡음 (Quantization Noise)\n\n신호의 양자화는 손실이 많은 작업이다. 이 과정에서 발생하는 왜곡을 양자화 잡음이라고 한다. 다음 코드 셀에서 샘플 값을 인코딩하기 위해 다른 수의 비트를 사용하여 C 장음계의 피아노 녹음을 양자화하여 이러한 왜곡의 impression을 줘본다. \\(b\\in\\mathbb{N}\\) 비트를 사용하여 \\(2^b\\)의 서로 다른 양자화 레벨을 인코딩할 수 있다.\n\n\ndef display_signal_quant(x, Fs, number_of_bits):\n    quant_level = 2 ** number_of_bits\n    x_quant = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)    \n    print('Signal after uniform quantization (%d bits) :'%number_of_bits, flush=True)\n    ipd.display(ipd.Audio(x_quant, rate=Fs))\n    return x_quant\n\n\nx, Fs = librosa.load(\"../audio/piano_c_scale.wav\", sr=11025)\n\nprint('Original audio signal (16 bits):', flush=True)\nipd.display(ipd.Audio(x, rate=Fs) )\n\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=8)\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=4)\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=2)\n\nOriginal audio signal (16 bits):\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (8 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (4 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (2 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n균일 및 비균일 양자화에 대한 양자화 노이즈\n\n위의 C 메이저 스케일의 피아노 녹음을 사용하여 양자화 노이즈 결과 균일 및 비균일 양자화를 비교한다. 샘플 값을 인코딩하기 위해 서로 다른 비트 수를 고려한다. 특히, \\(8\\) 비트 균일 양자화를 사용할 때보다 \\(8\\) 비트 비균일 양자화를 사용할 때 더 낮은 노이즈 레벨을 인지한다.\n\n\ndef compare_quant_signal(x, Fs, number_of_bits):\n    quant_level = 2 ** number_of_bits\n    mu = quant_level-1\n    x_qu = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)    \n    x_qn = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\n    audio_player_list([x, x_qu, x_qn], [Fs, Fs, Fs], width=160, \n                columns=['Original (16 bits)', 'Uniform (%d bits)'%number_of_bits, 'Nonuniform (%d bits)'%number_of_bits])\n\n\nx, Fs = librosa.load(\"../audio/piano_c_scale.wav\", sr=11025)\n\ncompare_quant_signal(x, Fs, number_of_bits=8)\ncompare_quant_signal(x, Fs, number_of_bits=4)\ncompare_quant_signal(x, Fs, number_of_bits=2)\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (8 bits)\n      Nonuniform (8 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n    \n  \n\n\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (4 bits)\n      Nonuniform (4 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n    \n  \n\n\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (2 bits)\n      Nonuniform (2 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#간섭interference",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#간섭interference",
    "title": "3.5. 디지털 신호",
    "section": "간섭(Interference)",
    "text": "간섭(Interference)\n\n신호 처리에서 간섭(interference)은 한 파동이 비슷한 주파수의 다른 파동과 중첩(superimposed)될 때 발생한다. 한 파동의 파고(crest)가 어떤 지점에서 다른 파동의 파고와 만나면 일정 기간 동안 개별적 크기가 합산되며 이를 보강 간섭(constructive interference)이라고 한다. 반대로, 한 파동의 파고가 다른 파동의 파고와 만나면 크기가 일정 시간 동안 상쇄되는데, 이를 상쇄 간섭(destructive interference)이라고 한다.\n\n\ndef plot_interference(x1, x2, t, figsize=(6, 2), xlim=None, ylim=None, title=''):\n    \"\"\"Helper function for plotting two signals and its superposition\n    Args:\n        x1: Signal 1\n        x2: Signal 2\n        t: Time\n        figsize: figure size (Default value = (8, 2))\n        xlim: x limits (Default value = None)\n        ylim: y limits (Default value = None)\n        title: figure title (Default value = '')\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.plot(t, x1, color='gray', linewidth=.5, linestyle='-', label='x1', alpha=.6)\n    plt.plot(t, x2, color='cyan', linewidth=.5, linestyle='-', label='x2', alpha=.6)\n    plt.plot(t, x1+x2, color='red', linewidth=1.0, linestyle='-', label='x1+x2', alpha=.6)\n    if xlim is None:\n        plt.xlim([0, t[-1]])\n    else:\n        plt.xlim(xlim)\n    if ylim is not None:\n        plt.ylim(ylim)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.title(title)\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.show()\n\n\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.05, phase=0.0)\nx2, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=0.95, phase=0.8)\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-2.2,2.2], title='Constructive Interference');\n\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.05, phase=0.0)\nx2, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.00, phase=0.4)\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-2.2,2.2], title='Destructive Interference');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비팅beating",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비팅beating",
    "title": "3.5. 디지털 신호",
    "section": "비팅(Beating)",
    "text": "비팅(Beating)\n\n앞의 그림은 주파수가 비슷한 두 정현파가 더해지거나(보강 간섭) 상쇄(상쇄 간섭)될 수 있음을 보여주었다.\n\\(f_1(t)=\\sin(2\\pi \\omega_1 t)\\) 및 \\(f_2(t)=\\sin(2\\pi \\omega_2 t)\\)를 뚜렷하지만 가까운 주파수 \\(\\omega_1\\approx\\omega_2\\)의 두 정현파라고 하자.\n이제 이 두 정현파의 중첩 \\(f_1+f_2\\)가 진폭이 천천히 변하는 단일 사인파처럼 보이는 함수를 생성한다는 것을 볼 수 있다. 이 현상은 비팅(beating) 이라고 한다. 수학적으로 이 현상은 삼각 항등식 (trigonometric identity)의 결과이다. \\[\\sin(2\\pi \\omega_1t)+\\sin(2\\pi \\omega_2t)=\n2\\cos\\left(2\\pi\\frac{\\omega_1-\\omega_2}{2}t\\right)\\sin\\left(2\\pi\\frac{\\omega_1+\\omega_2}{2}t\\right).\\]\n\\(\\omega_1-\\omega_2\\)의 차이가 작으면 코사인 항은 사인 항에 비해 빈도가 낮다.\n결과적으로 신호 \\(f_1+f_2\\)는 주파수 \\(|\\omega_1-\\omega_2|\\)의 천천히 변하는 진폭 포락선(amplitude envelope)을 가지는 주파수 \\((\\omega_1+\\omega_2)/2\\)의 사인파로 볼 수 있다.\n이 비율은 코사인 항의 빈도 \\((\\omega_1-\\omega_2)/2\\)의 두 배이다.\n\n\nFs = 4000\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=200)\nx2, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=203)\nplot_interference(x1, x2, t, ylim=[-1.1,1.1], xlim=[0, dur],\n    title=r'Beating with beating frequency $|\\omega_1-\\omega_2|=3$ ($\\omega_1=200, \\omega_2=203$)');\nplot_interference(x1, x2, t, ylim=[-1.1,1.1], xlim=[1.115, 1.225], title=r'Zoom-in section');\n\nipd.display(ipd.Audio(x1+x2, rate=Fs))\n\n\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n처프(Chirp) 실험\n\n비팅(beating)효과를 설명하기 위해 처프 신호(시간에 따라 주파수가 증가)를 보자.\n\\(\\omega_0,\\omega_1\\in\\mathbb{R}\\)를 두 주파수 파라미터(헤르츠 단위)라고 하고, \\(T\\in\\mathbb{R}\\)를 듀레이션 파라미터(초단위)라고 하자.\n\\(\\omega_0\\)에서 시작하여 \\(\\omega_1\\)로 주파수가 선형적으로 증가하는 듀레이션 \\(d\\)의 선형 처프는 다음과 같이 계산된다.\n\n$ f(t)=( t^2 + 2_0t)$ for \\(t\\in[0,T]\\)\n\n시간 \\(t\\)에서 처프 신호 \\(f\\)의 순간 주파수 (instantaneous frequency) 는 정현파의 인수를 \\(2\\pi\\)로 나눈 것의 도함수로 주어진다.\n\n\\[\n   g(t) = \\frac{\\omega_1-\\omega_0}{T} t + \\omega_0.\n\\]\n\n주파수 \\(\\omega_0=220.0~\\mathrm{Hz}\\)(피치 \\(\\mathrm{A3}\\))에서 시작하여 주파수 \\(\\omega_1=311.1~\\mathrm{Hz}\\)(피치 \\(\\mathrm{E}^\\flat 4\\))로 끝나는 듀레이션 \\(T=20~\\mathrm{sec}\\)의 선형 처프 신호를 보자.\n또한 동일한 듀레이션의 주파수 \\(261.5~\\mathrm{Hz}\\)(피치 \\(\\mathrm{C4}\\))를 갖는 정현파를 생각해보자.\n이 신호의 중첩을 들을 때, 처음에는 \\(\\mathrm{A3}\\) 및 \\(\\mathrm{C4}\\) 두 개의 개별 피치를 인식한다.\n처프가 \\(\\mathrm{C4}\\)에 가까워지면 두 음이 하나의 소리로 합쳐지기 시작한다. 동시에 처음에는 속도가 느려졌다가 사라지고(처프가 \\(\\mathrm{C4}\\)에 도달하면), 다시 속도가 빨라지는 비팅 효과를 볼 수 있다. 마지막에 다시 \\(\\mathrm{E}^\\flat 4\\) 및 \\(\\mathrm{C4}\\)인 두 피치를 인식한다.\n\n\ndef generate_chirp_linear(dur, freq_start, freq_end, amp=1.0, Fs=22050):\n    \"\"\"Generation chirp with linear frequency increase\n\n    Args:\n        dur (float): Duration (seconds) of the signal\n        freq_start (float): Start frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        amp (float): Amplitude of chirp (Default value = 1.0)\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    a = (freq_end - freq_start) / dur\n    freq = a * t + freq_start\n    x = amp * np.sin(np.pi * a * t ** 2 + 2 * np.pi * freq_start * t)\n    return x, t, freq\n\n\nf_pitch = lambda p: 440 * 2 ** ((p - 69) / 12)\n\nFs = 4000\ndur = 20\nfreq_start = f_pitch(57)   # A3\nfreq_end = f_pitch(63)     # Eflatp4\nfreq_sin = f_pitch(60)     # C4\nx1, t, freq = generate_chirp_linear(dur=dur, freq_start=freq_start, freq_end=freq_end, amp=0.5, Fs=Fs)\nx2, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=freq_sin)\n\ny = x1 + x2\nipd.display(ipd.Audio(y, rate=Fs))\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-1.1,1.1], \n    title=r'Superposition of a linear chirp $x_1$ (A3 to E$^\\flat$4) and sinusoid $x_2$ (C4)');\nplot_interference(x1, x2, t, xlim=[7, 11], ylim=[-1.1,1.1], title='Zoom-in section');\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "",
    "text": "음악 작품의 음악적 정보를 시간순으로 정렬하여 동기화(synchronize)하는데 필요한 오디오 피쳐(audio feature)를 소개한다. 특히 크로마(chroma) 기반 음악 피쳐의 개념을 알아본다."
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#stft와-피치-주파수",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#stft와-피치-주파수",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "STFT와 피치 주파수",
    "text": "STFT와 피치 주파수\n\n평균율(equal-tempered scale)에 따라 피치를 의미 있게 분류할 수 있는 음악을 다루고 있다고 가정하고, 오디오 녹음이 다양한 피치에 걸쳐 신호 에너지의 분포를 나타내는 특징 표현(feature representation)으로 변환될 수 있는 방법을 보자. (앞으로 “feature”를 피쳐 혹은 특징으로 해석해 서술하겠다.)\n이러한 특징(feature)은 선형 주파수 축(Hertz로 측정)을 로그(log) 축(피치로 측정)으로 변환하여 스펙트로그램에서 얻을 수 있다. 이 결과를 로그 주파수 스펙트로그램(log-frequency spectrogram) 이라고도 한다.\n시작하기 앞서 이산 STFT가 필요하다. \\(x\\)를 헤르츠로 주어진 고정 샘플링 속도 \\(F_\\mathrm{s}\\)에 대해 등거리(equidistant) 샘플링으로 얻은 실수 값 이산 신호라고 하자. 또한, \\(\\mathcal{X}\\)를 길이 \\(N\\in\\mathbb{N}\\) 및 홉(hop) 크기 \\(H\\in\\mathbb{N}\\)의 윈도우 \\(w\\)에 대한 이산 STFT라고 하자.\n제로-패딩을 적용하면 푸리에 계수 \\(\\mathcal{X}(n,k)\\)가 프레임 파라미터 \\(n\\in\\mathbb{Z}\\)와 주파수 파라미터 \\(k\\in[0: K]\\)로 인덱싱된다. 여기서 \\(K=N/2\\)는 Nyquist 주파수에 해당하는 주파수 인덱스이다.\n각 푸리에 계수 \\(\\mathcal{X}(n,k)\\)는 초 단위로 주어진 물리적 시간 위치 \\(T_\\mathrm{coef}(n) = nH/F_\\mathrm{s}\\)와 연관되어 있다.\n\n\\(F_\\mathrm{coef}(k) = \\frac{k \\cdot F_\\mathrm{s}}{N}\\)\n\n로그 주파수 스펙트로그램의 주요 아이디어는 평균율 스케일의 로그 간격 주파수 분포에 해당하도록 주파수 축을 재정의하는 것이다. MIDI 음표 번호로 피치를 식별하면(음표 A4는 MIDI 음표 번호 \\(p=69\\)에 해당), 중심 주파수는 다음과 같이 지정된다:\n\n\\(F_\\mathrm{pitch}(p) = 2^{(p-69)/12} \\cdot 440.\\)\n\n예를 들어 피아노 연주 반음계(chromatic scale)를 고려해보자. 결과의 스펙트로그램은 연주된 음의 피치에 대한 기본 주파수(fundamental frequency)의 기하급수적 종속성(exponential dependency)을 나타낸다. 또한 화음과 음의 온셋(onset) 위치(수직 구조)가 명확하게 표시된다.\n\n\nImage(\"../img/4.music_synchronization/f.4.1a.png\", width=500)\n\n\n\n\n\npiano_chromatic = \"../data_FMP/FMP_C3_F03.wav\"\nipd.Audio(piano_chromatic)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n# Load wav\nx, Fs = librosa.load(piano_chromatic)\n\n# Compute Magnitude STFT\nN = 4096\nH = 1024\nY, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H, mag=True)\n# Y = np.abs(Y) ** 2 (if mag=False)\n\n\n# Plot spectrogram\nfig = plt.figure(figsize=(8, 3))\neps = np.finfo(float).eps\nplt.imshow(10 * np.log10(eps + Y), origin='lower', aspect='auto', cmap='gray_r', \n           extent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]])\nplt.title(\"Magnitude spectrogram\")\nplt.clim([-30, 30])\nplt.ylim([0, 4500])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\ncbar = plt.colorbar()\ncbar.set_label('Magnitude (dB)')\nplt.tight_layout()\n\n# Plot rectangle corresponding to pitch C3 (p=48)\nrect = matplotlib.patches.Rectangle((29.3, 0.5), 1.2, 4490, linewidth=3, \n                                    edgecolor='r', facecolor='none')\nplt.gca().add_patch(rect)\nplt.text(28, -400, r'$\\mathrm{C3}$', color='r', fontsize='x-large');"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#로그-주파수-풀링pooling",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#로그-주파수-풀링pooling",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "로그 주파수 풀링(Pooling)",
    "text": "로그 주파수 풀링(Pooling)\n\n주파수에 대한 로그 인식은 평균율 음계의 피치로 레이블이 지정된 로그 주파수 축으로 시간-주파수 표현을 사용하도록 한다.\n주어진 스펙트로그램에서 그러한 표현을 도출하기 위한 기본 아이디어로는 각 스펙트럼 계수(sprectral coefficient) \\(\\mathcal{X}(n,k)\\)를 주파수 \\(F_\\mathrm{coef}(k)\\)에 가장 가까운 중심 주파수의 피치에 할당하는 것이다.\n보다 정확하게는 각 피치 \\(p\\in[0:127]\\)에 대해 다음의 집합을 정의한다. \\[\\begin{equation}\n  P(p) := \\{k:F_\\mathrm{pitch}(p-0.5) \\leq   F_\\mathrm{coef}(k) <  F_\\mathrm{pitch}(p+0.5)\\}.\n\\end{equation}\\]\n\\(P(p)\\)에 포함되는 주파수 범위는 로그 방식의 주파수에 따라 달라진다. 피치 \\(p\\)의 대역폭(bandwidth) \\(\\mathrm{BW}(p)\\)를 다음과 같이 정의한다.\n\n\\[\\mathrm{BW}(p):=F_\\mathrm{pitch}(p+0.5)-F_\\mathrm{pitch}(p-0.5)\\]\n\n대역폭 \\(\\mathrm{BW}(p)\\)는 피치가 낮아질수록 작아진다. 특히 피치를 한 옥타브 내리면 반으로 감소한다. 예를 들어, MIDI 피치 \\(p=66\\)의 경우 대역폭은 대략 \\(21.4~\\mathrm{Hz}\\)인 반면 \\(p=54\\)의 경우 대역폭은 \\(10.7~\\mathrm{Hz}\\) 아래로 떨어진다.\n다음 표는 다양한 음표와 MIDI 음표 번호 \\(p\\), 중심 주파수 \\(F_\\mathrm{pitch}(p)\\), 컷오프(cutoff) 주파수 \\(F_\\mathrm{pitch}(p-0.5)\\) 및 \\(F_\\mathrm{pitch}(p+0.5)\\) 및 대역폭 \\(\\mathrm{BW}(p)\\)을 보여준다.\n\n\ndef note_name(p):\n    \"\"\"Returns note name of pitch\n\n    Args:\n        p (int): Pitch value\n\n    Returns:\n        name (str): Note name\n    \"\"\"\n    chroma = ['A', 'A$^\\\\sharp$', 'B', 'C', 'C$^\\\\sharp$', 'D', 'D$^\\\\sharp$', 'E', 'F', 'F$^\\\\sharp$', 'G',\n              'G$^\\\\sharp$']\n    name = chroma[(p - 69) % 12] + str(p // 12 - 1)\n    return name\n\n\nf_pitch = lambda p: 440 * 2 ** ((p - 69) / 12)\n   \nnote_infos = []\nfor p in range(60, 73):\n    name = note_name(p)\n    p_pitch = f_pitch(p)\n    p_pitch_lower = f_pitch(p - 0.5)\n    p_pitch_upper = f_pitch(p + 0.5)\n    bw = p_pitch_upper - p_pitch_lower\n    note_infos.append([name, p, p_pitch, p_pitch_lower, p_pitch_upper, bw])\n\ndf = pd.DataFrame(note_infos, columns=['Note', '$p$', \n                                       '$F_\\mathrm{pitch}(p)$', \n                                       '$F_\\mathrm{pitch}(p-0.5)$', \n                                       '$F_\\mathrm{pitch}(p+0.5)$', \n                                       '$\\mathrm{BW}(p)$'])\n\n\nhtml = df.to_html(index=False, float_format='%.2f')\nhtml = html.replace('<table', '<table style=\"width: 80%\"')\nipd.HTML(html)\n\n\n\n  \n    \n      Note\n      $p$\n      $F_\\mathrm{pitch}(p)$\n      $F_\\mathrm{pitch}(p-0.5)$\n      $F_\\mathrm{pitch}(p+0.5)$\n      $\\mathrm{BW}(p)$\n    \n  \n  \n    \n      C4\n      60\n      261.63\n      254.18\n      269.29\n      15.11\n    \n    \n      C$^\\sharp$4\n      61\n      277.18\n      269.29\n      285.30\n      16.01\n    \n    \n      D4\n      62\n      293.66\n      285.30\n      302.27\n      16.97\n    \n    \n      D$^\\sharp$4\n      63\n      311.13\n      302.27\n      320.24\n      17.97\n    \n    \n      E4\n      64\n      329.63\n      320.24\n      339.29\n      19.04\n    \n    \n      F4\n      65\n      349.23\n      339.29\n      359.46\n      20.18\n    \n    \n      F$^\\sharp$4\n      66\n      369.99\n      359.46\n      380.84\n      21.37\n    \n    \n      G4\n      67\n      392.00\n      380.84\n      403.48\n      22.65\n    \n    \n      G$^\\sharp$4\n      68\n      415.30\n      403.48\n      427.47\n      23.99\n    \n    \n      A4\n      69\n      440.00\n      427.47\n      452.89\n      25.42\n    \n    \n      A$^\\sharp$4\n      70\n      466.16\n      452.89\n      479.82\n      26.93\n    \n    \n      B4\n      71\n      493.88\n      479.82\n      508.36\n      28.53\n    \n    \n      C5\n      72\n      523.25\n      508.36\n      538.58\n      30.23"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#로그-주파수-스펙트로그램",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#로그-주파수-스펙트로그램",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "로그-주파수 스펙트로그램",
    "text": "로그-주파수 스펙트로그램\n\n집합 \\(P(p)\\)를 기반으로 다음의 간단한 풀링 절차를 사용하여 로그-주파수 스펙트로그램 \\(\\mathcal{Y}_\\mathrm{LF}:\\mathbb{Z}\\times [0:127]\\)를 얻는다.\n\n\\[\\mathcal{Y}_\\mathrm{LF}(n,p) := \\sum_{k \\in P(p)}{|\\mathcal{X}(n,k)|^2}\\]\n\n이 절차에 따라 주파수 축은 로그적으로 분할되고 MIDI 피치에 따라 선형으로 레이블이 지정된다.\n\n\ndef f_pitch(p, pitch_ref=69, freq_ref=440.0):\n    \"\"\"Computes the center frequency/ies of a MIDI pitch\n\n    Args:\n        p (float): MIDI pitch value(s)\n        pitch_ref (float): Reference pitch (default: 69)\n        freq_ref (float): Frequency of reference pitch (default: 440.0)\n\n    Returns:\n        freqs (float): Frequency value(s)\n    \"\"\"\n    return 2 ** ((p - pitch_ref) / 12) * freq_ref\n\n\ndef pool_pitch(p, Fs, N, pitch_ref=69, freq_ref=440.0):\n    \"\"\"Computes the set of frequency indices that are assigned to a given pitch\n    \n    Args:\n        p (float): MIDI pitch value\n        Fs (scalar): Sampling rate\n        N (int): Window size of Fourier fransform\n        pitch_ref (float): Reference pitch (default: 69)\n        freq_ref (float): Frequency of reference pitch (default: 440.0)\n\n    Returns:\n        k (np.ndarray): Set of frequency indices\n    \"\"\"\n    lower = f_pitch(p - 0.5, pitch_ref, freq_ref)\n    upper = f_pitch(p + 0.5, pitch_ref, freq_ref)\n    k = np.arange(N // 2 + 1)\n    k_freq = k * Fs / N  # F_coef(k, Fs, N)\n    mask = np.logical_and(lower <= k_freq, k_freq < upper)\n    return k[mask]\n\n\ndef compute_spec_log_freq(Y, Fs, N):\n    \"\"\"Computes a log-frequency spectrogram\n\n    Args:\n        Y (np.ndarray): Magnitude or power spectrogram\n        Fs (scalar): Sampling rate\n        N (int): Window size of Fourier fransform\n\n    Returns:\n        Y_LF (np.ndarray): Log-frequency spectrogram\n        F_coef_pitch (np.ndarray): Pitch values\n    \"\"\"\n    Y_LF = np.zeros((128, Y.shape[1]))\n    for p in range(128):\n        k = pool_pitch(p, Fs, N)\n        Y_LF[p, :] = Y[k, :].sum(axis=0)\n    F_coef_pitch = np.arange(128)\n    return Y_LF, F_coef_pitch\n\n\nY_LF, F_coef_pitch = compute_spec_log_freq(Y, Fs, N)        \n\nfig = plt.figure(figsize=(8, 3))\nplt.imshow(10 * np.log10(eps + Y_LF), origin='lower', aspect='auto', cmap='gray_r', \n           extent=[T_coef[0], T_coef[-1], 0, 127])\nplt.title(\"Pitch-based log-frequency spectrogram\")\nplt.clim([-10, 50])\nplt.ylim([21, 108])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (pitch)')\ncbar = plt.colorbar()\ncbar.set_label('Magnitude (dB)')\nplt.tight_layout()\n\n# Create a Rectangle patch\nrect = matplotlib.patches.Rectangle((29.3, 21), 1.2, 86.5, linewidth=3, edgecolor='r', facecolor='none')\nplt.gca().add_patch(rect)\nplt.text(28, 15, r'$\\mathrm{C3}$', color='r', fontsize='x-large');\n\n\n\n\n\n스펙트로그램를 보면 다음과 같은 몇 가지 흥미로운 사실을 관찰할 수 있다.\n\n일반적으로 높은 음의 소리는 낮은 음의 소리보다 더 깨끗한 고조파 스펙트럼을 가진다. 낮은 음의 경우 신호의 에너지가 높은 고조파에 포함되는 경우가 많지만, 청취자는 여전히 낮은 피치의 소리로 인식할 수 있다.\n스펙트로그램에 표시된 수직 줄무늬(주파수 축을 따라)는 일부 신호 에너지가 스펙트럼의 큰 부분에 퍼져 있음을 나타낸다. 에너지 확산의 주요 원인은 건반 입력(기계적 소음)으로 인한 피아노 음향의 불협화음과 과도 및 공명 효과 때문이다.\n또한 소리의 주파수 내용은 마이크의 주파수 응답에 따라 달라진다. 예를 들어 마이크는 위의 오디오 예제의 경우와 같이 특정 임계값 이상의 주파수만 캡처할 수 있다. 이것은 또한 음 A0(\\(p=21\\))에서 B0(\\(p=32\\))에 대한 기본 주파수에서 가시적으로 에너지가 거의 없는 이유를 설명할 수 있다.\n\n음향적인 속성 외에도 이산 STFT를 기반으로 하는 풀링 전략을 사용할 때 낮은 피치를 제대로 표현하지 못하는 또 다른 이유가 있다. 이산 STFT는 주파수 축의 선형 샘플링을 도입하지만 풀링(pooling) 전략에 사용되는 대역폭은 로그 방식으로 주파수에 따라 달라진다. 그 결과, 집합 \\(P(p)\\)는 매우 적은 수의 스펙트럼 계수만 포함하거나 작은 \\(p\\) 값에 대해서는 비어 있을 수도 있다(위 그림에서 가로 흰색 줄무늬의 이유임).\n\n\nprint('Sampling rate: Fs = ', Fs)\nprint('Window size: N = ', N)\nprint('STFT frequency resolution (in Hz): Fs/N = %4.2f' % (Fs / N))\n\nfor p in [76, 64, 52, 40, 39, 38]:\n    print('Set P(%d) = %s' % (p, pool_pitch(p, Fs, N)))\n\nSampling rate: Fs =  22050\nWindow size: N =  4096\nSTFT frequency resolution (in Hz): Fs/N = 5.38\nSet P(76) = [119 120 121 122 123 124 125 126]\nSet P(64) = [60 61 62 63]\nSet P(52) = [30 31]\nSet P(40) = [15]\nSet P(39) = []\nSet P(38) = [14]"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#크로마그램-chromagram",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#크로마그램-chromagram",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "크로마그램 (Chromagram)",
    "text": "크로마그램 (Chromagram)\n\n이제 음색(timbre)과 악기에 따른 로그-주파수 스펙트로그램의 견고성을 높이는 전략에 대해 논의해본다. 하나 또는 여러 옥타브 차이의 피치에 해당하는 피치 밴드를 적절하게 결합하는 것이다.\n음정에 대한 인간의 인식은 두 음정이 한 옥타브 차이가 나는 경우 “색상”(유사한 하모닉 역할을 함)이 유사한 것으로 인식된다는 점에서 주기적이다. 이 관찰을 기반으로 피치는 톤 높이(tone height)와 크로마(chroma)라고 하는 두 가지 구성 요소로 분리될 수 있다. 톤 높이는 다음의 집합에 포함된 각 피치 스펠링 속성에 대한 옥타브 수와 크로마를 나타낸다.\n\n\\(\\{ \\mathrm{C},\\mathrm{C}^\\sharp,\\mathrm{D},\\mathrm{D}^\\sharp,\\ldots,\\mathrm{B} \\}\\)\n\n\n(크로마와 피치 클래스에 대해서는 2.1.악보 에서 다룬바 있다.)\n\n크로마 값을 enumerate하면서 이 집합을 \\([0:11]\\)로 식별할 수 있다. 여기서 \\(0\\)는 크로마 \\(\\mathrm{C}\\), \\(1\\)는 \\(\\mathrm{C}^\\sharp\\) 등을 나타낸다. 피치 클래스는 동일한 크로마를 공유하는 모든 피치의 집합으로 정의된다.\n크로마 특징의 기본 아이디어는 주어진 피치 클래스와 관련된 모든 스펙트럼 정보를 단일 계수로 집계하는 것이다. 피치 기반 로그-주파수 스펙트로그램 \\(\\mathcal{Y}_\\mathrm{LF}:\\mathbb{Z}\\times[0:127]\\to \\mathbb{R}_{\\geq 0}\\)가 주어지면, 크로마 표현 또는 크로마그램 \\(\\mathbb{Z}\\times[0:11]\\to \\mathbb{R}_{\\geq 0}\\)는 다음의 동일한 채도에 속한 모든 피치 계수를 더해 구할 수 있다.\n\n\\(\\mathcal{C}(n,c) := \\sum_{\\{p \\in [0:127]\\,:\\,p\\,\\mathrm{mod}\\,12 = c\\}}{\\mathcal{ Y}_\\mathrm{LF}(n,p)}\\) for \\(c\\in[0:11]\\).\n\n다음 코드 예에서 크로마 피쳐의 순환적(cyclic) 특성을 볼 수 있는 크로마틱 스케일의 크로마그램을 생성한다. 옥타브 등가(equivalence)로 인해 크로마틱 스케일의 증가하는 음은 크로마 축을 둘러싼다(wrapped around).\n로그-주파수 스펙트로그램과 마찬가지로 오디오 예제의 결과 크로마그램은 특히 낮은 음에 대해 노이즈가 많다. 게다가 고조파가 존재하기 때문에 에너지는 일반적으로 한 번에 하나의 음을 연주할 때에도 다양한 크로마 밴드에 분산된다.\n예를 들어 C3 음표를 연주하면 세 번째 배음(harmonic)은 G4에 해당하고 다섯 번째 배음은 E5에 해당한다. 따라서 C3음을 피아노로 연주할 때 크로마 밴드 \\(\\mathrm{C}\\)뿐만 아니라 크로마 밴드 \\(\\mathrm{G}\\) 및 \\(\\mathrm{E}\\)도 신호의 에너지의 상당한 부분을 포함하고 있다.\n\n\ndef compute_chromagram(Y_LF):\n    \"\"\"Computes a chromagram\n    \n    Args:\n        Y_LF (np.ndarray): Log-frequency spectrogram\n\n    Returns:\n        C (np.ndarray): Chromagram\n    \"\"\"\n    C = np.zeros((12, Y_LF.shape[1]))\n    p = np.arange(128)\n    for c in range(12):\n        mask = (p % 12) == c\n        C[c, :] = Y_LF[mask, :].sum(axis=0)\n    return C\n\n\nC = compute_chromagram(Y_LF)\n\nfig = plt.figure(figsize=(8, 3))\nplt.title('Chromagram')\nchroma_label = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\nplt.imshow(10 * np.log10(eps + C), origin='lower', aspect='auto', cmap='gray_r', \n           extent=[T_coef[0], T_coef[-1], 0, 12])\nplt.clim([10, 50])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Chroma')\ncbar = plt.colorbar()\ncbar.set_label('Magnitude (dB)')\nplt.yticks(np.arange(12) + 0.5, chroma_label)\nplt.tight_layout()\n\nrect = matplotlib.patches.Rectangle((29.3, 0.0), 1.2, 12, linewidth=3, edgecolor='r', facecolor='none')\nplt.gca().add_patch(rect)\nplt.text(28.5, -1.2, r'$\\mathrm{C3}$', color='r', fontsize='x-large');\n\n\n\n\nExample: Burgmüller\n\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F05.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nN = 4096\nH = 512\nX, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H)\neps = np.finfo(float).eps\nY = np.abs(X) ** 2\nY_LF, F_coef_pitch = compute_spec_log_freq(Y, Fs, N)\nC = compute_chromagram(Y_LF)\n\nfig = plt.figure(figsize=(8,3))\nplt.imshow(10 * np.log10(eps + Y_LF), origin='lower', aspect='auto', cmap='gray_r', \n           extent=[T_coef[0], T_coef[-1], 0, 128])\nplt.clim([-10, 50])\nplt.ylim([55, 92])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (pitch)')\ncbar = plt.colorbar()\ncbar.set_label('Magnitude (dB)')\nplt.tight_layout()\n\nfig = plt.figure(figsize=(8, 2.5))\nplt.imshow(10 * np.log10(eps + C), origin='lower', aspect='auto', cmap='gray_r', \n           extent=[T_coef[0], T_coef[-1], 0, 12])\nplt.clim([0, 50])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Chroma')\ncbar = plt.colorbar()\ncbar.set_label('Magnitude (dB)')\nplt.yticks(np.arange(12) + 0.5, chroma_label)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n#librosa example \nN = 4096\nH = 512\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F05.wav\")\nC = librosa.feature.chroma_stft(y=x, tuning=0, norm=None, hop_length=H, n_fft=N)\nplt.figure(figsize=(8, 2))\nlibrosa.display.specshow(10 * np.log10(eps + C), x_axis='time', \n                         y_axis='chroma', sr=Fs, hop_length=H)\nplt.colorbar();"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축-함수-compression-function",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축-함수-compression-function",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "압축 함수 (Compression Function)",
    "text": "압축 함수 (Compression Function)\n\n음악 신호 처리에서 스펙트로그램이나 크로마그램의 문제는 그 값이 큰 동적 범위(dynamic range)를 갖는다는 것이다. 결과적으로 작지만 여전히 관련성이 높은 값이 큰 값에 의해 가려질 수 있다. 따라서 데시벨 단위(decibel scale)를 사용하는 경우가 많다. 큰 값과 작은 값의 차이를 줄이고 작은 값을 향상시키는 효과로 이러한 불일치의 균형을 맞추는 것이다. 보다 일반적으로 로그 압축(=컴프레션) 이라고 하는 단계인 다른 유형의 로그-기반 함수를 적용할 수 있습니다.\n\\(\\gamma\\in\\mathbb{R}_{>0}\\)를 양의 상수로 두고, 다음과 같이 함수 \\(\\Gamma_\\gamma:\\mathbb{R}_{>0} \\to \\mathbb{R}_{>0}\\)를 정의할 수 있다.\n\n\\(\\Gamma_\\gamma(v):=\\log(1+ \\gamma \\cdot v)\\) for some positive value \\(v\\in\\mathbb{R}_{>0}\\)\n\n\\(\\mathrm{dB}\\) 함수와 달리 \\(\\Gamma_\\gamma\\) 함수는 모든 양수 값 \\(v\\in\\mathbb{R}_{>0}\\)에 대해 양수 값 \\(\\Gamma_\\gamma(v)\\)를 생성한다.\n압축 정도는 상수 \\(\\gamma\\)로 조정할 수 있다. \\(\\gamma\\)가 클수록 압축이 커진다.\n\n\ndef log_compression(v, gamma=1.0):\n    \"\"\"Logarithmically compresses a value or array\n\n    Args:\n        v (float or np.ndarray): Value or array\n        gamma (float): Compression factor (Default value = 1.0)\n\n    Returns:\n        v_compressed (float or np.ndarray): Compressed value or array\n    \"\"\"\n    return np.log(1 + gamma * v)\n\n\nv = np.arange(1001) / 100\n\nplt.figure(figsize=(4, 3.5))\nplt.plot(v, v, color='black', linestyle=':', label='Identity')\nplt.plot(v, log_compression(v, gamma=1), color='blue', label='$\\gamma$ = 1')\nplt.plot(v, log_compression(v, gamma=10), color='gray', label='$\\gamma$ = 10')\nplt.plot(v, log_compression(v, gamma=100), color='red', label='$\\gamma$ = 100')\nplt.xlabel('Original values')\nplt.ylabel('Compressed values')\nplt.xlim([v[0], v[-1]])\nplt.ylim([v[0], v[-1]])\n# plt.tick_params(direction='in')\nplt.legend(loc='upper left', fontsize=12)\nplt.tight_layout()"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축된-스펙트로그램-compressed-spectrogram",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축된-스펙트로그램-compressed-spectrogram",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "압축된 스펙트로그램 (Compressed Spectrogram)",
    "text": "압축된 스펙트로그램 (Compressed Spectrogram)\n\n스펙트로그램과 같은 양수 값을 가진 표현의 경우 \\(\\Gamma_\\gamma\\) 함수를 각 값에 적용하여 압축된 버전을 얻는다. 예를 들어, 스펙트로그램 \\(\\mathcal{Y}\\)의 경우 압축된 버전은 다음과 같이 정의된 concatenation \\(\\Gamma_\\gamma \\circ \\mathcal{Y}\\)이다.\n\n\\((\\Gamma_\\gamma\\circ \\mathcal{Y})(n,k):=\\log(1+ \\gamma \\cdot \\mathcal{Y}(n,k))\\)\n\n여기서 \\(n\\)은 시간 프레임 파라미터이고 \\(k\\)는 주파수 빈(bin) 파라미터이다. \\(\\gamma\\)의 적절한 선택은 데이터 특성과 염두에 둔 적용에 따라 크게 달라진다. 특히, 잡음이 있는 경우, 약하지만 관련된 신호 구성 요소를 향상시키는 것과 바람직하지 않은 잡음 구성 요소를 너무 많이 증폭시키지 않는 것 사이에서 적절한 균형을 찾아야 한다.\n\n\nx, Fs = librosa.load(\"../audio/piano_c4.wav\")\n\nN = 2048\nH = 512\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nT_coef = np.arange(X.shape[1]) * H / Fs\nK = N // 2\nF_coef = np.arange(K + 1) * Fs / N\nY = np.abs(X) ** 2\n\nplt.figure(figsize=(10, 3))\nextent = [T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\ngamma_set = [0, 1, 100, 10000]\nM = len(gamma_set)\nY = np.abs(X)\n\nfor m in range(M):\n    ax = plt.subplot(1, M, m + 1)\n    gamma = gamma_set[m]\n    if gamma == 0:\n        Y_compressed = Y\n        title = 'No compression'\n    else:\n        Y_compressed = log_compression(Y, gamma=gamma)\n        title = '$\\gamma$=%d' % gamma\n    plt.imshow(Y_compressed, cmap='gray_r', aspect='auto', origin='lower', extent=extent)\n    plt.xlabel('Time (seconds)')\n    plt.ylim([0, 4000])\n    plt.clim([0, Y_compressed.max()])\n    plt.ylabel('Frequency (Hz)')\n    plt.colorbar()\n    plt.title(title)\n\nplt.tight_layout()\n\n\n\n\n\n원본 스펙트로그램에서는 수평선이 거의 보이지 않지만 압축된 버전에서는 명확하게 나타난다. 단점으로는 스펙트로그램을 압축할 때 잡음과 같은 사운드 구성 요소도 향상된다는 것이다. 잡음이 있는 경우, 약하지만 관련된 신호 구성 요소를 강화하는 것과 바람직하지 않은 잡음 구성 요소를 너무 많이 증폭하지 않는 것 사이에서 적절한 균형을 찾아야 한다."
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축된-크로마그램-compressed-chromagram",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#압축된-크로마그램-compressed-chromagram",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "압축된 크로마그램 (Compressed Chromagram)",
    "text": "압축된 크로마그램 (Compressed Chromagram)\n\n다음으로 chromagram \\(\\mathcal{C}\\) 및 압축 버전 \\(\\Gamma_\\gamma \\circ \\mathcal{C}\\)를 생각해보자.\n\n\\((\\Gamma_\\gamma\\circ \\mathcal{C})(n,c):=\\log(1+ \\gamma \\cdot \\mathcal{C}(n,c))\\)\n\n\n\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F08_C-major-scale_pause.wav\")\n\nN = 4096\nH = 512\nC = librosa.feature.chroma_stft(y=x, tuning=0, norm=None, hop_length=H, n_fft=N)\nC = C / C.max()\n\nplt.figure(figsize=(6, 8))\ngamma_set = [0, 10, 1000, 100000]\nM = len(gamma_set)\nY = np.abs(X)\n\nfor m in range(M):\n    ax = plt.subplot(M, 1, m + 1)\n    gamma = gamma_set[m]\n    if gamma == 0:\n        C_compressed = C\n        title = 'No compression'\n    else:\n        C_compressed = log_compression(C, gamma=gamma)\n        title = '$\\gamma$=%d' % gamma\n    librosa.display.specshow(C_compressed, x_axis='time', \n                             y_axis='chroma', cmap='gray_r', sr=Fs, hop_length=H)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Chroma')\n    plt.clim([0, np.max(C_compressed)])\n    plt.title(title)\n    plt.colorbar()\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#노름norm",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#노름norm",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "노름(Norm)",
    "text": "노름(Norm)\n\n여태까지 스펙트럼 피쳐(spectral features), 로그-주파수 스펙트럼 피쳐 및 크로마 피쳐(chroma feautres)를 비롯한 다양한 기능 표현을 소개했다. 이러한 피쳐는 일반적으로 어떤 차원 \\(K\\in\\mathbb{N}\\)의 유클리드 공간의 요소이다.\n앞으로 이 피쳐 공간을 \\(\\mathcal{F}=\\mathbb{R}^K\\)로 표시한다. 종종 피처에 크기나 일종의 길이를 할당하는 측정이 필요하며, 이는 norm이라는 개념으로 이어진다. 수학 용어로 벡터 공간(예: \\(\\mathcal{F}=\\mathbb{R}^K\\))이 주어지면 norm은 다음의 세 가지 속성을 만족하는 음이 아닌 함수 \\(p:\\mathcal{F} \\to \\mathbb{R}_{\\geq 0}\\)이다:\n\nTriangle inequality: \\(p(x + y) \\leq p(x) + p(y)\\) for all \\(x,y\\in\\mathcal{F}\\).\nPositive scalability: \\(p(\\alpha x) = |\\alpha| p(x)\\) for all \\(x\\in\\mathcal{F}\\) and \\(\\alpha\\in\\mathbb{R}\\).\nPositive definiteness: \\(p(x) = 0\\) if an only if \\(x=0\\).\n\n벡터 \\(x\\in\\mathcal{F}\\)에 대한 숫자 \\(p(x)\\)를 벡터의 길이라고 한다. 또한 \\(p(x)=1\\)인 벡터를 단위 벡터라고 한다.\n여러 norm이 있음에 유의하자. 다음에서는 벡터 공간 \\(\\mathcal{F}=\\mathbb{R}^K\\)만 고려하고, 세 가지 norm을 살펴보자.\n\n\n유클리드 (Euclidean) 노름\n\n가장 보편적인 것은 유클리드(Euclidean) norm (or \\(\\ell^2\\)-norm)이다. 이 norm은 \\(\\|\\cdot\\|_2\\)로 표기되며 다음과 같이 정의할 수 있다.\n\n\\(||x||_2 = \\sqrt{\\langle x\\mid x\\rangle} = \\Big(\\sum_{k=1}^K x(k)^2\\Big)^{1/2}\\)\nfor a vector \\(x=(x(1),x(2),\\ldots,x(K))^\\top \\in\\mathbb{R}^K\\).\n\n유클리드 norm \\(||x||_2\\)는 원점 \\((0,0)\\)에서 점 \\(x\\)까지의 일반적인 거리를 나타낸다.\n유클리드 norm에 관한 단위 벡터 집합은 \\(S^{K-1}\\subset\\mathbb{R}^K\\)로 표시되는 단위 구(unit sphere) 를 형성한다.\n\\(K=2\\)인 경우 단위구는 원점이 \\((0,0)\\)인 단위원(unit circle) \\(S^1\\)이다.\n\n\ndef plot_vector(x,y, color='k', start=0, linestyle='-'):    \n    return plt.arrow(np.real(start), np.imag(start), x, y, \n                     linestyle=linestyle, head_width=0.05, \n                     fc=color, ec=color, overhang=0.3, length_includes_head=True)\n\n\ndef norm_Euclidean(x):\n    p = np.sqrt(np.sum(x ** 2))\n    return p\n\nfig, ax = plt.subplots(figsize=(3, 3))\nplt.grid()  \nplt.xlim([-1.5, 1.5])\nplt.ylim([-1.5, 1.5])\nplt.xlabel('Axis of first coordinate')\nplt.ylabel('Axis of second coordinate')\n\ncircle = plt.Circle((0, 0), 1, color='r', fill=0, linewidth=2)  \nax.add_artist(circle)\n\nx_list = [np.array([[1, 1], [0.6, 1.1]]),\n          np.array([[-np.sqrt(2)/2, np.sqrt(2)/2], [-1.45, 0.85]]),\n          np.array([[0, -1], [-0.4, -1.2]])]\n\nfor y in x_list:\n    x = y[0, :]\n    p = norm_Euclidean(x)\n    color = 'r' if p == 1 else 'k'\n    plot_vector(x[0], x[1], color=color)\n    plt.text(y[1, 0], y[1, 1], r'$||x||_2=%0.3f$'% p, size='12', color=color) \n\n\n\n\n\n\n맨해튼 (Manhattan) 노름\n\n맨해튼(Manhattan) norm (or \\(\\ell^1\\)-norm)에서 벡터의 길이는 벡터의 데카르트 좌표의 절대값을 합산하여 측정된다. 맨해튼 norm (\\(\\|\\cdot\\|_1\\))은 다음과 같이 정의된다,\n\n\\(||x||_1 = \\sum_{k=1}^K |x(k)|\\)\nfor a vector \\(x=(x(1),x(2),\\ldots,x(K))^\\top \\in\\mathbb{R}^K\\).\n\n맨해튼 norm에서 단위 벡터 집합은 좌표축에 대해 45도 각도로 향하는 면이 있는 정사각형을 형성한다. \\(K=2\\)인 경우 단위원은 \\(|x(1)| + |x(2)| = 1\\)로 설명된다.\n\n\ndef norm_Manhattan(x):\n    p = np.sum(np.abs(x))\n    return p\n    \nfig, ax = plt.subplots(figsize=(3, 3))\nplt.grid()  \nplt.xlim([-1.5, 1.5])\nplt.ylim([-1.5, 1.5])\nplt.xlabel('Axis of first coordinate')\nplt.ylabel('Axis of second coordinate')\n\nplt.plot([-1, 0, 1, 0, -1], [0, 1, 0, -1, 0], color='r', linewidth=2)\n\nfor y in x_list:\n    x = y[0, :]\n    p = norm_Manhattan(x)\n    color = 'r' if p == 1 else 'k'\n    plot_vector(x[0], x[1], color=color)\n    plt.text(y[1, 0], y[1, 1], r'$||x||_1=%0.3f$' % p, size='12', color=color)\n\n\n\n\n\n\n최대 (Maximum) 노름\n\n최대(maximum) norm (or \\(\\ell^\\infty\\)-norm)에서, 벡터의 길이는 최대 절대 데카르트 좌표로 측정된다. maximum norm (\\(\\|\\cdot\\|_\\infty\\))은 다음과 같이 정의된다.\n\n\\(||x||_\\infty = \\max\\big\\{|x(k)| \\,\\,\\mathrm{for}\\,\\, k\\in[1:K] \\big\\}\\)\nfor a vector \\(x=(x(1),x(2),\\ldots,x(K))^\\top \\in\\mathbb{R}^K\\).\n\n단위 벡터 집합은 가장자리 길이가 2인 hypercube의 표면을 형성한다.\n\n\ndef norm_max(x):\n    p = np.max(np.abs(x))\n    return p\n    \nfig, ax = plt.subplots(figsize=(3, 3))\nplt.grid()  \nplt.xlim([-1.5, 1.5])\nplt.ylim([-1.5, 1.5])\nplt.xlabel('Axis of first coordinate')\nplt.ylabel('Axis of second coordinate')\n\nplt.plot([-1, -1, 1, 1, -1], [-1, 1, 1, -1, -1], color='r', linewidth=2)\n\nfor y in x_list:\n    x = y[0, :]\n    p = norm_max(x)\n    color = 'r' if p == 1 else 'k'\n    plot_vector(x[0], x[1], color=color)\n    plt.text(y[1, 0], y[1, 1], r'$||x||_\\infty=%0.3f$' % p, size='12', color=color)"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#피쳐-정규화-feature-normalization-1",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#피쳐-정규화-feature-normalization-1",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "피쳐 정규화 (Feature Normalization)",
    "text": "피쳐 정규화 (Feature Normalization)\n\n음악 처리에서 오디오 녹음은 일반적으로 특징(feature) 표현으로 변환된다. 특징 표현은 \\(n\\in[1:N]\\)에 대한 특징 벡터 \\(x_n \\in \\mathcal{F}=\\mathbb{R}^K\\)가 있는 시퀀스 \\(X=(x_1,x_2,\\ldots x_N)\\)로 종종 구성된다.\n특징 표현을 더 잘 비교하기 위해 종종 정규화(normalization)를 적용한다.\n한 가지 정규화 전략은 적절한 norm \\(p\\)를 선택한 다음 각 특징 벡터 \\(x_n\\in\\mathcal{F}\\)를 \\(x_n/p(x_n)\\)로 바꾸는 것이다. 이 전략은 \\(x_n\\)이 0이 아닌 벡터인 한 작동한다. 정규화된 특징 벡터 \\(x_n/p(x_n)\\)는 norm \\(p\\)에 대한 단위 벡터이다.\n예를 들어 \\(X=(x_1,x_2,\\ldots x_N)\\)가 크로마 특징의 시퀀스인 경우를 생각해보자. 이 경우 특징 공간 \\(\\mathcal{F}=\\mathbb{R}^K\\)의 차원은 \\(K=12\\)이다. 위에서 설명한 정규화 절차는 각 크로마 벡터를 정규화된 버전으로 대체한다.\n결과적으로 정규화된 크로마 벡터는 12개의 크로마 계수 크기의 절대 차이가 아닌 상대만 차이만 인코딩한다. 직관적으로 말하면, 정규화는 다이나믹(dynamics) 또는 사운드 강도(sound intensity) 의 차이에 일종의 불변성(invariance) 을 도입한다.\n정규화 절차는 \\(p(x)\\not= 0\\)인 경우에만 가능하다. 실제 녹음 시작 전이나 긴 일시 중지 중에 무음 구간에서 발생할 수 있는 매우 작은 \\(p(x)\\) 값에 대해 정규화 할 시 다소 무작위적이고 무의미한 크로마 값 분포로 이어질 수 있다.\n따라서 \\(p(x)\\)가 특정 임계값 아래로 떨어지면, \\(p(x)\\)로 나누는 대신 \\(x\\) 벡터를 norm 1의 uniform 벡터와 같은 표준(standard) 벡터로 대체할 수 있다.\n수학적으로 이 정규화 절차는 다음과 같이 설명할 수 있다.\n\\(S^{K-1}\\subset\\mathbb{R}^{K}\\)를 norm 1의 모든 K-차원 벡터를 포함하는 단위 구라고 하자. 그런 다음 주어진 임계값 \\(\\varepsilon>0\\)에 대해 프로젝션 연산자 \\(\\pi^{\\varepsilon}:\\mathbb{R}^{K}\\to S^{K-1}\\)를 다음과 같이 정의한다.\n\n\\(\\pi^{\\varepsilon}(x):= \\left\\{\\begin{array}{cl} x / p(x) & \\,\\,\\,\\mbox{if}\\,\\, p(x) > \\varepsilon\\\\  u & \\,\\,\\,\\mbox{if}\\,\\, p(x) \\leq \\varepsilon \\end{array}\\right.\\)\n\\(u=v/p(v)\\) 는 all-one vector \\(v=(1,1,\\ldots,1)^\\top\\in\\mathbb{R}^K\\)의 unit vector\n\n이 연산자를 기반으로 각 chroma 벡터 \\(x\\)는 \\(\\pi^{\\varepsilon}(x)\\)로 대체될 수 있다.\n\\(\\varepsilon\\) 임계값은 신중하게 선택해야 하는 파라미터이다. 응용에 따라 적절한 값을 선택해야 한다.\n정규화에 대한 많은 변형도 생각할 수 있다. 분명히 정규화는 선택한 norm과 임계값에 따라 달라진다. 또한 균등하게 분산된 단위 벡터 \\(u\\)를 사용하는 대신, 작은 크기의 특징 벡터를 나타내는 다른 벡터를 사용할 수도 있다.\n\n\ndef normalize_feature_sequence(X, norm='2', threshold=0.0001, v=None):\n    \"\"\"Normalizes the columns of a feature sequence\n\n    Args:\n        X (np.ndarray): Feature sequence\n        norm (str): The norm to be applied. '1', '2', 'max' or 'z' (Default value = '2')\n        threshold (float): An threshold below which the vector ``v`` used instead of normalization\n            (Default value = 0.0001)\n        v (float): Used instead of normalization below ``threshold``. If None, uses unit vector for given norm\n            (Default value = None)\n\n    Returns:\n        X_norm (np.ndarray): Normalized feature sequence\n    \"\"\"\n    assert norm in ['1', '2', 'max', 'z']\n\n    K, N = X.shape\n    X_norm = np.zeros((K, N))\n\n    if norm == '1':\n        if v is None:\n            v = np.ones(K, dtype=np.float64) / K\n        for n in range(N):\n            s = np.sum(np.abs(X[:, n]))\n            if s > threshold:\n                X_norm[:, n] = X[:, n] / s\n            else:\n                X_norm[:, n] = v\n\n    if norm == '2':\n        if v is None:\n            v = np.ones(K, dtype=np.float64) / np.sqrt(K)\n        for n in range(N):\n            s = np.sqrt(np.sum(X[:, n] ** 2))\n            if s > threshold:\n                X_norm[:, n] = X[:, n] / s\n            else:\n                X_norm[:, n] = v\n\n    if norm == 'max':\n        if v is None:\n            v = np.ones(K, dtype=np.float64)\n        for n in range(N):\n            s = np.max(np.abs(X[:, n]))\n            if s > threshold:\n                X_norm[:, n] = X[:, n] / s\n            else:\n                X_norm[:, n] = v\n\n    if norm == 'z':\n        if v is None:\n            v = np.zeros(K, dtype=np.float64)\n        for n in range(N):\n            mu = np.sum(X[:, n]) / K\n            sigma = np.sqrt(np.sum((X[:, n] - mu) ** 2) / (K - 1))\n            if sigma > threshold:\n                X_norm[:, n] = (X[:, n] - mu) / sigma\n            else:\n                X_norm[:, n] = v\n\n    return X_norm\n\n\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F08_C-major-scale_pause.wav\")\n\nN, H = 4096, 512\nC = librosa.feature.chroma_stft(y=x, sr=Fs, tuning=0, norm=None, hop_length=H, n_fft=N)\nC = C / C.max()\n\nfigsize=(8, 3)\nplot_chromagram(C, Fs=Fs/H, figsize=figsize, title='Original chromagram')\n\nthreshold = 0.000001\nC_norm = normalize_feature_sequence(C, norm='2', threshold=threshold)\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, \n        title = r'Normalized chromgram ($\\ell^2$-norm, $\\varepsilon=%f$)' % threshold)\n\nthreshold = 0.01\nC_norm = normalize_feature_sequence(C, norm='2', threshold=threshold)\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, \n        title = r'Normalized chromgram ($\\ell^2$-norm, $\\varepsilon=%0.2f$)' % threshold)\n\nthreshold = 0.01\nC_norm = normalize_feature_sequence(C, norm='1', threshold=threshold)\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, \n        title = r'Normalized chromgram ($\\ell^1$-norm, $\\varepsilon=%0.2f$)' % threshold)\n\nthreshold = 0.01\nC_norm = normalize_feature_sequence(C, norm='max', threshold=threshold)\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, \n        title = r'Normalized chromgram (maximum norm, $\\varepsilon=%0.2f$)' % threshold)\n\nthreshold = 0.01\nv = np.zeros(C.shape[0])\nC_norm = normalize_feature_sequence(C, norm='max', threshold=threshold, v=v)\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, \n        title = r'Normalized chromgram (maximum norm, $v$ is zero vector)');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n정규점수 (Standard score)\n\n피쳐 \\(x=(x(1),x(2),\\ldots,x(K))^\\top \\in\\mathbb{R}^K\\)의 평균(mean) \\(\\mu(x)\\) and 분산(variance) \\(\\sigma(x)\\)을 사용해 standard score를 고려하자.\n\n\\[z(x) = \\frac{x-\\mu(x)}{\\sigma(x)}\\]\n\ndef normalize_feature_sequence_z(X, threshold=0.0001, v=None):\n    K, N = X.shape\n    X_norm = np.zeros((K, N))\n    \n    if v is None:\n        v = np.zeros(K)\n        \n    for n in range(N):\n        mu = np.sum(X[:, n]) / K\n        sigma = np.sqrt(np.sum((X[:, n] - mu) ** 2) / (K - 1))\n        if sigma > threshold:\n            X_norm[:, n] = (X[:, n] - mu) / sigma\n        else:\n            X_norm[:, n] = v  \n            \n    return X_norm\n\n\nthreshold = 0.0000001\nC_norm = normalize_feature_sequence_z(C, threshold=threshold)\nm = np.max(np.abs(C_norm))\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, cmap='seismic', clim=[-m, m],\n        title = r'Normalized chromgram (standard score, $\\varepsilon=%0.7f$)' % threshold)\n\nthreshold = 0.01\nC_norm = normalize_feature_sequence_z(C, threshold=threshold)\nm = np.max(np.abs(C_norm))\nplot_chromagram(C_norm, Fs=Fs/H, figsize=figsize, cmap='seismic', clim=[-m, m],\n        title = r'Normalized chromgram (standard score, $\\varepsilon=%0.2f$)' % threshold);"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#템포-스무딩과-다운샘플링-temporal-smoothing-and-downsampling-1",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#템포-스무딩과-다운샘플링-temporal-smoothing-and-downsampling-1",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "템포 스무딩과 다운샘플링 (Temporal Smoothing and Downsampling)",
    "text": "템포 스무딩과 다운샘플링 (Temporal Smoothing and Downsampling)\n\n특정 음악 검색 응용의 경우 이러한 크로마그램이 너무 상세할 수 있다. 특히 이들 간의 유사도를 더욱 높이는 것이 바람직할 수 있다. 이제 후처리 단계에서 적용되는 스무딩(smoothing)(=평활화) 절차를 통해 이것이 어떻게 달성될 수 있는지 보자. 시간이 지남에 따라 각 크로마 차원에 대해 일종의 로컬 평균을 계산한다.\n보다 정확하게는, \\(X=(x_1,x_2, ..., x_N)\\)를 \\(x_n\\in\\mathbb{R}^K\\) for \\(n\\in[1:N]\\)인 피쳐 시퀀스라고 하고, \\(w\\)는 \\(L\\in\\mathbb{N}\\) 길이의 직사각형 윈도우(rectangular window)라고 하자. 그런 다음 각 \\(k\\in[1:K]\\)에 대해 \\(w\\)와 시퀀스 \\((x_1(k), x_2(k),\\ldots, x_N(k))\\) 사이의 컨볼루션(convolution)을 계산한다. 중앙보기(“centered view”)를 가정하면 컨볼루션 길이 \\(N\\)의 중앙 부분만 유지한다. 결과는 동일한 차원 \\(K\\times N\\)의 평활화된 피쳐 시퀀스이다.\n다음에서 scipy.signal.convolve 함수를 사용하여 2D 컨볼루션을 계산한다. 윈도우(커널이라고도 함)에 대해 차원을 \\(1\\times L\\)로 설정하면 대역별(bandwise) 1D 컨벌루션이 생성된다.\nmode='same' 파라미터를 사용하면 중앙보기(centered view)가 적용된다.\n윈도우 \\(w\\)는 Hann 윈도우와 같은 다른 윈도우 유형을 사용할 수도 있다.\n직사각형 윈도우 또는 Hann 윈도우를 사용하여 템포 스무딩을 적용하는 것은 특징 표현에서 빠른 템포 변동을 감쇠시키는 대역 저역 통과 필터링 (lowpass filtering) 으로 간주될 수 있다.\n종종 후속 처리 및 분석 단계의 효율성을 높이기 위해, 모든 \\(H^\\mathrm{th}\\) 피쳐만 유지하여 평활화된 표현을 단순화(decimation)하며, 여기서 \\(H\\in\\mathbb{N}\\)는 적절한 상수(일반적으로 창 길이 \\(L\\)보다 훨씬 작음)이다. 다운샘플링(donwsampling) 이라고도 하는 이 단순화는 \\(H\\)개의 팩터로 피쳐 레이트(feature rate)를 감소시킨다.\n다음 그림은 위의 쇼팽의 예에서 스무딩 절차의 효과를 보여준다. 길이가 \\(L=11\\)인 직사각형 윈도우로 평활화한 후 유클리드 norm을 사용하여 피쳐 정규화를 적용하고 마지막으로 \\(H=2\\)만큼 다운샘플링을 적용한다.\n\n\ndef smooth_downsample_feature_sequence(X, Fs, filt_len=41, down_sampling=10, w_type='boxcar'):\n    \"\"\"Smoothes and downsamples a feature sequence. Smoothing is achieved by convolution with a filter kernel\n\n    Args:\n        X (np.ndarray): Feature sequence\n        Fs (scalar): Frame rate of ``X``\n        filt_len (int): Length of smoothing filter (Default value = 41)\n        down_sampling (int): Downsampling factor (Default value = 10)\n        w_type (str): Window type of smoothing filter (Default value = 'boxcar')\n\n    Returns:\n        X_smooth (np.ndarray): Smoothed and downsampled feature sequence\n        Fs_feature (scalar): Frame rate of ``X_smooth``\n    \"\"\"\n    filt_kernel = np.expand_dims(signal.get_window(w_type, filt_len), axis=0)\n    X_smooth = signal.convolve(X, filt_kernel, mode='same') / filt_len\n    X_smooth = X_smooth[:, ::down_sampling]\n    Fs_feature = Fs / down_sampling\n    return X_smooth, Fs_feature\n\n\nfilt_len = 11\ndown_sampling = 2\nC_smooth_dict = {}    \nfor name in fn_wav_dict:   \n    C_smooth, Fs_C_smooth = smooth_downsample_feature_sequence(C_dict[name], Fs_C, \n                                        filt_len=filt_len, down_sampling=down_sampling)\n    C_smooth_dict[name] = normalize_feature_sequence(C_smooth, norm='2', threshold=threshold)\n    plot_chromagram(C_smooth_dict[name], Fs_C_smooth, figsize=figsize, \n                             ylabel=name, title='',  xlabel='', chroma_yticks=yticks)"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#중앙값-필터링medain-filtering을-통한-스무딩",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#중앙값-필터링medain-filtering을-통한-스무딩",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "중앙값 필터링(medain filtering)을 통한 스무딩",
    "text": "중앙값 필터링(medain filtering)을 통한 스무딩\n\n로컬(local) 평균 필터를 적용하는 것의 대안으로 중앙값(median) 필터링을 사용할 수 있다. 이 필터를 사용하면 날카로운 전환을 더 잘 보존하면서 약간의 평활화 효과도 얻을 수 있다. 유한한 숫자 목록의 중앙값은 숫자의 절반이 그값보다 낮고 절반이 그값보다 높은 속성을 가진 숫자 값이다. 중앙값은 가장 낮은 값에서 가장 높은 값으로 모든 숫자를 정렬하고 가운데 값을 선택하여 계산한다.\n중앙값 필터링의 아이디어는 시퀀스의 각 항목을 인접 항목의 중앙값으로 바꾸는 것이다. 이웃의 크기는 적용된 중간 필터의 길이인 \\(L\\in\\mathbb{N}\\) 파라미터에 의해 결정된다. 피쳐 벡터 \\(x_n\\in\\mathbb{R}^K\\)의 시퀀스 \\(X=(x_1,x_2, ..., x_N)\\)가 주어지면, 각 \\(k\\in[1:K]\\)에 대해 각 차원에 대한 중앙값 필터링을 적용합니다(평균 평활화에서 수행한 것과 동일).\n다음 구현에서는 scipy.signal.medfilt2d 함수를 사용하여 2D 중앙값 필터링을 계산한다. 커널 크기 \\(1\\times L\\)로 중앙값 필터링을 사용하면 대역별 1D 중앙값 필터링이 된다.\nscipy.signal.medfilt2d를 사용할 때 중간 필터 길이 \\(L\\)은 홀수여야 한다.\n중앙값 필터링의 output array는 input array과 동일한 차원을 가진다. 경계 문제는 제로-패딩으로 처리된다.\n\n\nX = np.array([[1, 2, 3, 4, 5], [5, 6, 7, 8, 9], [5, 3, 2, 8, 2]], dtype='float')\nL = 3\nfilt_len = [1, L]\nX_smooth = signal.medfilt2d(X, filt_len)\nprint('Input array X of dimension (K,N) with K=3 and N=5')\nprint(X)\nprint('Output array after median filtering with L=3')\nprint(X_smooth)\n\nInput array X of dimension (K,N) with K=3 and N=5\n[[1. 2. 3. 4. 5.]\n [5. 6. 7. 8. 9.]\n [5. 3. 2. 8. 2.]]\nOutput array after median filtering with L=3\n[[1. 2. 3. 4. 4.]\n [5. 6. 7. 8. 8.]\n [3. 3. 3. 2. 2.]]\n\n\n\n다음 그림은 원본 크로마그램과 평활화된 버전(한 번은 평균 필터링을 적용하고 한 번은 중앙값 필터링을 적용함)을 비교한다. 원래 크로마그램에서 음(note) 전환의 결과인 날카로운 edge를 관찰할 수 있다. 평균 평활화는 이러한 전환 사이에 번짐을 초래하지만 중앙값 평활화는 에지(edge)를 더 잘 보존하는 경향이 있다.\n\n\ndef median_downsample_feature_sequence(X, Fs, filt_len=41, down_sampling=10):\n    \"\"\"Smoothes and downsamples a feature sequence. Smoothing is achieved by median filtering\n    \n    Args:\n        X (np.ndarray): Feature sequence\n        Fs (scalar): Frame rate of ``X``\n        filt_len (int): Length of smoothing filter (Default value = 41)\n        down_sampling (int): Downsampling factor (Default value = 10)\n\n    Returns:\n        X_smooth (np.ndarray): Smoothed and downsampled feature sequence\n        Fs_feature (scalar): Frame rate of ``X_smooth``\n    \"\"\"\n    assert filt_len % 2 == 1  # L needs to be odd\n    filt_len = [1, filt_len]\n    X_smooth = signal.medfilt2d(X, filt_len)\n    X_smooth = X_smooth[:, ::down_sampling]\n    Fs_feature = Fs / down_sampling\n    return X_smooth, Fs_feature\n\n\nfilt_len = 11\ndown_sampling = 2\nC_median_dict = {}    \nfor name in fn_wav_dict:   \n    C_median, Fs_C_smooth = median_downsample_feature_sequence(C_dict[name],  Fs_C,\n                                                               filt_len=filt_len, down_sampling=down_sampling)\n    C_median_dict[name] = normalize_feature_sequence(C_median, norm='2', threshold=threshold)\n\nfigsize=(8, 2)\n\nname = 'Karajan'\nplot_chromagram(C_dict[name], Fs_C_smooth, figsize=figsize, ylabel = name,\n                         title='Original chromagram', xlabel='', chroma_yticks=yticks)\nplot_chromagram(C_smooth_dict[name], Fs_C_smooth, figsize=figsize, ylabel = name,\n                         title='Smoothed chromagram using average filtering', xlabel='', chroma_yticks=yticks) \nplot_chromagram(C_median_dict[name], Fs_C_smooth, figsize=figsize, ylabel = name, \n                         title='Smoothed chromagram using median filtering', xlabel='', chroma_yticks=yticks)  \n\nC_diff = C_smooth_dict[name] - C_median_dict[name]\nm = np.max(np.abs(C_diff))\nplot_chromagram(C_diff, Fs_C_smooth, cmap='seismic', clim=[-m, m], figsize=figsize,\n                         title='Difference between average- and median-filtered chromagram', xlabel='',\n                         ylabel=name, chroma_yticks=yticks);"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조옮김-transposition",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조옮김-transposition",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "조옮김 (Transposition)",
    "text": "조옮김 (Transposition)\n\n음악에서는 종종 멜로디나 음악 전체를 다른 키로 전환하는 경우가 있다. 이러한 개념을 조옮김(transposition) 이라고 한다.\n이러한 수정은 주어진 곡의 피치 범위를 다른 악기나 가수에 적용하기 위해 종종 적용된다. 엄밀히 말하면, 조옮김은 일련의 음표를 일정한 간격으로 피치를 올리거나 내리는 과정을 말한다. 예를 들어 C-major 스케일의 음표를 4 반음 위로 이동하면 E-major 스케일이 된다.\n크로마 레벨에서 음악적 조옮김을 쉽게 시뮬레이션할 수 있다. \\([0:11]\\) 세트로 식별한 12개의 크로마 값은 순환적으로 정렬되며, 순환 이동 연산자(cyclic shift operator) \\(\\rho:\\mathbb{R}^{12} \\to \\mathbb{R}^{12}\\)의 정의와 연관된다.\n크로마 벡터 \\(x=(x(0),x(1),\\ldots,x(10),x(11))^\\intercal\\in\\mathbb{R}^{12}\\)가 주어지면, 순환 이동 연산자를 다음과 같이 정의할 수 있다.\n\n\\(\\rho(x):=(x(11),x(0),x(1),\\ldots,x(10))^\\intercal\\)\n\n즉, \\(x\\)의 크로마 밴드(chroma band) \\(\\mathrm{C}\\)는 \\(\\rho(x)\\)에서 크로마-밴드 \\(\\mathrm{C}^\\sharp\\)가, 그리고 \\(\\mathrm{C}^\\sharp\\)가, 그리고 \\(\\mathrm{D}\\)가, 계속해서 마지막으로 \\(\\mathrm{B}\\)는 \\(\\mathrm{C}\\)가 된다.\n\\(i\\)의 순환 이동을 정의하는 \\(\\rho^i:=\\rho\\circ\\rho^{i-1}\\)(for \\(i\\in\\mathbb{N}\\))를 얻기 위해 순환 이동 연산자를 반음 위로 연속적으로 적용할 수 있다. \\(\\rho^{12}(x) = x\\)는 크로마 벡터를 12반음(1옥타브) 위로 주기적으로 이동하여 원래 벡터를 복구함을 의미한다. 크로마그램의 모든 프레임에 순환 이동 연산자를 동시에 적용하면 전체 크로마그램이 수직 방향으로 순환 이동하게 된다.\n다음 예에서 \\(\\mathrm{C}\\)-major 스케일의 원래 크로마그램이 4반음 위로 이동된 것을 확인할 수 있다. 그 결과 E-major 스케일 중 하나처럼 보이는 크로마그램이 생성된다.\n\n\ndef cyclic_shift(C, shift=1):\n    \"\"\"Cyclically shift a chromagram\n\n    Args:\n        C (np.ndarray): Chromagram\n        shift (int): Tranposition shift (Default value = 1)\n\n    Returns:\n        C_shift (np.ndarray): Cyclically shifted chromagram\n    \"\"\"\n    C_shift = np.roll(C, shift=shift, axis=0)\n    return C_shift\n\n\nx_cmajor, Fs = librosa.load('../data_FMP/FMP_C3_F08_C-major-scale.wav')\nx_emajor, Fs = librosa.load('../data_FMP/FMP_C3_F08_C-major-scale_400-cents-up.wav')\n\nN = 4096\nH = 1024\nfigsize = (8, 2)\nyticks = [0, 4, 7, 11]\n\nC = librosa.feature.chroma_stft(y=x_cmajor, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\ntitle = 'Chromagram of C-major scale'\nplot_chromagram(C, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks)\n\nC = librosa.feature.chroma_stft(y=x_cmajor, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\nC_shift = cyclic_shift(C, shift=4)\ntitle = 'Chromagram of C-major scale cyclically shifted four semitones upwards'\nplot_chromagram(C_shift, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks)\n\nC = librosa.feature.chroma_stft(y=x_emajor, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\ntitle = 'Chromagram of E-major scale'\nplot_chromagram(C, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks);"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조율-tuning",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조율-tuning",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "조율 (Tuning)",
    "text": "조율 (Tuning)\n\n조옮김은 반음(semitone) 수준의 피치 이동이지만, 이제 하위 세미톤(sub-semitone) 수준의 전역적 주파수 편차(global frequency deviations)에 대해 살펴보자. 이러한 편차는 중심 주파수가 \\(440~\\mathrm{Hz}\\)인 예상 기준 피치 \\(\\mathrm{A4}\\)보다 낮거나 높게 조율된 악기의 결과일 수 있다. 예를 들어, 많은 현대 오케스트라는 \\(440\\)Hz보다 약간 높은 튜닝 주파수를 사용하는 반면 바로크 음악을 연주하는 앙상블은 종종 \\(440\\)Hz보다 낮게 튜닝한다.\n조율 효과를 보상하려면 MIDI 피치의 중심 주파수를 조정하는 추가 조율 추정 단계와 피치 기반 로그 주파수 스펙트로그램을 계산하기 위한 로그 분할을 수행해야 한다.\n보다 정확하게는 \\(\\theta\\in[-50,50)\\)(센트 단위)를 전연적 조율 편차(global tuning deviation)라고 하자. 그러면 조정된 중심 주파수의 공식은 다음과 같다. \\[F^\\theta_\\mathrm{pitch}(p) = 2^{(p-69+\\theta/100)/12} \\cdot 440\\]\n로그 분할의 조정은 크로마그램을 계산하기 위해 librosa-함수에 내장되어 있다.\n\n\nx, Fs = librosa.load('../data_FMP/FMP_C3_F08_C-major-scale.wav')\nx_detune, Fs = librosa.load('../data_FMP/FMP_C3_F08_C-major-scale_40-cents-up.wav')\n\nyticks = [0, 4, 7, 11]\nN = 4096\nH = 1024\n\nC = librosa.feature.chroma_stft(y=x, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\ntitle = 'Chromagram of original signal'\nplot_chromagram(C, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks)\n\nC = librosa.feature.chroma_stft(y=x_detune, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\ntitle = 'Chromagram of detuned signal'\nplot_chromagram(C, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks);\n\n\n\n\n\n\n\n\n# librosa로 adjust하기\n# logarithmic partitioning\n\ntheta = 40\ntuning = theta / 100\nC = librosa.feature.chroma_stft(y=x_detune, sr=Fs, tuning=tuning, norm=2, hop_length=H, n_fft=N)\ntitle = 'Chromagram of detuned signal with adjusted chroma bands'\nplot_chromagram(C, Fs/H, figsize=figsize, title=title, clim=[0, 1], chroma_yticks=yticks);"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조율-추정-tuning-estimation",
    "href": "posts/4. Music Synchronization/4.1.Audio_Synchronization_Features.html#조율-추정-tuning-estimation",
    "title": "4.1. 오디오 동기화 피쳐",
    "section": "조율 추정 (Tuning Estimation)",
    "text": "조율 추정 (Tuning Estimation)\n\n악기의 조율은 일반적으로 고정된 기준 피치를 기반으로 한다. 서양 음악에서는 일반적으로 주파수가 \\(440~\\mathrm{Hz}\\)인 concert 피치 \\(\\mathrm{A4}\\)를 사용한다. 따라서 \\(\\mathrm{A4}\\) 음을 연주하면 \\(440~\\mathrm{Hz}\\)(기본 주파수(fundamental frequency)에 해당) 및 정수 배수(고조파(harmonics)에 해당) 근처에서 우세한 주파수를 기대할 수 있다.\n\\(x=(x(0), x(1), ..., x(N-1))\\)를 녹음된 음 \\(\\mathrm{A4}\\)의 샘플 신호(샘플링 속도 \\(F_\\mathrm{s}\\) 사용)라고 하자. 또한 \\(X = \\mathrm{DFT}_N \\cdot x\\)를 이산 푸리에 변환이라고 하자. 푸리에 계수 \\(X(k)\\)의 인덱스 \\(k\\in[0:N-1]\\)는 헤르츠로 주어진 다음의 물리적 주파수(physical frequency)에 해당된다.\n\n\\(F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\\)\n\n한 가지 간단한 방법은 \\(440~\\mathrm{Hz}\\) 부근(예: 반음 더하기/빼기)에서 최대 크기 계수 \\(|X(k_0)|\\)를 생성하는 주파수 인덱스 \\(k_0\\)를 찾는 것이다.\n\\(\\log_2\\left(\\frac{F_\\mathrm{coef}(k_0)}{440}\\right) \\cdot 1200\\)는 조율 편차의 추정치를 산출한다(cent로). 보다 강력한 추정치를 얻기 위해 고조파의 적절히 정의된 이웃에서 스펙트럼 피크 위치를 고려할 수도 있다. 물론 다른 음도 조율 편차를 추정하기 위한 기준으로 사용될 수 있다.\n일반적으로 음악 녹음이 주어지면 하나의 음을 따로 연주한다고 가정할 수는 없다. 다음에서는 녹음된 음악이 \\(12\\)음 평균율 음계를 기반으로 하지만 이상적인 조율에서 벗어날 가능성이 있는 시나리오를 고려해본다. 이 편차가 센트로 주어진 단일 파라미터 \\(\\theta\\)로 표현될 수 있다고 가정한다.\n예를 들어, 이전에 사용된 디튜닝된(detuned) \\(\\mathrm{C}\\)-major 스케일은 \\(\\theta=40\\) 센트가 사용됐다. 조율 추정의 목적은 이 파라미터 \\(\\theta\\)를 결정하는 것이다. 다음은 기본 절차를 설명한다.\n\n\n먼저 신호의 전체 주파수 분포를 계산한다. 함수 compute_freq_distribution에서 두 가지 옵션을 고려한다.\n\nLocal=True: 신호의 (로컬) 크기 STFT를 계산한 다음, 평균을 냄\nLocal=False: 전체 신호의 (전역) 크기 DFT를 계산함\n\n크기(magnitude) DFT 또는 STFT를 계산할 때 로그 압축(compression)을 적용하여 작은 신호 구성 요소(예: gamma=100)를 향상시킨다.\n그런 다음 보간 기술(interpolation technique)을 사용하여 주파수 축(헤르츠로 주어짐)을 로그 축(1센트 해상도(resolution)의 센트 단위로 주어짐)으로 변환환다. 그 결과 신호의 주파수 분포를 나타내는 벡터 \\(v\\in\\mathbb{R}^M\\)가 생성된다.\n로컬 주파수 평균을 빼고, 결과를 수정(양수 부분만 고려)하여 이 벡터를 더 향상시킬 수 있다. filt_len 파라미터는 로컬 평균을 계산하는 데 사용되는 필터 길이(센트 단위)를 지정한다. 예를 들어 filt_len=101은 대략 1반음에 해당된다.\n다음 단계에서는 모든 조율 파라미터 \\(\\theta\\in \\Theta\\)에 대해 “comb-like template vectors” \\(\\mathbf{t}_\\theta\\in\\mathbb{R}^M\\)(함수 template_comb로 계산됨)를 정의한다. 각 템플릿 \\(\\mathbf{t}_\\theta\\)는 기준 조율이 \\(\\theta\\) 센트 이동된 12음 평균율 음계를 기반으로 이상적인 피치 그리드를 인코딩한다. \\(\\Theta\\) 집합은 고려해야 할 모든 가능한 조율 편차 집합을 나타낸다. 1센트 해상도에서 한 반음의 범위를 나타내는 \\(\\Theta=[-50:49]=\\{-50, -49, \\ldots,-1, 0, 1, \\ldots, 48, 49\\}\\)를 사용할 수 있다.\n마지막으로, 적절한 유사성 척도를 사용하여 \\(v\\)를 \\(\\mathbf{t}_\\theta\\) for all \\(\\theta\\in \\Theta\\)와 비교한다. tuning_similarity 함수를 이용해, 이 비교를 위해 단순히 내적(inner product) \\(\\langle v\\mid\\mathbf{t}_\\theta\\rangle\\)을 사용한다. 조율 파라미터는 유사성 최대화 매개변수 (similarity-maximizing parameter) \\(\\theta_\\mathrm{max}\\)로 다음과 같이 정의된다.\n\n\\[\\theta_\\mathrm{max} = \\mathrm{argmax}_{\\theta\\in\\Theta}\\langle v\\mid\\mathbf{t}_\\theta\\rangle\\]\n\ndef compute_freq_distribution(x, Fs, N=16384, gamma=100.0, local=True, filt=True, filt_len=101):\n    \"\"\"Compute an overall frequency distribution\n\n    Args:\n        x (np.ndarray): Signal\n        Fs (scalar): Sampling rate\n        N (int): Window size (Default value = 16384)\n        gamma (float): Constant for logarithmic compression (Default value = 100.0)\n        local (bool): Computes STFT and averages; otherwise computes global DFT (Default value = True)\n        filt (bool): Applies local frequency averaging and by rectification (Default value = True)\n        filt_len (int): Filter length for local frequency averaging (length given in cents) (Default value = 101)\n\n    Returns:\n        v (np.ndarray): Vector representing an overall frequency distribution\n        F_coef_cents (np.ndarray): Frequency axis (given in cents)\n    \"\"\"\n    if local:\n        # Compute an STFT and sum over time\n        if N > len(x)//2:\n            raise Exception('The signal length (%d) should be twice as long as the window length (%d)' % (len(x), N))\n        Y, T_coef, F_coef = stft_convention_fmp(x=x, Fs=Fs, N=N, H=N//2, mag=True, gamma=gamma)\n        # Error \"range() arg 3 must not be zero\" occurs when N is too large. Why?\n        Y = np.sum(Y, axis=1)\n    else:\n        # Compute a single DFT for the entire signal\n        N = len(x)\n        Y = np.abs(np.fft.fft(x)) / Fs\n        Y = Y[:N//2+1]\n        Y = np.log(1 + gamma * Y)\n        # Y = libfmp.c3.log_compression(Y, gamma=100)\n        F_coef = np.arange(N // 2 + 1).astype(float) * Fs / N\n\n    # Convert linearly spaced frequency axis in logarithmic axis (given in cents)\n    # The minimum frequency F_min corresponds 0 cents.\n    f_pitch = lambda p: 440 * 2 ** ((p - 69) / 12)\n    p_min = 24               # C1, MIDI pitch 24\n    F_min = f_pitch(p_min)   # 32.70 Hz\n    p_max = 108              # C8, MIDI pitch 108\n    F_max = f_pitch(p_max)   # 4186.01 Hz\n    F_coef_log, F_coef_cents = compute_f_coef_log(R=1, F_min=F_min, F_max=F_max)\n    Y_int = interp1d(F_coef, Y, kind='cubic', fill_value='extrapolate')(F_coef_log)\n    v = Y_int / np.max(Y_int)\n\n    if filt:\n        # Subtract local average and rectify\n        filt_kernel = np.ones(filt_len)\n        Y_smooth = signal.convolve(Y_int, filt_kernel, mode='same') / filt_len\n        # Y_smooth = signal.medfilt(Y_int, filt_len)\n        Y_rectified = Y_int - Y_smooth\n        Y_rectified[Y_rectified < 0] = 0\n        v = Y_rectified / np.max(Y_rectified)\n\n    return v, F_coef_cents\n\n\ndef template_comb(M, theta=0):\n    \"\"\"Compute a comb template on a pitch axis\n\n    Args:\n        M (int): Length template (given in cents)\n        theta (int): Shift parameter (given in cents); -50 <= theta < 50 (Default value = 0)\n\n    Returns:\n        template (np.ndarray): Comb template shifted by theta\n    \"\"\"\n    template = np.zeros(M)\n    peak_positions = (np.arange(0, M, 100) + theta)\n    peak_positions = np.intersect1d(peak_positions, np.arange(M)).astype(int)\n    template[peak_positions] = 1\n    return template\n\n\ndef tuning_similarity(v):\n    \"\"\"Compute tuning similarity\n\n    Args:\n        v (np.ndarray): Vector representing an overall frequency distribution\n\n    Returns:\n        theta_axis (np.ndarray): Axis consisting of all tuning parameters -50 <= theta < 50\n        sim (np.ndarray): Similarity values for all tuning parameters\n        ind_max (int): Maximizing index\n        theta_max (int): Maximizing tuning parameter\n        template_max (np.ndarray): Similiarty-maximizing comb template\n    \"\"\"\n    theta_axis = np.arange(-50, 50)  # Axis (given in cents)\n    num_theta = len(theta_axis)\n    sim = np.zeros(num_theta)\n    M = len(v)\n    for i in range(num_theta):\n        theta = theta_axis[i]\n        template = template_comb(M=M, theta=theta)\n        sim[i] = np.inner(template, v)\n    sim = sim / np.max(sim)\n    ind_max = np.argmax(sim)\n    theta_max = theta_axis[ind_max]\n    template_max = template_comb(M=M, theta=theta_max)\n    return theta_axis, sim, ind_max, theta_max, template_max\n\n\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F08_C-major-scale.wav\")\n\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, \n                                            local=True, filt_len=101)\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\n\nprint('Estimated tuning: %d cents' % theta_max)\n\nEstimated tuning: 8 cents\n\n\n\n매개변수 의존도 (Parameter dependency)\n\n이 조율 추정이 작동하는 방법을 잘 이해하기 위해 \\(\\theta\\in\\Theta=[-50:49]\\)에 대한 함수로 \\(v\\)와 \\(\\mathbf{t}_\\theta\\) 사이의 유사성을 시각화해보자(plot_tuning_similarity 함수 사용). 또한 유사성 최대화 템플릿(plot_freq_vector_template 함수 사용)과 함께 주파수 벡터를 그려보자.\n\n\ndef plot_tuning_similarity(sim, theta_axis, theta_max, ax=None, title=None, figsize=(4, 3)):\n    \"\"\"Plots tuning similarity\n\n    Args:\n        sim: Similarity values\n        theta_axis: Axis consisting of cent values [-50:49]\n        theta_max: Maximizing tuning parameter\n        ax: Axis (in case of ax=None, figure is generated) (Default value = None)\n        title: Title of figure (or subplot) (Default value = None)\n        figsize: Size of figure (only used when ax=None) (Default value = (4, 3))\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n        line: handle for line plot\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(1, 1, 1)\n    if title is None:\n        title = 'Estimated tuning: %d cents' % theta_max\n    line = ax.plot(theta_axis, sim, 'k')\n    ax.set_xlim([theta_axis[0], theta_axis[-1]])\n    ax.set_ylim([0, 1.1])\n    ax.plot([theta_max, theta_max], [0, 1.1], 'r')\n    ax.set_xlabel('Tuning parameter (cents)')\n    ax.set_ylabel('Similarity')\n    ax.set_title(title)\n    if fig is not None:\n        plt.tight_layout()\n    return fig, ax, line\n\n\ndef plot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=None, title=None, figsize=(8, 3)):\n    \"\"\"Plots frequency distribution and similarity-maximizing template\n\n    Args:\n        v: Vector representing an overall frequency distribution\n        F_coef_cents: Frequency axis\n        template_max: Similarity-maximizing template\n        theta_max: Maximizing tuning parameter\n        ax: Axis (in case of ax=None, figure is generated) (Default value = None)\n        title: Title of figure (or subplot) (Default value = None)\n        figsize: Size of figure (only used when ax=None) (Default value = (8, 3))\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n        line: handle for line plot\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(1, 1, 1)\n    if title is None:\n        title = r'Frequency distribution with maximizing comb template ($\\theta$ = %d cents)' % theta_max\n    line = ax.plot(F_coef_cents, v, c='k', linewidth=1)\n    ax.set_xlim([F_coef_cents[0], F_coef_cents[-1]])\n    ax.set_ylim([0, 1.1])\n    x_ticks_freq = np.array([0, 1200, 2400, 3600, 4800, 6000, 7200, 8000])\n    ax.plot(F_coef_cents, template_max * 1.1, 'r:', linewidth=0.5)\n    ax.set_xticks(x_ticks_freq)\n    ax.set_xlabel('Frequency (cents)')\n    plt.title(title)\n    if fig is not None:\n        plt.tight_layout()\n    return fig, ax, line\n\n\n# Load audio signal\nx, Fs = librosa.load(\"../data_FMP/FMP_C3_F08_C-major-scale.wav\")\n\nprint('Average STFT (Local=True), without enhancement (Filt=False):', flush=True)\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, \n                                            local=True, filt=False)\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\nfig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                          'height_ratios': [1]}, figsize=(10, 2))\nplot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\nplot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1])\nplt.show()\n\nprint('Average STFT (Local=True), with enhancement (Filt=True):', flush=True)\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, \n                                            local=True, filt_len=101)\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\nfig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                          'height_ratios': [1]}, figsize=(10, 2))\nplot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\nplot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1])\nplt.show()\n\nprint('Global DFT (Local=False), with enhancement (Filt=True):', flush=True)\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, \n                                            local=False, filt_len=101)\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\nfig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                          'height_ratios': [1]}, figsize=(10, 2))\nplot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\nplot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1])\nplt.show()\n\nAverage STFT (Local=True), without enhancement (Filt=False):\n\n\n\n\n\nAverage STFT (Local=True), with enhancement (Filt=True):\n\n\n\n\n\nGlobal DFT (Local=False), with enhancement (Filt=True):\n\n\n\n\n\n\n# 음악 예\n\nfn_wav_dict = {}\nfn_wav_dict['Cmaj'] = '../data_FMP/FMP_C3_F08_C-major-scale.wav'\nfn_wav_dict['Cmaj40'] = '../data_FMP/FMP_C3_F08_C-major-scale_40-cents-up.wav'\nfn_wav_dict['C4violin'] = '../data_FMP/FMP_C3_NoteC4_Violin.wav'\nfn_wav_dict['Burgmueller'] = '../data_FMP/FMP_C3_F05_BurgmuellerFirstPart.wav'\n\nfor name in fn_wav_dict:\n    fn_wav = fn_wav_dict[name]\n    x, Fs = librosa.load(fn_wav)\n    print('Audio example: %s' % name)\n    ipd.display(ipd.Audio(x, rate=Fs) )\n    v, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, \n                                                local=True, filt_len=101)\n    theta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\n    fig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                              'height_ratios': [1]}, figsize=(10, 2))\n    plot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\n    #title=r'Frequency distribution with maximizing comb template'\n    title = None\n    plot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1],  title=title)\n    plt.show()\n\nAudio example: Cmaj\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\nAudio example: Cmaj40\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\nAudio example: C4violin\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\nAudio example: Burgmueller\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n\n주파수 범위 (Frequency Range)\n\n조율 추정의 또 다른 중요한 측면은 고려되는 주파수 범위이다. 12음 음계에 따라 완벽하게 튜닝된 음악 녹음을 고려할 때에도 튜닝된 피치의 고조파는 평균율 그리드에서 상당한 편차를 유발할 수 있다.\n또한 피아노와 같은 특정 악기의 경우 “string stiffness”로 인한 부조화 (inharmonicities) 로 인해 높은 고조파가 늘어나는 경향이 있다. 따라서 상위 주파수 스펙트럼이 너무 큰 역할을 할 때, 조율 추정치를 약간 증가시킬 수 있다.\n마지막으로 특정 주파수 범위가 조율 추정에 도움이 될 수 있는 음악적 이유가 있다. 예를 들어 Weber 오페라 녹음에서 가수의 강한 비브라토 및 여타 피치 변동의 존재는 조율 추정을 흐릿하고 불안정하게 만든다. 특히 소프라노 가수의 상위 주파수 대역이 문제가 되기도 한다.\n기본 조율 추정 절차(compute_freq_distribution 함수의 세팅 참조)에서 \\(33.7Hz\\)(C1, 0센트)에서 \\(4186Hz\\)(C8, 8400센트) 사이의 로그 샘플링 주파수 범위를 사용한다. 다음 코드 셀에서는 tuning_similarity 함수를 적용하기 전에 6000센트 이상의 상위 주파수 범위를 잘라낸다.\n\n\nx, Fs = librosa.load(\"../data_FMP/FMP_C8_F10_Weber_Freischuetz-06_FreiDi-35-40.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, local=True, filt_len=101)\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\nfig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                          'height_ratios': [1]}, figsize=(12, 2))\nplot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\nplot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1])\nplt.show()\n\nv, F_coef_cents = compute_freq_distribution(x, Fs=Fs, N=16384, gamma=10, local=True, filt_len=101)\nv[6000:] = 0\ntheta_axis, sim, ind_max, theta_max, template_max = tuning_similarity(v)\nfig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 3], \n                                          'height_ratios': [1]}, figsize=(12, 2))\nplot_tuning_similarity(sim, theta_axis, theta_max, ax=ax[0])\nplot_freq_vector_template(v, F_coef_cents, template_max, theta_max, ax=ax[1])\nplt.show()\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C3/C3.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "",
    "text": "두 음악/오디오 시퀀스를 최적의 방법으로 시간에 따라 정렬할 수 있는 동적 시간 워핑 (dynamic time warping, DTW)에 대해 설명한다."
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#기본-개념",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#기본-개념",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "기본 개념",
    "text": "기본 개념\n\n두 시퀀스, 길이 \\(N\\in\\mathbb{N}\\)의 \\(X:=(x_1,x_2,\\ldots,x_N)\\)와 길이 \\(M\\in\\mathbb{N}\\)의 \\(Y:=(y_1,y_2,\\ldots,y_M)\\)가 주어져있을 때, 동적 시간 워핑 (dynamic time warping, DTW) 의 목적은 특정 제약 조건에서 최적으로 두 시퀀스를 시간적으로 정렬하는 것이다.\n시퀀스는 이산 신호, 피쳐 시퀀스, 문자 시퀀스 또는 모든 종류의 시계열일 수 있다. 종종 시퀀스의 인덱스는 균일한 시간 간격으로 간격을 둔 연속적인 시간 점에 해당한다. 다음 그림은 길이 \\(N=9\\)의 시퀀스 \\(X\\)와 길이 \\(M=7\\)의 시퀀스 \\(Y\\) 사이의 정렬(빨간색 양방향 화살표로 표시됨)을 보여준다.\n\n\nImage('../img/4.music_synchronization/FMP_C3_F12.png', width=600)\n\n\n\n\n\n각각의 빨간색 양방향 화살표는 \\(n\\in[1:N]\\) 및 \\(m\\in[1:M]\\)에 대한 두 요소 \\(x_n\\) 및 \\(y_m\\) 간의 대응 관계를 인코딩한다. 이러한 로컬 대응은 인덱스 쌍 \\((n,m)\\)로 모델링할 수 있다. 위 그림의 오른쪽은 왼쪽에 표시된 정렬이 일련의 인덱스 쌍으로 인코딩되는 방식을 보여준다."
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#워핑-경로-warping-path",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#워핑-경로-warping-path",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "워핑 경로 (Warping Path)",
    "text": "워핑 경로 (Warping Path)\n\n시퀀스 \\(X\\) 및 \\(Y\\)의 원소 간 전역(global) 정렬을 모델링하려면, 특정 제약 조건을 충족하는 인덱스 쌍(pairs) 시퀀스를 고려하는 것이 좋다.\n이것은 워핑 경로라는 개념으로 이어진다. 정의에 따르면 \\(L\\in\\mathbb{N}\\) 길이의 \\((N,M)\\)-워핑 경로는 다음의 시퀀스와 같다.\n\n\\(P=(p_1,\\ldots,p_L)\\)\nwith \\(p_\\ell=(n_\\ell,m_\\ell)\\in[1:N]\\times [1:M]\\) for \\(\\ell\\in[1:L]\\)\n\n그리고 다음의 세가지 조건을 만족한다.\n\n경계 조건(Boundary condition): \\(p_1= (1,1)\\) and \\(p_L=(N,M)\\)\n단조 조건(Monotonicity condition): \\(n_1\\leq n_2\\leq\\ldots \\leq n_L\\) and \\(m_1\\leq m_2\\leq \\ldots \\leq m_L\\)\n단계-크기 조건(Step-size condition): \\(p_{\\ell+1}-p_\\ell\\in \\Sigma:=\\{(1,0),(0,1),(1,1)\\}\\) for \\(\\ell\\in[1:L]\\)\n\n\\((N,M)\\)-워핑 경로 \\(P=(p_1,\\ldots,p_L)\\)는 두 시퀀스 \\(X=(x_1,x_2,\\ldots,x_N)\\) 및 \\(Y=(y_1,y_2,\\ldots,y_M)\\) 사이의 정렬을 \\(X\\)의 원소 \\(x_{n_\\ell}\\)를 \\(Y\\)의 원소 \\(y_{m_\\ell}\\)에 할당하여 정의한다.\n경계 조건(boundary condition)은 \\(X\\) 및 \\(Y\\)의 첫 번째 원소와 \\(X\\) 및 \\(Y\\)의 마지막 원소가 서로 정렬되도록 강제한다.\n단조 조건(monotonicity condition)은 정확한 타이밍의 요구 사항을 반영한다. \\(X\\)의 원소가 \\(X\\)의 두 번째 원소 앞에 오는 경우 \\(Y\\)의 해당 원소에도 적용되어야 하며 그 반대의 경우도 마찬가지이다.\n마지막으로 집합 \\(\\Sigma\\)에 대한 단계-크기 조건(step-size condition)은 일종의 연속성 조건을 나타낸다. \\(X\\) 및 \\(Y\\)의 원소는 생략할 수 없으며 정렬에 복제가 없다.\n다음 그림은 세 조건(boundary, monotonicity, step-size)이 위반되는 예를 각각 보여준다.\n\n\nImage(\"../img/4.music_synchronization/FMP_C3_F13.png\", width=600)"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#비용행렬과-최적성-cost-matrix-and-optimality",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#비용행렬과-최적성-cost-matrix-and-optimality",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "비용행렬과 최적성 (Cost Matrix and Optimality)",
    "text": "비용행렬과 최적성 (Cost Matrix and Optimality)\n\n다음으로, 워핑 경로의 quality 에 대해 알려주는 개념을 살펴본다. 이를 위해서는 피쳐 시퀀스 \\(X\\)와 \\(Y\\)의 원소를 수치적으로 비교할 수 있는 방법이 필요하다. \\(\\mathcal{F}\\)를 피쳐 공간으로 두고, \\(x_n,y_m\\in\\mathcal{F}\\) for \\(n\\in[1:N]\\) and \\(m\\in[1:M]\\)를 가정한다.\n두 가지 다른 피쳐를 비교하려면 다음과 같은 함수로 정의된 로컬 비용 측정 (local cost measure)이 필요하다. \\[c:\\mathcal{F}\\times\\mathcal{F}\\to \\mathbb{R}\\]\n일반적으로 \\(x\\)와 \\(y\\)가 서로 유사하면 \\(c(x,y)\\)는 작고(저비용), 그렇지 않으면 \\(c(x,y)\\)가 크다(고비용). 시퀀스 \\(X\\) 및 \\(Y\\)의 각 원소 쌍에 대한 로컬 비용 측정값을 평가하면 다음과 같이 정의된 비용 매트릭스 (cost matirx) \\(C\\in\\mathbb{R}^{N\\times M}\\)를 얻는다. \\[C(n,m):=c(x_n,y_m)\\] for \\(n\\in[1:N]\\) and \\(m\\in[1:M]\\).\n행렬 \\(C\\)의 항목을 나타내는 튜플 \\((n,m)\\)은 행렬의 셀 (cell) 이라고 한다. 로컬 비용 측정 \\(c\\)와 관련하여 두 시퀀스 \\(X\\) 및 \\(Y\\) 사이의 워핑 경로 \\(P\\)의 총 비용 \\(c_P(X,Y)\\)는 다음과 같이 정의된다. \\[ c_P:=\\sum_{\\ell=1}^L c(x_{n_\\ell},y_{m_\\ell}) = \\sum_{\\ell=1}^L C(n_\\ell,m_\\ell)\\]\n위 정의는 워핑 경로가 통과하는 모든 셀의 비용을 누적한다. 워핑 경로는 총 비용이 낮으면 “좋은 것”이고 총 비용이 높으면 “나쁜 것”이다.\n이제 \\(X\\)와 \\(Y\\) 사이의 최적 워핑 경로 (optimal warping path) 를 보자. 이는 가능한 모든 워핑 경로 중에서 총 비용이 최소인 워핑 경로 \\(P^\\ast\\)로 정의된다.\n이 워핑 경로의 셀은 두 시퀀스의 원소 간의 전반적인 최적 정렬을 인코딩한다. 여기서 워핑 경로 조건은 \\(X\\) 시퀀스의 각 원소가 \\(Y\\)의 적어도 하나의 원소에 할당되며 그 반대의 경우도 마찬가지다.\n이것은 길이 \\(N\\)의 \\(X\\)와 길이 \\(M\\)의 \\(Y\\) 사이에서 \\(\\mathrm{DTW}(X,Y)\\)로 표시되는 DTW 거리(distance) 의 정의로 이어진다. 이는 최적의 \\((N,M)\\)-워핑 경로 \\(P^\\ast\\)의 총 비용으로 정의된다. \\[\\mathrm{DTW}(X,Y) :=c_{P^\\ast}(X,Y) = \\min\\{c_P(X,Y)\\mid P \\mbox{ is an $(N,M)$-warping path} \\}\\]"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#예시",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#예시",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "예시",
    "text": "예시\n\n# 길이가 다른 두 시퀀스\nX =  [1, 3, 9, 2, 1] #시퀀스\nY = [2, 0, 0, 8, 7, 2] #시퀀스\nN = len(X)\nM = len(Y)\n\nplt.figure(figsize=(6, 2))\nplt.plot(X, c='k', label='$X$')\nplt.plot(Y, c='b', label='$Y$')\nplt.legend()\nplt.tight_layout()\n\n\n\n\n\ndef compute_cost_matrix(X, Y, metric='euclidean'):\n    \"\"\"Compute the cost matrix of two feature sequences\n\n    Args:\n        X (np.ndarray): Sequence 1\n        Y (np.ndarray): Sequence 2\n        metric (str): Cost metric, a valid strings for scipy.spatial.distance.cdist (Default value = 'euclidean')\n\n    Returns:\n        C (np.ndarray): Cost matrix\n    \"\"\"\n    X, Y = np.atleast_2d(X, Y)\n    C = scipy.spatial.distance.cdist(X.T, Y.T, metric=metric)\n    return C\n\n\n# 비용행렬 계산\nC =  compute_cost_matrix(X, Y, metric='euclidean')\nprint('Cost matrix C =', C, sep='\\n')\n\nCost matrix C =\n[[1. 1. 1. 7. 6. 1.]\n [1. 3. 3. 5. 4. 1.]\n [7. 9. 9. 1. 2. 7.]\n [0. 2. 2. 6. 5. 0.]\n [1. 1. 1. 7. 6. 1.]]\n\n\n\ndef compute_accumulated_cost_matrix(C):\n    \"\"\"Compute the accumulated cost matrix given the cost matrix\n\n    Args:\n        C (np.ndarray): Cost matrix\n\n    Returns:\n        D (np.ndarray): Accumulated cost matrix\n    \"\"\"\n    N = C.shape[0]\n    M = C.shape[1]\n    D = np.zeros((N, M))\n    D[0, 0] = C[0, 0]\n    for n in range(1, N):\n        D[n, 0] = D[n-1, 0] + C[n, 0]\n    for m in range(1, M):\n        D[0, m] = D[0, m-1] + C[0, m]\n    for n in range(1, N):\n        for m in range(1, M):\n            D[n, m] = C[n, m] + min(D[n-1, m], D[n, m-1], D[n-1, m-1])\n    return D\n\n\n# 누적 비용행렬 계산\nD =  compute_accumulated_cost_matrix(C)\nprint('Accumulated cost matrix D =', D, sep='\\n')\nprint('DTW distance DTW(X, Y) =', D[-1, -1])\n\nAccumulated cost matrix D =\n[[ 1.  2.  3. 10. 16. 17.]\n [ 2.  4.  5.  8. 12. 13.]\n [ 9. 11. 13.  6.  8. 15.]\n [ 9. 11. 13. 12. 11.  8.]\n [10. 10. 11. 18. 17.  9.]]\nDTW distance DTW(X, Y) = 9.0\n\n\n\ndef compute_optimal_warping_path(D):\n    \"\"\"Compute the warping path given an accumulated cost matrix\n\n    Args:\n        D (np.ndarray): Accumulated cost matrix\n\n    Returns:\n        P (np.ndarray): Optimal warping path\n    \"\"\"\n    N = D.shape[0]\n    M = D.shape[1]\n    n = N - 1\n    m = M - 1\n    P = [(n, m)]\n    while n > 0 or m > 0:\n        if n == 0:\n            cell = (0, m - 1)\n        elif m == 0:\n            cell = (n - 1, 0)\n        else:\n            val = min(D[n-1, m-1], D[n-1, m], D[n, m-1])\n            if val == D[n-1, m-1]:\n                cell = (n-1, m-1)\n            elif val == D[n-1, m]:\n                cell = (n-1, m)\n            else:\n                cell = (n, m-1)\n        P.append(cell)\n        (n, m) = cell\n    P.reverse()\n    return np.array(P)\n\n\n# 최적 warping path 계산\nP = compute_optimal_warping_path(D)\nprint('Optimal warping path P =', P.tolist())\n\nOptimal warping path P = [[0, 0], [0, 1], [1, 2], [2, 3], [2, 4], [3, 5], [4, 5]]\n\n\n\nc_P = sum(C[n, m] for (n, m) in P)\nprint('Total cost of optimal warping path:', c_P)\nprint('DTW distance DTW(X, Y) =', D[-1, -1])\n\nTotal cost of optimal warping path: 9.0\nDTW distance DTW(X, Y) = 9.0\n\n\n\nP = np.array(P) \nplt.figure(figsize=(8, 3))\nplt.subplot(1, 2, 1)\nplt.imshow(C, cmap='gray_r', origin='lower', aspect='equal')\nplt.plot(P[:, 1], P[:, 0], marker='o', color='r')\nplt.clim([0, np.max(C)])\nplt.colorbar()\nplt.title('$C$ with optimal warping path')\nplt.xlabel('Sequence Y')\nplt.ylabel('Sequence X')\n\nplt.subplot(1, 2, 2)\nplt.imshow(D, cmap='gray_r', origin='lower', aspect='equal')\nplt.plot(P[:, 1], P[:, 0], marker='o', color='r')\nplt.clim([0, np.max(D)])\nplt.colorbar()\nplt.title('$D$ with optimal warping path')\nplt.xlabel('Sequence Y')\nplt.ylabel('Sequence X')\n\nplt.tight_layout()\n\n\n\n\n\n## librosa example\n\nD, P = librosa.sequence.dtw(X, Y, metric='euclidean', \n                            step_sizes_sigma=np.array([[1, 1], [0, 1], [1, 0]]),\n                            weights_add=np.array([0, 0, 0]), weights_mul=np.array([1, 1, 1]))\n\nplt.figure(figsize=(8, 3))\nax = plt.subplot(1,1,1)\nplot_matrix_with_points(D, P, linestyle='-', \n    ax=[ax], aspect='equal', clim=[0, np.max(D)],\n    title='$D$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#단계-크기-조건-step-size-condition",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#단계-크기-조건-step-size-condition",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "단계 크기 조건 (Step-size Condition)",
    "text": "단계 크기 조건 (Step-size Condition)\n\n기존 DTW에서 step-size 조건은 \\(\\Sigma=\\{(1,0),(0,1),(1,1)\\}\\) 집합으로 표현된다. 일종의 local 연속성 조건을 도입하는 이 조건은 워핑 경로가 시퀀스 \\(X=(x_1,x_2,\\ldots,x_N)\\)의 각 원소를 \\(Y=(y_1,y_2,\\ldots, y_M)\\)의 원소로 할당하도록 하며 그 반대도 마찬가지이다.\n이 조건의 한 가지 단점은 한 시퀀스의 단일 원소가 다른 시퀀스의 많은 연속된 원소에 할당되어 워핑 경로에서 수직 및 수평 섹션으로 이어질 수 있다는 것이다.\n직관적으로 이러한 경우 워핑 경로는 시퀀스 중 하나의 시퀀스에서는 특정 위치에 고정되고 다른 시퀀스에서는 이동한다. 물리적 시간 측면에서 이 상황은 두 시계열의 정렬에서 강한 시간적 변형(temporal deformation)에 해당된다. 이러한 변성을 피하기 위해 허용 가능한 워핑 경로의 기울기를 제한하여 step-size 조건을 수정할 수 있다.\n이는 집합 \\(\\Sigma\\)를 교체하여 수행할 수 있다.\n\n\nImage(\"../img/4.music_synchronization/FMP_C3_F17.png\", width=600)\n\n\n\n\n\n첫 번째 경우 원래의 집합 \\(\\Sigma=\\{(1,0),(0,1),(1,1)\\}\\)가 사용된다(워핑 경로의 degeneration 관찰).\n이 집합을 \\(\\Sigma = \\{(2,1),(1,2),(1,1)\\}\\)과 같이 교체하면 워핑 경로가 \\(1/2\\) 및 \\(2\\) 범위 내에서 local 기울기를 갖는 워핑 경로로 이어진다.\n새로운 step size 제약을 만족하는 최적 워핑 경로를 계산하기 위해 원래의 DTW 알고리즘을 조금만 변형하면 된다. 누적 비용행렬 \\(\\mathbf{D}\\)을 계산하기 위해 다음의 recursion을 사용한다. \\[\\mathbf{D}(n,m)= \\mathbf{C}(n,m) + \\min\\left\\{\n           \\begin{array}{l}\\mathbf{D}(n-1,m-1),\\\\ \\mathbf{D}(n-2,m-1),\\\\\\mathbf{D}(n-1,m-2) \\end{array}\\right.\\] for \\(n\\in [1:N]\\) and \\(m\\in [1:N]\\) with \\((n,m)\\not=(1,1)\\).\n초기화를 위해 \\(\\mathbf{D}\\)를 두 개의 추가 행과 열(\\(-1\\) 및 \\(0\\)로 인덱싱됨), 그리고 집합 \\(\\mathbf{D}(1,1):=\\mathbf{C}(1,1)\\), \\(\\mathbf{D}(n,-1):=\\mathbf{D}(n,0):=\\infty\\) for \\(n\\in [-1:N]\\)와 \\(\\mathbf{D}(-1,m):=\\mathbf{D}(0,m):=\\infty\\) for \\(m\\in [-1:M]\\) 로 확장하는 트릭을 사용할 수 있다.\n수정된 step-size 조건과 관련하여 두 시퀀스 \\(X\\)와 \\(Y\\) 사이에 유한의 총 비용 워핑 경로가 있다. 또한 \\(X\\)의 모든 원소를 \\(Y\\)의 일부 원소에 할당할 필요는 없으며 그 반대도 마찬가지다(위 그림 참조). 위 그림의 세 번째 경우는 워핑 경로의 기울기에 제약을 가하면서 이러한 누락을 피하는 step-size 조건을 보여준다.\n\n\ndef compute_accumulated_cost_matrix_21(C):\n    \"\"\"Compute the accumulated cost matrix given the cost matrix\n\n    Args:\n        C (np.ndarray): Cost matrix\n\n    Returns:\n        D (np.ndarray): Accumulated cost matrix\n    \"\"\"\n    N = C.shape[0]\n    M = C.shape[1]\n    D = np.zeros((N + 2, M + 2))\n    D[:, 0:2] = np.inf\n    D[0:2, :] = np.inf\n    D[2, 2] = C[0, 0]\n\n    for n in range(N):\n        for m in range(M):\n            if n == 0 and m == 0:\n                continue\n            D[n+2, m+2] = C[n, m] + min(D[n-1+2, m-1+2], D[n-2+2, m-1+2], D[n-1+2, m-2+2])\n    D = D[2:, 2:]\n    return D\n\n\ndef compute_optimal_warping_path_21(D):\n    \"\"\"Compute the warping path given an accumulated cost matrix\n\n    Args:\n        D (np.ndarray): Accumulated cost matrix\n\n    Returns:\n        P (np.ndarray): Optimal warping path\n    \"\"\"\n    N = D.shape[0]\n    M = D.shape[1]\n    n = N - 1\n    m = M - 1\n    P = [(n, m)]\n    while n > 0 or m > 0:\n        if n == 0:\n            cell = (0, m - 1)\n        elif m == 0:\n            cell = (n - 1, 0)\n        else:\n            val = min(D[n-1, m-1], D[n-2, m-1], D[n-1, m-2])\n            if val == D[n-1, m-1]:\n                cell = (n-1, m-1)\n            elif val == D[n-2, m-1]:\n                cell = (n-2, m-1)\n            else:\n                cell = (n-1, m-2)\n        P.append(cell)\n        (n, m) = cell\n    P.reverse()\n    P = np.array(P)\n    return P\n\n\n# Sequences\nX = [1, 3, 9, 2, 1]\nY = [2, 0, 0, 8, 7, 2]\nN, M = len(X), len(Y)\n\nC = compute_cost_matrix(X, Y, metric='euclidean')\nD = compute_accumulated_cost_matrix_21(C)\nP = compute_optimal_warping_path_21(D)  \n    \nplt.figure(figsize=(6, 2))\nplt.plot(X, c='k', label='X')\nplt.plot(Y, c='b', label='Y')\nplt.legend()\nplt.tight_layout()\n\nplt.figure(figsize=(9, 3))\nax = plt.subplot(1, 2, 1)\nplot_matrix_with_points(C, P, linestyle='-', \n    ax=[ax], aspect='equal', clim=[0, np.max(C)],\n    title='$C$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n\nax = plt.subplot(1, 2, 2)\nD_max = np.nanmax(D[D != np.inf])\nplot_matrix_with_points(D, P, linestyle='-', \n    ax=[ax], aspect='equal', clim=[0, D_max],\n    title='$D$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\nfor x, y in zip(*np.where(np.isinf(D))):\n    plt.text(y, x, '$\\infty$', horizontalalignment='center', verticalalignment='center')\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n## librosa 예\n\ndef compute_plot_D_P(X, Y, ax, step_sizes_sigma=np.array([[1, 1], [0, 1], [1, 0]]),\n                     weights_mul=np.array([1, 1, 1]), title='',\n                     global_constraints=False, band_rad=0.25):\n    D, P = librosa.sequence.dtw(X, Y, metric='euclidean', weights_mul=weights_mul,\n                    step_sizes_sigma=step_sizes_sigma, \n                    global_constraints=global_constraints, band_rad=band_rad)\n    D_max = np.nanmax(D[D != np.inf])\n    plot_matrix_with_points(D, P, linestyle='-', \n        ax=[ax], aspect='equal', clim=[0, D_max],\n        title= title, xlabel='Sequence Y', ylabel='Sequence X');\n    for x, y in zip(*np.where(np.isinf(D))):\n        plt.text(y, x, '$\\infty$', horizontalalignment='center', verticalalignment='center')\n    \nX = [1, 3, 9, 2, 1, 3, 9, 9]\nY = [2, 0, 0, 9, 1, 7]  \n\nprint('다양한 step-size 조건에 대한 누적 비용 행렬 및 최적 워핑 경로:')\nplt.figure(figsize=(10, 3))\n\nax = plt.subplot(1, 3, 1)\nstep_sizes_sigma = np.array([[1, 0], [0, 1], [1, 1]])\ntitle='Step sizes:'+''.join(str(s) for s in step_sizes_sigma)\ncompute_plot_D_P(X, Y, ax=ax, step_sizes_sigma=step_sizes_sigma, title=title)\n\nax = plt.subplot(1, 3, 2)\nstep_sizes_sigma = np.array([[1, 1], [2, 1], [1, 2]])\ntitle='Step sizes:'+''.join(str(s) for s in step_sizes_sigma)\ncompute_plot_D_P(X, Y, ax=ax, step_sizes_sigma=step_sizes_sigma, title=title)\n\nax = plt.subplot(1, 3, 3)\nstep_sizes_sigma = np.array([[1, 1], [3, 1], [1, 3]])\ntitle='Step sizes:'+''.join(str(s) for s in step_sizes_sigma)                                                       \ncompute_plot_D_P(X, Y, ax=ax, step_sizes_sigma=step_sizes_sigma, title=title)\n\nplt.tight_layout()\n\n다양한 step-size 조건에 대한 누적 비용 행렬 및 최적 워핑 경로:"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#로컬-가중치-local-weights",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#로컬-가중치-local-weights",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "로컬 가중치 (Local Weights)",
    "text": "로컬 가중치 (Local Weights)\n\n정렬에 수직, 수평 또는 대각선 방향 등 특정 방향을 선호한다면, 추가 로컬 가중치 (local weights) \\(w_{\\mathrm{d}},w_{\\mathrm{h}},w_{\\mathrm{v}}\\in\\mathbb{R}\\)를 도입할 수 있다. 누적 비용 행렬 \\(\\mathbf{D}\\)를 계산하기 위해 다음 initialization 및 recursion을 사용한다.\n\n\\[\\mathbf{D}(1,1):=\\mathbf{C}(1,1)\\] \\[\\mathbf{D}(n,1)=\\sum_{k=1}^{n} w_{\\mathrm{h}}\\cdot \\mathbf{C}(k,1) \\,\\,\\mbox{for}\\,\\, n\\in [2:N]\\] \\[\\mathbf{D}(1,m)=\\sum_{k=1}^{m} w_{\\mathrm{v}}\\cdot \\mathbf{C}(1,k) \\,\\,\\mbox{for}\\,\\, m\\in [2:M]\\] \\[\\mathbf{D}(n,m)=\\min \\left\\{\n   \\begin{array}{l}\n    \\mathbf{D}(n-1,m-1) + w_{\\mathrm{d}}\\cdot \\mathbf{C}(n,m) \\\\\n    \\mathbf{D}(n-1,m)   + w_{\\mathrm{v}}\\cdot \\mathbf{C}(n,m) \\\\\n    \\mathbf{D}(n,m-1)   + w_{\\mathrm{h}}\\cdot \\mathbf{C}(n,m)\n   \\end{array}\n   \\right.\\]\nfor \\(n\\in[2:N]\\) and \\(m\\in[2:M]\\).\n\n\\(w_{\\mathrm{d}}=w_{\\mathrm{h}}=w_{\\mathrm{v}}=1\\)이면 기존 DTW로 축소된다.\n기본적으로 하나의 대각선 단계(셀 하나의 비용)가 하나의 수평 단계와 하나의 수직 단계(두 셀의 비용)의 조합에 해당하기 때문에, 대각선 정렬 방향을 선호한다. 이러한 선호의 균형을 맞추기 위해 종종 \\(w_{\\mathrm{d}}=2\\) 및 \\(w_{\\mathrm{h}}=w_{\\mathrm{v}}=1\\)를 선택한다.\n마찬가지로 다른 step-size 조건에 대한 가중치를 도입할 수 있다.\n다음 코드 셀에서 다른 가중치 설정으로 librosa.sequence.dtw 함수를 호출한다.\n\n\nX = [1, 1, 1, 1, 2, 1, 1, 6, 6]\nY = [0, 3, 3, 3, 9, 9, 7, 7]\n\nprint(r'다양한 local 가중치에 따른 누적 비용 행렬과 최적 warping 경로:')\nplt.figure(figsize=(10, 3))\n\nax = plt.subplot(1, 3, 1)\nweights_mul = np.array([1, 1, 1])\ntitle='Weights: '+'[ '+''.join(str(s)+' ' for s in weights_mul)+']'\ncompute_plot_D_P(X, Y, ax=ax, weights_mul=weights_mul, title=title)\n\nax = plt.subplot(1, 3, 2)\nweights_mul = np.array([2, 1, 1])\ntitle='Weights: '+'[ '+''.join(str(s)+' ' for s in weights_mul)+']'\ncompute_plot_D_P(X, Y, ax=ax, weights_mul=weights_mul, title=title)\n\nax = plt.subplot(1, 3, 3)\nweights_mul = np.array([1, 3, 3])\ntitle='Weights: '+'[ '+''.join(str(s)+' ' for s in weights_mul)+']'                                                      \ncompute_plot_D_P(X, Y, ax=ax, weights_mul=weights_mul, title=title)\n\nplt.tight_layout()\n\n다양한 local 가중치에 따른 누적 비용 행렬과 최적 warping 경로:"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#전역-제약-global-constraints",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#전역-제약-global-constraints",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "전역 제약 (Global Constraints)",
    "text": "전역 제약 (Global Constraints)\n\n일반적인 DTW 변형 중 하나는 허용 가능한 워핑 경로에 전역 제약(global constraint)을 부과하는 것이다.\n이러한 제약 조건은 DTW 계산 속도를 높일 뿐만 아니라 워핑 경로의 전체 과정을 전체적으로 제어하여 “pathological” 정렬을 방지한다.\n보다 정확하게는 \\(R\\subseteq [1:N]\\times[1:M]\\)를 전역적 제약 영역이라고 하는 하위 집합이라고 하자. 그러면 \\(R\\)과 연관된(relative to) 워핑 경로 는 \\(R\\) 지역 내에서 완전히 실행되는 워핑 경로이다.\n\\(P^\\ast_{R}\\)로 표시되는 \\(R\\)과 연관된 최적 워핑 경로 는 \\(R\\)에 대한 모든 워핑 경로 중에서 비용을 최소화하는 워핑 경로이다.\n다음 그림은 Sakoe–Chiba 밴드 및 Itakura 평행사변형으로 알려진 두 개의 전역 제약 영역을 보여준다. 셀의 정렬은 각 음영 영역에서만 선택할 수 있다.\n\n\nImage(\"../img/4.music_synchronization/FMP_C3_F18_text.png\", width=600)\n\n\n\n\n\n일반적으로 제약 영역 \\(R\\)의 경우, 경로 \\(P^\\ast_{R}\\)는 \\(\\mathbf{C}(n,m):=\\infty\\) for all \\((n,m)\\in [1:N]\\times[1:M]\\setminus R\\)로 세팅하여 제약 없는 경우와 유사하게 계산할 수 있다.\n따라서 \\(P^\\ast_{R}\\) 계산에서 \\(R\\)에 있는 셀만 평가하면 된다. 이렇게 하면 DTW 계산 속도가 상당히 빨라질 수 있다. 그러나 제약되지 않은 최적 워핑 경로 \\(P^\\ast\\)가 지정된 제약 영역 외부의 셀을 통과할 수 있기 때문에 전역 제약 영역의 사용 또한 문제가 된다. 이 경우 제한된 최적 워핑 경로 \\(P^\\ast_{R}\\)는 \\(P^\\ast\\)와 일치하지 않는다(위 그림의 마지막 경우 참조).\n다음 코드 셀에서 Sakoe-Chiba 밴드에 의해 결정된 다양한 제약 영역으로 librosa.sequence.dtw 함수를 사용해본다.\n다음의 예에서 워핑 경로는 \\((1, 1)\\)에서 시작하지 않는데, 이는 librosa의 역추적 버그 때문이다.(차후 수정될 수 있음)\n\n\nX = [1, 1, 1, 1, 2, 1, 1, 6, 6]\nY = [0, 3, 3, 3, 9, 9, 7, 7]\n\nprint(r'Accumulated cost matrix and optimal warping path for different constraint regions:')\nplt.figure(figsize=(10, 3))\nglobal_constraints = True\n\nax = plt.subplot(1, 3, 1)\nband_rad = 1\ntitle='Sakao-Chiba band (rad = %.2f)'%band_rad\ncompute_plot_D_P(X, Y, ax=ax, global_constraints=global_constraints, band_rad=band_rad,title=title)\n\nax = plt.subplot(1, 3, 2)\nband_rad = 0.5\ntitle='Sakao-Chiba band (rad = %.2f)'%band_rad\ncompute_plot_D_P(X, Y, ax=ax, global_constraints=global_constraints, band_rad=band_rad,title=title)\n\nax = plt.subplot(1, 3, 3)\nband_rad = 0.25\ntitle='Sakao-Chiba band (rad = %.2f)'%band_rad\ncompute_plot_D_P(X, Y, ax=ax, global_constraints=global_constraints, band_rad=band_rad,title=title)\n\nplt.tight_layout()\n\nAccumulated cost matrix and optimal warping path for different constraint regions:"
  },
  {
    "objectID": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#멀티스케일-multiscale-dtw",
    "href": "posts/4. Music Synchronization/4.2.Dynamic_Time_Warping.html#멀티스케일-multiscale-dtw",
    "title": "4.2. 동적 시간 워핑 (DTW)",
    "section": "멀티스케일 (Multiscale) DTW",
    "text": "멀티스케일 (Multiscale) DTW\n\nglobal 제약 영역의 개념을 사용할 때, 계산할 최적 워핑 경로가 실제로 이 영역 내에 있는지 확인해야 한다. 이 경로는 선험적으로 알려져 있지 않기 때문에, 제한 영역을 가능한 한 작게 선택(계산 속도를 높이기 위해)하지만 원하는 경로를 포함할 만큼 충분히 크게 선택하는 것 사이에서 적절한 절충점을 찾기가 어렵다.\n“올바른” 경로를 찾을 확률을 높이는 한 가지 가능한 전략은 데이터 독립적인 고정 제약 조건 영역 대신 데이터 종속 제약 조건 영역을 사용하는 것이다. 이 아이디어는 DTW에 대한 멀티스케일 접근 방식 (multiscale approach) 에 의해 실현될 수 있다.\n여기서 일반적인 전략은 재귀적으로 거친 해상도 수준에서 계산된 최적 워핑 경로를 다음 상위 수준으로 투영한 다음, 투영된 경로를 미세 조정하는 것이다. 다음 그림은 이러한 접근 방식의 주요 단계를 요약한 것이다. 거친 해상도 수준에서 계산된 최적 워핑은 더 미세한 해상도 수준으로 투영된다. 작은 이웃과 함께(전체 절차의 견고성을 높이기 위해) 더 미세한 해상도 수준에서 워핑 경로를 계산하는 데 사용되는 제약 조건 영역을 정의한다.\n\n\nImage(\"../img/4.music_synchronization/FMP_C3_F19.png\", width=600)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html",
    "title": "5.1. 음악 구조와 분할",
    "section": "",
    "text": "주어진 음악 녹음에 대한 구조적(structural) 분석과 시간적 분할(segmentation)를 소개하고, 반복성(repitition), 동질성(homogeneity) 및 새로움(novelty)을 기반으로 하는 기본 분할 원칙에 대해 논의한다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#분할과-구조-분석-segmentation-and-structure-analysis",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#분할과-구조-분석-segmentation-and-structure-analysis",
    "title": "5.1. 음악 구조와 분할",
    "section": "분할과 구조 분석 (Segmentation and Structure Analysis)",
    "text": "분할과 구조 분석 (Segmentation and Structure Analysis)\n\n분할/세분화(Segmentation) 은 일반적으로 원본보다 더 의미 있고 분석하기 쉬운 것으로 표시를 단순화하기 위해 지정된 문서를 여러 세그먼트로 분할하는 과정을 말한다. 예를 들어 이미지 처리에서 목표는 주어진 이미지를 영역 집합으로 분할하여 각 영역이 색상, 강도 또는 질감과 같은 일부 특성과 관련하여 유사하도록 하는 것이다. 영역 경계는 종종 이미지 밝기 또는 기타 속성이 급격하게 변하고 불연속성을 나타내는 등고선이나 가장자리로 설명될 수 있다.\n음악에서 분할 작업은 주어진 오디오 스트림을 음향적으로 의미 있는 섹션으로 분해하는 것이다. 각각은 시작 및 종료 경계(boundary) 로 지정된 연속 시간 간격에 해당한다.\n미세한 수준에서의 분할은 개별 음 사이의 경계를 찾거나 비트 위치에 의해 지정된 비트 간격을 찾는 것을 목표로 할 수 있다. 대략적인 수준에서의 목표는 악기나 화음의 변화를 감지하거나 절(verse)과 합창 부분 사이의 경계를 찾는 것일 수 있다. 또한 침묵, 말, 음악을 구별하거나 실제 음악 녹음의 시작 부분을 찾거나 공연이 끝난 후 박수를 분리하는 것이 전형적인 분할 작업이다.\n구조 분석(structural analysis) 의 목표는 단순한 분할을 넘어 세그먼트 간의 관계를 찾고 이해하는 것이다.\n예를 들어, 특정 세그먼트는 악기에 의해 특징지어질 수 있다. 현악기로만 연주되는 구간이 있을 수 있으며, 전체 오케스트라가 연주하는 섹션 다음에 솔로 섹션이 이어질 수 있다. 노래하는 목소리가 있는 절 부분은 순전히 기악 부분으로 대체될 수 있다. 또는 부드럽고 느린 도입부 부분이 훨씬 빠른 템포로 연주되는 메인 테마 앞에 나올 수 있다.\n또한 섹션이 자주 반복된다. 대부분의 음악 관련 이벤트는 어떤 식으로든 반복된다. 그러나 반복은 원래 섹션과 거의 동일하지 않으며 가사, 악기 또는 멜로디와 같은 측면에서 조금씩 수정된다. 구조 분석의 주요 작업 중 하나는 주어진 음악 녹음을 분할하는 것뿐만 아니라 세그먼트를 음악적으로 의미 있는 범주(예: 인트로, 코러스, 절, 아웃트로)로 그룹화하는 것이다.\n전산 음악 구조 분석의 문제는 음악의 구조가 반복, 대조, 변형 및 동질성을 비롯한 다양한 종류의 관계에서 발생한다는 것이다. 음악 구조에 결정적으로 영향을 미치는 다양한 원리를 고려하여 음악 구조 분석에 대한 다양한 접근 방식이 많이 개발되었다. 세 가지 방법 분류를 대략적으로 구분해보자.\n\n첫째, 반복(repetition) 기반 방법은 반복 패턴을 식별하는 데 사용된다.\n둘째, 새로움(novelty) 기반 방법을 사용하여 대조되는 부분 간의 전환을 감지한다.\n셋째, 동질성(homogeneity) 기반 방법은 일부 음악적 속성과 관련하여 일관된 구절을 결정하는 데 사용된다.\n\n새로움 기반 및 동질성 기반 접근 방식은 동전의 양면 같다. 새로움 감지는 더 동질적인 세그먼트 이후의 놀라운 이벤트 또는 변화를 관찰하는 것을 기반으로 한다. 새로움 감지의 목적은 변경 사항의 시간 위치를 찾는 것이지만 동질성 분석의 초점은 일부 음악적 속성과 관련하여 일관성 있는 더 긴 악절을 식별하는 데 있다.\n다음 그림은 유사한 분할 및 구조화 원칙이 이미지 및 3D 데이터와 같은 다른 도메인에 적용됨을 보여준다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F03_text.png\", width=600)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#음악-구조-musical-structure",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#음악-구조-musical-structure",
    "title": "5.1. 음악 구조와 분할",
    "section": "음악 구조 (Musical Structure)",
    "text": "음악 구조 (Musical Structure)\n\n음악 구조를 구체화하기 위해 몇 가지 용어를 소개한다. 먼저 음악 작품(a piece of music)(다소 추상적인 의미)과 특정 오디오 녹음(audio recording)(실제 연주)을 구분해야 한다. 파트(part) 라는 용어는 추상적인 음악 영역에서 사용되는 반면 세그먼트(segment) 라는 용어는 오디오 영역에서 사용된다.\n음악적 파트는 일반적으로 처음 나타나는 순서대로 대문자 \\(A,B,C,\\ldots\\)로 표시되며 여기서 숫자(종종 아래 첨자로 표시됨)는 반복되는 순서를 나타낸다.\n예를 들어 요하네스 브람스의 헝가리 무곡 5번을 생각해보자. 이 춤은 피아노 버전에서 풀 오케스트라 버전에 이르기까지 다양한 악기와 앙상블을 위해 편곡되었다. 다음 그림은 전체 오케스트라를 위한 편곡의 바이올린 음성에 대한 악보 표현을 보여준다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F05_Sibelius_annotated.png\", width=600)\n\n\n\n\n\n음악적 구조는 \\(A_1A_2B_1B_2CA_3B_3B_4D\\)로 \\(A\\) 파트 3개, \\(B\\) 파트 4개, \\(C\\) 파트 1개, 닫는 \\(D\\) 파트 1개로 구성되어 있다. \\(A\\) 부분에는 두 개 이상 반복되는 하위 부분으로 구성된 하위 구조가 있다. 또한 악보를 보면 알 수 있듯이 중간 \\(C\\) 부분은 \\(d_1d_2e_1e_2e_3e_4\\)로 설명할 수 있는 하위 구조로 더 분할될 수 있다. 악보에서 이러한 하위 부분은 종종 소문자 \\(a,b,c,\\ldots\\)를 사용하여 표시된다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F28.png\", width=400)\n\n\n\n\n\ndef convert_structure_annotation(ann, Fs=1, remove_digits=False, index=False):\n    \"\"\"Convert structure annotations\n\n    Args:\n        ann (list): Structure annotions\n        Fs (scalar): Sampling rate (Default value = 1)\n        remove_digits (bool): Remove digits from labels (Default value = False)\n        index (bool): Round to nearest integer (Default value = False)\n\n    Returns:\n        ann_converted (list): Converted annotation\n    \"\"\"\n    ann_converted = []\n    for r in ann:\n        s = r[0] * Fs\n        t = r[1] * Fs\n        if index:\n            s = int(np.round(s))\n            t = int(np.round(t))\n        if remove_digits:\n            label = ''.join([i for i in r[2] if not i.isdigit()])\n        else:\n            label = r[2]\n        ann_converted = ann_converted + [[s, t, label]]\n    return ann_converted\n\n\ndef read_structure_annotation(fn_ann, fn_ann_color, Fs=1, remove_digits=False, index=False):\n    \"\"\"Read and convert structure annotation and colors\n\n    Args:\n        fn_ann (str): Path and filename for structure annotions\n        fn_ann_color (str): Filename used to identify colors (Default value = '')\n        Fs (scalar): Sampling rate (Default value = 1)\n        remove_digits (bool): Remove digits from labels (Default value = False)\n        index (bool): Round to nearest integer (Default value = False)\n\n    Returns:\n        ann (list): Annotations\n        color_ann (dict): Color scheme\n    \"\"\"\n    df = pd.read_csv(fn_ann, sep=';', keep_default_na=False, header=0)\n    ann = [(start, end, label) for i, (start, end, label) in df.iterrows()]\n    ann = convert_structure_annotation(ann, Fs=Fs, remove_digits=remove_digits, index=index)\n    color_ann = {}\n    if len(fn_ann_color) > 0:\n        color_ann = fn_ann_color\n        if remove_digits:\n            color_ann_reduced = {}\n            for key, value in color_ann.items():\n                key_new = ''.join([i for i in key if not i.isdigit()])\n                color_ann_reduced[key_new] = value\n            color_ann = color_ann_reduced\n    return ann, color_ann\n\n\nann_color = {'A1': [1, 0, 0, 0.2], 'A2': [1, 0, 0, 0.2], 'A3': [1, 0, 0, 0.2],\n                     'B1': [0, 1, 0, 0.2], 'B2': [0, 1, 0, 0.2], 'B3': [0, 1, 0, 0.2],\n                     'B4': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0]}\n\n\n# Annotation file\nfn_ann = \"../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.csv\"\n\n# Read annotations\nann, color_ann = read_structure_annotation(fn_ann, fn_ann_color=fn_ann_color)\nprint('Original annotations with time specified in seconds')\nprint('Annotations:', ann)\nprint('Colors:', color_ann)\nfig, ax = plot_segments(ann, figsize=(8, 1.2), colors=color_ann, time_label='Time (seconds)')\nplt.show()\n\n# Read and convert annotations\nFs = 2\nann, color_ann = read_structure_annotation(fn_ann, fn_ann_color=fn_ann_color, Fs=Fs, remove_digits=True, index=True)\nprint('Converted annotations (Fs = %d) with reduced labels (removing digits)'%Fs)\nprint('Annotations:', ann)\nprint('Colors:', color_ann)\nfig, ax = plot_segments(ann, figsize=(8, 1.2), colors=color_ann, time_label='Time (frames)')\nplt.show()\n\nOriginal annotations with time specified in seconds\nAnnotations: [[0.0, 1.01, ''], [1.01, 22.11, 'A1'], [22.11, 43.06, 'A2'], [43.06, 69.42, 'B1'], [69.42, 89.57, 'B2'], [89.57, 131.64, 'C'], [131.64, 150.84, 'A3'], [150.84, 176.96, 'B3'], [176.96, 196.9, 'B4'], [196.9, 199.64, '']]\nColors: {'A1': [1, 0, 0, 0.2], 'A2': [1, 0, 0, 0.2], 'A3': [1, 0, 0, 0.2], 'B1': [0, 1, 0, 0.2], 'B2': [0, 1, 0, 0.2], 'B3': [0, 1, 0, 0.2], 'B4': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0]}\n\n\n\n\n\nConverted annotations (Fs = 2) with reduced labels (removing digits)\nAnnotations: [[0, 2, ''], [2, 44, 'A'], [44, 86, 'A'], [86, 139, 'B'], [139, 179, 'B'], [179, 263, 'C'], [263, 302, 'A'], [302, 354, 'B'], [354, 394, 'B'], [394, 399, '']]\nColors: {'A': [1, 0, 0, 0.2], 'B': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0]}"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#크로마그램",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#크로마그램",
    "title": "5.1. 음악 구조와 분할",
    "section": "크로마그램",
    "text": "크로마그램\n\n첫째, 크로마 기반 표현은 음악 녹음의 화성(harmonic) 및 멜로디(melodic) 속성과 관련된다.\n크로마그램에서 볼 수 있는 패턴은 중요한 구조 정보를 나타낸다.\n\n\n# Chromagram\nN, H = 4096, 2048\nchromagram = librosa.feature.chroma_stft(y=x, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\n\nfilt_len = 41\ndown_sampling = 10\nfilt_kernel = np.ones([1,filt_len])\nchromagram_smooth =  signal.convolve(chromagram, filt_kernel, mode='same')/filt_len\nchromagram_smooth = chromagram_smooth[:,::down_sampling]\nchromagram_smooth, Fs_smooth = smooth_downsample_feature_sequence(chromagram, \n                        Fs/H, filt_len=filt_len, down_sampling=down_sampling)\n\n# Visualization\nfig, ax = plt.subplots(3, 2, gridspec_kw={'width_ratios': [1, 0.03], \n                                          'height_ratios': [2, 2, 0.5]}, figsize=(9, 5))       \nplot_chromagram(chromagram, Fs=Fs/H, ax=[ax[0,0], ax[0,1]],  \n                         chroma_yticks = [0,4,7,11], \n                         title='Chromagram (resolution %0.1f Hz)'%(Fs/H), \n                         ylabel='Chroma', colorbar=True);\nplot_chromagram(chromagram_smooth, Fs_smooth, ax=[ax[1,0], ax[1,1]],  \n                         chroma_yticks = [0,4,7,11], \n                         title='Smoothed chromagram (resolution %0.1f Hz)'%Fs_smooth, \n                         ylabel='Chroma', colorbar=True);\nplot_segments(ann, ax=ax[2,0], time_max=x_dur, \n                       colors=color_ann, time_label='Time (seconds)')\nax[2,1].axis('off')\n\nplt.tight_layout()\n\n\n\n\n\nAABBCABB\n4개의 반복되는 \\(B\\) 부분 세그먼트는 크로마그램에서 4개의 유사한 특성 하위 시퀀스로 명확하게 표시된다.\n또한 \\(C\\) 부분 세그먼트는 전체 섹션에서 높은 수준의 동질성을 보여줌으로써 크로마그램에서 두드러진다. 실제로 이 세그먼트의 모든 크로마 기능에 대해 대부분의 신호 에너지는 \\(\\mathrm{G}\\)-, \\(\\mathrm{B}\\)- 및 \\(\\mathrm{D}\\)-대역에 포함된다(이는 \\(C\\) 부분이 \\(\\mathrm{G}\\) major에 있기 때문에 놀라운 일은 아니다).\n대조적으로, \\(A\\) 부분 세그먼트의 경우 많은 크로마 벡터가 \\(\\mathrm{G}\\)-, \\(\\mathrm{B}^\\flat\\)- 및 \\(\\mathrm{D}\\)에 지배적으로 분포한다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#mfcc-표현",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#mfcc-표현",
    "title": "5.1. 음악 구조와 분할",
    "section": "MFCC 표현",
    "text": "MFCC 표현\n\n멜로디와 하모니 외에도 악기와 음색(timbre)의 특성은 음악 구조에 대한 인간의 인식에 매우 중요하다.\n음색 기반 구조 분석의 맥락에서 원래 자동 음성 인식용으로 개발된 MFCC(mel-frequency cepstral coefficients) 를 자주 사용한다.\n음악의 경우 MFFC 기반 특징은 악기 및 음색과 같은 측면과 상관관계가 있는 중간 수준(mid-level)의 표현이다.\n노래하는 목소리가 있는 섹션과 악기 섹션이 번갈아 나타나는 팝송과 같은 많은 음악 녹음의 경우 MFCC 기반 특징 표현은 새로움(novelty) 기반 및 동질성 기반 분할에 매우 적합하다.\n\n\n# MFCC\nN, H = 4096, 2048\nX_MFCC = librosa.feature.mfcc(y=x, sr=Fs, hop_length=H, n_fft=N)\ncoef = np.arange(4,15)\nX_MFCC_upper = X_MFCC[coef,:]\n\n# Visualization\nfig, ax = plt.subplots(3, 2, gridspec_kw={'width_ratios': [1, 0.03], \n                                          'height_ratios': [2, 2, 0.5]}, figsize=(9, 5))       \nplot_matrix(X_MFCC, Fs=Fs/H, ax=[ax[0,0], ax[0,1]], \n                     title='MFCC (coefficents 0 to 19)', ylabel='', colorbar=True);\nax[0,0].set_yticks([0, 10, 19])\nplot_matrix(X_MFCC_upper, Fs=Fs/H, ax=[ax[1,0], ax[1,1]], \n                     title='MFFC (coefficents 4 to 14)', ylabel='', colorbar=True);\nax[1,0].set_yticks([0, 5, 10])\nax[1,0].set_yticklabels(coef[0] + [0, 5, 10])\nplot_segments(ann, ax=ax[2,0], time_max=x_dur, \n                       colors=color_ann, time_label='Time (seconds)');  \nax[2,1].axis('off')\nplt.tight_layout()\n\n\n\n\n\n\\(A\\) 부분 세그먼트 내의 MFCC 기능이 \\(B\\) 부분 및 \\(C\\) 부분 세그먼트의 기능과 다르다는 것을 인식할 수 있다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#템포그램-tempogram-표현",
    "href": "posts/5. Music Structure Analysis/5.1.Music_Structure_and_Segmentation.html#템포그램-tempogram-표현",
    "title": "5.1. 음악 구조와 분할",
    "section": "템포그램 (Tempogram) 표현",
    "text": "템포그램 (Tempogram) 표현\n\n음악 구조 분석에서 템포 및 비트 정보는 동질성 기반 분할 접근 방식과 함께 사용될 수도 있다. 이러한 정보를 명시적으로 추출하는 대신, 템포 및 리듬과 관련된 중간-수준의 특징 표현으로 더 높은 구조 수준에서 의미 있는 분할을 유도하는 데 충분할 수 있다.\n로컬 템포 정보를 인코딩하는 중간-수준 표현인 템포그램을 사용한다.\n템포그램의 순환 변형이 표시되며 여기서 2의 거듭제곱 차이가 나는 템포가 식별된다. 옥타브별로 다른 피치가 식별되는 순환 크로마 특징과 유사하다. 템포그램 표현을 살펴보면 다양한 음악 파트가 다른 템포로 연주된다는 것을 알 수 있다(단, 표현이 정확한 템포를 나타내지는 않지만). 또한 템포그램 특징에 지배적인 항목이 없는 섹션이 있는데, 이는 녹음에 템포에 대한 명확한 개념이 없음을 나타낼 수 있다.\n\n(자세한 것은 템포에 대해 다루는 챕터에서 보기로 한다.)\n\nimport utils.tempo_tools as tmpo\n\n\n# Tempogram\nnov, Fs_nov = tmpo.compute_novelty_spectrum(x, Fs=Fs, N=2048, H=512, gamma=100, M=10, norm=True)\nnov, Fs_nov = tmpo.resample_signal(nov, Fs_in=Fs_nov, Fs_out=100)\n\nX, T_coef, F_coef_BPM = tmpo.compute_tempogram_fourier(nov, Fs_nov, N=1000, H=100, Theta=np.arange(30, 601))\n\noctave_bin = 30\ntempogram_F = np.abs(X)\noutput = tmpo.compute_cyclic_tempogram(tempogram_F, F_coef_BPM, octave_bin=octave_bin)\ntempogram_cyclic_F = output[0]\nF_coef_scale = output[1]\ntempogram_cyclic_F = normalize_feature_sequence(tempogram_cyclic_F, norm='max')\n\noutput = tmpo.compute_tempogram_autocorr(nov, Fs_nov, N=500, H=100, norm_sum=False,\n                                              Theta=np.arange(30, 601))\ntempogram_A = output[0]\nT_coef = output[1]\nF_coef_BPM = output[2]\n\noutput = tmpo.compute_cyclic_tempogram(tempogram_A, F_coef_BPM, octave_bin=octave_bin)\ntempogram_cyclic_A = output[0]\nF_coef_scale = output[1]\ntempogram_cyclic_A = normalize_feature_sequence(tempogram_cyclic_A, norm='max')\n\n# Visualization\nfig, ax = plt.subplots(3, 2, gridspec_kw={'width_ratios': [1, 0.03], \n                                          'height_ratios': [2, 2, 0.5]}, figsize=(9, 5))       \n\nplot_matrix(tempogram_cyclic_F, T_coef=T_coef, ax=[ax[0,0], ax[0,1]], \n                     title='Fourier-based cyclic tempogram', ylabel='Scaling',\n                     colorbar=True, clim=[0, 1])\ntmpo.set_yticks_tempogram_cyclic(ax[0,0], octave_bin, F_coef_scale, num_tick=5)\n\nplot_matrix(tempogram_cyclic_A, T_coef=T_coef, ax=[ax[1,0], ax[1,1]], \n                     title='Autocorrelation-based cyclic tempogram', ylabel='Scaling',\n                     colorbar=True, clim=[0, 1])\ntmpo.set_yticks_tempogram_cyclic(ax[1,0], octave_bin, F_coef_scale, num_tick=5)\n\nplot_segments(ann, ax=ax[2,0], time_max=x_dur, \n                       colors=color_ann, time_label='Time (seconds)')\nax[2,1].axis('off')\n\nplt.tight_layout()\n\n\n\n\n\n다양한 음악적 차원 외에도 적절한 특징 표현을 찾을 때 염두에 두어야 할 또 다른 측면이 있다. 바로 시간적(temporal) 차원이다. 위에서 언급한 모든 특징 표현에서 분석 창(winodw)은 음악 신호 위로 이동한다.\n분명히 분석 윈도우의 길이와 홉 크기 매개변수는 특징 표현의 품질에 결정적인 영향을 미친다. 예를 들어 긴 윈도우 크기와 큰 홉 크기는 동질성 기반 분할에서 종종 원하는 속성인 관련 없는 로컬 변형을 부드럽게 하는 데 도움이 될 수 있다. 단점은 시간적 해상도가 감소하고 중요한 세부 정보가 손실될 수 있어 정확한 분할 경계를 찾을 때 문제가 발생할 수 있다는 것이다.\n요약하면 특징 표현 및 매개변수 설정의 적절한 선택은 응용 맥락에 따라 크게 달라진다. 음악 구조의 풍부함과 다양성은 구조 분석을 어렵게 할 수 있다.\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C4/C4S1_MusicStructureGeneral.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "",
    "text": "음악 구조를 분석하기 위한 기술적 도구인 자기 유사성 행렬(self similarity matrix)의 개념에 대해 상세히 다루고, 그 구조적 속성에 대해 논의한다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#기본-정의",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#기본-정의",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "기본 정의",
    "text": "기본 정의\n\n\\(\\mathcal{F}\\)를 특징(feature) 공간이라고 하고 \\(s:\\mathcal{F}\\times\\mathcal{F}\\to \\mathbb{R}\\)를 두 요소 \\(x,y\\in\\mathcal{F}\\)를 비교할 수 있는 유사성(similarity) 척도라고 하자. 일반적으로 \\(s(x,y)\\) 값은 요소 \\(x,y\\in\\mathcal{F}\\)가 비슷하면 높고 그렇지 않으면 작다.\n특징 시퀀스 \\(X=(x_1,x_2,\\ldots,x_N)\\)가 주어지면 시퀀스의 모든 요소를 서로 비교할 수 있다.\n결과적으로 \\(N\\)-square 자기 유사성 행렬(self-similarity matrix) \\(\\mathbf{S}\\in\\mathbb{R}^{N\\times N}\\)이 아래와 같이 정의된다.\n\n\\[\\mathbf{S}(n,m):=s(x_n,x_m),\\] where \\(x_n,x_m\\in\\mathcal{F}\\) for \\(n,m\\in[1:N]\\)\n\n다음에서 \\((n,m)\\in[1:N]\\times[1:N]\\) 튜플은 \\(\\mathbf{S}\\)의 셀(cell)이라고도 하며 값 \\(\\mathbf{S}(n,m)\\)는 셀 \\((n,m)\\)의 점수(score)라고 한다.\n응용의 맥락 및 데이터를 비교하는 데 사용되는 개념에 따라 반복 플롯(recurrence plot), 비용 매트릭스(cost matrix) 또는 자기-거리 매트릭스(self-distance matrix) 와 같은 다른 이름으로 알려진 관련된 개념이 많다.\n종종 특징 공간이 차원 \\(K\\in\\mathbb{N}\\)의 유클리드 공간 \\(\\mathcal{F}=\\mathbb{R}^K\\)라고 가정한다. 간단한 유사성 측정 \\(s\\)는 예를 들어 다음과 같이 정의된 내적이다.\n\n\\[s(x,y) := \\langle x,y\\rangle\\] for two vectors \\(x,y\\in\\mathcal{F}\\)\n\n이 유사성 측정을 사용하면 직교(orthogonal)하는 두 특징(feature) 벡터 사이의 점수는 0이고, 그렇지 않으면 0이 아니다. 특징 벡터가 유클리드 노름(norm)에 대해 정규화되는 경우, 유사성 값 \\(s(x,y)\\)는 \\([-1,1]\\) 구간에 있다. 이 경우 정규화된 피쳐의 시퀀스 \\(X=x_1,x_2,\\ldots,x_N)\\)가 주어지면, \\(s(x_n,x_n)=1\\) for all \\(n\\in[1:N]\\)인 경우 SSM의 최대값이 가정된다. 따라서 결과 SSM에는 값이 큰 대각선이 있다. 더 일반적으로 말하면, 주어진 특징 시퀀스의 반복 패턴은 유사성 값이 큰 구조의 형태로 SSM에서 볼 수 있다.\n다음 예에서는 정규화된(normalized) 특징 벡터의 합성(synthetic) 특징 시퀀스를 생성한다. 특징 벡터의 차원은 \\(K=4\\)이고 시퀀스의 길이는 \\(N=500\\)이다. 그림은 특징 시퀀스와 결과 SSM을 보여준다.\n중요 사항:\n\nSSM을 시각화할 때 컬러맵 ’cmap’의 선택은 그림의 전체적인 모습에 상당한 영향을 미칠 수 있다. 적합한 컬러맵을 선택하면 SSM의 특정 속성을 시각적으로 강조하는 데 도움이 될 수 있다.\n위에서 설명한 정규화된 특징의 특징 시퀀스와 유사도 측정을 사용하면 간단한 행렬-행렬 곱으로 SSM을 계산할 수 있다. 보다 정확하게는 \\(K\\times N\\)-matrix \\(X\\)에 의해 특성 시퀀스가 구현되는 경우, SSM \\(S\\)는 \\(S=X^\\top X\\)로 주어진다. \n또한, 특징 벡터의 모든 항목이 양수라고 종종 가정한다. 이 경우 \\(s(x_n,x_m)\\) 값은 양수이며 \\([0,1]\\) 간격에 있다.\n\n\n\n# Generate normalized feature sequence\nK = 4\nM = 100\nr = np.arange(M)\nb1 = np.zeros((K,M))\nb1[0,:] = r\nb1[1,:] = M-r\nb2 = np.ones((K,M))\nX = np.concatenate(( b1, b1, np.roll(b1, 2, axis=0), b2, b1 ), axis=1)\nX_norm = normalize_feature_sequence(X, norm='2', threshold=0.001)\n\n# Compute SSM\nS = np.dot(np.transpose(X_norm), X_norm)\n\n# Visualization\ncmap = 'gray_r'\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [0.3, 1]}, figsize=(4, 5))\nplot_matrix(X_norm, Fs=1, ax=[ax[0,0], ax[0,1]], cmap=cmap,\n            xlabel='Time (frames)', ylabel='', title='Feature sequence')\nplot_matrix(S, Fs=1, ax=[ax[1,0], ax[1,1]], cmap=cmap,\n            title='SSM', xlabel='Time (frames)', ylabel='Time (frames)', colorbar=True);\nplt.tight_layout()\n\n\n\n\n\n컬러맵을 적절하게 조정하여 시각적 모양을 변경할 수 있다. 예를 들어 색상 분포를 더 밝은 색상으로 이동하면 시각화의 경로 구조가 향상된다.\n\n\ncmap = compressed_gray_cmap(alpha=-1000)\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [0.3, 1]}, figsize=(4,5))\nplot_matrix(X, Fs=1, ax=[ax[0,0], ax[0,1]], cmap=cmap,\n            xlabel='Time (frames)', ylabel='', title='Feature sequence')\nplot_matrix(S, Fs=1, ax=[ax[1,0], ax[1,1]], cmap=cmap,\n            title='SSM', xlabel='Time (frames)', ylabel='Time (frames)', colorbar=True);\nplt.tight_layout()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#블록과-경로구조-block-and-path-structures",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#블록과-경로구조-block-and-path-structures",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "블록과 경로구조 (Block and Path Structures)",
    "text": "블록과 경로구조 (Block and Path Structures)\n\nSSM에서 가장 눈에 띄는 두 가지 구조는 이미 앞의 예에서 볼 수 있듯이 블록(block) 및 경로(paths) 라고 한다.\n특징 시퀀스가 전체 음악의 지속 기간(duration) 동안 다소 일정하게 유지되는 음악 속성을 캡처하는 경우, 각 특징 벡터는 이 세그먼트 내의 다른 모든 특징 벡터와 유사함을 의미한다. 결과적으로 큰 값의 전체 블록이 SSM에 나타난다.\n\n즉, 동질성(homogeneity) 속성은 블록 같은(block-like) 구조에 해당한다.\n\n특징 시퀀스가 2개의 반복 하위시퀀스(예를 들어, 동일한 멜로디에 대응하는 2개의 세그먼트)를 포함하는 경우, 두 하위시퀀스의 대응하는 요소는 서로 유사하다. 결과적으로 주 대각선과 평행하게 실행되는 유사성이 높은 경로(또는 스트라이프(stripe))가 SSM에 표시된다.\n\n즉, 반복(repetitive) 속성은 경로 같은(path-like) 구조에 해당한다.\n\n예로, 다음 그림은 음악적 구조가 \\(A_1A_2B_1B_2CA_3B_3B_4D\\)인 Brahms의 헝가리 무곡 5번에 대한 이상적인 SSM을 보여준다. 세 개의 반복되는 \\(A\\) 부분 세그먼트가 동종이라고 가정하면 SSM에는 \\(A_1A_2\\)에 해당하는 세그먼트를 자신과 관련시키는 2차 블록과 \\(A_3\\) 부분 세그먼트를 자신과 관련시키는 또 다른 2차 블록이 있다. 또한 두 개의 직사각형 블록이 있는데, 하나는 \\(A_1A_2\\) 부분 세그먼트를 \\(A_3\\) 부분 세그먼트에 연결하고 다른 하나는 \\(A_3\\) 부분 세그먼트를 \\(A_1A_2\\) 부분 세그먼트에 연결한다. 3개의 반복되는 \\(A\\) 부분 세그먼트가 동질적이지 않은 경우 SSM은 주 대각선에 평행하게 실행되는 경로 구조를 나타낸다. 예를 들어 \\(A_1\\)와 \\(A_2\\)의 유사도가 큰 경로와 \\(A_1\\)와 \\(A_3\\)의 경로가 있다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F07a.png\", width=300)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#크로마그램-기반-ssm",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#크로마그램-기반-ssm",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "크로마그램 기반 SSM",
    "text": "크로마그램 기반 SSM\n\n다음 코드는 크로마그램(chromagram) 을 특징 표현으로 사용하여 Brahms의 헝가리 댄스 녹음에서 SSM을 생성한다. 시각화에서 \\(\\mathbf{S}\\)의 큰 값은 어두운 회색으로 표시되고 작은 값은 밝은 회색으로 표시된다.\n실제로 이 경우 얻은 SSM은 이상적인 SSM과 상당 부분 유사하다. \\(A\\) 부분 세그먼트에 해당하는 block-like 구조는 이러한 세그먼트가 화음과 관련하여 상당히 동질적임을 나타낸다. \\(C\\) 부분 세그먼트도 마찬가지다. 또한, \\(C\\) 부분 블록 외부의 작은 유사성 값(즉, \\(C\\) 부분 프레임을 다른 세그먼트의 프레임에 연결하는 모든 셀)은 \\(C\\) 부분 세그먼트가 화성적으로 모든 부분과 거의 관련이 없음을 보여준다. \\(B\\) 부분 세그먼트의 경우 path-like 구조가 있고 block-like 구조는 없다. 이는 \\(B\\) 파트 세그먼트가 동일한 화성 진행(즉, 화성에 대한 반복)을 공유하지만 화성에 대해 동질적이지 않음을 보여준다.\n흥미로운 점은 반복하더라도 \\(B\\) 부분 세그먼트가 다른 템포로 재생되므로 길이가 다르다는 것이다. 예를 들어 짧은 \\(B_2\\) 섹션은 \\(B_1\\) 섹션보다 빠르게 재생된다. 결과적으로 해당 경로는 정확히 병렬로 실행되지 않는다.\n\n\ndef compute_sm_dot(X, Y):\n    \"\"\"Computes similarty matrix from feature sequences using dot (inner) product\n\n    Args:\n        X (np.ndarray): First sequence\n        Y (np.ndarray): Second Sequence\n\n    Returns:\n        S (float): Dot product\n    \"\"\"\n    S = np.dot(np.transpose(X), Y)\n    return S\n\n\ndef plot_feature_ssm(X, Fs_X, S, Fs_S, ann, duration, color_ann=None,\n                     title='', label='Time (seconds)', time=True,\n                     figsize=(5, 6), fontsize=10, clim_X=None, clim=None):\n    \"\"\"Plot SSM along with feature representation and annotations (standard setting is time in seconds)\n\n    Args:\n        X: Feature representation\n        Fs_X: Feature rate of ``X``\n        S: Similarity matrix (SM)\n        Fs_S: Feature rate of ``S``\n        ann: Annotaions\n        duration: Duration\n        color_ann: Color annotations (see :func:`libfmp.b.b_plot.plot_segments`) (Default value = None)\n        title: Figure title (Default value = '')\n        label: Label for time axes (Default value = 'Time (seconds)')\n        time: Display time axis ticks or not (Default value = True)\n        figsize: Figure size (Default value = (5, 6))\n        fontsize: Font size (Default value = 10)\n        clim_X: Color limits for matrix X (Default value = None)\n        clim: Color limits for matrix ``S`` (Default value = None)\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n    \"\"\"\n    cmap = compressed_gray_cmap(alpha=-10)\n    fig, ax = plt.subplots(3, 3, gridspec_kw={'width_ratios': [0.1, 1, 0.05],\n                                              'wspace': 0.2,\n                                              'height_ratios': [0.3, 1, 0.1]},\n                           figsize=figsize)\n    plot_matrix(X, Fs=Fs_X, ax=[ax[0, 1], ax[0, 2]], clim=clim_X,\n                         xlabel='', ylabel='', title=title)\n    ax[0, 0].axis('off')\n    plot_matrix(S, Fs=Fs_S, ax=[ax[1, 1], ax[1, 2]], cmap=cmap, clim=clim,\n                         title='', xlabel='', ylabel='', colorbar=True)\n    ax[1, 1].set_xticks([])\n    ax[1, 1].set_yticks([])\n    plot_segments(ann, ax=ax[2, 1], time_axis=time, fontsize=fontsize,\n                           colors=color_ann,\n                           time_label=label, time_max=duration*Fs_X)\n    ax[2, 2].axis('off')\n    ax[2, 0].axis('off')\n    plot_segments(ann, ax=ax[1, 0], time_axis=time, fontsize=fontsize,\n                           direction='vertical', colors=color_ann,\n                           time_label=label, time_max=duration*Fs_X)\n    return fig, ax\n\n\nfn_wav = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.wav'\nx, Fs = librosa.load(fn_wav)\nipd.Audio(x,rate=Fs)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nx_duration = (x.shape[0])/Fs\n\n# Chroma Feature Sequence\nN, H = 4096, 1024\nchromagram = librosa.feature.chroma_stft(y=x, sr=Fs, tuning=0, norm=2, hop_length=H, n_fft=N)\nX, Fs_X = smooth_downsample_feature_sequence(chromagram, Fs/H, filt_len=41, down_sampling=10) #smoothed\n\n# Annotation\nfn_ann = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.csv'\nann, color_ann = read_structure_annotation(fn_ann)\nann_frames = convert_structure_annotation(ann, Fs=Fs_X) \n\n# SSM \nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\nS = compute_sm_dot(X,X)\n\n\nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X, color_ann=color_ann,\n                           clim_X=[0,1], clim=[0,1], label='Time (frames)',\n                           title='Chroma feature (Fs=%0.2f)'%Fs_X)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#mfcc-기반-ssm",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#mfcc-기반-ssm",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "MFCC 기반 SSM",
    "text": "MFCC 기반 SSM\n\n다음으로 MFCC 특징을 기반으로 SSM을 계산해본다. 이 표현의 모든 \\(K(=20)\\)개의 MFCC 계수를 사용하면 주로 block-like 구조를 가지는 SSM이 생성된다. 특히 \\(A\\) 부분과 \\(C\\) 부분에 대략적으로 대응하는 블록을 관찰할 수 있다. 실제로 블록 구조는 MFCC 특징의 처음 두 개(낮은) 계수에 의해 지배된다. 계수 \\(4\\) ~ \\(14\\)만 고려하면 더 미세한 블록 구조를 갖고 경로와 같은 구조를 나타내는 SSM이 생성된다.\n중요 사항:\n\nSSM을 계산하기 전에, 다운샘플링과 함께 평균화 필터를 적용하여 스무딩을 적용한다. 스무딩은 피처 시퀀스의 작은 로컬 변동을 억제하고 결과 SSM에 상당한 영향을 미칠 수 있다.\n특징 시퀀스를 \\(H\\)만큼 다운샘플링하면 SSM \\(\\mathbf{S}\\)를 계산할 때 \\(H^2\\)만큼 효율성이 증가한다.\nMFCC 특징의 값이 음수일 수 있으므로 SSM 값도 음수일 수 있다(MFCC 기능을 정규화한 후 \\([1,-1]\\) 구간에서).\n\n\n\n# MFCC-based feature sequence\nN, H = 2048, 1024\nX_MFCC = librosa.feature.mfcc(y=x, sr=Fs, hop_length=H, n_fft=N)\n\ncoef = np.arange(0,20)\nX_MFCC_upper = X_MFCC[coef,:]\nX, Fs_X = smooth_downsample_feature_sequence(X_MFCC_upper, Fs/H, filt_len=41, down_sampling=10)\nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\nS = compute_sm_dot(X,X)\n\nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X, color_ann=color_ann,\n    title='MFCC (20 coefficients, Fs=%0.2f)'%Fs_X, label='Time (frames)')\n\n\n# MFCC-based feature sequence only using coefficients 4 to 14\ncoef = np.arange(4,15)\nX_MFCC_upper = X_MFCC[coef,:]\nX, Fs_X = smooth_downsample_feature_sequence(X_MFCC_upper, Fs/H, filt_len=41, down_sampling=10)\nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\nS = compute_sm_dot(X,X)\nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X, \n                           color_ann=color_ann, label='Time (frames)',\n                           title='MFCC (coefficients 4 to 14, Fs=%0.2f)'%Fs_X)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#템포그램-기반-ssm",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#템포그램-기반-ssm",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "템포그램 기반 SSM",
    "text": "템포그램 기반 SSM\n\n마지막으로 순환 푸리에 템포그램(cyclic Fourier tempogram) 을 기본 특징(feature) 표현으로 사용하여 SSM을 계산한다. 크로마 기반의 SSM에 비해 템포그램 기반의 SSM은 구조가 명확하지 않다.\n적어도 \\(C\\) 부분 세그먼트에 해당하는 블록을 관찰할 수 있으므로 대조되는 역할을 강조한다. 또한 SSM은 음악 녹음에서 발생하는 많은 템포 변화를 나타낸다.\n\n\n# Tempogram feature sequence\nnov, Fs_nov = tmpo.compute_novelty_spectrum(x, Fs=Fs, N=2048, H=512, gamma=100, M=10, norm=True)\nnov, Fs_nov = tmpo.resample_signal(nov, Fs_in=Fs_nov, Fs_out=100)\n\n\nN, H = 1000, 100\nX, T_coef, F_coef_BPM = tmpo.compute_tempogram_fourier(nov, Fs_nov, N=N, H=H, Theta=np.arange(30, 601))\noctave_bin = 12\ntempogram_F = np.abs(X)\noutput = tmpo.compute_cyclic_tempogram(tempogram_F, F_coef_BPM, octave_bin=octave_bin)\nX = output[0]\nF_coef_scale = output[1]\nFs_X = Fs_nov/H\nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\nS = compute_sm_dot(X,X)\n\n\nann_frames = convert_structure_annotation(ann, Fs=Fs_X)\n\nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X, color_ann=color_ann,\n    title='Tempogram (Fs=%0.2f)'%Fs_X, label='Time (frames)')"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#경로와-블록의-정의",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#경로와-블록의-정의",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "경로와 블록의 정의",
    "text": "경로와 블록의 정의\n\n세그먼트(segment)를 시작점 \\(s\\)와 끝점 \\(t\\)로 지정된 집합 \\(\\alpha=[s:t]\\subseteq [1:N]\\)로 정의한다. (특징 인덱스로 주어짐).\n\\(|\\alpha|:=t-s+1\\)가 \\(\\alpha\\)의 길이를 나타낸다고 하자.\n다음으로, 길이 \\(L\\)의 \\(\\alpha\\) 의 경로(path)는 다음의 시퀀스와 같다. \\[P=((n_1,m_1), \\ldots,(n_L,m_L))\\]\n\n\\((n_\\ell,m_\\ell)\\in[1:N]^2\\), \\(\\ell\\in[1:L]\\)\n\\(m_1=s\\) 및 \\(m_L=t\\)를 만족 (boundary condition)\n\\((n_{\\ell+1},m_{\\ell+1}) -(n_\\ell,m_\\ell)\\in \\Sigma\\) (step size condition), 여기서 \\(\\Sigma\\)는 허용 가능한 step size 집합을 나타냄\n\n이 정의는 워핑 경로(warping path)의 정의와 비슷하다. \\(\\Sigma = \\{(1,1)\\}\\)의 경우, 경로는 “strictly diagonal”하다.\n다음에서 집합 \\(\\Sigma = \\{(2,1),(1,2),(1,1)\\}\\)을 사용한다. 경로 \\(P\\)에 대해, 각각 \\(\\pi_1(P):=[n_1:n_L]\\)와 \\(\\pi_2(P):=[m_1:m_L]\\) 투영(projection)으로 정의된 두 세그먼트를 연결할 수 있다.\n경계 조건에 따라 \\(\\pi_2(P)=\\alpha\\)이 적용된다. 다른 세그먼트 \\(\\pi_1(P)\\)는 유도된(induced) 세그먼트라고 한다.\n\\(P\\)의 점수 \\(\\sigma(P)\\)는 다음과 같이 정의된다. \\[\\sigma(P) := \\sum_{\\ell=1}^L \\mathbf{S}(n_\\ell,m_\\ell)\\]\n\\(\\alpha\\) 세그먼트의 각 경로는 \\(\\alpha\\)와 유도된 세그먼트 사이의 관계를 인코딩하며, 이 때 \\(\\sigma(P)\\) 점수는 이 관계에 대한 퀄리티 척도(quality measure)를 산출한다.\n세그먼트 \\(\\alpha=[s:t]\\) 위의 블록은 다음의 하위 집합이다.. \\[B=\\alpha' \\times \\alpha \\subseteq [1:N]\\times [1:N]\\] for some segment \\(\\alpha'=[s':t']\\)\n경로와 마찬가지로 블록 \\(B\\)에 대한 두 개의 투영 \\(\\pi_1(B)=\\alpha'\\) 및 \\(\\pi_2(B)=\\alpha\\)를 정의하고 \\(\\alpha'\\)를 유도된 세그먼트라고 부른다.\n또한 블록 \\(B\\)의 점수를 다음과 같이 정의한다.\n\n\\(\\sigma(B)=\\sum_{(n,m)\\in B}\\mathbf{S}(n,m)\\)\n\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F08.png\", width=600)\n\n\n\n\n\n경로와 블록을 기반으로 세그먼트 간의 서로 다른 종류의 유사 관계를 고려할 수 있다.\n\n\\(\\pi_1(P)=\\alpha_1\\) 및 \\(\\pi_2(P)=\\alpha_2\\)의 높은 점수의 경로 \\(P\\)가 있는 경우, \\(\\alpha_1\\) 세그먼트는 \\(\\alpha_2\\) 세그먼트와 경로 유사(path-similar) 하다고 한다.\n\\(\\pi_1(B)=\\alpha_1\\) 및 \\(\\pi_2(B)=\\alpha_2\\)의 높은 점수의 블록 \\(B\\)가 있는 경우, \\(\\alpha_1\\)는 \\(\\alpha_2\\)와 블록 유사(block-similar) 하다.\n\n유사성 측정 \\(s\\)가 대칭인 경우, 자기 유사성 행렬 \\(\\mathbf{S}\\)와 위에서 정의한 세그먼트 간의 유사성 관계도 대칭적이다.\n유사성 관계의 또 다른 중요한 속성은 전이성(transitivity)이다. 즉 \\(\\alpha_1\\) 세그먼트가 \\(\\alpha_2\\) 세그먼트와 유사하고 \\(\\alpha_2\\) 세그먼트가 \\(\\alpha_3\\) 세그먼트와 유사하면 \\(\\alpha_1\\)도 \\(\\alpha_3\\)와 유사해야 한다.\n또한 유사성 척도 \\(s\\)에 전이성이 있는 경우 경로 및 블록 유사성에 대해서도 전이성은 유지된다. 결과적으로 경로 및 블록 구조는 (적어도 이상적인 경우에는) 특정 대칭 및 전이 속성을 충족하는 그룹으로 나타나는 경우가 많다.\n음악 구조 분석에 대한 대부분의 계산적 접근은 SSM의 경로- 및 블록-like 구조를 어떤 식으로든 활용하며, 전체 알고리즘 파이프라인에는 일반적으로 다음과 같은 일반적인 단계가 포함된다.\n\n음악 신호는 적절한 특징 시퀀스(feature sequence)로 변환된다.\n자기 유사성 행렬(SSM)은 유사성 측정을 기반으로 특징 시퀀스에서 계산된다.\n전체 점수가 높은 블록과 경로는 SSM에서 구해진다. 각 블록 또는 경로는 유사한 세그먼트 쌍을 정의한다.\n상호 유사한 세그먼트의 전체 그룹은 클러스터링 단계를 적용하여 쌍별(pairwise) 관계에서 형성된다.\n\n마지막 단계는 블록 및 경로 구조에 의해 유도된 쌍별 세그먼트 관계의 일종의 전이적 폐쇄(transitive closure)를 형성하는 것으로 간주할 수 있다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/f.4.9.PNG\")"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#대각-스무딩-diagonal-smoothing",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#대각-스무딩-diagonal-smoothing",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "대각 스무딩 (Diagonal Smoothing)",
    "text": "대각 스무딩 (Diagonal Smoothing)\n\n유사성 행렬의 중요한 속성 중 하나는 주 대각선과 평행한 높은 유사성의 경로 모양이다.\n이러한 각 경로는 각각 가로 및 세로 축에 경로를 투영하여 얻은 두 세그먼트의 유사성을 인코딩한다. 이러한 경로의 식별과 추출은 많은 음악 분석의 응용 단계이다. 그러나 음악적 및 음향적 변화로 인해 경로 구조는 종종 매우 노이지하며 추출하기 어려워 진다.\n이러한 노이즈는 피쳐 계산 단계에서 더 긴 분석 윈도우를 사용하고 피쳐 레이트를 조정함으로써 어느 정도 줄일 수 있다.\n경로 구조를 더욱 향상시키기 위한 일반적인 전략 중 하나는 주 대각선 방향을 따라 일종의 스무딩 필터를 적용하여 \\(\\mathbf{S}\\)의 대각선 정보를 강조하고 다른 구조의 노이즈를 제거하는 것이다.\n대각 스무딩(diagonal smoothing)이라고도 하는 이러한 필터링 과정은 동적 시스템(dynamical system) 분석에 널리 사용되는 시간 지연 임베딩(time-delay embedding) 개념과 밀접한 관련이 있다.\n\\(\\mathbf{S}\\)를 \\(N\\times N\\) 크기의 SSM이라고 하고 \\(L\\in\\mathbb{N}\\)를 스무딩 필터의 길이(length)라고 하자. 평활화된 SSM \\(\\mathbf{S}_L\\)을 다음과 같이 정의한다. \\[\\mathbf{S}_L(n,m) := \\frac{1}{L} \\sum_{\\ell=0}^{L-1} \\mathbf{S}(n+\\ell,m+\\ell)\\] for \\(n,m\\in[1:N-L+1]\\)\n\\(\\mathbf{S}\\)를 적절하게 확장함으로써(예: 제로 패딩으로 0열과 행이 추가됨) \\(n,m\\in[1:N]\\)에 대해 \\(\\mathbf{S}_L(n,m)\\)이 정의된다.\n효율성 문제를 생각했을 때, 행렬 기반 작업을 사용하여 스무딩 절차를 구현한다. 구현의 주요 아이디어는 다음과 같다.\n\n\\(\\ell\\in[0:L-1]\\)에 대해 \\(\\mathbf{S}\\)의 \\(\\ell\\)-shifted 버전을 생성한다. 이를 위해 주 대각선을 따라 \\(\\ell\\) 위치만큼 \\(\\mathbf{S}\\)를 이동시킨다.\n그런 다음 \\(\\ell\\in[0:L-1]\\)에서 \\(\\ell\\)-이동된 버전을 합산한다. 결과 행렬을 \\(L\\)로 나누면 \\(\\mathbf{S}_L\\) 행렬이 된다.\n경계 효과를 처리하기 위해 \\((N+L)\\) 사각 행렬(all zero)로 시작하는 제로 패딩을 사용한다.\n\n\n\ndef filter_diag_sm(S, L):\n    \"\"\"Path smoothing of similarity matrix by forward filtering along main diagonal\n\n    Args:\n        S (np.ndarray): Similarity matrix (SM)\n        L (int): Length of filter\n\n    Returns:\n        S_L (np.ndarray): Smoothed SM\n    \"\"\"\n    N = S.shape[0]\n    M = S.shape[1]\n    S_L = np.zeros((N, M))\n    S_extend_L = np.zeros((N + L, M + L))\n    S_extend_L[0:N, 0:M] = S\n    for pos in range(0, L):\n        S_L = S_L + S_extend_L[pos:(N + pos), pos:(M + pos)]\n    S_L = S_L / L\n    return S_L\n\n\ndef subplot_matrix_colorbar(S, fig, ax, title='', Fs=1,\n                            xlabel='Time (seconds)', ylabel='Time (seconds)',\n                            clim=None, xlim=None, ylim=None, cmap=None, interpolation='nearest'):\n    \"\"\"Visualization function for showing zoomed sections of matrices\n\n    Args:\n        S: Similarity matrix (SM)\n        fig: Figure handle\n        ax: Axes handle\n        title: Title for figure (Default value = '')\n        Fs: Feature rate (Default value = 1)\n        xlabel: Label for x-axis (Default value = 'Time (seconds)')\n        ylabel: Label for y-axis (Default value = 'Time (seconds)')\n        clim: Color limits (Default value = None)\n        xlim: Limits for x-axis (Default value = None)\n        ylim: Limits for x-axis (Default value = None)\n        cmap: Colormap for imshow (Default value = None)\n        interpolation: Interpolation value for imshow (Default value = 'nearest')\n\n    Returns:\n        im: Imshow handle\n    \"\"\"\n    if cmap is None:\n        cmap = compressed_gray_cmap(alpha=-100)\n    len_sec = S.shape[0] / Fs\n    extent = [0, len_sec, 0, len_sec]\n    im = ax.imshow(S, aspect='auto', extent=extent, cmap=cmap,  origin='lower', interpolation=interpolation)\n    fig.sca(ax)\n    fig.colorbar(im)\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if xlim is not None:\n        ax.set_xlim(xlim)\n    if ylim is not None:\n        ax.set_ylim(ylim)\n    if clim is not None:\n        im.set_clim(clim)\n    return im\n\n\nL, H = 21, 5\nX, Fs_X = smooth_downsample_feature_sequence(C, Fs_C, \n                        filt_len=L, down_sampling=H)\n\nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\nS = compute_sm_dot(X,X)\n\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 3))\nsubplot_matrix_colorbar(S, fig, ax[0], clim=[0,1], ylabel='Time (frames)', xlabel='Time (frames)',\n                     title=r'Original SSM $\\mathbf{S}$')\nL = 20\nS_L = filter_diag_sm(S, L)\nsubplot_matrix_colorbar(S_L, fig, ax[1], clim=[0,1], ylabel='Time (frames)', xlabel='Time (frames)',\n                     title=r'Smoothed SSM $\\mathbf{S}_{L}$ (L = %d)'%L)\nL_long = 40\nS_L_long = filter_diag_sm(S, L_long)\nsubplot_matrix_colorbar(S_L_long, fig, ax[2], clim=[0,1], ylabel='Time (frames)', xlabel='Time (frames)',\n                     title=r'Smoothed SSM $\\mathbf{S}_{L}$ (L = %d)'%L_long)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n비교할 세그먼트 간에 상대적인 템포 차이가 없는 경우 주 대각선을 따라 간단한 필터링이 잘 작동한다. 그러나 이 가정은 파트가 더 빠르거나 더 느린 템포로 반복될 때는 위반된다.\nBrahms 예의 B 섹션에서 짧은 B2 섹션은 B1 섹션보다 훨씬 빠르게 재생된다. B2 섹션의 시작 부분만 B1 섹션의 시작 부분보다 훨씬 빠르게 재생되는 반면, 두 섹션은 파트의 끝 부분에서 거의 동일한 템포를 가진다.\n이로 인해 경로가 주 대각선(특히 시작 부분)과 정확히 평행하지 않으므로 주 대각선 방향으로 평균화 필터를 적용하면 일부 경로 구조가 파괴된다. 이것은 필터 길이 L이 큰 경우에 발생한다.\n\n\nxlim = [75, 150]\nylim = [125, 200]\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 3.5))\nsubplot_matrix_colorbar(S, fig, ax[0], clim=[0,1], xlim=xlim, ylim=ylim,\n                        title=r'Original SSM $\\mathbf{S}$', \n                        xlabel='Time (frames)', ylabel='Time (frames)')\nsubplot_matrix_colorbar(S_L, fig, ax[1], clim=[0,1], xlim=xlim, ylim=ylim,\n                        title=r'Smoothed SSM $\\mathbf{S}_{L}$ (L = %d)'%L, \n                        xlabel='Time (frames)', ylabel='Time (frames)')\nsubplot_matrix_colorbar(S_L_long, fig, ax[2], clim=[0,1], xlim=xlim, ylim=ylim,\n                        title=r'Smoothed SSM $\\mathbf{S}_{L}$ (L = %d)'%L_long, \n                        xlabel='Time (frames)', ylabel='Time (frames)')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#다중-필터링-multiple-filtering",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#다중-필터링-multiple-filtering",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "다중 필터링 (Multiple Filtering)",
    "text": "다중 필터링 (Multiple Filtering)\n\n상대적인 템포 차이로 인한 비대각선 경로 구조를 처리하기 위해, 특정 가정 하에 이러한 구조를 보존하는 다중 필터링 접근 방식을 도입한다.\n이 접근법의 주요 아이디어는 주 대각선으로 정의된 방향의 이웃에 있는 다양한 방향을 따라 유사성 행렬을 필터링하는 것이다. 이러한 각 방향은 템포 차이에 해당하며, 별도로 필터링된 유사성 매트릭스가 생성된다. 최종 유사성 행렬은 이러한 모든 행렬에 대해 셀별 최대값을 취하여 얻는다.\n이러한 방식으로 경로 구조는 로컬 템포 변형이 있는 경우에도 향상된다.\n템포 차이가 실수 \\(\\theta>0\\)로 주어진다고 가정하자. \\((1,\\theta)\\) 방향으로 평활화된 자기 유사성 행렬을 다음과 같이 정의한다. \\[\\mathbf{S}_{L,\\theta}(n,m) := \\frac{1}{L} \\sum_{\\ell=0}^{L-1} \\mathbf{S}(n+\\ell,m+[\\ell\\cdot\\theta])\\]\n\n\\([\\ell\\cdot\\theta]\\)는 실수 \\(\\ell\\cdot\\theta\\)에 가장 가까운 정수\n\n다시, 행렬 \\(\\mathbf{S}\\)를 적절히 제로-패딩함으로써 \\(\\mathbf{S}_{L,\\theta}\\)가 \\(n,m\\in[1:N]\\)에 대해 정의되었다고 가정할 수 있다.\n실제로는 주어진 음악 녹음에서 발생할 수 있는 로컬 템포 차이를 알 수 없다. 또한 두 반복 섹션 간의 상대적인 템포 차이는 시간이 지남에 따라 변경될 수 있다. 따라서 다른 상대적 템포 차이에 대한 템포 매개변수 \\(\\theta\\in\\Theta\\)로 구성된 (유한) 집합 \\(\\Theta\\)를 고려한다. 그런 다음 각 \\(\\theta\\)에 대해 행렬 \\(\\mathbf{S}_{L,\\theta}\\)를 계산하고 모든 \\(\\theta\\in\\Theta\\)에 대한 셀별 최대화로 최종 행렬 \\(\\mathbf{S}_{L,\\Theta}\\)를 얻는다. \\[\\mathbf{S}_{L,\\Theta}(n,m) := \\max_{\\theta\\in\\Theta} \\mathbf{S}_{L,\\theta}(n,m)\\]\n\\(\\Theta=\\{1\\}\\)를 선택하면 \\(\\mathbf{S}_{L,\\Theta}=\\mathbf{S}_{L}\\)의 경우로 축소된다.\n실제로는 \\(\\Theta\\) 집합을 결정하기 위해 예상되는 상대 템포 차이에 대한 사전 정보를 사용할 수 있다.\n\n예를 들어, 반복되는 세그먼트 간의 상대적 템포 차이가 \\(50\\)퍼센트보다 큰 경우는 거의 발생하지 않으므로, \\(\\Theta\\)를 대략 \\(-50\\)에서 \\(+50\\)퍼센트까지의 템포 변화를 처리할 수 있도록 선택할 수 있다.\n\n또한 실제로는 상대적으로 적은 수의 템포 매개변수만 고려하면 템포 범위를 잘 커버할 수 있다.\n\n예를 들어, 집합 \\(\\Theta=\\{0.66,0.81,1.00,1.22,1.50\\}\\) (로그 간격의 템포 매개변수 포함)은 대략 \\(-50\\)에서 \\(+50\\) 퍼센트의 템포 변화를 다룬다.\n\n\n\ndef compute_tempo_rel_set(tempo_rel_min, tempo_rel_max, num):\n    \"\"\"Compute logarithmically spaced relative tempo values\n\n    Args:\n        tempo_rel_min (float): Minimum relative tempo\n        tempo_rel_max (float): Maximum relative tempo\n        num (int): Number of relative tempo values (inlcuding the min and max)\n\n    Returns:\n        tempo_rel_set (np.ndarray): Set of relative tempo values\n    \"\"\"\n    tempo_rel_set = np.exp(np.linspace(np.log(tempo_rel_min), np.log(tempo_rel_max), num))\n    return tempo_rel_set\n\n\ntempo_rel_min = 0.66\ntempo_rel_max = 1.5\nnum = 5\ntempo_rel_set = compute_tempo_rel_set(tempo_rel_min=tempo_rel_min, tempo_rel_max=tempo_rel_max, num=num) \nprint(tempo_rel_set)\n\n[0.66       0.81036517 0.99498744 1.22167146 1.5       ]\n\n\n\n스무딩 길이 매개변수 \\(L\\in\\mathbb{N}\\) 및 상대적 템포 차이의 이산 집합 \\(\\Theta\\)는 스무딩 품질을 제어하기 위한 두 가지 주요 매개변수이다.\n대각선 스무딩과 마찬가지로 다중 필터링 접근 방식의 구현은 효율적으로 계산할 수 있는 전체 행렬 연산으로 표현된다. 구현의 주요 아이디어는 다음과 같다.\n\n각 템포 매개변수 \\(\\theta\\in\\Theta\\)에 대해 \\(\\theta\\)에 의해 결정된 계수로 한 축을 따라 SSM을 리샘플링한다. 리샘플링은 \\(\\theta\\)로 지정된 상대 템포 차이를 시뮬레이션한다.\n리샘플링된 각 행렬에 대해 길이 \\(L\\)의 대각선 필터링을 적용한다.\n필터링된 각 행렬은 (역)리샘플링을 적용하여 원래 형식으로 다시 변환된다.\n\\(\\theta\\in\\Theta\\)에 대한 결과 행렬의 셀별 최대값을 취하면 행렬 \\(\\mathbf{S}_{L,\\Theta}\\)를 얻을 수 있다.\n\n\n\ndef filter_diag_mult_sm(S, L=1, tempo_rel_set=np.asarray([1]), direction=0):\n    \"\"\"Path smoothing of similarity matrix by filtering in forward or backward direction\n    along various directions around main diagonal.\n    Note: Directions are simulated by resampling one axis using relative tempo values\n\n    Args:\n        S (np.ndarray): Self-similarity matrix (SSM)\n        L (int): Length of filter (Default value = 1)\n        tempo_rel_set (np.ndarray): Set of relative tempo values (Default value = np.asarray([1]))\n        direction (int): Direction of smoothing (0: forward; 1: backward) (Default value = 0)\n\n    Returns:\n        S_L_final (np.ndarray): Smoothed SM\n    \"\"\"\n    N = S.shape[0]\n    M = S.shape[1]\n    num = len(tempo_rel_set)\n    S_L_final = np.zeros((N, M))\n\n    for s in range(0, num):\n        M_ceil = int(np.ceil(M / tempo_rel_set[s]))\n        resample = np.multiply(np.divide(np.arange(1, M_ceil+1), M_ceil), M)\n        np.around(resample, 0, resample)\n        resample = resample - 1\n        index_resample = np.maximum(resample, np.zeros(len(resample))).astype(np.int64)\n        S_resample = S[:, index_resample]\n\n        S_L = np.zeros((N, M_ceil))\n        S_extend_L = np.zeros((N + L, M_ceil + L))\n\n        # Forward direction\n        if direction == 0:\n            S_extend_L[0:N, 0:M_ceil] = S_resample\n            for pos in range(0, L):\n                S_L = S_L + S_extend_L[pos:(N + pos), pos:(M_ceil + pos)]\n\n        # Backward direction\n        if direction == 1:\n            S_extend_L[L:(N+L), L:(M_ceil+L)] = S_resample\n            for pos in range(0, L):\n                S_L = S_L + S_extend_L[(L-pos):(N + L - pos), (L-pos):(M_ceil + L - pos)]\n\n        S_L = S_L / L\n        resample = np.multiply(np.divide(np.arange(1, M+1), M), M_ceil)\n        np.around(resample, 0, resample)\n        resample = resample - 1\n        index_resample = np.maximum(resample, np.zeros(len(resample))).astype(np.int64)\n\n        S_resample_inv = S_L[:, index_resample]\n        S_L_final = np.maximum(S_L_final, S_resample_inv)\n\n    return S_L_final\n\n\ntempo_rel_min = 0.66\ntempo_rel_max = 1.5\nnum = 5\ntempo_rel_set = compute_tempo_rel_set(tempo_rel_min=tempo_rel_min, tempo_rel_max=tempo_rel_max, num=num) \nL = 20\nS_L = filter_diag_sm(S, L)\nS_L_mult = filter_diag_mult_sm(S, L, tempo_rel_set)\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 3))\nsubplot_matrix_colorbar(S, fig, ax[0], clim=[0,1], xlabel='Time (frames)', ylabel='Time (frames)',\n                        title=r'Original SSM $\\mathbf{S}$')\nsubplot_matrix_colorbar(S_L, fig, ax[1], clim=[0,1], xlabel='Time (frames)', ylabel='Time (frames)',\n                        title=r'Smoothed SSM $\\mathbf{S}_{L}$ (L = %d)'%L)\nsubplot_matrix_colorbar(S_L_mult, fig, ax[2], clim=[0,1], xlabel='Time (frames)', ylabel='Time (frames)',\n                        title=r'Multiple filtering SSM $\\mathbf{S}_{L,\\theta}$ (L = %d)'%L)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#forward-backward-스무딩",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#forward-backward-스무딩",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "Forward-Backward 스무딩",
    "text": "Forward-Backward 스무딩\n\n이전 그림은 특히 경로 구조의 끝에 페이딩 아티팩트(fading artifact)가 있음을 보여준다. 이 아티팩트의 이유는 지금까지 설명한 스무딩 절차가 순방향으로 작동하기 때문이다. 페이딩 아티팩트를 방지하기 위한 방법으로 역방향으로 평균화 필터를 추가로 적용할 수 있다. 최종 자기 유사성 행렬은 forward-smoothed 및 backward-smoothed 행렬에 대해 셀별 최대값을 취하여 얻는다.\n\n\ntempo_rel_min = 0.66\ntempo_rel_max = 1.5\nnum = 5\ntempo_rel_set = compute_tempo_rel_set(tempo_rel_min=tempo_rel_min, tempo_rel_max=tempo_rel_max, num=num) \nL = 20\nS_forward = filter_diag_mult_sm(S, L, tempo_rel_set, direction=0)\nS_backward = filter_diag_mult_sm(S, L, tempo_rel_set, direction=1)\nS_final = np.maximum(S_forward, S_backward)\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 3))\nsubplot_matrix_colorbar(S, fig, ax[0], clim=[0,1], \n                        title=r'Original SSM', xlabel='Time (frames)', ylabel='Time (frames)')\nsubplot_matrix_colorbar(S_forward, fig, ax[1], clim=[0,1],\n                        title=r'Forward SSM', xlabel='Time (frames)', ylabel='Time (frames)')\nsubplot_matrix_colorbar(S_final, fig, ax[2], clim=[0,1], \n                        title=r'Forward-backward SSM', xlabel='Time (frames)', ylabel='Time (frames)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n위의 리샘플 기반(resample-based) 접근법의 대안은 Librosa에서 구현된 것처럼 여러 2D 컨볼루션 커널(각 방향에 대해 하나의 커널)을 적용하는 것이다. 또 다른 수정 방법은 페이딩 부산물을 방지하기 위해 중앙값 필터링(평균 필터링 대신)을 사용하는 것이다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#조옮김된transposed-ssm",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#조옮김된transposed-ssm",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "조옮김된(transposed) SSM",
    "text": "조옮김된(transposed) SSM\n순환 시프트 연산자 (Cyclic Shift Operator)\n\n이미 조옮김(transposition)이 크로마 특징을 주기적으로 이동하여 시뮬레이션할 수 있음을 확인한 바 있다(4.1. 오디오 동기화 피쳐). \\([0:11]\\) 집합으로 12개 크로마 값을 식별하면 순환 이동은 순환 이동 연산자 \\(\\rho:\\mathbb{R}^{12} \\to \\mathbb{R}^{12}\\)에 의해 모델링된다. \\[\\rho(x):=(x(11),x(0),x(1),\\ldots,x(10))^\\top\\] for \\(x=(x(0),x(1),\\ldots,x(10),x(11))^\\top\\in\\mathbb{R}^{12}\\).\n\\(i\\)의 반음 위 순환 이동을 정의하는 \\(\\rho^i:=\\rho\\circ\\rho^{i-1}\\) for \\(i\\in\\mathbb{N}\\) 를 얻기 위해 순환 이동 연산자가 연속적으로 적용될 수 있다.\n\\(\\rho^{12}(x) = x\\)는 크로마 벡터를 12반음(1옥타브) 위로 주기적으로 이동하여 원래 벡터를 복구한다. 크로마그램의 모든 프레임에 순환 이동 연산자를 동시에 적용하면 전체 크로마그램이 수직 방향으로 순환 이동하게 된다.\n\\(X=(x_1,x_2,\\ldots,x_N)\\)를 특징 시퀀스라고 하자. 그러면 \\(i\\)-조옮김(-transposed) 특징 행렬 은 다음과 같이 주어진다. \\[\\rho^i(X)=(\\rho^i(x_1),\\rho^i(x_2),\\ldots,\\rho^i(x_N))\\]\n\n\ndef shift_cyc_matrix(X, shift=0):\n    \"\"\"Cyclic shift of features matrix along first dimension\n\n    Args:\n        X (np.ndarray): Feature respresentation\n        shift (int): Number of bins to be shifted (Default value = 0)\n\n    Returns:\n        X_cyc (np.ndarray): Cyclically shifted feature matrix\n    \"\"\"\n    # Note: X_cyc = np.roll(X, shift=shift, axis=0) does to work for jit\n    K, N = X.shape\n    shift = np.mod(shift, K)\n    X_cyc = np.zeros((K, N))\n    X_cyc[shift:K, :] = X[0:K-shift, :]\n    X_cyc[0:shift, :] = X[K-shift:K, :]\n    return X_cyc\n\n\nshift_set = [0,1,2]\nshift_num = len(shift_set)\n\nfig, ax = plt.subplots(shift_num, 2, gridspec_kw={'width_ratios': [1, 0.02]}, figsize=(6, 6))   \n                                          \nfor m in range(shift_num):\n    shift = shift_set[m]\n    X_cyc = shift_cyc_matrix(X, shift)    \n    plot_chromagram(X_cyc, Fs=Fs_X, ax=[ax[m,0], ax[m,1]], chroma_yticks=[0,2,4,5,7,9,11],\n                     title=r'$%d$-transposed chromgram'%shift, ylabel='Chroma', colorbar=True);\n\nplt.tight_layout()\nplt.show() \n\n\n\n\n\n동일한 멜로디 또는 조화 진행을 공유하지만 하나 또는 여러 개의 반음이 조옮김된 유사한 세그먼트를 감지해보자.\n주어진 특징 시퀀스 \\(X=(x_1,x_2,\\ldots,x_N)\\)에 대해, \\(i\\)-transposed self-similarity matrix \\(\\rho^i(\\mathrm{S})\\)를 다음과 같이 정의한다. \\[\\rho^i(\\mathrm{S})(n,m):=s(\\rho^i(x_n),x_m)\\]\n\nfor \\(n,m\\in[1:N]\\) and \\(i\\in\\mathbb{Z}\\)\n\\(\\rho^{12}(\\mathrm{S})=\\mathrm{S}\\)\n\n직관적으로 \\(\\rho^i(\\mathrm{S})\\)는 원본 음악 녹음(\\(X=(x_1,x_2,\\ldots,x_N)\\)로 표현됨)과 \\(i\\) 반음 위쪽(\\(i\\)-transposed 기능 시퀀스로 표시됨)으로 조옮김된 음악 녹음 간의 유사성 관계를 설명한다.\n\n\nL = 8\ntempo_rel_set = np.asarray([1])\nshift_set = np.asarray([0,1,2])\nshift_num = len(shift_set)\n\nfig, ax = plt.subplots(1, shift_num, figsize=(10, 3))\nfor m in range(shift_num):\n    shift = shift_set[m]\n    X_cyc = shift_cyc_matrix(X, shift)    \n    S = compute_sm_dot(X,X_cyc)\n    S_forward = filter_diag_mult_sm(S, L, tempo_rel_set=tempo_rel_set, direction=0)\n    S_backward = filter_diag_mult_sm(S, L, tempo_rel_set=tempo_rel_set, direction=1)\n    S_final = np.maximum(S_forward, S_backward)\n    subplot_matrix_colorbar(S_final, fig, ax[m], clim=[0.5,1], \n                        title=r'$%5d$-transposed SSM'%shift)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#조옮김-불변transposition-invariant-ssm",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#조옮김-불변transposition-invariant-ssm",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "조옮김-불변(Transposition-Invariant) SSM",
    "text": "조옮김-불변(Transposition-Invariant) SSM\n\n일반적으로 음악 녹음에서 발생하는 조옮김의 종류를 모르기 때문에 상대적인 템포 편차(relative tempo deviations)를 처리할 때 이전과 유사한 전략을 적용한다. 12개의 서로 다른 순환 이동에 대해 셀별 최대값을 취하면 다음과 같이 정의된 단일 조옮김-불변(transposition-invariant) 자기 유사성 행렬 \\(\\mathrm{S}^\\mathrm{TI}\\)를 얻는다.\n\n\\[\\mathrm{S}^\\mathrm{TI}(n,m):=\\max_{i\\in [0:11]} \\,\\rho^i(\\mathrm{S})(n,m)\\]\n\n또한 추가 \\(N\\)-정사각 행렬 \\(\\mathrm{I}\\)에 최대화 이동(shift) 지수를 저장하며 이를 전치 인덱스 행렬이라고 하고 다음과 같다. \\[\\mathrm{I}(n,m):= \\underset{i\\in [0:11]}{\\mathrm{argmax}} \\,\\,\\, \\rho^i(\\mathrm{S})(n,m)\\]\n다음의 코드 셀에서는 조옮김-불변 SSM과 조옮김 인덱스 행렬을 계산하기 위한 구현을 제공한다.\n다음 사항에 유의해야 한다.\n\n이 함수는 X와 Y 두 가지 특징 시퀀스를 허용하여 보다 일반적이다. ’X = Y’의 경우는 이 노트북에서 고려된 SSM 케이스로 축소된다.\n조옮김된 각 SSM에 대해 평활화(정방향, 역방향, 조합) 및 정규화가 적용된다.\n마지막에 (조옮김된 12개의 모든 SSM에 대해)단일 최대화를 갖는 대신, 최대화는 이동 인덱스 루프(shift index loop) 내에서 업데이트된다. 동시에 두 개의 행렬만 저장하면 되므로 메모리 요구 사항이 줄어든다.\n\n\n\ndef compute_sm_ti(X, Y, L=1, tempo_rel_set=np.asarray([1]), shift_set=np.asarray([0]), direction=2):\n    \"\"\"Compute enhanced similaity matrix by applying path smoothing and transpositions\n\n    Args:\n        X (np.ndarray): First feature sequence\n        Y (np.ndarray): Second feature sequence\n        L (int): Length of filter (Default value = 1)\n        tempo_rel_set (np.ndarray): Set of relative tempo values (Default value = np.asarray([1]))\n        shift_set (np.ndarray): Set of shift indices (Default value = np.asarray([0]))\n        direction (int): Direction of smoothing (0: forward; 1: backward; 2: both directions) (Default value = 2)\n\n    Returns:\n        S_TI (np.ndarray): Transposition-invariant SM\n        I_TI (np.ndarray): Transposition index matrix\n    \"\"\"\n    for shift in shift_set:\n        Y_cyc = shift_cyc_matrix(Y, shift)\n        S_cyc = compute_sm_dot(X, Y_cyc)\n\n        if direction == 0:\n            S_cyc = filter_diag_mult_sm(S_cyc, L, tempo_rel_set, direction=0)\n        if direction == 1:\n            S_cyc = filter_diag_mult_sm(S_cyc, L, tempo_rel_set, direction=1)\n        if direction == 2:\n            S_forward = filter_diag_mult_sm(S_cyc, L, tempo_rel_set=tempo_rel_set, direction=0)\n            S_backward = filter_diag_mult_sm(S_cyc, L, tempo_rel_set=tempo_rel_set, direction=1)\n            S_cyc = np.maximum(S_forward, S_backward)\n        if shift == shift_set[0]:\n            S_TI = S_cyc\n            I_TI = np.ones((S_cyc.shape[0], S_cyc.shape[1])) * shift\n        else:\n            # jit does not like the following lines\n            # I_greater = np.greater(S_cyc, S_TI)\n            # I_greater = (S_cyc > S_TI)\n            I_TI[S_cyc > S_TI] = shift\n            S_TI = np.maximum(S_cyc, S_TI)\n\n    return S_TI, I_TI\n\n\ndef subplot_matrix_ti_colorbar(S, fig, ax, title='', Fs=1, xlabel='Time (seconds)', ylabel='Time (seconds)',\n                               clim=None, xlim=None, ylim=None, cmap=None, alpha=1, interpolation='nearest',\n                               ind_zero=False):\n    \"\"\"Visualization function for showing transposition index matrix\n\n    Args:\n        S: Self-similarity matrix (SSM)\n        fig: Figure handle\n        ax: Axes handle\n        title: Title for figure (Default value = '')\n        Fs: Feature rate (Default value = 1)\n        xlabel: Label for x-axis (Default value = 'Time (seconds)')\n        ylabel: Label for y-axis (Default value = 'Time (seconds)')\n        clim: Color limits (Default value = None)\n        xlim: Limits for x-axis (Default value = None)\n        ylim: Limits for y-axis (Default value = None)\n        cmap: Color map (Default value = None)\n        alpha: Alpha value for imshow (Default value = 1)\n        interpolation: Interpolation value for imshow (Default value = 'nearest')\n        ind_zero: Use white (True) or black (False) color for index zero (Default value = False)\n\n    Returns:\n        im: Imshow handle\n    \"\"\"\n    if cmap is None:\n        color_ind_zero = np.array([0, 0, 0, 1])\n        if ind_zero == 0:\n            color_ind_zero = np.array([0, 0, 0, 1])\n        else:\n            color_ind_zero = np.array([1, 1, 1, 1])\n        colorList = np.array([color_ind_zero, [1, 1, 0, 1],  [0, 0.7, 0, 1],  [1, 0, 1, 1],  [0, 0, 1, 1],\n                             [1, 0, 0, 1], [0, 0, 0, 0.5], [1, 0, 0, 0.3], [0, 0, 1, 0.3], [1, 0, 1, 0.3],\n                             [0, 0.7, 0, 0.3], [1, 1, 0, 0.3]])\n        cmap = ListedColormap(colorList)\n    len_sec = S.shape[0] / Fs\n    extent = [0, len_sec, 0, len_sec]\n    im = ax.imshow(S, aspect='auto', extent=extent, cmap=cmap,  origin='lower', alpha=alpha,\n                   interpolation=interpolation)\n    if clim is None:\n        im.set_clim(vmin=-0.5, vmax=11.5)\n    fig.sca(ax)\n    ax_cb = fig.colorbar(im)\n    ax_cb.set_ticks(np.arange(0, 12, 1))\n    ax_cb.set_ticklabels(np.arange(0, 12, 1))\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if xlim is not None:\n        ax.set_xlim(xlim)\n    if ylim is not None:\n        ax.set_ylim(ylim)\n    return im\n\n\nL = 8\ntempo_rel_set = np.asarray([1])\nshift_set = np.array(range(12))\nS_TI, I_TI = compute_sm_ti(X, X, L=L, tempo_rel_set=tempo_rel_set, \n                           shift_set=shift_set, direction=2)\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3.5))\nsubplot_matrix_colorbar(S_TI, fig, ax[0], clim=[0.5,1], \n                                  title='Transposition-invariant SSM')\nsubplot_matrix_ti_colorbar(I_TI, fig, ax[1], ind_zero=True,\n                                  title='Transposition index matrix')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n오른쪽의 조옮김 인덱스 행렬(transposition index matrix)을 자세히 살펴보자.\n먼저 \\(\\mathrm{I}\\) 행렬이 \\(i=0\\)(흰색) 값을 가정하는 경우,\n\n\\((n,m)\\) 셀의 \\(i=0\\) 값은 \\(s(\\rho^{i}(x_n),x_m)\\)가 \\(i=0\\)에 대해 최대값을 가정함을 나타낸다.\n즉, 크로마 벡터 \\(x_m\\)은 \\(x_n\\)의 다른 이동된 버전보다 \\(x_n\\)에 더 가깝다.그러나 이것이 반드시 \\(x_m\\)이 절대적으로 \\(x_n\\)에 가깝다는 것을 의미하지는 않는다.\n최대화 지수는 원래 SSM이 저비용 경로를 나타내는 모든 위치에서 \\(i=0\\)이다.\n\n다음으로 \\(\\mathrm{I}\\) 행렬이 \\(i=1\\)(노란색 ) 값을 가정하는 경우를 고려해보자.\n\n\\((n,m)\\) 셀의 \\(i=1\\) 값은 반음 위로 이동했을 때 \\(x_n\\)이 \\(x_m\\)과 가장 비슷해짐을 나타낸다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#매개변수에-따른-의존도",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#매개변수에-따른-의존도",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "매개변수에 따른 의존도",
    "text": "매개변수에 따른 의존도\n\n샘플링 속도(rate) \\(F_\\mathrm{s}=22050~\\mathrm{Hz}\\)의 오디오 신호로 시작하여 먼저 윈도우 및 홉 크기 매개변수가 필요한 STFT를 계산한다. 예를 들어 \\(N=4410\\)의 윈도우 크기와 \\(H=2050\\)의 홉 크기를 사용하면 특징 해상도가 \\(10~\\mathrm{Hz}\\)가 된다.\n둘째, 크로마그램을 도출하기 위해 스무딩 및 다운샘플링 전략을 적용한다. \\(41\\) 특징(약 \\(4\\)초 커버)의 스무딩 윈도우와 \\(10\\)의 홉 크기를 사용하면 \\(1~\\mathrm{Hz}\\)의 크로마 해상도가 생성된다.\n셋째, SSM을 계산할 때 경로 향상(path enhancement)을 적용한다. 이것은 다시 길이 매개변수가 필요하다. 예를 들어 \\(20\\) 길이를 사용하면 \\(20\\)초의 오디오에 해당한다. 순방향 및 역방향 스무딩을 적용하면 “번짐(smearing)”이 더욱 증가한다.\n마지막으로, 다중 필터링을 적용하면 “번짐” 효과가 또 발생한다.\n다음 그림은 이러한 매개변수의 선택이 최종 결과에 결정적인 영향을 미친다는 것을 보여준다. SSM 계산에서 경로 향상을 사용하지 않으면 노이즈가 많은 SSM이 발생하고 “scattered”된 조옮김 인덱스 분포가 발생한다. 경로 향상을 도입하면 구조적 속성이 향상되지만 과도한 평활화로 중요한 세부 사항의 손실이 발생할 수도 있다.\n\n\nC = librosa.feature.chroma_stft(y=x, sr=Fs, tuning=0, norm=2, hop_length=2205, n_fft=4410)\nFs_C = Fs/2205\n\nL_feature = 41\nH_feature = 10\nX, Fs_X = smooth_downsample_feature_sequence(C, Fs_C, \n                                    filt_len=L_feature, down_sampling=H_feature)\nX = normalize_feature_sequence(X, norm='2', threshold=0.001)\n\ntempo_rel_min = 0.66\ntempo_rel_max = 1.5\nnum = 5\ntempo_rel_set = compute_tempo_rel_set(tempo_rel_min=tempo_rel_min, tempo_rel_max=tempo_rel_max, num=num) \n\nshift_set = np.array(range(12))\n\nL_set = [1, 20]\nL_num = len(L_set)\ntitle_set = ['Transposition-invariant SSM', 'Smoothed transposition-invariant SSM']\n\nfig, ax = plt.subplots(L_num, 2, figsize=(8, 7))\nfor m in range(L_num):\n    L = L_set[m]\n    S_TI, I_TI = compute_sm_ti(X, X, L=L, tempo_rel_set=tempo_rel_set, shift_set=shift_set, direction=2)\n    subplot_matrix_colorbar(S_TI, fig, ax[m,0], clim=[0.5,1], \n                                  title=title_set[m])\n    subplot_matrix_ti_colorbar(I_TI, fig, ax[m,1], ind_zero=True,\n                                  title='Transposition index matrix')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#전역-임계값-global-thresholding",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#전역-임계값-global-thresholding",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "전역 임계값 (Global Thresholding)",
    "text": "전역 임계값 (Global Thresholding)\n\n가장 간단한 방법은 전역 임계값 global thresholding을 적용하는 것이다. 여기서 주어진 임계값 매개변수 \\(\\tau>0\\) 보다 작은 행렬 \\(\\mathbf{S}\\in\\mathbb{R}_{\\geq 0}^{N\\times M}\\)의 모든 값 \\(\\mathbf{S}(n,m)\\)은 0으로 설정된다.\n\n\\[\\mathbf{S}_\\tau(n,m):=\\left\\{\\begin{array}{ll}\n    \\mathbf{S}(n,m) &\\quad \\mbox{if $\\mathbf{S}(n,m)\\geq\\tau$,}\\\\\n    0,&\\quad\\mbox{otherwise.}\n\\end{array}\\right.\\]\n\n또한 임계값 이상의 모든 값을 1로 설정하고 다른 모든 값을 0으로 설정하여 행렬의 이진화(binarization)를 적용할 수 있다.\n\n\nS_global = np.copy(S)\n\nthresh = 6\nS_global = np.copy(S)\nS_global[S_global < thresh] = 0\nS_binary = np.copy(S_global)\nS_binary[S_global >= thresh] = 1\n\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 2))\nplot_matrix(S, ax=[ax[0]], xlabel='', ylabel='',\n                     title=r'Original matrix')\nplot_matrix(S_global, ax=[ax[1]], xlabel='', ylabel='',\n                     title=r'Global thresholding ($\\tau = %0.2f$)'%thresh)\nplot_matrix(S_binary, ax=[ax[2]], xlabel='', ylabel='', \n                     title=r'Binarization')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#스케일링과-페널티-scaling-and-penalty",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#스케일링과-페널티-scaling-and-penalty",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "스케일링과 페널티 (Scaling and Penalty)",
    "text": "스케일링과 페널티 (Scaling and Penalty)\n\n이진화 대신, 범위 \\([\\tau,\\mu]\\)를 \\([0,1]\\)로 선형 스케일링 할 수 있다.(단, \\(\\mu:=\\max_{n,m}\\{\\mathbf{S}(n,m)\\}>\\tau\\)의 경우, 그렇지 않으면 모든 항목 0으로 설정)\n경우에 따라 추가 페널티(penalty) 매개변수 \\(\\delta\\leq 0\\)를 도입하여, 임계값 미만의 모든 원래 값을 \\(\\delta\\) 값으로 설정하는 것이 도움이 될 수도 있다.\n다음 그림은 스케일링 전과 후의 결과를 보여준다. 또한 페널티 매개변수 \\(\\delta=-2\\)를 적용한다.\n\n\nmin_value = thresh\nmax_value = np.max(S_global) \nif max_value > min_value:\n    S_scale = np.divide((S_global - min_value), (max_value -  min_value)) \n    S_scale[S_global<thresh] = 0\nelse:\n    raise Exception('Scaling not possible: max > min is violated')    \n        \npenalty = -2\nS_penalty = np.divide((S_global - min_value), (max_value -  min_value)) \nS_penalty[S_global<thresh] = penalty\n\nfig, ax = plt.subplots(1, 3, figsize=(10,2))\nplot_matrix(S_global, ax=[ax[0]], xlabel='', ylabel='', \n                     title=r'Global thresholding ($\\tau = %0.2f$)'%thresh)\nplot_matrix(S_scale, ax=[ax[1]], xlabel='', ylabel='', \n                     title=r'Scaling')\nplot_matrix(S_penalty, ax=[ax[2]], xlabel='', ylabel='', \n                     title=r'Penalty ($\\rho = %0.2f$)'%penalty)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#상대-임계값-relative-thresholding",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#상대-임계값-relative-thresholding",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "상대 임계값 (Relative Thresholding)",
    "text": "상대 임계값 (Relative Thresholding)\n\n전역 임계값 \\(\\tau\\)는 상대적(relative) 방식으로도 선택할 수 있다. 상대 임계값(relative threshold) 매개변수 \\(\\rho\\in [0,1]\\)가 주어지면 가장 높은 값을 가진 셀의 \\(\\rho\\cdot 100\\%\\)를 유지한다.\n이를 위해 행렬 항목을 값에 따라 정렬해야 한다. 정렬된 목록에서 \\(\\rho\\)에 따라 값을 분할하는 전역 임계값을 결정할 수 있다. 이 상대 임계값 전략은 다른 상대 임계값 매개변수를 사용한다.\n\n반올림 문제와 서로 다른 행렬 항목이 동일한 값을 가질 수 있다는 문제 때문에 \\(\\rho\\)로 지정된 분할이 정확하지 않을 수 있다.\n\n\n\ndef threshold_matrix_relative(S, thresh_rel=0.2, details=False):\n    \"\"\"Treshold matrix in a relative fashion\n\n    Args:\n        S (np.ndarray): Input matrix\n        thresh_rel (float): Relative treshold (Default value = 0.2)\n        details (bool): Print details on thresholding procedure (Default value = False)\n\n    Returns:\n        S_thresh (np.ndarray): Thresholded matrix\n        thresh_abs (float): Absolute threshold used for thresholding\n    \"\"\"\n    S_thresh = np.copy(S)\n    num_cells_below_thresh = int(np.round(S_thresh.size*(1-thresh_rel)))\n    values_sorted = np.sort(S_thresh.flatten('F'))\n    thresh_abs = values_sorted[num_cells_below_thresh]\n    S_thresh[S_thresh < thresh_abs] = 0\n    if details:\n        print('thresh_rel=%0.2f, thresh_abs=%d, total_num_cells=%d, num_cells_below_thresh=%d, ' %\n              (thresh_rel, thresh_abs, S_thresh.size, num_cells_below_thresh))\n    return S_thresh, thresh_abs\n\n\nthresh_rel_set = [0.5, 0.3, 0.1]\nnum = len(thresh_rel_set)\nfig, ax = plt.subplots(1, num, figsize=(10,2))\nfor m in range(num):\n    thresh_rel = thresh_rel_set[m]\n    S_relative, thresh_abs = threshold_matrix_relative(S, thresh_rel, details=True)\n    plot_matrix(S_relative, ax=[ax[m]], xlabel='', ylabel='', \n                         title=r'Relative thresholding ($\\rho = %0.2f$)'%thresh_rel)\n\nplt.tight_layout()\nplt.show()\n\nthresh_rel=0.50, thresh_abs=5, total_num_cells=24, num_cells_below_thresh=12, \nthresh_rel=0.30, thresh_abs=6, total_num_cells=24, num_cells_below_thresh=17, \nthresh_rel=0.10, thresh_abs=8, total_num_cells=24, num_cells_below_thresh=22,"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#로컬-임계값-local-thresholding",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#로컬-임계값-local-thresholding",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "로컬 임계값 (Local Thresholding)",
    "text": "로컬 임계값 (Local Thresholding)\n\n마지막으로, 임계값은 row-wise 및 column-wise으로 임계값을 지정하여 더 많은 로컬 전략을 사용하여 수행할 수도 있다.\n\\(\\rho_1\\in[0,1]\\)를 행(row)의 상대 임계값으로 하고 \\(\\rho_2\\in[0,1]\\)를 열(column)의 상대 임계값으로 설정한다.\n각 셀 \\((n,m)\\)에 대해 \\(\\mathbf{S}(n,m)\\) 값은 행 \\(n\\)에서 가장 큰 셀의 \\(\\rho_1\\cdot 100\\%\\)에 있으면 유지된다. 동시에 \\(m\\) 열에서 가장 큰 셀의 \\(\\rho_2\\cdot 100\\%\\) 중에 있으면 다른 모든 값은 0으로 설정된다.\n다음 그림에서는 셀이 각각 행 또는 열 중에서 가장 큰지 여부와 최종 결과를 나타내는 두 개의 이진 마스크(binary masks)(중간 결과)를 보여준다.\n\n\nthresh_rel_row=0.8\nthresh_rel_col=0.5\n\nS_binary_row = np.ones([N,M])\nnum_cells_row_below_thresh = int(np.round(M*(1-thresh_rel_row)))\nfor n in range(N):\n    row = S[n,:]\n    values_sorted = np.sort(row)\n    thresh_abs = values_sorted[num_cells_row_below_thresh]\n    S_binary_row[n,:] = (row>=thresh_abs)\n\nS_binary_col = np.ones([N,M])\nnum_cells_col_below_thresh = int(np.round(N*(1-thresh_rel_col)))  \nfor m in range(M):\n    col = S[:,m]\n    values_sorted = np.sort(col)\n    thresh_abs = values_sorted[num_cells_col_below_thresh]\n    S_binary_col[:,m] = (col>=thresh_abs)\n    \nS_local =  S * S_binary_row * S_binary_col\n    \nfig, ax = plt.subplots(1, 3, figsize=(10,2))\nplot_matrix(S_binary_row, ax=[ax[0]], xlabel='', ylabel='', \n                     title=r'Binary mask for rows ($\\rho_1 = %0.2f$)'%thresh_rel_row)\nplot_matrix(S_binary_col, ax=[ax[1]], xlabel='', ylabel='', \n                     title=r'Binary mask for columns ($\\rho_2 = %0.2f$)'%thresh_rel_col)\nplot_matrix(S_local, ax=[ax[2]], xlabel='', ylabel='', \n                     title=r'Local thresholding ($\\rho_1 = %0.2f$, $\\rho_2 = %0.2f$)'%(thresh_rel_row,thresh_rel_col))\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#구현",
    "href": "posts/5. Music Structure Analysis/5.2.Self_Similarity_Matrix.html#구현",
    "title": "5.2. 자기 유사성 행렬 (SSM)",
    "section": "구현",
    "text": "구현\n\ndef threshold_matrix(S, thresh, strategy='absolute', scale=False, penalty=0.0, binarize=False):\n    \"\"\"Treshold matrix in a relative fashion\n\n    Args:\n        S (np.ndarray): Input matrix\n        thresh (float or list): Treshold (meaning depends on strategy)\n        strategy (str): Thresholding strategy ('absolute', 'relative', 'local') (Default value = 'absolute')\n        scale (bool): If scale=True, then scaling of positive values to range [0,1] (Default value = False)\n        penalty (float): Set values below treshold to value specified (Default value = 0.0)\n        binarize (bool): Binarizes final matrix (positive: 1; otherwise: 0) (Default value = False)\n\n    Returns:\n        S_thresh (np.ndarray): Thresholded matrix\n    \"\"\"\n    if np.min(S) < 0:\n        raise Exception('All entries of the input matrix must be nonnegative')\n\n    S_thresh = np.copy(S)\n    N, M = S.shape\n    num_cells = N * M\n\n    if strategy == 'absolute':\n        thresh_abs = thresh\n        S_thresh[S_thresh < thresh] = 0\n\n    if strategy == 'relative':\n        thresh_rel = thresh\n        num_cells_below_thresh = int(np.round(S_thresh.size*(1-thresh_rel)))\n        if num_cells_below_thresh < num_cells:\n            values_sorted = np.sort(S_thresh.flatten('F'))\n            thresh_abs = values_sorted[num_cells_below_thresh]\n            S_thresh[S_thresh < thresh_abs] = 0\n        else:\n            S_thresh = np.zeros([N, M])\n\n    if strategy == 'local':\n        thresh_rel_row = thresh[0]\n        thresh_rel_col = thresh[1]\n        S_binary_row = np.zeros([N, M])\n        num_cells_row_below_thresh = int(np.round(M * (1-thresh_rel_row)))\n        for n in range(N):\n            row = S[n, :]\n            values_sorted = np.sort(row)\n            if num_cells_row_below_thresh < M:\n                thresh_abs = values_sorted[num_cells_row_below_thresh]\n                S_binary_row[n, :] = (row >= thresh_abs)\n        S_binary_col = np.zeros([N, M])\n        num_cells_col_below_thresh = int(np.round(N * (1-thresh_rel_col)))\n        for m in range(M):\n            col = S[:, m]\n            values_sorted = np.sort(col)\n            if num_cells_col_below_thresh < N:\n                thresh_abs = values_sorted[num_cells_col_below_thresh]\n                S_binary_col[:, m] = (col >= thresh_abs)\n        S_thresh = S * S_binary_row * S_binary_col\n\n    if scale:\n        cell_val_zero = np.where(S_thresh == 0)\n        cell_val_pos = np.where(S_thresh > 0)\n        if len(cell_val_pos[0]) == 0:\n            min_value = 0\n        else:\n            min_value = np.min(S_thresh[cell_val_pos])\n        max_value = np.max(S_thresh)\n        # print('min_value = ', min_value, ', max_value = ', max_value)\n        if max_value > min_value:\n            S_thresh = np.divide((S_thresh - min_value), (max_value - min_value))\n            if len(cell_val_zero[0]) > 0:\n                S_thresh[cell_val_zero] = penalty\n        else:\n            print('Condition max_value > min_value is voliated: output zero matrix')\n\n    if binarize:\n        S_thresh[S_thresh > 0] = 1\n        S_thresh[S_thresh < 0] = 0\n    return S_thresh\n\n\nfigsize=(11, 4)\nfig, ax = plt.subplots(2, 3, figsize=figsize)\nplot_matrix(S, ax=[ax[0,0]], xlabel='', ylabel='', title=r'Original matrix')\n\nstrategy = 'relative'\nthresh = 0.7\nS_thresh = threshold_matrix(S, thresh=thresh, strategy=strategy, scale=0, penalty=0, binarize=0)\nplot_matrix(S_thresh, ax=[ax[0,1]], xlabel='', ylabel='', \n                     title=[strategy, thresh])\n\nstrategy = 'relative'\nthresh = 0.7\nS_thresh = threshold_matrix(S, thresh=thresh, strategy=strategy, scale=1, penalty=-2, binarize=0)\nplot_matrix(S_thresh, ax=[ax[0,2]], xlabel='', ylabel='', \n                     title=[strategy, thresh, \"scale\", \"-2\"])\n\nstrategy = 'relative'\nthresh = 0.7\nS_thresh = threshold_matrix(S, thresh=thresh, strategy=strategy, scale=1, penalty=-2, binarize=1)\nplot_matrix(S_thresh, ax=[ax[1,0]], xlabel='', ylabel='', \n                     title=[strategy, thresh, \"scale\", \"-2\", \"binarize\"])\n\nstrategy = 'local'\nthresh = [0.7, 0.7]\nS_thresh = threshold_matrix(S, thresh=thresh, strategy=strategy, scale=0, penalty=0, binarize=0)\nplot_matrix(S_thresh, ax=[ax[1,1]], xlabel='', ylabel='', \n                     title=[strategy, thresh])\n\nstrategy = 'local'\nthresh = [0.7, 0.7]\nS_thresh = threshold_matrix(S, thresh=thresh, strategy=strategy, scale=1, penalty=-2, binarize=0)\nplot_matrix(S_thresh, ax=[ax[1,2]], xlabel='', ylabel='', \n                     title=[strategy, thresh, \"scale\", \"-2\"])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html",
    "title": "5.3. 오디오 썸네일",
    "section": "",
    "text": "음악 녹음의 가장 대표적인 섹션을 자동으로 결정하는 오디오 썸네일(thumbnail)에 대해 다룬다. 세그먼트의 반복 기반 접근 방식의 최적화 방법을 알아본다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#ssm의-필요조건",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#ssm의-필요조건",
    "title": "5.3. 오디오 썸네일",
    "section": "SSM의 필요조건",
    "text": "SSM의 필요조건\n\n적합도(fitness) 측정의 아이디어는 주어진 세그먼트와 그것의 대략적인 반복 간의 모든 관계를 동시에 설정하는 것이다. 이를 위해서는 자기 유사성 행렬(SSM) 이 필요하다. 적합도 측정에 대한 다음 설명은 일부 기본 정규화 속성(normalization properties) 만 충족하는 일반 자기 유사성 행렬과 함께 작동한다는 점에서 일반적이다. \\[\\mathbf{S}(n,m)\\leq 1 \\text{ and } \\mathbf{S}(n,n)=1 \\text{ for all } n,m\\in[1:N]\\]\n5.2. 자기 유사성 행렬에서 사용한 브람스 예시를 계속하여 보면, 향상된(enhanced) SSM에서 시작하여 정규화 속성을 만족시키는 임계값 절차(thresholding procedure)를 거친다. 결과적으로 SSM의 모든 상관있는(relevant) 성분은 0과 1 사이(주대각선 성분은 1)가 되며, 상관없는 성분은 \\(\\delta=-2\\)의 음수 점수를 가진다.\n\n\ndef colormap_penalty(penalty=-2, cmap=compressed_gray_cmap(alpha=5)):\n    \"\"\"Extend colormap with white color between the penalty value and zero\n\n    Args:\n        penalty (float): Negative number (Default value = -2.0)\n        cmap (mpl.colors.Colormap): Original colormap (Default value = libfmp.b.compressed_gray_cmap(alpha=5))\n\n    Returns:\n        cmap_penalty (mpl.colors.Colormap): Extended colormap\n    \"\"\"\n    if isinstance(cmap, str):\n        cmap = matplotlib.cm.get_cmap(cmap, 128)\n    cmap_matrix = cmap(np.linspace(0, 1, 128))[:, :3]\n    num_row = int(np.abs(penalty)*128)\n    # cmap_penalty = np.flip(np.concatenate((cmap_matrix, np.ones((num_row, 3))), axis=0), axis=0)\n    cmap_penalty = np.concatenate((np.ones((num_row, 3)), cmap_matrix), axis=0)\n    cmap_penalty = ListedColormap(cmap_penalty)\n\n    return cmap_penalty\n\n\ndef normalization_properties_ssm(S):\n    \"\"\"Normalizes self-similartiy matrix to fulfill S(n,n)=1.\n    Yields a warning if max(S)<=1 is not fulfilled\n\n    Args:\n        S (np.ndarray): Self-similarity matrix (SSM)\n\n    Returns:\n        S_normalized (np.ndarray): Normalized self-similarity matrix\n    \"\"\"\n    S_normalized = S.copy()\n    N = S_normalized.shape[0]\n    for n in range(N):\n        S_normalized[n, n] = 1\n        max_S = np.max(S_normalized)\n    if max_S > 1:\n        print('Normalization condition for SSM not fulfill (max > 1)')\n    return S_normalized\n\n\ndef plot_ssm_ann(S, ann, Fs=1, cmap='gray_r', color_ann=[], ann_x=True, ann_y=True,\n                 fontsize=12, figsize=(5, 4.5), xlabel='', ylabel='', title=''):\n    \"\"\"Plot SSM and annotations (horizontal and vertical as overlay)\n\n    Args:\n        S: Self-similarity matrix\n        ann: Annotations\n        Fs: Feature rate of path_family (Default value = 1)\n        cmap: Color map for S (Default value = 'gray_r')\n        color_ann: color scheme used for annotations (see :func:`libfmp.b.b_plot.plot_segments`)\n            (Default value = [])\n        ann_x: Plot annotations on x-axis (Default value = True)\n        ann_y: Plot annotations on y-axis (Default value = True)\n        fontsize: Font size used for annotation labels (Default value = 12)\n        figsize: Size of figure (Default value = (5, 4.5))\n        xlabel: Label for x-axis (Default value = '')\n        ylabel: Label for y-axis (Default value = '')\n        title: Figure size (Default value = '')\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n        im: Handle for imshow\n    \"\"\"\n    fig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05],\n                                              'height_ratios': [1, 0.1]}, figsize=figsize)\n\n    fig_im, ax_im, im = plot_matrix(S, Fs=Fs, Fs_F=Fs,\n                                             ax=[ax[0, 0], ax[0, 1]], cmap=cmap,\n                                             xlabel='', ylabel='', title='')\n    ax[0, 0].set_ylabel(ylabel)\n    ax[0, 0].set_xlabel(xlabel)\n    ax[0, 0].set_title(title)\n    if ann_y:\n        plot_segments_overlay(ann, ax=ax_im[0], direction='vertical',\n                                       time_max=S.shape[0]/Fs, print_labels=False,\n                                       colors=color_ann, alpha=0.05)\n    if ann_x:\n        plot_segments(ann, ax=ax[1, 0], time_max=S.shape[0]/Fs, colors=color_ann,\n                               time_axis=False, fontsize=fontsize)\n    else:\n        ax[1, 0].axis('off')\n    ax[1, 1].axis('off')\n    plt.tight_layout()\n    return fig, ax, im\n\n\nfn_wav = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.wav'\n\ntempo_rel_set = compute_tempo_rel_set(0.66, 1.5, 5)\npenalty = -2\nx, x_duration, X, Fs_feature, S, I = compute_sm_from_filename(fn_wav, L=21, H=5, \n                        L_smooth=12, tempo_rel_set=tempo_rel_set, penalty=penalty, thresh=0.15)\nS = normalization_properties_ssm(S)\n \nfn_ann = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.csv'\nann_frames, color_ann = read_structure_annotation(fn_ann, Fs=Fs_feature)\n\ncmap_penalty = colormap_penalty(penalty=penalty)\nfig, ax, im = plot_ssm_ann(S, ann_frames, Fs=1, color_ann=color_ann, cmap=cmap_penalty, \n                       xlabel='Time (frames)', ylabel='Time (frames)')\n\n\n\n\n\nS.shape\n\n(409, 409)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#경로군-path-family",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#경로군-path-family",
    "title": "5.3. 오디오 썸네일",
    "section": "경로군 (Path Family)",
    "text": "경로군 (Path Family)\n\n\\(P=((n_1,m_1), (n_2,m_2), \\ldots,(n_L,m_L))\\)를 주어진 세그먼트 \\(\\alpha=[s:t]\\subseteq [ 1:N]\\)의 경로(path)라고 하고, \\(\\Sigma\\)를 기본 허용 가능한 step size 집합을 나타낸다고 하자. 그러면 정의에 따라 \\(m_1=s\\) 및 \\(m_L=t\\) 이고, 경로 \\(P\\)는 \\(\\alpha=\\pi_2(P)\\)와 유도된(induced) 세그먼트 \\(\\pi_1(P)\\) 사이의 관계를 인코딩한다.\n경로의 개념을 확장하여 이제 음악 녹음에서 \\(\\alpha\\)와 다른 여러 세그먼트 간의 관계를 캡처할 수 있는 경로군(path family)의 개념을 소개한다. 이를 위해 먼저 \\(K\\) 크기의 세그먼트 군(segment family)을 다음의 집합으로 정의한다. \\[\\mathcal{A}:=\\{\\alpha_1,\\alpha_2,\\ldots,\\alpha_K\\}\\]\n즉, \\(k\\not= j\\)인 모든 \\(k,j\\in[1:K]\\)에 대해 \\(\\alpha_k\\cap\\alpha_j=\\emptyset\\)이다. \\(\\alpha\\) 위의 경로군는 다음의 집합으로 정의된다. \\[\\mathcal{P}:=\\{P_1,P_2,\\ldots,P_K\\}\\]\n\nof size \\(K\\),\nconsisting of paths \\(P_k\\) over \\(\\alpha\\) for \\(k\\in[1:K]\\)\n\n또한 추가 조건으로 유도된 세그먼트가 “pairwise disjoint”이어야 한다. 즉, \\(\\{\\pi_1(P_1),\\ldots,\\pi_1(P_K)\\}\\) 집합이 세그먼트 군이 되어야 한다.\n이러한 정의는 다음의 그림으로 설명된다.\n\n(왼쪽부터) 세그먼트 \\(\\alpha\\)가 있는 SSM / 세 개의 경로로 구성된 \\(\\alpha\\) 위에 경로군가 있이 SSM / 경로군이 아닌 경로들(유도된 세그먼트가 겹치기 때문에) / 두 개의 경로로 구성된 경로군\n\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F16.png\", width=1000)\n\n\n\n\n\ndef plot_path_family(ax, path_family, Fs=1, x_offset=0, y_offset=0, proj_x=True, w_x=7, proj_y=True, w_y=7):\n    \"\"\"Plot path family into a given axis\n\n    Args:\n        ax: Axis of plot\n        path_family: Path family\n        Fs: Feature rate of path_family (Default value = 1)\n        x_offset: Offset x-axis (Default value = 0)\n        y_offset: Yffset x-axis (Default value = 0)\n        proj_x: Display projection on x-axis (Default value = True)\n        w_x: Width used for projection on x-axis (Default value = 7)\n        proj_y: Display projection on y-axis (Default value = True)\n        w_y: Width used for projection on y-axis (Default value = 7)\n    \"\"\"\n    for path in path_family:\n        y = [(path[i][0] + y_offset)/Fs for i in range(len(path))]\n        x = [(path[i][1] + x_offset)/Fs for i in range(len(path))]\n        ax.plot(x, y, \"o\", color=[0, 0, 0], linewidth=3, markersize=5)\n        ax.plot(x, y, '.', color=[0.7, 1, 1], linewidth=2, markersize=6)\n    if proj_y:\n        for path in path_family:\n            y1 = path[0][0]/Fs\n            y2 = path[-1][0]/Fs\n            ax.add_patch(plt.Rectangle((0, y1), w_y, y2-y1, linewidth=1,\n                                       facecolor=[0, 1, 0], edgecolor=[0, 0, 0]))\n            # ax.plot([0, 0], [y1, y2], linewidth=8, color=[0, 1, 0])\n    if proj_x:\n        for path in path_family:\n            x1 = (path[0][1] + x_offset)/Fs\n            x2 = (path[-1][1] + x_offset)/Fs\n            ax.add_patch(plt.Rectangle((x1, 0), x2-x1, w_x, linewidth=1,\n                                       facecolor=[0, 0, 1], edgecolor=[0, 0, 0]))\n            # ax.plot([x1, x2], [0, 0], linewidth=8, color=[0, 0, 1])                 \n\n\n# Manually defined path family\n# For implementation reasons, the seconds components are of the paths \n# start with index 0 (corresponding to seg[0])\nseg_sec = [20, 80]\nseg = [int(seg_sec[0]*Fs_feature), int(seg_sec[1]*Fs_feature)]\npath_1 = [np.array([i+seg[0],i]) for i in range(0, seg[-1]-seg[0]+1)]\npath_2 = [np.array([int(i+130*Fs_feature),i]) for i in range(0, seg[-1]-seg[0]+1)]\npath_family = [path_1, path_2]\nprint('Segment:', seg)\nfig, ax, im = plot_ssm_ann(S, ann_frames, Fs=1, color_ann=color_ann, cmap=cmap_penalty, \n                       xlabel='Time (frames)', ylabel='Time (frames)') \nplot_path_family(ax[0,0], path_family, Fs=1, x_offset=seg[0])\n\nSegment: [20, 80]"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#커버리지-coverage",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#커버리지-coverage",
    "title": "5.3. 오디오 썸네일",
    "section": "커버리지 (Coverage)",
    "text": "커버리지 (Coverage)\n\n이제 경로군 \\(\\mathcal{P}\\)의 특정 속성을 설명하는 몇 가지 측정값을 정의한다.\n\\(\\mathcal{A}:=\\{\\alpha_1,\\alpha_2,\\ldots,\\alpha_K\\}\\)를 세그먼트 군이라고 하자.\n\\(\\mathcal{A}\\)의 커버리지/반영범위(coverage) \\(\\gamma(\\mathcal{A})\\)는 다음과 같이 정의된다. \\[\\gamma(\\mathcal{A}):=\\sum_{k=1}^K|\\alpha_k|\\]\n또한, 경로군 \\(\\mathcal{P}=\\{P_1,P_2,\\ldots,P_K\\}\\)의 범위 \\(\\gamma(\\mathcal{P})\\)는 유도된 세그먼트 군 \\(\\{\\pi_1(P_1),\\ldots,\\pi_1(P_K)\\}\\)의 커버리지로 정의된다.\n다음 코드에서 유도된 세그먼트군과 주어진 경로군에 대한 커버리지를 유도하는 함수를 제공한다. 이 함수는 위에서 생성한 경로군에 적용된다.\n\n\ndef compute_induced_segment_family_coverage(path_family):\n    \"\"\"Compute induced segment family and coverage from path family\n\n    Args:\n        path_family (list): Path family\n\n    Returns:\n        segment_family (np.ndarray): Induced segment family\n        coverage (float): Coverage of path family\n    \"\"\"\n    num_path = len(path_family)\n    coverage = 0\n    if num_path > 0:\n        segment_family = np.zeros((num_path, 2), dtype=int)\n        for n in range(num_path):\n            segment_family[n, 0] = path_family[n][0][0]\n            segment_family[n, 1] = path_family[n][-1][0]\n            coverage = coverage + segment_family[n, 1] - segment_family[n, 0] + 1\n    else:\n        segment_family = np.empty\n\n    return segment_family, coverage\n\n\nsegment_family, coverage = compute_induced_segment_family_coverage(path_family)\nprint('Segment (alpha):', seg)\nprint('Induced segment family:')\nprint(segment_family)\nprint('Coverage: %d'%coverage)    \n\nSegment (alpha): [20, 80]\nInduced segment family:\n[[ 20  80]\n [130 190]]\nCoverage: 122"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#점수와-최적-score-and-optimality",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#점수와-최적-score-and-optimality",
    "title": "5.3. 오디오 썸네일",
    "section": "점수와 최적 (Score and Optimality)",
    "text": "점수와 최적 (Score and Optimality)\n\n다음으로 점수(score)의 개념을 경로에서 경로군로 전환한다. 주어진 SSM \\(\\mathbf{S}\\)에서 경로 \\(P\\)의 점수 \\(\\sigma(P)\\)는 다음과 같이 정의된다. \\[\\sigma(P)=\\sum_{\\ell=1}^L \\mathbf{S}(n_\\ell,m_\\ell).\\]\n이 값은 세그먼트 \\(\\pi_1(P)\\)와 \\(\\pi_2(P)\\) 사이의 유사성 관계에 대한 품질 척도로 생각할 수 있다. 경로군 \\(\\mathcal{P}\\)의 경우 점수 \\(\\sigma(\\mathcal{P})\\)는 다음과 같이 정의된다. \\[\\sigma(\\mathcal{P}) := \\sum_{k=1}^{K} \\sigma(P_k).\\]\n큰 점수 \\(\\sigma(\\mathcal{P})\\)는 \\(\\mathcal{P}\\)의 경로 구성 요소가 해당 세그먼트 간에 강력한 유사성 관계를 표현함을 나타낸다.\n일반적으로 많은 수의 \\(\\alpha\\) 위로의 가능한 경로군가 있다. 이러한 경로군 중에서 \\(\\mathcal{P}^\\ast := \\underset{\\mathcal{P}}{\\mathrm{argmax}} \\,\\,\\, \\sigma(\\mathcal{P})\\)를 최대 점수의 최적 경로군을 나타낸다고 하자.\n다음에서는 \\(\\mathcal{P}^\\ast\\) 경로에 의해 유도된(induced) 세그먼트로 구성된 것을 유도된(induced) 세그먼트 군 (of \\(\\mathcal{P}^\\ast\\) 또는 간단히 \\(\\alpha\\))이라고 한다. 직관적으로, 유도된 세그먼트 군은 세그먼트 \\(\\alpha\\)의 (겹치지 않는) 반복을 포함한다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#최적-경로군-계산-computation-of-optimal-path-families",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#최적-경로군-계산-computation-of-optimal-path-families",
    "title": "5.3. 오디오 썸네일",
    "section": "최적 경로군 계산 (Computation of Optimal Path Families)",
    "text": "최적 경로군 계산 (Computation of Optimal Path Families)\n\n최적 워핑 경로를 계산하는 DTW(dynamic time warping)과 유사하게 동적(dynamic) 프로그래밍을 사용하여 최적 경로군 \\(\\mathcal{P}^\\ast\\)를 계산하는 효율적인 알고리즘이 있다.\n다음 코드에서 허용 가능한 step size의 \\(\\Sigma = \\{(2,1),(1,2),(1,1)\\}\\) 집합을 사용하여 이 알고리즘의 구현한다.\n\\(\\mathbf{S}\\)를 필요한 정규화 속성(점수 매트릭스라고도 함)과 세그먼트 \\(\\alpha=[s:t]\\subseteq [ 1:N]\\)와 \\(M:=|\\alpha|\\)을 충족하는 \\(N\\)-square SSM이라고 하자.\n알고리즘의 입력(input)은 \\(\\mathbf{S}\\)의 열 \\(s\\)에서 \\(t\\)로 구성된 \\(N\\times M\\) 부분행렬(submatrix) \\(\\mathcal{S}^{\\alpha}\\)이다.\n먼저 동적 프로그래밍을 사용하여 누적 점수 매트릭스 \\(D\\)를 계산한다.\n\n\ndef compute_accumulated_score_matrix(S_seg):\n    \"\"\"Compute the accumulated score matrix\n\n    Args:\n        S_seg (np.ndarray): Submatrix of an enhanced and normalized SSM ``S``.\n            Note: ``S`` must satisfy ``S(n,m) <= 1 and S(n,n) = 1``\n\n    Returns:\n        D (np.ndarray): Accumulated score matrix\n        score (float): Score of optimal path family\n    \"\"\"\n    inf = math.inf\n    N = S_seg.shape[0]\n    M = S_seg.shape[1]+1\n\n    # Iinitializing score matrix\n    D = -inf * np.ones((N, M), dtype=np.float64)\n    D[0, 0] = 0.\n    D[0, 1] = D[0, 0] + S_seg[0, 0]\n\n    # Dynamic programming\n    for n in range(1, N):\n        D[n, 0] = max(D[n-1, 0], D[n-1, -1])\n        D[n, 1] = D[n, 0] + S_seg[n, 0]\n        for m in range(2, M):\n            D[n, m] = S_seg[n, m-1] + max(D[n-1, m-1], D[n-1, m-2], D[n-2, m-1])\n\n    # Score of optimal path family\n    score = np.maximum(D[N-1, 0], D[N-1, M-1])\n\n    return D, score\n\n\n다음으로, 역추적(backtracking)을 이용하여 최적 경로군 \\(\\mathcal{P}^\\ast\\)를 도출한다.\n\n\ndef compute_optimal_path_family(D):\n    \"\"\"Compute an optimal path family given an accumulated score matrix\n\n    Args:\n        D (np.ndarray): Accumulated score matrix\n\n    Returns:\n        path_family (list): Optimal path family consisting of list of paths\n            (each path being a list of index pairs)\n    \"\"\"\n    # Initialization\n    inf = math.inf\n    N = int(D.shape[0])\n    M = int(D.shape[1])\n\n    path_family = []\n    path = []\n\n    n = N - 1\n    if(D[n, M-1] < D[n, 0]):\n        m = 0\n    else:\n        m = M-1\n        path_point = (N-1, M-2)\n        path.append(path_point)\n\n    # Backtracking\n    while n > 0 or m > 0:\n\n        # obtaining the set of possible predecesors given our current position\n        if(n <= 2 and m <= 2):\n            predecessors = [(n-1, m-1)]\n        elif(n <= 2 and m > 2):\n            predecessors = [(n-1, m-1), (n-1, m-2)]\n        elif(n > 2 and m <= 2):\n            predecessors = [(n-1, m-1), (n-2, m-1)]\n        else:\n            predecessors = [(n-1, m-1), (n-2, m-1), (n-1, m-2)]\n\n        # case for the first row. Only horizontal movements allowed\n        if n == 0:\n            cell = (0, m-1)\n        # case for the elevator column: we can keep going down the column or jumping to the end of the next row\n        elif m == 0:\n            if D[n-1, M-1] > D[n-1, 0]:\n                cell = (n-1, M-1)\n                path_point = (n-1, M-2)\n                if(len(path) > 0):\n                    path.reverse()\n                    path_family.append(path)\n                path = [path_point]\n            else:\n                cell = (n-1, 0)\n        # case for m=1, only horizontal steps to the elevator column are allowed\n        elif m == 1:\n            cell = (n, 0)\n        # regular case\n        else:\n\n            # obtaining the best of the possible predecesors\n            max_val = -inf\n            for i, cur_predecessor in enumerate(predecessors):\n                if(max_val < D[cur_predecessor[0], cur_predecessor[1]]):\n                    max_val = D[cur_predecessor[0], cur_predecessor[1]]\n                    cell = cur_predecessor\n\n            # saving the point in the current path\n            path_point = (cell[0], cell[1]-1)\n            path.append(path_point)\n\n        (n, m) = cell\n\n    # adding last path to the path family\n    path.reverse()\n    path_family.append(path)\n    path_family.reverse()\n\n    return path_family\n\n\n다음 그림에서 부분 행렬 \\(\\mathcal{S}^{\\alpha}\\)와 세그먼트 \\(\\alpha=[83:137]\\) (seg = [82, 136])에 대한 누적 점수 행렬 \\(D\\)가 나타나 있다.\n\\(2~\\mathrm{Hz}\\)의 프레임 속도(frame rate)를 사용하여 이 세그먼트는 \\(41\\)에서 \\(68\\)초 범위의 간격에 해당하며 대략적으로 Brahms 레코딩의 \\(B_1\\) 부분이다. 다음 사항에 유의하자.\n\n부분 행렬 \\(\\mathcal{S}^{\\alpha}\\)의 열 수는 \\(M=55\\)이다.\nPython 구현에서 \\(\\mathcal{S}^{\\alpha}\\)의 열은 인덱스 0부터 인덱스 M-1까지 열거된다.\n행렬 \\(D\\)에는 소위 엘리베이터(elevator) 컬럼을 포함하는 \\(M+1\\) 컬럼이 있다.\n단계 크기(step size) 조건 \\(\\Sigma = \\{(2,1),(1,2),(1,1)\\}\\)를 사용하면, 경로가 로컬 템포 차이에 적응할 수 있다.\n최적의 경로군은 4개의 경로로 구성된다. 유도된(induced) 세그먼트는 Brahms 녹음의 4개의 \\(B\\) 파트 섹션에 대략 해당된다.\n\n\n\ndef plot_matrix_seg(ax, M, seg, title='', xlabel='', cmap='gray_r'):\n    plot_matrix(M, Fs=1, ax=[ax], cmap=cmap, \n        xlabel=xlabel, ylabel='Time (frames)', title=title)\n    ax.set_xticks([0, M.shape[1]-1])    \n    \nseg_sec = [41,68]\nseg = [int(seg_sec[0]*Fs_feature), int(seg_sec[1]*Fs_feature)]\nprint('Segment:', seg)\nprint('Length of segment: M = ', seg[1]-seg[0]+1)\nS_seg = S[:,seg[0]:seg[1]+1]\nD, score = compute_accumulated_score_matrix(S_seg)\npath_family = compute_optimal_path_family(D)\n\nplt.figure(figsize=(8, 8))\nax = plt.subplot(2, 2, 1)\ntitle = r'$\\mathcal{S}^{\\alpha}$'\nplot_matrix_seg(ax, S_seg, seg, title=title, xlabel='', cmap=cmap_penalty)\n\nax = plt.subplot(2, 2, 2)\ntitle = r'$D$'\nplot_matrix_seg(ax, D, seg, title=title)\n\nax = plt.subplot(2, 2, 3)\ntitle = r'$\\mathcal{S}^{\\alpha}$ with optimal path family'\nplot_matrix_seg(ax, S_seg, seg, title=title, xlabel='', cmap=cmap_penalty)\nplot_path_family(ax, path_family, x_offset=0, w_y=1)\n\nax = plt.subplot(2, 2, 4)\ntitle = r'$D$ with optimal path family'\nplot_matrix_seg(ax, D, seg, title=title)\nplot_path_family(ax, path_family, x_offset=1, w_y=1)\n\nplt.tight_layout()\n\nSegment: [41, 68]\nLength of segment: M =  28"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#적합도-측정-fitness-measure",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#적합도-측정-fitness-measure",
    "title": "5.3. 오디오 썸네일",
    "section": "적합도 측정 (Fitness Measure)",
    "text": "적합도 측정 (Fitness Measure)\n\n주어진 세그먼트 \\(\\alpha\\)에 대해, \\(\\mathcal{P}^\\ast=\\{P_1,\\ldots,P_K\\}\\)를 최적 경로군이라고 하자. 이제 \\(\\sigma(\\mathcal{P}^\\ast)\\) 점수와 \\(\\mathcal{P}^\\ast\\)의 유도된 세그먼트 군에서 적합도(fitness) 측정을 유도하는 방법을 설명한다.\n첫 번째, 총 점수 \\(\\sigma(\\mathcal{P}^\\ast)\\)를 \\(\\alpha\\)의 적합도 값으로 사용한다. 그러나 이 측정은 \\(\\alpha\\)의 길이와 경로에 의존할 뿐만 아니라 당연한 자체-설명(self-explanation)도 캡처하기 때문에 아직 원하는 속성을 갖지 않는다.\n\n예를 들어 \\(\\alpha=[1:N]\\) 세그먼트는 전체 시퀀스 \\(X\\)를 완벽하게 설명하며 이는 당연한 사실이다. 좀 더 일반적으로 각 세그먼트 \\(\\alpha\\)는 자기 유사성 행렬의 주 대각선으로 인코딩된 정보를 완벽하게 설명한다.\n\n따라서 적합도 측정을 정의할 때의 한 가지 방법은 이러한 당연한 자기-설명(trivial self-explanation)을 무시하는 것이다.\n\n정규화 속성 \\(\\mathbf{S}(n,m)\\leq 1\\) 및 \\(\\mathbf{S}(n,n)=1\\)를 가정하면, \\(\\sigma(\\mathcal{P}^\\ast)\\) 점수에서 \\(|\\alpha|\\) 길이를 빼는 방법을 사용할 수 있다.\n\n또한 최적 경로군 \\(\\mathcal{P}^\\ast\\)에 포함된 경로 \\(P_k\\)의 길이 \\(L_k:=|P_k|\\)에 대한 점수를 정규화한다.\n\n다음과 같이 정의된 정규화 점수(normalized score) \\(\\bar{\\sigma}(\\alpha)\\)를 산출한다. \\[\\bar{\\sigma}(\\alpha) := \\frac{\\sigma(\\mathcal{P}^\\ast) - |\\alpha|}{\\sum_{k=1}^{K} L_k}\\]\n\n직관적으로 \\(\\bar{\\sigma}(\\alpha)\\) 값은 최적 경로군 \\(\\mathcal{P}^\\ast\\)의 평균 점수를 나타낸다.\n정규화 점수는 주어진 세그먼트가 다른 세그먼트를 얼마나 잘 설명하는지를 나타내며, 여기서 정규화는 세그먼트 길이의 영향을 제거한다. 이렇게 하면 길이가 다른 세그먼트를 비교할 때 정규화된 점수가 공정한 측정이 될 수 있다.\n반복성 외에 또 다른 문제는 썸네일 및 썸네일 관련 세그먼트가 기본 음악 녹음을 얼마나 많이 (how much) 포함하는지이다.\n이 속성을 포착하기 위해 주어진 \\(\\alpha\\)에 대한 커버리지(coverage) 측정을 정의한다.\n이를 위해 \\(\\mathcal{A}^\\ast:=\\{\\pi_1(P_1),\\ldots,\\pi_1(P_K)\\}\\)를 최적 경로군 \\(\\mathcal{P}^\\ast\\)에 의해 유도된 세그먼트 군이라고 하고, \\(\\gamma(\\mathcal{A}^\\ast)\\)를 그것의 커버리지라고 하자.\n그런 다음 정규화 커버리지 \\(\\bar{\\gamma}(\\alpha)\\)를 다음과 같이 정의한다. \\[\\bar{\\gamma}(\\alpha) := \\frac{\\gamma(\\mathcal{A}^\\ast) - |\\alpha|}{N}.\\]\n위와 같이 사소한(trivial) 커버리지에 대해 \\(|\\alpha|\\) 길이를 뺀다.\n\\(\\bar{\\gamma}(\\alpha)\\) 값은 \\(\\alpha\\)의 유도된 세그먼트의 합집합과 원본 녹음의 전체 길이 사이의 비율을 나타낸다(자기-설명의 비율을 뺀 값).\n높은 평균 점수와 높은 커버리지는 썸네일 세그먼트를 정의하는 데 바람직한 속성이다. 그러나 이 두 가지 속성을 동시에 만족시키기 어려운 경우가 있다.\n세그먼트가 짧을수록 평균 점수는 더 높지만 커버리지는 더 낮고, 길이가 더 긴 세그먼트는 평균 점수가 더 낮지만 커버리지가 더 높은 경향이 있다.\n이 두 추세의 균형을 맞추기 위해 적절한 평균을 취하여 점수와 커버리지 측정을 결합한다.\n특히 세그먼트 \\(\\alpha\\)의 적합도(fitness) \\(\\varphi(\\alpha)\\)를 정규화된 점수와 정규화된 커버리지 사이의 조화 평균 (harmonic mean) 을 \\[\\varphi(\\alpha) := 2\\cdot \\frac{\\bar{\\sigma}(\\alpha) \\cdot \\bar{\\gamma}(\\alpha)}{\\bar{\\sigma}(\\alpha)+\\bar{\\gamma}(\\alpha )}\\] 라고 정의한다.\n정규화된 값 \\(\\bar{\\sigma}(\\alpha)\\) 및 \\(\\bar{\\gamma}(\\alpha)\\)를 기반으로, \\(\\varphi(\\alpha)\\leq 1-|\\alpha |/N\\) 임을 보일 수 있다.\n다음 코드 셀에서는 이전 코드 셀에서 고려한 경로군에 대해 이러한 다양한 측정값을 계산한다.\n\n\ndef compute_fitness(path_family, score, N):\n    \"\"\"Compute fitness measure and other metrics from path family\n\n    Args:\n        path_family (list): Path family\n        score (float): Score\n        N (int): Length of feature sequence\n\n    Returns:\n        fitness (float): Fitness\n        score (float): Score\n        score_n (float): Normalized score\n        coverage (float): Coverage\n        coverage_n (float): Normalized coverage\n        path_family_length (int): Length of path family (total number of cells)\n    \"\"\"\n    eps = 1e-16\n    num_path = len(path_family)\n    M = path_family[0][-1][1] + 1\n\n    # Normalized score\n    path_family_length = 0\n    for n in range(num_path):\n        path_family_length = path_family_length + len(path_family[n])\n    score_n = (score - M) / (path_family_length + eps)\n\n    # Normalized coverage\n    segment_family, coverage = compute_induced_segment_family_coverage(path_family)\n    coverage_n = (coverage - M) / (N + eps)\n\n    # Fitness measure\n    fitness = 2 * score_n * coverage_n / (score_n + coverage_n + eps)\n\n    return fitness, score, score_n, coverage, coverage_n, path_family_length\n\n\nN = S.shape[0]\n\nsegment_family, coverage = compute_induced_segment_family_coverage(path_family)\nfitness, score, score_n, coverage, coverage_n, path_family_length = compute_fitness(\n    path_family, score, N)\n\nprint('Segment (alpha):', seg)\nprint('Length of segment:', seg[-1]-seg[0]+1)\nprint('Length of feature sequence:', N)\nprint('Induced segment path family:\\n', segment_family)\nprint('Fitness: %0.3f'%fitness) \nprint('Score: %0.3f'%score) \nprint('Normalized score: %0.3f'%score_n) \nprint('Coverage: %d'%coverage) \nprint('Normalized coverage: %0.3f'%coverage_n) \nprint('Length of all paths of family: %d'%path_family_length)\n\nSegment (alpha): [41, 68]\nLength of segment: 28\nLength of feature sequence: 205\nInduced segment path family:\n [[ 41  67]\n [ 68  88]\n [149 174]\n [175 196]]\nFitness: 0.392\nScore: 73.857\nNormalized score: 0.478\nCoverage: 96\nNormalized coverage: 0.332\nLength of all paths of family: 96"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#썸네일-선정-thumbnail-selection",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#썸네일-선정-thumbnail-selection",
    "title": "5.3. 오디오 썸네일",
    "section": "썸네일 선정 (Thumbnail Selection)",
    "text": "썸네일 선정 (Thumbnail Selection)\n\n적합도 측정을 기반으로 구한 오디오 썸네일을 최대 적합도(maximizing-fitness) 세그먼트로 정의한다. \\[\\alpha^\\ast := \\underset{\\alpha}{\\mathrm{argmax}} \\,\\, \\varphi(\\alpha)\\]\n적합도 측정으로 이 세그먼트는 오디오 녹음의 “가능한 많은 부분을 포함하는 겹치지 않는 반복”을 가지게 된다. 또한 이러한 반복은 오디오 녹음을 “pairwise disjoint” 세그먼트로 분할하는 \\(\\alpha^\\ast\\)의 최적 경로군으로 얻은 유도된 세그먼트에 의해 주어진다.\n사전 지식을 설명하고 잘못된 추정을 제거하기 위해 썸네일 솔루션에 추가 요구 사항을 부과할 수 있다. 가능한 최소 썸네일 길이에 대한 하한 \\(\\theta\\)를 도입하면 자기 유사성 행렬(SSM)에 분산된 노이즈의 영향을 줄일 수 있다. 위의 정의를 확장하여 \\(\\alpha^\\ast_\\theta := \\underset{\\alpha, |\\alpha|\\geq \\theta}{\\mathrm{argmax}} \\,\\, \\varphi(\\alpha)\\)를 정의한다.\n오디오 썸네일 계산에는 가능한 모든 세그먼트 \\(\\alpha\\)에 대한 적합도 측정 계산이 포함된다.\n적합도 최대화 세그먼트를 선택하는 것 외에도 모든 세그먼트에 대한 적합도 값의 시각화는 매우 유익하며 음악 녹음의 구조적 속성에 대한 음악적 통찰력을 제공한다. 그 중 scape plot에 대해 뒤에서 다룰 것이며, 여기서 적합도 측정의 추가 속성에 대해서도 논의하기로 한다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#세그먼트의-삼각형-표현triangular-representation",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#세그먼트의-삼각형-표현triangular-representation",
    "title": "5.3. 오디오 썸네일",
    "section": "세그먼트의 삼각형 표현(Triangular Representation)",
    "text": "세그먼트의 삼각형 표현(Triangular Representation)\n\n위에서 오디오 썸네일링의 맥락에서 세그먼트 특정의 속성을 표현하는 적합도(fitness) 값을 가능한 각 세그먼트에 할당하도록 적합도 측정을 계산했다.\n이제 세그먼트 의존적(segment-dependent) 속성을 간결하고(compact) 계층적인(hierarchical) 방식으로 시각화할 수 있는 표현을 소개한다.\n세그먼트 \\(\\alpha=[s:t]\\subseteq [1:N]\\)는 시작점 \\(s\\)와 끝점 \\(t\\)에 의해 고유하게 결정된다. \\(s\\leq t\\)인 임의의 두 숫자 \\(s,t\\in[1:N]\\)가 세그먼트를 정의하므로, \\((N+1)N/2\\)개의 다른 세그먼트가 있다고 볼 수 있다.\n시작점과 끝점을 고려하는 대신 각 세그먼트를 그것의 중심(center) \\(c(\\alpha):=(s+t)/2\\)과 길이 \\(|\\alpha|\\)로 고유하게 설명할 수도 있다. 중심을 사용하여 수평 축을 매개변수화하고, 길이를 사용하여 높이를 매개변수화하면 각 세그먼트는 삼각형 표현(triangular representation) 의 점으로 표시될 수 있다.\n이렇게 하면 세그먼트 집합이 길이에 따라 계층적 방식으로 아래에서 위로 정렬된다. 특히, 이 삼각형의 상단은 최대 길이 \\(N\\)의 고유 세그먼트에 해당하고, 삼각형의 하단 점은 길이가 1인 \\(N\\) 세그먼트에 해당한다(시작점과 끝점이 일치함). 또한 주어진 세그먼트 \\(\\alpha\\)에 포함된 모든 세그먼트 \\(\\alpha'\\subseteq\\alpha\\)는 \\(\\alpha\\)로 주어진 점 아래의 하위 삼각형에 있는 삼각형 표현의 점에 해당한다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F19.png\", width=500)\n\n\n\n\n\n\\([1:N]\\) 내의 모든 세그먼트를 삼각형으로 표현한 경우, 다음 예는 다음 세그먼트 집합을 시각적으로 나타낸다.\n\n\n주어진 임계값 \\(\\theta\\geq 0\\) 이상의 최소 길이를 갖는 모든 세그먼트\n\n\n주어진 세그먼트 \\(\\alpha\\)를 포함하는 모든 세그먼트\n\n\n주어진 세그먼트 \\(\\alpha\\)와 분리된 모든 세그먼트\n\n\n주어진 세그먼트 \\(\\alpha\\)의 중심 \\(c(\\alpha)\\)를 포함하는 모든 세그먼트\n\n\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_E12.png\", width=600)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#scape-plot",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#scape-plot",
    "title": "5.3. 오디오 썸네일",
    "section": "Scape Plot",
    "text": "Scape Plot\n\n삼각형 표현은 모든 세그먼트 \\(\\alpha\\)에 대해 계산할 수 있는 특정 숫자 속성 \\(\\varphi(\\alpha)\\in\\mathbb{R}\\)를 시각화하기 위한 그리드로 사용할 수 있다. 예를 들어 이 속성은 오디오 썸네일에 사용되는 적합성 값(fitness value)일 수 있다.\n이러한 시각적 표현은 속성의 “scape plot” 표현이라고도 한다.\n보다 정확하게는 다음을 설정하여 scape plot \\(\\Delta\\)를 정의한다. \\[\\label{eq:AudioStru:Thumb:SPfitness} \\Delta(c(\\alpha),|\\alpha|):=\\varphi(\\alpha)\\]\n쉬운 예제로 \\(\\alpha=[s:t]\\)에 대해 \\(\\varphi(\\alpha):= (t-s+1)/N\\)로 정의된 \\(\\varphi\\) 함수를 고려해보자. 총 길이 \\(N\\)에 대한 세그먼트 길이를 인코딩한다.\n주의: 이 구현에서는 세그먼트 종속 속성 \\(\\varphi(\\alpha)\\in\\mathbb{R}\\)을 저장하기 위한 데이터 구조로 N-스퀘어 행렬 SP를 사용한다. 길이를 인코딩하기 위해 SP의 첫 번째 차원을 사용하고 중심을 인코딩하기 위해 두 번째 차원을 사용한다. Python의 인덱싱은 인덱스 0부터 시작하므로 길이 차원을 해석할 때 주의해야 한다. 특히, 엔트리 SP[length_minus_one, start]는 length_minus_one = 0, ..., N-1에 대해 length_minus_one + 1의 길이를 갖는 세그먼트에 대한 정보를 포함한다. 또한 SP는 왼쪽 위 부분(대각선 포함)만 사용한다는 점에 유의해야 한다.\n\n\ndef visualize_scape_plot(SP, Fs=1, ax=None, figsize=(4, 3), title='',\n                         xlabel='Center (seconds)', ylabel='Length (seconds)', interpolation='nearest'):\n    \"\"\"Visualize scape plot\n\n    Args:\n        SP: Scape plot data (encodes as start-duration matrix)\n        Fs: Sampling rate (Default value = 1)\n        ax: Used axes (Default value = None)\n        figsize: Figure size (Default value = (4, 3))\n        title: Title of figure (Default value = '')\n        xlabel: Label for x-axis (Default value = 'Center (seconds)')\n        ylabel: Label for y-axis (Default value = 'Length (seconds)')\n        interpolation: Interpolation value for imshow (Default value = 'nearest')\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n        im: Handle for imshow\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.gca()\n    N = SP.shape[0]\n    SP_vis = np.zeros((N, N))\n    for length_minus_one in range(N):\n        for start in range(N-length_minus_one):\n            center = start + length_minus_one//2\n            SP_vis[length_minus_one, center] = SP[length_minus_one, start]\n\n    extent = np.array([-0.5, (N-1)+0.5, -0.5, (N-1)+0.5]) / Fs\n    im = plt.imshow(SP_vis, cmap='hot_r', aspect='auto', origin='lower', extent=extent, interpolation=interpolation)\n    x = np.asarray(range(N))\n    x_half_lower = x/2\n    x_half_upper = x/2 + N/2 - 1/2\n    plt.plot(x_half_lower/Fs, x/Fs, '-', linewidth=3, color='black')\n    plt.plot(x_half_upper/Fs, np.flip(x, axis=0)/Fs, '-', linewidth=3, color='black')\n    plt.plot(x/Fs, np.zeros(N)/Fs, '-', linewidth=3, color='black')\n    plt.xlim([0, (N-1) / Fs])\n    plt.ylim([0, (N-1) / Fs])\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    plt.tight_layout()\n    plt.colorbar(im, ax=ax)\n    return fig, ax, im\n\n\nN = 9\nSP = np.zeros((N,N))\nfor k in range(N):\n    for s in range(N-k):\n        length = k + 1\n        SP[k, s]= length/N  \n\nplt.figure(figsize=(7,3))\nax = plt.subplot(121)\nplt.imshow(SP, cmap='hot_r', aspect='auto') \nax.set_title('Data structure (N = %d)'%N)\nax.set_xlabel('Segment start (samples)')\nax.set_ylabel('Length minus one (samples)')\nplt.colorbar()  \n\nax = plt.subplot(122)\nfig, ax, im = visualize_scape_plot(SP, Fs=1, ax=ax, title='Scape plot visualization', \n                xlabel='Segment center (samples)', ylabel='Length minus one (samples)')"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#적합도-scape-plot",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#적합도-scape-plot",
    "title": "5.3. 오디오 썸네일",
    "section": "적합도 Scape Plot",
    "text": "적합도 Scape Plot\n\nscape plot 표현을 사용해 모든 세그먼트에 대한 적합도 측정을 시각화한다.\n\n\nfn_wav = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.wav'\n\ntempo_rel_set = compute_tempo_rel_set(0.66, 1.5, 5)\npenalty = -2\nx, x_duration, X, Fs_feature, S, I = compute_sm_from_filename(fn_wav, L=41, H=10, \n                        L_smooth=8, tempo_rel_set=tempo_rel_set, penalty=penalty, thresh= 0.15)\nS = normalization_properties_ssm(S)\n \nfn_ann = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.csv'\nann_frames, color_ann = read_structure_annotation(fn_ann, Fs=Fs_feature)\n\ncmap_penalty = colormap_penalty(penalty=penalty)\nfig, ax, im = plot_ssm_ann(S, ann_frames, Fs=1, color_ann=color_ann, cmap=cmap_penalty, \n                       xlabel='Time (frames)', ylabel='Time (frames)')\n\n\n\n\n\n다음 코드는 세그먼트 \\(\\alpha\\)에 대한 적합도 척도 \\(\\varphi(\\alpha)\\in\\mathbb{R}\\) (및 점수 \\(\\sigma(\\alpha)\\), 정규화된 점수 \\(\\bar{\\sigma}(\\alpha)\\), 커버리지(coverage) \\(\\gamma(\\alpha)\\), 정규화된 커버리지 \\(\\bar{\\gamma}(\\alpha)\\))를 계산한다.\n\n\ndef compute_fitness_scape_plot(S):\n    \"\"\"Compute scape plot for fitness and other measures\n\n    Args:\n        S (np.ndarray): Self-similarity matrix\n\n    Returns:\n        SP_all (np.ndarray): Vector containing five different scape plots for five measures\n            (fitness, score, normalized score, coverage, normlized coverage)\n    \"\"\"\n    N = S.shape[0]\n    SP_fitness = np.zeros((N, N))\n    SP_score = np.zeros((N, N))\n    SP_score_n = np.zeros((N, N))\n    SP_coverage = np.zeros((N, N))\n    SP_coverage_n = np.zeros((N, N))\n\n    for length_minus_one in range(N):\n        for start in range(N-length_minus_one):\n            S_seg = S[:, start:start+length_minus_one+1]\n            D, score = compute_accumulated_score_matrix(S_seg)\n            path_family = compute_optimal_path_family(D)\n            fitness, score, score_n, coverage, coverage_n, path_family_length = compute_fitness(\n                path_family, score, N)\n            SP_fitness[length_minus_one, start] = fitness\n            SP_score[length_minus_one, start] = score\n            SP_score_n[length_minus_one, start] = score_n\n            SP_coverage[length_minus_one, start] = coverage\n            SP_coverage_n[length_minus_one, start] = coverage_n\n    SP_all = [SP_fitness, SP_score, SP_score_n, SP_coverage, SP_coverage_n]\n    return SP_all\n\n\nSP_all = compute_fitness_scape_plot(S)\n\n\n다음으로 적합도 scape plot라고도 하는 scape plot 표현을 사용하여 적합성 값 \\(\\varphi(\\alpha)\\)를 시각화한다.\n또한 경로군 및 유도된 세그먼트에 걸쳐 적합도-최대화 세그먼트 또는 오디오 썸네일 \\(\\alpha^\\ast := \\underset{\\alpha}{\\mathrm{argmax}} \\,\\, \\varphi(\\alpha)\\)를 그린다.\n썸네일과 유도된 세그먼트는 scape plot 표현에서 점(각각 파란색과 녹색 점)으로 표시된다.\n\n\ndef seg_max_sp(SP):\n    \"\"\"Return segment with maximal value in SP\n\n    Args:\n        SP (np.ndarray): Scape plot\n\n    Returns:\n        seg (tuple): Segment ``(start_index, end_index)``\n    \"\"\"\n    N = SP.shape[0]\n    # value_max = np.max(SP)\n    arg_max = np.argmax(SP)\n    ind_max = np.unravel_index(arg_max, [N, N])\n    seg = [ind_max[1], ind_max[1]+ind_max[0]]\n    return seg\n\n\ndef plot_seg_in_sp(ax, seg, S=None, Fs=1):\n    \"\"\"Plot segment and induced segements as points in SP visualization\n\n    Args:\n        ax: Axis for image\n        seg: Segment ``(start_index, end_index)``\n        S: Self-similarity matrix (Default value = None)\n        Fs: Sampling rate (Default value = 1)\n    \"\"\"\n    if S is not None:\n        S_seg = S[:, seg[0]:seg[1]+1]\n        D, score = compute_accumulated_score_matrix(S_seg)\n        path_family = compute_optimal_path_family(D)\n        segment_family, coverage = compute_induced_segment_family_coverage(path_family)\n        length = segment_family[:, 1] - segment_family[:, 0] + 1\n        center = segment_family[:, 0] + length//2\n        ax.scatter(center/Fs, length/Fs, s=64, c='white', zorder=9999)\n        ax.scatter(center/Fs, length/Fs, s=16, c='lime', zorder=9999)\n    length = seg[1] - seg[0] + 1\n    center = seg[0] + length//2\n    ax.scatter(center/Fs, length/Fs, s=64, c='white', zorder=9999)\n    ax.scatter(center/Fs, length/Fs, s=16, c='blue', zorder=9999)\n\n    \ndef plot_sp_ssm(SP, seg, S, ann, color_ann=[], title='', figsize=(5, 4)):\n    \"\"\"Visulization of SP and SSM\n\n    Args:\n        SP: Scape plot\n        seg: Segment ``(start_index, end_index)``\n        S: Self-similarity matrix\n        ann: Annotation\n        color_ann: color scheme used for annotations (Default value = [])\n        title: Title of figure (Default value = '')\n        figsize: Figure size (Default value = (5, 4))\n    \"\"\"\n    fig, ax, im = visualize_scape_plot(SP, figsize=figsize, title=title,\n                                       xlabel='Center (frames)', ylabel='Length (frames)')\n    plot_seg_in_sp(ax, seg, S)\n\n    penalty = np.min(S)\n    cmap_penalty = colormap_penalty(penalty=penalty)\n    fig, ax, im = plot_ssm_ann_optimal_path_family(\n        S, ann, seg, color_ann=color_ann, fontsize=8, cmap=cmap_penalty, figsize=(4, 4),\n        ylabel='Time (frames)')\n\n    \n    \ndef check_segment(seg, S):\n    \"\"\"Prints properties of segments with regard to SSM ``S``\n\n    Args:\n        seg (tuple): Segment ``(start_index, end_index)``\n        S (np.ndarray): Self-similarity matrix\n\n    Returns:\n         path_family (list): Optimal path family\n    \"\"\"\n    N = S.shape[0]\n    S_seg = S[:, seg[0]:seg[1]+1]\n    D, score = compute_accumulated_score_matrix(S_seg)\n    path_family = compute_optimal_path_family(D)\n    fitness, score, score_n, coverage, coverage_n, path_family_length = compute_fitness(\n                path_family, score, N)\n    segment_family, coverage2 = compute_induced_segment_family_coverage(path_family)\n    print('Segment (alpha):', seg)\n    print('Length of segment:', seg[-1]-seg[0]+1)\n    print('Length of feature sequence:', N)\n    print('Induced segment path family:\\n', segment_family)\n    print('Fitness: %0.10f' % fitness)\n    print('Score: %0.10f' % score)\n    print('Normalized score: %0.10f' % score_n)\n    print('Coverage: %d, %d' % (coverage, coverage2))\n    print('Normalized coverage: %0.10f' % coverage_n)\n    print('Length of all paths of family: %d' % path_family_length)\n    return path_family\n\n\nfigsize=(5,4)\nSP = SP_all[0]\nseg = seg_max_sp(SP)\nplot_sp_ssm(SP=SP, seg=seg, S=S, ann=ann_frames, color_ann=color_ann, \n            title='Scape plot: Fitness', figsize=figsize)\nplt.show()\npath_family = check_segment(seg, S)\n\n\n\n\n\n\n\nSegment (alpha): [175, 197]\nLength of segment: 23\nLength of feature sequence: 205\nInduced segment path family:\n [[ 41  67]\n [ 68  90]\n [150 175]\n [176 197]]\nFitness: 0.4286698291\nScore: 68.0249475309\nNormalized score: 0.5175281325\nCoverage: 98, 98\nNormalized coverage: 0.3658536585\nLength of all paths of family: 87\n\n\n\n결과의 적합도 scape plot는 계층적 방식으로 음악적 구조를 반영한다.\n썸네일 세그먼트는 \\(\\alpha^\\ast=[175:197]\\)이며 음악적으로 \\(B_4\\) 부분에 해당한다.\nscape plot의 좌표는 중심 \\(c(\\alpha)=186\\) 및 길이 \\(|\\alpha|=23\\)로 지정된다.\n유도된 세그먼트 군은 4개의 \\(B\\) 부분으로 구성된다. 네 개의 \\(B\\) 부분 세그먼트는 모두 거의 동일한 적합성을 가지며 거의 동일한 세그먼트 군으로 이어진다.\n적합도 측정은 짧은 세그먼트를 조금 더 선호한다. 따라서 이 녹음에서 \\(B_4\\)-파트가 \\(B_1\\)-파트보다 빠르게 재생되기 때문에 적합도 측정은 \\(B_1\\)-파트 세그먼트보다 \\(B_4\\)-파트 세그먼트를 선호한다. 즉, 이 절차는 가장 짧은 가장 대표적인 세그먼트를 썸네일로 선택하게 된다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#정규화된-점수와-커버리지",
    "href": "posts/5. Music Structure Analysis/5.3.Audio_Thumbnail.html#정규화된-점수와-커버리지",
    "title": "5.3. 오디오 썸네일",
    "section": "정규화된 점수와 커버리지",
    "text": "정규화된 점수와 커버리지\n\n다음으로 적합도 측정의 정의에서 점수(score)와 커버리지(coverage)의 정규화(normalization)와 두 측정의 조합(조화 평균)이 매우 중요함을 설명한다.\n이를 위해 다양한 척도(및 척도-최대화(measure-maximizing) 세그먼트)의 scape plot를 개별적으로 살펴보자.\n점수 척도 \\(\\sigma\\)를 시작한다. 점수 극대화 구간은 전체 녹음인 \\(\\alpha=[1:N]\\) 이다.\n\n\nSP = SP_all[1]\nseg = seg_max_sp(SP)\nplot_sp_ssm(SP=SP, seg=seg, S=S, ann=ann_frames, color_ann=color_ann, \n            title='Scape plot: Score', figsize=figsize)\npath_family = check_segment(seg, S)\n\nSegment (alpha): [0, 204]\nLength of segment: 205\nLength of feature sequence: 205\nInduced segment path family:\n [[  0 204]]\nFitness: 0.0000000000\nScore: 205.0000000000\nNormalized score: 0.0000000000\nCoverage: 205, 205\nNormalized coverage: 0.0000000000\nLength of all paths of family: 205\n\n\n\n\n\n\n\n\n\n사소한(trivial) 자기-설명을 빼고 최적 경로군의 길이에 대해 정규화하면 정규화 점수 \\(\\bar{\\sigma}\\)가 된다.\n이 척도는 오디오 자료가 실제로 얼마나 커버되는지를 나타내지 않고 경로군의 평균 점수를 나타내므로, 많은 작은 세그먼트가 상대적으로 높은 점수를 얻는다. 이러한 측정을 사용하면 일반적으로 짧은 길이의 false-positive 세그먼트가 생성된다.\n이는 다음과 같은 scape plot와 \\(\\bar{\\sigma}\\)-최대화 경로 군으로도 증명된다.\n\n\nSP = SP_all[2]\nseg = seg_max_sp(SP)\nplot_sp_ssm(SP=SP, seg=seg, S=S, ann=ann_frames, color_ann=color_ann, \n            title='Scape plot: Normalized score', figsize=figsize)\npath_family = check_segment(seg, S)\n\nSegment (alpha): [183, 188]\nLength of segment: 6\nLength of feature sequence: 205\nInduced segment path family:\n [[ 54  61]\n [ 76  81]\n [163 168]\n [183 188]]\nFitness: 0.1680842515\nScore: 20.5560875887\nNormalized score: 0.6065036495\nCoverage: 26, 26\nNormalized coverage: 0.0975609756\nLength of all paths of family: 24\n\n\n\n\n\n\n\n\n\n다음 그림은 커버리지 측정 \\(\\gamma\\)에 대한 scape plot를 보여준다. 악보의 경우 커버리지-최대화 세그먼트는 \\(\\alpha=[1:N]\\)로 전체 녹음이다.\n\n\nSP = SP_all[3]\nseg = seg_max_sp(SP)\nplot_sp_ssm(SP=SP, seg=seg, S=S, ann=ann_frames, color_ann=color_ann, \n            title='Scape plot: Coverage', figsize=figsize)\npath_family = check_segment(seg, S)\n\nSegment (alpha): [91, 204]\nLength of segment: 114\nLength of feature sequence: 205\nInduced segment path family:\n [[  0  92]\n [ 93 204]]\nFitness: 0.1205736958\nScore: 128.2312820570\nNormalized score: 0.0697611866\nCoverage: 205, 205\nNormalized coverage: 0.4439024390\nLength of all paths of family: 204\n\n\n\n\n\n\n\n\n\ntrivial한 자기-설명을 빼고 길이 \\(N\\)에 대해 정규화하면 정규화 커버리지 \\(\\bar{\\gamma}\\)가 된다.\n\\(\\bar{\\gamma}\\)-최대화 세그먼트와 함께 다음 scape plot에서 볼 수 있듯이, 커버리지(coverage)는 점수(score)와는 개념적으로 다른 속성을 측정한다. 정규화된 점수와 달리, 정규화된 커버리지는 일반적으로 입력 시퀀스의 많은 부분을 차지하는 세그먼트군을 유도하는 세그먼트를 선호한다.\n\n\nSP = SP_all[4]\nseg = seg_max_sp(SP)\nplot_sp_ssm(SP=SP, seg=seg, S=S, ann=ann_frames, color_ann=color_ann, \n            title='Scape plot: Normalized coverage', figsize=figsize)\npath_family = check_segment(seg, S)\n\nSegment (alpha): [56, 76]\nLength of segment: 21\nLength of feature sequence: 205\nInduced segment path family:\n [[ 32  55]\n [ 56  76]\n [ 77  94]\n [140 163]\n [164 184]\n [185 204]]\nFitness: 0.3370126389\nScore: 50.3634037795\nNormalized score: 0.2488424049\nCoverage: 128, 128\nNormalized coverage: 0.5219512195\nLength of all paths of family: 118"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html",
    "title": "5.4. 노벨티 기반 분할",
    "section": "",
    "text": "음악 구조 섹션 사이의 전환을 표시할 수 있는 노벨티(novelty) 기반 분할을 소개하며, 노벨티를 감지하는 방법을 알아본다.\n주요 참고자료: Jonathan Foote: Automatic audio segmentation using a measure of audio novelty. Proceedings of the IEEE International Conference on Multimedia and Expo (ICME), New York, NY, USA, 2000, pp. 452–455."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#체커보드-커널-checkerboard-kernel-박스box",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#체커보드-커널-checkerboard-kernel-박스box",
    "title": "5.4. 노벨티 기반 분할",
    "section": "체커보드 커널 (Checkerboard Kernel): 박스(Box)",
    "text": "체커보드 커널 (Checkerboard Kernel): 박스(Box)\n\n\\(X=(x_1,x_2,\\ldots x_N)\\)을 특징 시퀀스라고 하고 \\(\\mathbf{S}\\)를 \\(X\\)에서 파생된 \\(N\\times N\\) 크기의 SSM이라고 하자.\n먼저 두 개의 동질적이지만 대조되는 섹션으로 구성된 오디오 녹음을 고려해 보기로 한다. 시각화하면 SSM 결과는 \\(2\\times 2\\) 체커보드처럼 보인다.\n\n\nipd.Image('../img/5.music_structure_analysis/FMP_C4_F23a-b.png', width= 500)\n\n\n\n\n\n주대각선에 있는 두 개의 어두운 블록은 두 섹션 내에서 유사도가 높은 영역에 해당한다. 대조적으로, 이 블록 외부의 밝은 영역은 섹션 간의 낮은 교차 유사성이 있음을 나타낸다. 따라서 두 부분의 경계를 찾기 위해서는 바둑판의 크럭스를 식별해야 한다.\n이는 \\(\\mathbf{S}\\)를 체커보드처럼 보이는 커널과 연관시켜 수행할 수 있다. 가장 간단한 커널은 다음과 같이 정의된 \\((2\\times 2)\\) 단위 커널이다.\n\n\\[\\mathbf{K} = \\left[\\begin{array}{rr} -1 & 1\\\\ 1 & -1 \\end{array}\\right]\n        = \\left[\\begin{array}{rr} 0 & \\,\\,\\,\\,\\,1\\\\ 1 & 0 \\end{array}\\right] -\n          \\left[\\begin{array}{rr} 1 & \\,\\,\\,\\,\\,0\\\\ 0 & 1 \\end{array}\\right]\\]\n\n이 커널은 “coherence” 커널과 “anti-coherence” 커널의 차이로 쓸 수 있다.\n첫 번째 커널은 중심점 양쪽의 자기 유사성(self-similarity)을 측정하며 두 영역이 각각 동질일 때 높을 것이다.\n두 번째 커널은 두 영역 간의 교차 유사성(cross-similarity)을 측정하며 중심점에서 차이가 거의 없을 때 높을 것이다.\n두 값의 차이는 중심점에서 특징 시퀀스의 새로움/노벨티(novelty) 을 추정한다. 두 영역이 자기-유사하지만 서로 다를 때 노벨티가 높다.\n일반적으로 더 큰 시간 척도의 변화에 관심이 있는 오디오 구조 분석에서는 더 큰 크기의 커널이 사용된다.\n물리적 시간 위치가 윈도우 또는 커널의 중심과 연관되는 중심 보기(centered view)를 채택하면, 어떤 \\(L\\in\\mathbb{N}\\)에 대해 \\(M=2L+1\\)로 주어진 커널의 크기가 홀수라고 가정한다.\n\\(M\\) 크기의 상자 모양(box-like)의 체커보드 커널은 \\([-L:L]\\times[-L:L]\\)로 인덱싱되는 \\((M\\times M)\\) 행렬 \\(\\mathbf{K}_\\mathrm{Box}\\)이다.\n행렬은 다음과 같이 정의된다. \\[\\mathbf{K}_\\mathrm{Box} = \\mathrm{sgn}(k)\\cdot \\mathrm{sgn}(\\ell),\\] \\(k,\\ell\\in[-L:L]\\), “\\(\\mathrm{sgn}\\)”는 부호 함수(\\(-1\\)는 음수, \\(0\\)는 0, \\(1\\)는 양수)\n예를 들어, \\(L=2\\)인 경우 다음과 같다. \\[\\mathbf{K}_\\mathrm{Box} = \\left[\\begin{array}{rrrrr}\n-1 & -1 & \\,\\,\\,\\,\\,0 & 1 & 1 \\\\\n-1 & -1 & 0 &1 & 1 \\\\\n0 &  0  & 0 & 0 &0 \\\\\n1 & 1  & 0 & -1 & -1 \\\\\n1 & 1  & 0 & -1 & -1       \n\\end{array}\\right]\\]\n커널 행렬의 대칭성을 확보하기 위해 이론적인 이유로 중간에 0 행과 0 열을 더 많이 도입한다.\n다음 코드 셀에서는 상자 모양의 바둑판 커널을 구현하고 시각화한다.\n\n\ndef compute_kernel_checkerboard_box(L):\n    \"\"\"Compute box-like checkerboard kernel [FMP, Section 4.4.1]\n\n    Args:\n        L (int): Parameter specifying the kernel size 2*L+1\n\n    Returns:\n        kernel (np.ndarray): Kernel matrix of size (2*L+1) x (2*L+1)\n    \"\"\"\n    axis = np.arange(-L, L+1)\n    kernel = np.outer(np.sign(axis), np.sign(axis))\n    return kernel\n\n\nL = 10\nkernel = compute_kernel_checkerboard_box(L)\nplt.figure(figsize=(4,3))\nplt.imshow(kernel, aspect='auto', origin='lower', \n           extent=[-L-0.5,L+0.5,-L-0.5,L+0.5], cmap='seismic')\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#체커보드-커널-가우시안-gaussian",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#체커보드-커널-가우시안-gaussian",
    "title": "5.4. 노벨티 기반 분할",
    "section": "체커보드 커널: 가우시안 (Gaussian)",
    "text": "체커보드 커널: 가우시안 (Gaussian)\n\n가장자리 효과(edge effect)를 피하기 위해 가장자리에서 0을 향해 점점 가늘어지는 윈도우를 사용하여 바둑판 커널을 부드럽게 할 수 있다.\n이를 위해 다음과 같이 정의된 방사형(radially) 대칭 가우시안(Gaussian) 함수 \\(\\phi:\\mathbb{R}^2\\to \\mathbb{R}\\)를 사용할 수 있다. \\[\\phi(s,t) = \\mathrm{exp}(-\\varepsilon^2(s^2+t^2)),\\] 이때 \\(\\varepsilon>0\\) 매개변수를 사용하면 테이퍼링 정도를 조정할 수 있다.\n그런 다음 행렬 \\(\\mathbf{K}_\\mathrm{Gauss}\\)에 의해 주어진 가우시안 체커보드 커널은 pointwise 곱셈으로 얻는다. \\[\\mathbf{K}_\\mathrm{Gauss}(k,\\ell) = \\phi(k,\\ell) \\cdot \\mathbf{K}_\\mathrm{Box}(k,\\ell),\\] for \\(k,\\ell\\in[-L:L]\\)\n\n\nipd.Image('../img/5.music_structure_analysis/FMP_C4_F23c-d.png',width=500)\n\n\n\n\n\n실제 커널 크기와 테이퍼링의 영향을 보상하기 위해 커널을 정규화할 수 있다.\n커널을 커널 행렬의 절대값 합계로 나누어 할 수 있다. \\[\\mathbf{K}_\\mathrm{norm}(k,\\ell) = \\frac{\\mathbf{K}_\\mathrm{Gauss}(k,\\ell)}{\\sum_{k,\\ell\\in[-L:L]}|\\mathbf{K}_\\mathrm{Gauss}(k,\\ell)|}\\]\n서로 다른 크기의 커널에서 얻은 노벨티 정보를 결합하고 융합할 때 정규화가 중요해진다.\n다음 구현에서 테이퍼 매개변수 \\(\\varepsilon\\)은 분산 \\(\\sigma\\)(커널 크기 \\(M=2L+1\\)에 대해 정규화됨)로 지정된다.\n\n\ndef compute_kernel_checkerboard_gaussian(L, var=1, normalize=True):\n    \"\"\"Compute Guassian-like checkerboard kernel [FMP, Section 4.4.1].\n    See also: https://scipython.com/blog/visualizing-the-bivariate-gaussian-distribution/\n\n    Args:\n        L (int): Parameter specifying the kernel size M=2*L+1\n        var (float): Variance parameter determing the tapering (epsilon) (Default value = 1.0)\n        normalize (bool): Normalize kernel (Default value = True)\n\n    Returns:\n        kernel (np.ndarray): Kernel matrix of size M x M\n    \"\"\"\n    taper = np.sqrt(1/2) / (L * var)\n    axis = np.arange(-L, L+1)\n    gaussian1D = np.exp(-taper**2 * (axis**2))\n    gaussian2D = np.outer(gaussian1D, gaussian1D)\n    kernel_box = np.outer(np.sign(axis), np.sign(axis))\n    kernel = kernel_box * gaussian2D\n    if normalize:\n        kernel = kernel / np.sum(np.abs(kernel))\n    return kernel\n\n\nL = 10\nvar = 0.5\nkernel = compute_kernel_checkerboard_gaussian(L, var)\nplt.figure(figsize=(4,3))\nplt.imshow(kernel, aspect='auto', origin='lower', \n           extent=[-L-0.5,L+0.5,-L-0.5,L+0.5], cmap='seismic')\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#노벨티-함수",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#노벨티-함수",
    "title": "5.4. 노벨티 기반 분할",
    "section": "노벨티 함수",
    "text": "노벨티 함수\n\n인접한 블록 사이의 2D 코너 포인트를 감지하기 위해 SSM을 바둑판 커널과 로컬에서 비교할 수 있다.\n이를 위해 SSM의 주 대각선을 따라 적절한 체커보드 커널 \\(\\mathbf{K}\\)를 슬라이드하고 \\(\\mathbf{K}\\)와 \\(\\mathbf{S}\\)의 요소별 곱을 합산한다. \\[\\Delta_\\mathrm{Kernel}(n) := \\sum_{k,\\ell\\in[-L:L]} \\mathbf{K}(k,\\ell) \\mathbf{S}(n+k,n+\\ell)\\] for \\(n\\in[L+1:N-L]\\)\n제로-패딩으로 경계에서 행렬 \\(\\mathbf{S}\\)을 확장하면(즉, \\((k,\\ell)\\in\\mathbb{Z}\\times\\mathbb{Z} \\setminus [1:N]\\times[1:N]\\)에 대해 \\(\\mathbf{S}(k,\\ell)=0\\) 설정), \\(n\\in[1:N]\\)로 가정할 수 있다.\n이는 \\(\\Delta_\\mathrm{Kernel}:[1:N]\\to\\mathbb{R}\\) 함수를 정의하며, 노벨티 함수라고도 하며, 이는 특징 시퀀스의 각 인덱스 \\(n\\in[1:N]\\)에 대해 새로움의 척도 \\(\\Delta_\\mathrm{Kernel}(n)\\)를 구체화한다.\n\\(\\mathbf{K}\\) 커널이 \\(\\mathbf{S}\\)의 비교적 균일한(uniform) 영역에 위치할 때 그 곱의 양수 값과 음수 값의 합은 0이 되고 \\(\\Delta_\\mathrm{Kernel}( n)\\)이 작아진다.\n반대로 \\(\\mathbf{K}\\) 커널이 \\(\\mathbf{S}\\)의 체커보드와 같은 구조의 꼭지점에 정확히 위치하면 곱의 값은 모두 양수이고 합계는 큰 \\(\\Delta_\\mathrm{Kernel}( n)\\)이 된다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F24_color.png\", width=400)\n\n\n\n\n\ndef compute_novelty_ssm(S, kernel=None, L=10, var=0.5, exclude=False):\n    \"\"\"Compute novelty function from SSM [FMP, Section 4.4.1]\n\n    Args:\n        S (np.ndarray): SSM\n        kernel (np.ndarray): Checkerboard kernel (if kernel==None, it will be computed) (Default value = None)\n        L (int): Parameter specifying the kernel size M=2*L+1 (Default value = 10)\n        var (float): Variance parameter determing the tapering (epsilon) (Default value = 0.5)\n        exclude (bool): Sets the first L and last L values of novelty function to zero (Default value = False)\n\n    Returns:\n        nov (np.ndarray): Novelty function\n    \"\"\"\n    if kernel is None:\n        kernel = compute_kernel_checkerboard_gaussian(L=L, var=var)\n    N = S.shape[0]\n    M = 2*L + 1\n    nov = np.zeros(N)\n    # np.pad does not work with numba/jit\n    S_padded = np.pad(S, L, mode='constant')\n\n    for n in range(N):\n        # Does not work with numba/jit\n        nov[n] = np.sum(S_padded[n:n+M, n:n+M] * kernel)\n    if exclude:\n        right = np.min([L, N])\n        left = np.max([0, N-L])\n        nov[0:right] = 0\n        nov[left:N] = 0\n\n    return nov\n\n\nL_kernel = 20\nnov = compute_novelty_ssm(S, L=L_kernel, exclude=False)   \nfig, ax, line = plot_signal(nov, Fs = Fs_X, color='k')    \n\n\n\n\n\n위는 Brahms 예의 크로마 기반 SSM에 대해 노벨티 곡선을 계산했다.\n우선, 노벨티 함수는 시작과 끝에서 큰 값을 가진다는 것을 알 수 있다. SSM의 제로 패딩으로 인한 이 아티팩트(부산물)는 첫 번째와 마지막 \\(L\\) 프레임에 대해 노벨티 곡선 \\(\\Delta_\\mathrm{Kernel}\\)을 0으로 설정하여 억제할 수 있다.\n다음 그림은 세그먼트 주석(annotation)으로 오버레이된 결과 노벨티 곡선을 보여준다. 그림에서 알 수 있듯이, 노벨티 함수의 local maxima는 하모니의 변화를 잘 나타내고 있으며, 특히 서로 다른 음악적 부분에 해당하는 세그먼트 간의 경계에서 발생한다.\n\n\nL_kernel = 20\nnov = compute_novelty_ssm(S, L=L_kernel, exclude=True)        \nfig, ax, line = plot_signal(nov, Fs = Fs_X, color='k') \nplot_segments_overlay(ann, ax=ax, colors=color_ann, alpha=0.1, edgecolor='k', print_labels=False)\nplt.tight_layout()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#커널-크기-kernel-size",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#커널-크기-kernel-size",
    "title": "5.4. 노벨티 기반 분할",
    "section": "커널 크기 (Kernel Size)",
    "text": "커널 크기 (Kernel Size)\n\n시작하는 SSM의 quality 외에도 커널의 크기는 노벨티 함수의 속성에 중요한 영향을 미친다.\n작은 커널은 짧은 시간 척도에서 새로움을 감지하는 데 적합할 수 있는 반면, 큰 커널은 거친 구조 섹션 간의 경계 및 전환을 감지하는 데 적합하다.\n주어진 커널의 적합성은 각 응용과 기본이 되는 SSM의 속성에 따라 크게 달라진다.\n다음 예는 다른 특징 표현(다른 특징 속도 포함)을 기반으로 다른 크기와 SSM을 사용하는 노벨티 함수를 보여준다. 작은 커널 크기를 사용하면 거짓 피크와 함께 노이즈가 많은 노벨티 함수가 발생할 수 있다. 이것은 기본 SSM이 블록뿐만 아니라 경로와 같은 구조를 포함할 때 특히 그렇다.\n더 큰 커널을 사용하면 로컬 변동을 평균화하고 더 부드러운 노벨티 함수가 생성된다.\nSSM 스무딩(smoothing)으로 유사한 효과를 얻을 수 있으며, 이는 종종 블록 구조의 향상과 경로 구조의 감쇠로 이어진다.\nSSM 속성과 커널 크기 사이의 상호 작용은 다음 그림에 설명되어 있다.\n\n\n\nS_dict = {}\nFs_dict = {}\nx, x_duration, X, Fs_X, S, I = compute_sm_from_filename(fn_wav, \n                                                L=11, H=5, L_smooth=1, thresh=1)\nS_dict[0], Fs_dict[0] = S, Fs_X\nann_frames = convert_structure_annotation(ann, Fs=Fs_X) \nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X,\n            label='Time (frames)', color_ann=color_ann, clim_X=[0,1], clim=[0,1], \n            title='Feature rate: %0.0f Hz'%(Fs_X), figsize=(4.5, 5.5))\n\n\nx, x_duration, X, Fs_X, S, I = compute_sm_from_filename(fn_wav, \n                                                L=41, H=10, L_smooth=1, thresh=1)\nS_dict[1], Fs_dict[1] = S, Fs_X\nann_frames = convert_structure_annotation(ann, Fs=Fs_X) \nfig, ax = plot_feature_ssm(X, 1, S, 1, ann_frames, x_duration*Fs_X,\n            label='Time (frames)', color_ann=color_ann, clim_X=[0,1], clim=[0,1], \n            title='Feature rate: %0.0f Hz'%(Fs_X), figsize=(4.5, 5.5))\n\n\n\n\n\n\n\n\nfigsize=(8,6)\nL_kernel_set = [5, 10, 20, 40]\nnum_kernel = len(L_kernel_set)\nnum_SSM = len(S_dict)\n\nfig, ax = plt.subplots(num_kernel, num_SSM, figsize=figsize)\nfor s in range(num_SSM):\n    for t in range(num_kernel):\n        L_kernel = L_kernel_set[t]\n        S = S_dict[s]\n        nov = compute_novelty_ssm(S, L=L_kernel, exclude=True)        \n        fig_nov, ax_nov, line_nov = plot_signal(nov, Fs = Fs_dict[s], \n                color='k', ax=ax[t,s], figsize=figsize, \n                title='Feature rate = %0.0f Hz, $L_\\mathrm{kernel}$ = %d'%(Fs_dict[s],L_kernel)) \n        plot_segments_overlay(ann, ax=ax_nov, colors=color_ann, alpha=0.1, \n                                       edgecolor='k', print_labels=False)\nplt.tight_layout()\nplt.show()  \n\n\n\n\n\n종종 해당 값이 노벨티 함수의 로컬 평균을 초과할 때만 피크가 선택되는 적응적(adaptive) 임계값 전략이 적용되기도 한다.\n거짓 피크의 수를 더 줄이기 위한 또 다른 전략으로 두 개의 후속 피크 위치 사이의 최소 거리에 제약을 가하는 방법도 있다."
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#시차time-lag-표현",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#시차time-lag-표현",
    "title": "5.4. 노벨티 기반 분할",
    "section": "시차(Time-lag) 표현",
    "text": "시차(Time-lag) 표현\n\n구조 특징을 정의하기 위한 주요 기술 요소인 시차 행렬(time-lag matrix) 의 개념을 소개한다.\n\\(\\mathbf{S}\\)를 특징 시퀀스 \\(X=(x_1,x_2,\\ldots,x_N)\\)에서 파생된 자기 유사성 행렬(SSM)이라고 하자.\n\\(\\alpha_1=[s_1:t_1]\\) 및 \\(\\alpha_2=[s_2:t_2]\\)와 같은 두 개의 반복 세그먼트는 \\((s_1,s_2)\\)에서 시작하여 \\((t_1,t_2)\\)에서 끝나는 \\(\\mathbf{S}\\)의 높은 유사성 경로이다. 또한 두 세그먼트 사이에 상대적인 템포 차이가 없으면 경로는 기본 대각선과 정확히 평행하다.\n\\(\\ell=s_2-s_1\\) 프레임에 해당하는 시차가 지나면 \\(\\alpha_1\\) 세그먼트가 반복된다는 것으로 이 속성을 표현할 수도 있다. 이것은 하나의 시간(time) 축이 지연(lag) 축으로 대체되는 SSM의 시차 표현이라는 개념으로 이어진다.\n표기를 단순화하기 위해 다음에서 프레임이 인덱스 \\(n=0\\)부터 시작하여 인덱싱된다고 가정한다. 따라서 \\(X=(x_0,x_1,\\ldots,x_{N-1})\\)와 자기 유사성 행렬 \\(\\mathbf{S}\\)는 \\([0:N-1]\\times[0 :N-1]\\)으로 인덱싱된다.\n\\(\\mathbf{S}\\)의 시차 표현은 다음과 같이 정의된다. \\[\\mathrm{L}(\\ell,n)=\\mathbf{S}(n+\\ell,n)\\] for \\(n\\in[0:N-1]\\) and \\(\\ell\\in[-n:N-1-n]\\)\n시차 매개변수 \\(\\ell\\)의 범위는 시간 매개변수 \\(n\\)에 따라 달라진다. \\(n+\\ell\\) 합계가 \\([0:N-1]\\) 범위에 있도록 시차 지수를 선택해야 한다. 예를 들어 시간 인덱스 \\(n=0\\)의 경우 \\(\\ell\\in[0:N-1]\\)로만 미래를 볼 수 있지만 시간 인덱스 \\(n=N-1\\)의 경우 \\(\\ell\\in[-N+1:0]\\)로 과거만을 볼 수 있다.\n표기법을 단순화하기 위해 정의를 통해 순환(circular) 시차 표현 \\(\\mathrm{L}^{\\!\\circ}\\)을 도입한다. \\[\\mathrm{L}^{\\!\\circ}(\\ell,n)=\\mathbf{S}\\big( (n+\\ell) \\mod N, n \\big)\\] for \\(n\\in[0:N-1]\\) and \\(\\ell\\in[0:N-1]\\)\n\n\n구현과 예제\n\n이제 음악 형식 \\(A_1B_1A_2B_2B_3A_3\\)에 해당하는 종합적으로 생성된 SSM을 고려하여 정의를 설명해보자\n다음 그림은 입력 SSM \\(\\mathbf{S}\\), 시차 표현 결과 \\(\\mathrm{L}\\) 및 순환 버전 \\(\\mathrm{L}^{\\!\\circ}\\)를 보여준다.\n\\(\\mathrm{L}\\) 표현은 원본 행렬 \\(\\mathbf{S}\\)를 가로축에 평행하게 잘라 얻는다.\n결과적으로 \\(\\mathbf{S}\\)에서 주대각선과 평행한 선은 \\(\\mathrm{L}\\)에서 수평선이 된다. 즉, 대각선 구조가 수평 구조로 변형된다.\n순환 버전에서 \\(\\mathrm{L}\\)에서 사용되는 음의 시차 매개변수 \\(\\ell\\in[-n:-1]\\)는 \\(\\mathrm{L}^{\\!\\circ}\\)에서 \\(\\ell+N\\)로 식별된다.\n이렇게 하면 시차 표현 \\(\\mathrm{L}^{\\!\\circ}\\)는 다시 \\([0:N-1]\\times[0:N-1]\\)로 인덱싱된 행렬이 되며, 행렬 \\(\\mathbf{S}\\)에 대해서도 그렇다.\n\n\nipd.Image('../img/5.music_structure_analysis/FMP_C4_F26.png', width=600)\n\n\n\n\n\ndef compute_time_lag_representation(S, circular=True):\n    \"\"\"Computation of (circular) time-lag representation\n\n    Args:\n        S (np.ndarray): Self-similarity matrix\n        circular (bool): Computes circular version (Default value = True)\n\n    Returns:\n        L (np.ndarray): (Circular) time-lag representation of S\n    \"\"\"\n    N = S.shape[0]\n    if circular:\n        L = np.zeros((N, N))\n        for n in range(N):\n            L[:, n] = np.roll(S[:, n], -n)\n    else:\n        L = np.zeros((2*N-1, N))\n        for n in range(N):\n            L[((N-1)-n):((2*N)-1-n), n] = S[:, n]\n    return L\n\n\nann = [[0, 9, 'A'], [10, 19, 'B'], [20, 29, 'A'], [30, 39, 'B'], [40, 49, 'B'], [50, 59, 'A']]\nS = generate_ssm_from_annotation(ann, score_path=1, score_block=0.3)\nN = S.shape[0]\nL = compute_time_lag_representation(S, circular=False)\nL_circ = compute_time_lag_representation(S, circular=True)\n\nplt.figure(figsize=(5, 5))\n\nax1 = plt.axes([0, 0.6, 0.4, 0.4]) \nax2 = plt.axes([0, 0, 0.4, 0.4])\nax3 = plt.axes([0.6, 0.0, 0.4, 0.8]) \n\nfig, ax, im = plot_matrix(S, ax=[ax1], title='SSM', \n                                   xlabel='Time (frames)', ylabel='Time (frames)', colorbar=None)\n\nfig, ax, im = plot_matrix(L_circ, ax=[ax2], title='Circular time-lag matrix', \n                                   xlabel='Time (frames)', ylabel='Lag (frames)', colorbar=None)\n\nfig, ax, im = plot_matrix(L, ax=[ax3], extent=[0, N-1, -(N-1), N-1], title='Time-lag matrix', \n                                   xlabel='Time (frames)', ylabel='Lag (frames)', colorbar=None)\n\n\n\n\n\n\\(A\\) 파트가 \\(B_1\\) 파트 세그먼트의 길이와 같고 \\(B_2\\) 파트 세그먼트의 길이가 두 배(\\(B_1\\)의 템포의 절반으로 연주됨)인 \\(AB_1B_2\\) 구조의 음악 작품을 보자.\n주 대각선과 평행하지 않은 \\(\\mathbf{S}\\)에서의 경로 구조는 결과 원형 시차 표현 \\(\\mathrm{L}^{\\!\\circ}\\)에서 해석하기 어려워진다.\n\n\nann = [[0, 9, 'A'], [10, 19, 'B'], [20, 39, 'B']]\nS = generate_ssm_from_annotation(ann, score_path=1, score_block=0.3)\nN = S.shape[0]\nL = compute_time_lag_representation(S, circular=False)\nL_circ = compute_time_lag_representation(S, circular=True)\n\nplt.figure(figsize=(5, 2.5))\nax = plt.subplot(121)\nfig, ax, im = plot_matrix(S, ax=[ax], title='SSM', \n                                   xlabel='Time (frames)', ylabel='Time (frames)', colorbar=None)\nax = plt.subplot(122)\nfig, ax, im = plot_matrix(L_circ, ax=[ax], title='Circular time-lag matrix', \n                                   xlabel='Time (frames)', ylabel='Lag (frames)', colorbar=None)\nplt.tight_layout()"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#구조-특징과-노벨티-함수",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#구조-특징과-노벨티-함수",
    "title": "5.4. 노벨티 기반 분할",
    "section": "구조 특징과 노벨티 함수",
    "text": "구조 특징과 노벨티 함수\n\n다음에서 \\(\\mathbf{S}^{[n]}\\)는 주어진 시간 프레임 \\(n\\in[0:N-1]\\)에 대해 \\(\\mathbf{S}\\)의 \\(n^{\\mathrm{th}}\\) 열을 나타낸다.\n\\(\\mathbf{S}^{[n]}\\in\\mathbb{R}^N\\) 벡터는 \\(n\\) 시간 프레임에 존재하는 관계의 종류를 나타낸다. \\(\\mathbf{S}^{[n]}(m)\\) (for \\(m\\in[0:N-1]\\))가 큰 경우, \\(n\\) 시간 프레임은 \\(m\\) 시간 프레임과 관련된다. 값이 작은 경우, 두 프레임은 관련이 없다.\n즉, \\(\\mathbf{S}^{[n]}\\)는 프레임 \\(n\\)의 전역적인 구조 관계를 드러낸다.\n시차 행렬 \\({\\mathrm{L}^{\\!\\circ}}^{[n]}\\)의 \\(n^{\\mathrm{th}}\\) 열에 대해서도 동일한 해석이 적용된다.\n그러나 \\(\\mathbf{S}\\)와 \\(\\mathrm{L}^{\\!\\circ}\\) 사이에는 결정적인 차이가 있다. 연속되는 두 프레임 \\(n\\)과 \\(n+1\\)이 동일한 구조적 속성을 갖는 경우, 두 벡터 \\(\\mathbf{S}^{[n]}\\)와 \\(\\mathbf{S}^{[n+ 1]}\\)는 서로 순환 이동(cyclically shifted) 버전인 반면, 두 벡터 \\({\\mathrm{L}^{\\!\\circ}}^{[n]}\\) 및 \\({\\mathrm{L} ^{\\!\\circ}}^{[n+1]}\\)는 동일(identical) 하다.\n이 관찰을 기반으로 구조 특징(structure feature) 을 \\(y_n:={\\mathrm{L}^{\\!\\circ}}^{[n]}\\in\\mathbb{R}^N\\) for \\(\\mathrm{L}^{\\!\\circ}\\), \\(n\\in[0:N-1]\\) 열로 정의한다.\n이 과정을 통해 지역적(음향, 음악적) 특성을 포착한 \\(x_n\\)의 원래 시퀀스 \\(X=(x_0,x_1,\\ldots,x_{N-1})\\)를 전역(구조) 특성을 캡처하는 피처 \\(y_n\\)의 시퀀스 \\(Y=(y_0,y_1,\\ldots,y_{N-1})\\)로 변환했다. 결과적으로 전역 구조 부분의 경계는 특징 시퀀스 \\(Y\\)의 지역적 변화를 찾아 식별할 수 있다.\n이러한 지역적 변화를 포착하는 방법에는 여러 가지가 있다. 간단한 전략은 적절한 거리 함수를 기반으로 연속 구조 특징 간의 차이를 계산하는 것이다. 예를 들어 \\(\\mathbb{R}^N\\)의 유클리드 norm을 사용하면 노벨티 함수를 얻는다. \\[\\Delta_\\mathrm{Structure}(n) := \\| y_{n+1}-y_n \\|= \\|{\\mathrm{L}^{\\!\\circ}}^{[n+1]}-{\\mathrm{L}^{\\!\\circ}}^{[n]}\\|\\] for \\(n\\in[0:N-2]\\).\n다시 제로 패딩으로 \\(n\\in[0:N-1]\\)를 가정할 수 있다. 이 함수의 로컬 최대값 또는 피크의 위치는 구조적 경계에 대한 후보를 선정한다.\n전체 절차는 원래 시퀀스 \\(X\\)에 사용된 특징 유형 또는 \\(\\mathbf{S}\\)가 계산되는 방식을 포함하여 많은 설계 선택 및 매개변수 설정에 따라 달라진다.\n또한 실제로는 더 많은 관련 도함수 연산자를 사용하고 적절한 전처리 단계(예: 행렬 \\(\\mathrm{L}^{\\!\\circ}\\) 추가 향상) 및 후처리 단계(예: novelty 함수 \\(\\Delta_\\mathrm{Structure}\\) 정규화)를 적용하는 경우가 많다.\n마지막으로 피크 선택 전략은 최종 결과에 결정적인 영향을 미칠 수 있다.\n\n\n구현과 예제\n\n다음 코드 셀에서는 구조 특징을 기반으로 novelty 함수를 계산한다. 위에서 소개한 합성 예제 \\(A_1B_1A_2B_2B_3A_3\\)에 대한 결과를 표시한다.\n이 예에서 생성되는 novelty 함수의 피크 위치는 경로 구성 요소의 (조인트) 시작 및 끝 위치와 일치하며, 이는 차례로 음악 섹션의 경계와 일치한다.\n\n\ndef novelty_structure_feature(L, padding=True):\n    \"\"\"Computation of the novelty function from a circular time-lag representation\n\n    Args:\n        L (np.ndarray): Circular time-lag representation\n        padding (bool): Padding the result with the value zero (Default value = True)\n\n    Returns:\n        nov (np.ndarray): Novelty function\n    \"\"\"\n    N = L.shape[0]\n    if padding:\n        nov = np.zeros(N)\n    else:\n        nov = np.zeros(N-1)\n    for n in range(N-1):\n        nov[n] = np.linalg.norm(L[:, n+1] - L[:, n])\n    return nov\n\n\ndef plot_ssm_structure_feature_nov(S, L, nov, Fs=1, figsize=(10, 3), ann=[], color_ann=[]):\n    \"\"\"Plotting an SSM, structure features, and a novelty function\n\n    Args:\n        S: SSM\n        L: Circular time-lag representation\n        nov: Novelty function\n        Fs: Feature rate (indicated in title of SSM) (Default value = 1)\n        figsize: Figure size (Default value = (10, 3))\n        ann: Annotations (Default value = [])\n        color_ann: Colors used for annotations (see :func:`libfmp.b.b_plot.plot_segments`) (Default value = [])\n\n    Returns:\n        ax1: First subplot\n        ax2: Second subplot\n        ax3: Third subplot\n    \"\"\"\n    plt.figure(figsize=figsize)\n    ax1 = plt.subplot(131)\n    if Fs == 1:\n        title = 'SSM'\n    else:\n        title = 'SSM (Fs = %d)' % Fs\n    fig_im, ax_im, im = plot_matrix(S, ax=[ax1], title=title,\n                                             xlabel='Time (frames)', ylabel='Time (frames)')\n    if ann:\n        plot_segments_overlay(ann, ax=ax_im[0], edgecolor='k',\n                                       print_labels=False, colors=color_ann, alpha=0.05)\n\n    ax2 = plt.subplot(132)\n    fig_im, ax_im, im = plot_matrix(L, ax=[ax2], title='Structure features',\n                                             xlabel='Time (frames)', ylabel='Lag (frames)', colorbar=True)\n    if ann:\n        plot_segments_overlay(ann, ax=ax_im[0], edgecolor='k', ylim=False,\n                                       print_labels=False, colors=color_ann, alpha=0.05)\n\n    ax3 = plt.subplot(133)\n    fig, ax, im = plot_signal(nov, ax=ax3, title='Novelty function',\n                                       xlabel='Time (frames)', color='k')\n    if ann:\n        plot_segments_overlay(ann, ax=ax, edgecolor='k', colors=color_ann, alpha=0.05)\n    plt.tight_layout()\n    return ax1, ax2, ax3\n\n\ncolor_ann = {'A': [1, 0, 0, 0.2], 'B': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0.2]}\nann = [[0, 9, 'A'], [10, 19, 'B'], [20, 29, 'A'], [30, 39, 'B'], [40, 49, 'B'], [50, 59, 'A']]\nS = generate_ssm_from_annotation(ann, score_path=1, score_block=0)\nL = compute_time_lag_representation(S, circular=True)\nnov = novelty_structure_feature(L)\nax = plot_ssm_structure_feature_nov(S, L, nov, ann=ann, color_ann=color_ann)\n\n\n\n\n\n구조 특징은 두 가지 이유로 이 예에서 특히 잘 작동한다.\n\n첫째, 반복되는 부분이 많아 경로 구조가 풍부하다.\n둘째, 두 개의 반복되는 음악 부분이 서로 다른 순으로 발생하여, 구조 특징에 잘 포착되는 특성적인 경로 단절이 발생한다.\n\n즉, \\(A_1A_2A_3A_4\\) 또는 \\(A_1B_1A_2B_2\\)의 음악적 구조를 가진 작품에서는 구조 기반 참신성 감지가 작동하지 않지만 \\(A_1B_1A_2A_3\\) 또는 \\(A_1A_2B_1B_2\\)의 음악적 구조를 가진 작품에서는 잘 작동한다.\n다음 그림으로 그 사실을 볼 수 있다.\n\n\ncolor_ann = {'A': [1, 0, 0, 0.2], 'B': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0.2]}\nfigsize = (8,2.5)\n\nann_set = [[[0, 9, 'A'], [10, 19, 'A'], [20, 29, 'A'], [30, 39, 'A']],\n       [[0, 9, 'A'], [10, 19, 'B'], [20, 29, 'A'], [30, 39, 'B']],\n       [[0, 9, 'A'], [10, 19, 'B'], [20, 29, 'A'], [30, 39, 'A']],\n       [[0, 9, 'A'], [10, 19, 'A'], [20, 29, 'B'], [30, 39, 'B']]]\n\nfor ann in ann_set:\n    S = generate_ssm_from_annotation(ann, score_path=1, score_block=0)\n    L = compute_time_lag_representation(S, circular=True)\n    nov = novelty_structure_feature(L)\n    ax = plot_ssm_structure_feature_nov(S, L, nov, figsize=figsize, ann=ann, color_ann=color_ann)"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#example-chopin",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#example-chopin",
    "title": "5.4. 노벨티 기반 분할",
    "section": "Example: Chopin",
    "text": "Example: Chopin\n\n구조-기반 노벨티 감지(novelty detection)의 전체적인 과정을 설명하기 위해 쇼팽의 Prelude Op.28, No. 11 (구조 \\(A_1A_2BA_3A_4CD\\))를 보자.\n다음 그림은 크로마-기반의 특징 표현으로부터 계산된 (경로-향상과 임계값-설정된) SSM이다.\n또한, 그림은 시차(time-lag) 행렬 \\(\\mathrm{L}^{\\!\\circ}\\)과 참신성 함수 \\(\\Delta_\\mathrm{Structure}\\)를 보여준다.\n녹음과 세그먼트가 짧기 때문에, 상대적으로 높은 피쳐 레이트를 사용한다.\n\n\nfn_wav = '../data_FMP/FMP_C4_Audio_Chopin_Op028-11_003_20100611-SMD.wav'\nfn_ann = '../data_FMP/FMP_C4_Audio_Chopin_Op028-11_003_20100611-SMD.csv'\nx, x_duration, X, Fs_feature, S, I = compute_sm_from_filename(fn_wav, L=9, H=2, L_smooth=11, thresh= 0.1)\n\nann_frames, color_ann = read_structure_annotation(fn_ann, Fs=Fs_feature, remove_digits=True, index=True)\ncolor_ann = {'A': [1, 0, 0, 0.2], 'B': [0, 1, 0, 0.2], 'C': [0, 0, 1, 0.2], '': [1, 1, 1, 0.2]}\n\nL = compute_time_lag_representation(S, circular=True)\nnov = novelty_structure_feature(L)\nax = plot_ssm_structure_feature_nov(S, L, nov, Fs=Fs_feature, ann=ann_frames, color_ann=color_ann)\n\n\n\n\n\n하지만 노벨티 곡선이 상당히 노이즈해 보인다. 세그먼트 경계 중 일부(예: \\(A_2\\)에서 \\(B\\) 또는 \\(A_4\\)에서 \\(C\\))만 피크 위치로 잘 표시된다.\n최종 결과에 상당한 영향을 미칠 수 있는 많은 매개 변수(예: 특징 표현 또는 시간적 해상도)가 있다.\n이 예에서 \\(\\mathrm{L}^{\\!\\circ}\\)로 정의된 구조 특징은 잡음이 많고, 최종 참신성 함수를 손상시키는 많은 작은 조각을 포함하고 있다.\n이러한 이상값을 제거하고 노이즈를 억제하는 좋은 방법은 가로 방향으로 중앙값 필터를 적용하는 것이다. 또한, 참신함 계산의 미분을 작은 편차에 덜 취약하게 만들기 위해 가우시안 커널과 함께 컨볼루션(convolution) 을 적용하여 시차 행렬을 더 매끄럽게 할 수 있다.\n이 두 가지 후처리 전략의 효과는 다음 그림에 설명되어 있다.\n\n\nprint('Application of median filter')\nL_filter = ndimage.median_filter(L, (3,11))\nnov = novelty_structure_feature(L_filter)\nax = plot_ssm_structure_feature_nov(S, L_filter, nov, ann=ann_frames, color_ann=color_ann)\nplt.show()\n\nprint('Application of convolution filter')\nL_filter = ndimage.gaussian_filter(L_filter, 4)\nnov = novelty_structure_feature(L_filter)\nax = plot_ssm_structure_feature_nov(S, L_filter, nov, ann=ann_frames, color_ann=color_ann)\n\nApplication of median filter\n\n\n\n\n\nApplication of convolution filter"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#example-brahms",
    "href": "posts/5. Music Structure Analysis/5.4.Novelty-Based_Segmentation.html#example-brahms",
    "title": "5.4. 노벨티 기반 분할",
    "section": "Example: Brahms",
    "text": "Example: Brahms\n\n다음으로 브람스의 헝가리 무곡 예(\\(A_1A_2B_1B_2CA_3B_3B_4D\\))도 적용해보자.\nB파트 세그먼트 사이의 상대적 템포 차이 때문에, 시차 표현을 쓰는 것에 문제가 생기는 것을 볼 수 있다.\n\n\nfn_wav = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.wav'\nfn_ann = '../data_FMP/FMP_C4_Audio_Brahms_HungarianDances-05_Ormandy.csv'\n\ntempo_rel_set = np.array([0.8, 1, 1.25])\nx, x_duration, X, Fs_feature, S, I = compute_sm_from_filename(fn_wav, L=21, H=5, \n                                    L_smooth=11, tempo_rel_set=tempo_rel_set, thresh= 0.1)\n\nann_frames, color_ann = read_structure_annotation(fn_ann, Fs=Fs_feature, remove_digits=True, index=True)\n\nL = compute_time_lag_representation(S, circular=True)\nnov = novelty_structure_feature(L)\nax = plot_ssm_structure_feature_nov(S, L, nov, Fs=Fs_feature, ann=ann_frames, color_ann=color_ann)\n\n\n\n\n\n노벨티 함수의 문제는 입력 SSM에서 이미 볼 수 있는 잡음이 많은 경로 관계 때문이며, 또한 상대적인 템포 차이로 인한 비대각선 경로 구조 때문이기도 하다.\n다시 말하지만, 노벨티 함수를 계산하기 전에 일부 후처리(중앙값 필터링, 가우시안 커널과의 컨볼루션)를 적용하면 일부 문제가 완화된다.\n\n\nL_filter = ndimage.median_filter(L, (3,21))\nL_filter = ndimage.gaussian_filter(L_filter, 6)\nnov = novelty_structure_feature(L_filter)\nax = plot_ssm_structure_feature_nov(S, L_filter, nov, Fs=Fs_feature, ann=ann_frames, color_ann=color_ann)\n\n\n\n\n\n입력된 SSM의 품질은 의미 있는 노벨티를 얻기 위해 매우 중요하다. 스무딩 기술(중앙값, 컨볼루션)을 적용하여 시차 행렬을 후처리하는 것은 전체 절차의 견고성을 높이는 중요한 단계이다.\n음악적으로 정보를 얻은 방식(예: 세그먼트의 예상 최소 길이, 음악 녹음 기간)으로 절차의 매개변수(예: 기능 해상도, SSM 매개변수, SSM 임계값, 필터 매개변수)를 조정하면 최종 결과를 크게 향상시킬 수 있다.\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C4/C4S4_NoveltySegmentation.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C4/C4S4_StructureFeature.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/5. Music Structure Analysis/5.5.Evaluation.html",
    "href": "posts/5. Music Structure Analysis/5.5.Evaluation.html",
    "title": "5.5. 음악 처리의 평가 방법",
    "section": "",
    "text": "음악 구조에 대한 처리(예: 분할)가 얼마나 잘 되었는지를 평가하는 방법에 대해 알아본다.\n\n이 글은 FMP(Fundamentals of Music Processing) Notebooks을 참고로 합니다.\n\n\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport IPython.display as ipd\n\nfrom utils.plot_tools import plot_segments\n\n\n주어진 음악 녹음에서 구조적인 정보를 추출하는 다양한 절차를 설명한 바 있다. 그러나 주어진 절차가 당면한 작업을 얼마나 잘 수행하는지 측정하는 문제에 대해서는 아직 논의한 바가 없다.\n음악 처리 알고리즘을 (자동으로)평가하는 문제는 구조 분석을 넘어서 그 자체로도 중요한 작업이다. 일반적인 평가 방식은 자동화된 절차로 얻은 추정 결과(estimated result) 를 일부 참조 결과(reference result) 와 비교하는 것이다. 이러한 일반적인 접근 방식을 구현하려면 다음 질문에 대한 답을 찾아야 한다.\n\n주어진 분석 결과는 실제로 어떻게 모델링되는가?\n추정 결과를 참조 결과와 어떻게 비교해야 하는가?\n참조 결과는 어떻게 구했으며 신뢰할 수 있는가?\n\n특히 마지막 질문은 음악적 서술의 본질과 의미에 대한 철학적 고찰로 쉽게 이어진다. 예를 들어, 음악 구조 분석은 실제 음악 녹음에서 발생하는 음악적 및 음향적 변화 뿐만 아니라 다양한 요인에 의존하는 어려운 문제이다.\n분석 결과는 음악적 맥락과 고려되는 시간적 수준에 크게 좌우되기 때문에 두 명의 전문가가 있다고 하더라도 주어진 음악에 대한 분석에 서로 동의하지 않을 수 있다. 브람스 예의 경우, 한 전문가는 음악적 구조 \\(A_1A_2B_1B_2CA_3B_3B_4D\\)가 되는 더 큰 규모의 구조에 주석을 달고, 다른 전문가는 부분이 더 세분화된 더 작은 규모를 고려할 수 있다.\n다음 코드 셀에서는 세 가지 다른 축척에 대한 주석(annotation)의 예를 제공한다.\n\n\nann_Brahms = {}\nann_Brahms[0] = [[0, 16, 'G major'], [16, 28, 'G minor'], [28, 40, 'G major']]\n\nann_Brahms[1] = [[0, 4, 'A'], [4, 8, 'A'],  [8, 12, 'B'], [12, 16, 'B'],\n                [16, 27, 'C'], [27, 32, 'A'], [32, 36, 'B'], [36, 39, 'B'], [39, 40, '']]\n\nann_Brahms[2] = [[0, 2, 'a'], [2, 4, 'a'], [4, 6, 'a'], [6, 8, 'a'],\n                [8, 10, 'b'], [10, 12, 'c'], [12, 13, 'b'], [13, 15, 'c'],\n                [15, 18, 'd'], [18, 20, 'd'], \n                [20, 22, 'e'], [22, 24, 'e'], [24, 26, 'e'], [26, 28, 'e'],\n                [28, 30, 'a'], [30, 32, 'a'], \n                [32,34, 'b'], [34, 36, 'c'], [36, 37, 'b'], [37, 39, 'c'], [39, 40, '']]\n\ncolor_ann_Brahms = {'G major': [1, 0.8, 0, 0.3], 'G minor': [0, 0, 1, 0.3],\n    'A': [1, 0, 0, 0.3], 'B': [0, 1, 0, 0.3], 'C': [0, 0, 1, 0.3], '': [1, 1, 1, 0.3],\n    'a': [1, 0, 0, 0.3], 'b': [0, 1, 0, 0.2], 'c': [0.3, 0.5, 0, 0.6], \n    'd': [0, 0, 1, 0.2], 'e': [0.2, 0, 0.5, 0.6],  '': [1, 1, 1, 1]}                    \n\nfigsize = (6,1)\nfor k in range(3):\n    plot_segments(ann_Brahms[k], figsize = figsize, colors=color_ann_Brahms); \n\n\n\n\n\n\n\n\n\n\n\n실제로 단순하고 때로는 문제가 있는 가정이지만, 일반적으로 전문가에 의해 유효한 참조 주석(annotation) 하나가 주어졌다고 가정한다. 이러한 주석은 종종 “ground truth”라고 한다. 자동화 절차의 목적은 가능한 이러한 참조에 가까운 주석을 추정하는 것이다.\n\n\nPrecision, Recall, F-Measure\n\n많은 평가 지표들이 precision(정밀도), recall(재현율), 그리고 F-measure에 기반한다.\n우선 \\(\\mathcal{I}\\)를 아이템(items)이라고 하는 유한 집합이라고 하자.\n\n각 아이템 \\(i\\in \\mathcal{I}\\)은 라벨 ‘\\(+\\)’ (positive or relevant) 혹은 라벨 ‘\\(-\\)’ (negative or not relevant)로 지정된다.\n\n\\(\\mathcal{I}^\\mathrm{Ref}_+\\)를 양의 아이템, \\(\\mathcal{I}^\\mathrm{Ref}_-\\)를 음의 아이템의 집합이라고 하자.\n\\(\\mathcal{I}^\\mathrm{Est}_+\\)를 양으로 추정된 아이템, \\(\\mathcal{I}^\\mathrm{Est}_-\\)를 음으로 추정된 아이템의 집합이라고 하자.\n\\(i\\in\\mathcal{I}^\\mathrm{Est}_+\\cap\\mathcal{I}^\\mathrm{Ref}_+\\) 이면 true positive (TP)\n\\(i\\in\\mathcal{I}^\\mathrm{Est}_+\\cap\\mathcal{I}^\\mathrm{Ref}_-\\) 이면 false positive (FP)\n\\(i\\in\\mathcal{I}^\\mathrm{Est}_-\\cap\\mathcal{I}^\\mathrm{Ref}_+\\) 이면 false negative (FN)\n\\(i\\in\\mathcal{I}^\\mathrm{Est}_-\\cap\\mathcal{I}^\\mathrm{Ref}_-\\) 이면 true negative (TN)\nprecision \\(\\mathrm{P}\\)은 true positives의 수를 positive로 추정한 모든 아이템으로 나눈 것이다:\n\n\\[\\mathrm{P} = \\frac{|\\mathcal{I}^\\mathrm{Est}_+\\cap\\mathcal{I}^\\mathrm{Ref}_+|}{|\\mathcal{I}^\\mathrm{Est}_+|} = \\frac{\\#\\mathrm{TP}}{\\#\\mathrm{TP}+\\#\\mathrm{FP}}\\]\n\nrecall \\(\\mathrm{R}\\)은 true positives의 수를 전체 positive 아이템으로 나눈 것이다: \\[\\mathrm{R} = \\frac{|\\mathcal{I}^\\mathrm{Est}_+\\cap\\mathcal{I}^\\mathrm{Ref}_+|}{|\\mathcal{I}^\\mathrm{Ref}_+|} = \\frac{\\#\\mathrm{TP}}{\\#\\mathrm{TP}+\\#\\mathrm{FN}}\\]\nprecision과 recall 모두 \\([0,1]\\)에 있다.\n\\(\\mathrm{P}=1\\)는 양으로 추정한 모든 아이템이 실제로 양인 경우이며, 이 경우 false positive가 없으나 false negative는 있을 수 있다.\n\\(\\mathrm{R}=1\\)는 모든 양의 아이템이 양으로 추정되었음을 의미하며, 이 경우 false negative가 없으나 false positive는 있을 수 있다.\n\\(\\mathrm{P}=1\\)이면서 \\(\\mathrm{R}=1\\)일 때만 추정 주석과 참조 주석이 일치하는 경우이다.\nPrecision과 recall은 종종 F-measure라고 하는 단일 측정값을 형성하기 위해 조화 평균을 사용하여 결합된다.\n\n\\[\\mathrm{F} = \\frac{2\\cdot \\mathrm{P}\\cdot \\mathrm{R}}{\\mathrm{P} + \\mathrm{R}}\\]\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F29.png\",width=500)\n\n\n\n\n\ndef measure_prf(num_TP, num_FN, num_FP):\n    \"\"\"Compute P, R, and F from size of TP, FN, and FP [FMP, Section 4.5.1]\n\n    Args:\n        num_TP (int): True positives\n        num_FN (int): False negative\n        num_FP (int): False positives\n\n    Returns:\n        P (float): Precision\n        R (float): Recall\n        F (float): F-measure\n    \"\"\"\n    P = num_TP / (num_TP + num_FP)\n    R = num_TP / (num_TP + num_FN)\n    if (P + R) > 0:\n        F = 2 * P * R / (P + R)\n    else:\n        F = 0\n    return P, R, F\n    \n\ndef measure_prf_sets(I, I_ref_pos, I_est_pos, details=False):\n    \"\"\"Compute P, R, and F from sets I, I_ref_pos, I_est_pos [FMP, Section 4.5.1]\n\n    Args:\n        I: Set of items\n        I_ref_pos: Reference set of positive items\n        I_est_pos: Set of items being estimated as positive\n        details: Print details (Default value = False)\n\n    Returns:\n        P (float): Precision\n        R (float): Recall\n        F (float): F-measure\n    \"\"\"\n    I_ref_neg = I.difference(I_ref_pos)\n    I_est_neg = I.difference(I_est_pos)\n    TP = I_est_pos.intersection(I_ref_pos)\n    FN = I_est_neg.intersection(I_ref_pos)\n    FP = I_est_pos.intersection(I_ref_neg)\n    P, R, F = measure_prf(len(TP), len(FN), len(FP))\n    if details:\n        print('TP = ', TP, ';  FN = ', FN, ';  FP = ', FP)\n        print('P = %0.3f;  R = %0.3f;  F = %0.3f' % (P, R, F))\n    return P, R, F\n\n\n\n라벨링 평가 (Labeling Evaluation)\n\n프레임 수준의 음악 분석 작업을 고려해보자.\n\\(\\varphi:[1:N]\\)를 프레임으로 주어진 시간 축으로 하고 \\(\\Lambda\\)를 가능한 레이블 집합이라고 하자.\n레이블 함수(label function) 는 각 프레임 인덱스 \\(n\\in[1:N]\\)에 레이블 \\(\\varphi(n)\\in\\Lambda\\)를 할당하는 함수 \\(\\varphi:[1:N] \\to \\Lambda\\)로 정의한다.\n이제 pair-wise precision, pair-wise recall 및 pair-wise F-measure라고 하는 몇 가지 프레임 기반 평가 측정값을 소개한다.\n\\(\\varphi^\\mathrm{Ref}\\) 및 \\(\\varphi^\\mathrm{Est}\\)를 각각 참조 및 추정 구조 주석에 대한 레이블 함수로 둔다.\n실제 레이블 네이밍에서 독립적이기 위해서는, 레이블을 직접 보지 않고 레이블 동시 발생을 찾는 것이 주요 아이디어다.\n이를 위해 동일한 레이블에 할당된 프레임 쌍(pair)을 고려한다.\n\n\\[\\mathcal{I}=\\{(n,m)\\in[1:N]\\times[1:N]\\mid m<n\\},\\]\n\n참조 및 추정 주석에 대해 양의 아이템을 다음과 같이 정의한다. \\[\\mathcal{I}^\\mathrm{Ref}_+=\\{(n,m)\\in\\mathcal{I}\\mid \\varphi^\\mathrm{Ref}(n)=\\varphi^\\mathrm{Ref}(m)\\},\\\\\n\\mathcal{I}^\\mathrm{Est}_+=\\{(n,m)\\in\\mathcal{I}\\mid \\varphi^\\mathrm{Est}(n)=\\varphi^\\mathrm{Est}(m)\\},\\] whereas \\(\\mathcal{I}^\\mathrm{Ref}_-=\\mathcal{I}\\setminus\\mathcal{I}^\\mathrm{Ref}_+\\) and \\(\\mathcal{I}^\\mathrm{Est}_-=\\mathcal{I}\\setminus\\mathcal{I}^\\mathrm{Est}_+\\)\n즉, \\((n,m)\\) 항목은 프레임 \\(n\\)과 \\(m\\)이 동일한 레이블을 갖는 경우 주석에 대해 양(positive) 으로 간주된다.\n이제 pairwise precision는 이 이진 분류 체계의 precision으로 정의된다. 유사하게 pairwise recall와 pairwise F-measure은 위의 체계의 recall 및 F-measure이다.\n다음 두 예에서 샘플링된 시간 간격은 \\(N=10\\) 샘플로 구성된다.\n\n\ndef convert_ann_to_seq_label(ann):\n    \"\"\"Convert structure annotation with integer time positions (given in indices)\n    into label sequence\n\n    Args:\n        ann (list): Annotation (list ``[[s, t, 'label'], ...]``, with ``s``, ``t`` being integers)\n\n    Returns:\n        X (list): Sequencs of labels\n    \"\"\"\n    X = []\n    for seg in ann:\n        K = seg[1] - seg[0]\n        for k in range(K):\n            X.append(seg[2])\n    return X\n\n    \ndef plot_seq_label(ax, X, Fs=1, color_label=[], direction='horizontal',\n                   fontsize=10, time_axis=False, print_labels=True):\n    \"\"\"Plot label sequence in the style of annotations\n\n    Args:\n        ax: Axis used for plotting\n        X: Label sequence\n        Fs: Sampling rate (Default value = 1)\n        color_label: List of colors for labels (Default value = [])\n        direction: Parameter used for :func:`libfmp.b.b_plot.plot_segments` (Default value = 'horizontal')\n        fontsize: Parameter used for :func:`libfmp.b.b_plot.plot_segments` (Default value = 10)\n        time_axis: Parameter used for :func:`libfmp.b.b_plot.plot_segments` (Default value = False)\n        print_labels: Parameter used for :func:`libfmp.b.b_plot.plot_segments` (Default value = True)\n\n    Returns:\n         ann_X: Structure annotation for label sequence\n    \"\"\"\n    ann_X = []\n    for m, cur_x in enumerate(X):\n        ann_X.append([(m-0.5)/Fs, (m+0.5)/Fs, cur_x])\n    plot_segments(ann_X, ax=ax, time_axis=time_axis, fontsize=fontsize,\n                           direction=direction, colors=color_label, print_labels=print_labels)\n    return ann_X\n\n\ncolor_label = {'A': [1, 0, 0, 0.2], 'B': [0, 0, 1, 0.2], 'C': [0, 1, 0, 0.2],\n             'X': [1, 0, 0, 0.2], 'Y': [0, 0, 1, 0.2], 'Z': [0, 1, 0, 0.2]}\n\nann_ref = [[0, 4, 'A'], [4, 7, 'B'], [7, 10, 'A']]\nann_est = [[0, 1, 'X'], [1, 3, 'Y'], [3, 7, 'Z'], [7, 9, 'Y'], [9, 10, 'X']]\n\nX_ref = convert_ann_to_seq_label(ann_ref)\nX_est = convert_ann_to_seq_label(ann_est)\n\nprint('Segment-based structure annotation:')\nplt.figure(figsize=(5,2))\nax = plt.subplot(211)\nplot_segments(ann_ref, ax=ax, colors=color_label); \n#ax.set_xticks([])\nax = plt.subplot(212)\nplot_segments(ann_est, ax=ax, colors=color_label); \n#ax.set_xticks([])\nplt.tight_layout()\nplt.show()\n\nprint('Frame-based label sequence:')\nplt.figure(figsize=(5,2))\nax = plt.subplot(211)\nplot_seq_label(ax, X_ref, color_label=color_label, time_axis=True);\nax = plt.subplot(212)\nplot_seq_label(ax, X_est, color_label=color_label, time_axis=True);\nplt.tight_layout()\n\nSegment-based structure annotation:\n\n\n\n\n\nFrame-based label sequence:\n\n\n\n\n\n\n첫 번째 시퀀스를 참조 \\(\\varphi^\\mathrm{Est}\\)로 사용하고, 두 번째 시퀀스를 추정 \\(\\varphi^\\mathrm{Est}\\)로 사용하여 이제 pairwise precision, recall, F-measure를 설명한다.\n특히 참조 및 추정 주석의 양의 항목(회색 항목으로 표시)을 표시한다. 또한 true positive (TP), false negative (FN), false positive (FP) 항목을 시각화한다.\n\n\ndef compare_pairwise(X):\n    \"\"\"Compute set of positive items from label sequence [FMP, Section 4.5.3]\n\n    Args:\n        X (list or np.ndarray): Label sequence\n\n    Returns:\n        I_pos (np.ndarray): Set of positive items\n    \"\"\"\n    N = len(X)\n    I_pos = np.zeros((N, N))\n    for n in range(1, N):\n        for m in range(n):\n            if X[n] is X[m]:\n                I_pos[n, m] = 1\n    return I_pos\n\n\ndef evaluate_pairwise(I_ref_pos, I_est_pos):\n    \"\"\"Compute pairwise evaluation measures [FMP, Section 4.5.3]\n\n    Args:\n        I_ref_pos (np.ndarray): Referenence set of positive items\n        I_est_pos (np.ndarray): Set of items being estimated as positive\n\n    Returns:\n        P (float): Precision\n        R (float): Recall\n        F (float): F-measure\n        num_TP (int): Number of true positives\n        num_FN (int): Number of false negatives\n        num_FP (int): Number of false positives\n        I_eval (np.ndarray): Data structure encoding TP, FN, FP\n    \"\"\"\n    I_eval = np.zeros(I_ref_pos.shape)\n    TP = (I_ref_pos + I_est_pos) > 1\n    FN = (I_ref_pos - I_est_pos) > 0\n    FP = (I_ref_pos - I_est_pos) < 0\n    I_eval[TP] = 1\n    I_eval[FN] = 2\n    I_eval[FP] = 3\n    num_TP = np.sum(TP)\n    num_FN = np.sum(FN)\n    num_FP = np.sum(FP)\n    P, R, F = measure_prf(num_TP, num_FN, num_FP)\n    return P, R, F, num_TP, num_FN, num_FP, I_eval\n\n\ndef plot_matrix_label(M, X, color_label=None, figsize=(3, 3), cmap='gray_r', fontsize=8, print_labels=True):\n    \"\"\"Plot matrix and label sequence\n\n    Args:\n        M: Matrix\n        X: Label sequence\n        color_label: List of colors for labels (Default value = None)\n        figsize: Figure size (Default value = (3, 3))\n        cmap: Colormap for imshow (Default value = 'gray_r')\n        fontsize: Font size (Default value = 8)\n        print_labels: Display labels inside Rectangles (Default value = True)\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n    \"\"\"\n    fig, ax = plt.subplots(2, 3, gridspec_kw={'width_ratios': [0.1, 1, 0.05],\n                                              'wspace': 0.2, 'height_ratios': [1, 0.1]},\n                           figsize=figsize)\n\n    colorList = np.array([[1, 1, 1, 1],  [0, 0, 0, 0.7]])\n    cmap = ListedColormap(colorList)\n    im = ax[0, 1].imshow(M, aspect='auto', cmap=cmap,  origin='lower', interpolation='nearest')\n    im.set_clim(vmin=-0.5, vmax=1.5)\n    ax_cb = plt.colorbar(im, cax=ax[0, 2])\n    ax_cb.set_ticks(np.arange(0, 2, 1))\n    ax_cb.set_ticklabels(np.arange(0, 2, 1))\n    ax[0, 1].set_xticks([])\n    ax[0, 1].set_yticks([])\n    plot_seq_label(ax[1, 1], X, color_label=color_label, fontsize=fontsize, print_labels=print_labels)\n    ax[1, 2].axis('off')\n    ax[1, 0].axis('off')\n    plot_seq_label(ax[0, 0], X, color_label=color_label, fontsize=fontsize, print_labels=print_labels,\n                   direction='vertical')\n    return fig, ax\n\n\ndef plot_matrix_pairwise(I_eval, figsize=(3, 2.5)):\n    \"\"\"Plot matrix I_eval encoding TP, FN, FP (see :func:`libfmp.c4.c4s5_evaluation.evaluate_pairwise`)\n\n   Args:\n        I_eval: Data structure encoding TP, FN, FP\n        figsize: Figure size (Default value = (3, 2.5))\n\n    Returns:\n        fig: Handle for figure\n        im: Handle for imshow\n    \"\"\"\n    fig = plt.figure(figsize=figsize)\n    colorList = np.array([[1, 1, 1, 1], [0, 0.7, 0, 1], [1, 0, 0, 1], [1, 0.5, 0.5, 1]])\n    cmap = ListedColormap(colorList)\n    im = plt.imshow(I_eval, aspect='auto', cmap=cmap,  origin='lower', interpolation='nearest')\n    im.set_clim(vmin=-0.5, vmax=3.5)\n    plt.xticks([])\n    plt.yticks([])\n    ax_cb = plt.colorbar(im)\n    ax_cb.set_ticks(np.arange(0, 4, 1))\n    ax_cb.set_ticklabels(['', 'TP', 'FN', 'FP'])\n    return fig, im\n\n\nI_ref_pos = compare_pairwise(X_ref)\nfig, ax = plot_matrix_label(I_ref_pos, X_ref, color_label=color_label)\nax[0,1].set_title('Reference')\n\nI_est_pos = compare_pairwise(X_est)\nfig, ax = plot_matrix_label(I_est_pos, X_est, color_label=color_label)\nax[0,1].set_title('Estimation')\n\nP, R, F, num_TP, num_FN, num_FP, I_eval =  evaluate_pairwise(I_ref_pos, I_est_pos)\nfig, im = plot_matrix_pairwise(I_eval)\nplt.title('Pairwise TP, FN, FP')\n\nplt.show()\n\nprint('#TP = ', num_TP, '\\n#FN = ', num_FN, '\\n#FP = ', num_FP)\nprint('precision = %0.4f\\nrecall = %0.4f\\nF-measure = %0.4f' % (P, R, F))\n\n\n\n\n\n\n\n\n\n\n#TP =  10 \n#FN =  14 \n#FP =  3\nprecision = 0.7692\nrecall = 0.4167\nF-measure = 0.5405\n\n\n\n첫 번째 그림에 참조 주석이 표시된다. \\(45\\) 아이템 중 \\(24\\)는 이 주석과 관련하여 positive(회색 상자로 표시됨)이다.\n추정된 주석을 나타내는 두 번째 그림에는 \\(13\\)의 positive 항목이 있다(회색 상자로 표시됨).\n세 번째 그림에서 true positive(\\(\\#\\mathrm{TP}=10\\)), false positive (\\(\\#\\mathrm{FP}=3\\)) 및 false negative(\\(\\#\\mathrm{FN) }=14\\))가 표시된다.\n이로부터 다음을 얻을 수 있다. \\[\\begin{eqnarray}\n\\mathrm{P} &=& \\#\\mathrm{TP}/(\\#\\mathrm{TP}+\\#\\mathrm{FP})=10/13\\approx 0.769,\\\\\n\\mathrm{R} &=& \\#\\mathrm{TP}/(\\#\\mathrm{TP}+\\#\\mathrm{FN})=10/24\\approx 0.417,\\\\\n\\mathrm{F} &=& 2\\mathrm{P}\\mathrm{R}/(\\mathrm{P} + \\mathrm{R})\\approx 0.541.\n\\end{eqnarray}\\]\n이 예에서 거의 \\(77\\%\\)의 precision은 상대적으로 높은 반면 \\(42\\%\\)의 recall은 상대적으로 낮다.\nF-measure은 이 두 값 사이이며 더 작은 쪽으로 편향된다.\n추가 예시로 브람스 주석을 보자.\n\n\nX_0 = convert_ann_to_seq_label(ann_Brahms[0])\nX_1 = convert_ann_to_seq_label(ann_Brahms[1])\nX_2 = convert_ann_to_seq_label(ann_Brahms[2])\n\nX_set = [X_0, X_1, X_2]\ncombinations = [(0,1), (0,2), (1,2)]\ncase_label = ['Coarse', 'Medium', 'Fine']\n\nfor c in combinations:\n    X_ref = X_set[c[0]]\n    X_est = X_set[c[1]]\n    \n    I_ref_pos = compare_pairwise(X_ref)\n    fig, ax = plot_matrix_label(I_ref_pos, X_ref, color_label=color_ann_Brahms, print_labels=False)\n    ax[0,1].set_title('Reference: '+case_label[c[0]])\n    \n    I_est_pos = compare_pairwise(X_est)\n    fig, ax = plot_matrix_label(I_est_pos, X_est, color_label=color_ann_Brahms, print_labels=False)\n    ax[0,1].set_title('Estimation: '+case_label[c[1]])\n\n    P, R, F, num_TP, num_FN, num_FP, I_eval =  evaluate_pairwise(I_ref_pos, I_est_pos)\n    fig, im = plot_matrix_pairwise(I_eval)\n    plt.title('Pairwise TP, FN, FP')\n    \n    plt.show()\n    \n    print('#TP = ', num_TP, ';  #FN = ', num_FN, ';  #FP = ', num_FP)\n    print('P = %0.3f;  R = %0.3f;  F = %0.3f' % (P, R, F))\n    print()\n\n\n\n\n\n\n\n\n\n\n#TP =  226 ;  #FN =  218 ;  #FP =  12\nP = 0.950;  R = 0.509;  F = 0.663\n\n\n\n\n\n\n\n\n\n\n\n\n#TP =  143 ;  #FN =  301 ;  #FP =  4\nP = 0.973;  R = 0.322;  F = 0.484\n\n\n\n\n\n\n\n\n\n\n\n\n#TP =  136 ;  #FN =  102 ;  #FP =  11\nP = 0.925;  R = 0.571;  F = 0.706\n\n\n\n\n\n경계 평가 (Boundary Evaluation)\n\n쌍별(pairwise) precision, recall, F-measure은 전적으로 레이블 정보를 기반으로 하는 반면, 세그먼트 경계는 레이블 변경의 존재에 의해 암시적으로 처리된다.\n노벨티(novelty) 기반 분할과 같은 다른 구조 분석 작업의 경우 경계의 정확한 감지가 중요하다.\n이러한 절차를 평가하기 위해 참조 주석의 경계에서 추정된 세그먼트 경계의 편차를 측정한다.\n이를 수학적으로 모델링하기 위해 시퀀스로 제공되는 경계 주석(boundary annotation) 개념을 도입한다. \\[B=(b_1,b_2,\\ldots,b_K)\\] \\(b_k\\in[1:N]\\), \\(k\\in[1:K]\\)는 증가하는 인덱스\n예를 들어, 이러한 경계 주석은 주석이 달린 세그먼트의 시작 및 가능한 끝 인덱스를 취함으로써 구조 주석에서 유도될 수 있다.\n\\(B^\\mathrm{Ref}\\)를 참조 경계 주석, \\(B^\\mathrm{Est}\\)를 추정 경계 주석이라고 하자.\n\\(B^\\mathrm{Est}\\)와 \\(B^\\mathrm{Ref}\\)를 비교하는 방법에는 여러 가지가 있다. 예를 들어 \\(\\mathcal{I}=[1:N]\\) 집합을 사용하면 \\(\\mathcal{I}^\\mathrm{Ref}_+:=B^\\mathrm{Ref}\\) 및 \\(\\mathcal{I}^\\mathrm{Est}_+:=B^\\mathrm{Est}\\)를 정의할 수 있다.\n이로부터 Precision, Recall, F-Measure를 일반적인 방법으로 계산할 수 있다. 이 경우 추정된 경계는 참조 경계와 일치하는 경우에만 올바른 것으로 간주된다.\n특정 응용의 경우 경계 위치의 작은 편차가 허용된다. 따라서 최대 허용 편차에 대한 허용(tolerance) 매개변수 \\(\\tau\\geq 0\\)를 도입하여 이전 측정을 일반화한다.\n추정된 경계 \\(b^\\mathrm{Est}\\in B^\\mathrm{Est}\\)는 참조 경계 \\(b^\\mathrm{Ref}\\in B^\\mathrm{Ref}\\)의 \\(\\tau\\)-이웃(-neighborhood) 내에 있는 경우 올바른 것으로 간주된다.: \\[|b^\\mathrm{Est}-b^\\mathrm{Ref}|\\leq \\tau\\]\n이 경우 \\(\\mathcal{I}^\\mathrm{Ref}_+\\) 및 \\(\\mathcal{I}^\\mathrm{Est}_+\\) 집합은 더 이상 precision 및 recall을 정의하는 데 사용할 수 없다.\n대신, true positives, false positives, 및 false negatives의 개념을 일반화한다.\ntrue positive(TP)은 올바른 항목 \\(b^\\mathrm{Est}\\in B^\\mathrm{Est}\\)로 정의되고 false positive(FP)은 올바르지 않은 \\(b^\\mathrm{Est}\\in B^\\mathrm{Est}\\) 항목이다. 또한, false negative(FN)은 \\(\\tau\\)-neighborhood에 추정 항목이 없는 \\(b^\\mathrm{Ref}\\in B^\\mathrm{Ref}\\) 항목으로 정의된다.\n이러한 정의에 따라 이전과 같이 \\(\\#\\mathrm{TP}\\), \\(\\#\\mathrm{FP}\\) 및 \\(\\#\\mathrm{FN}\\)에서 precision, recall을 및 F-measure을 계산할 수 있다.\n그러나 이러한 일반화는 주의해야 할 점이 있다. 허용오차(tolerance) 매개변수 \\(\\tau\\)로 인해 여러 추정 경계가 단일 참조 경계의 \\(\\tau\\)-이웃에 포함될 수 있다. 반대로, 여러 참조 경계의 \\(\\tau\\)-neighborhood에 단일 추정 경계가 포함될 수도 있다.\n결과적으로 \\(B^\\mathrm{Est}\\)와 \\(B^\\mathrm{Ref}\\)가 서로 다른 수의 경계를 포함하는 경우에도 완벽한 F-measure을 얻을 수 있다. 그러나 이것은 의미가 없다.\n이러한 변칙을 피하기 위해 다음을 요구하는 경계 주석의 정의의 가정을 추가할 수 있다. \\[|b_{k+1}-b_k| > 2\\tau\\] for \\(k\\in[1:N-1]\\)\n이것은 또한 음악적 관점에서 의미 있는 가정이다. 음악 섹션(두 개의 후속 경계로 결정됨)은 허용 오차 매개변수의 크기보다 훨씬 길어야 한다.\n다음 그림은 간단한 예를 통해 경계 평가 측정을 보여준다.\n\n\nipd.Image(\"../img/5.music_structure_analysis/FMP_C4_F31_text.png\", width=800)\n\n\n\n\n\n허용오차 매개변수 \\(\\tau=0\\)((c) 참고)를 사용하여 \\(\\#\\mathrm{TP}=1\\), \\(\\#\\mathrm{FP}=3\\) 및 \\(\\#\\mathrm{FN}=2\\)을 얻는다. 그 결과 \\(\\mathrm{P}=1/4\\), \\(\\mathrm{R}=1/3\\) 및 \\(\\mathrm{F}=2/7\\)이다.\n\\(\\tau=1\\)의 경우((e) 참고) \\(\\#\\mathrm{TP}=2\\), \\(\\#\\mathrm{FP}=2\\), \\(\\#\\mathrm{FN}=1\\), 결과는 \\(\\mathrm{P}=1/2\\), \\(\\mathrm{R}=2/3\\) 및 \\(\\mathrm{F}=4/7\\)이다.\n마지막으로 \\(\\tau=2\\)((g) 참고)를 사용하면 완벽한 F-measure을 얻을 수 있다. 그러나 이 경우 최소 거리 조건을 위반하기에 평가 척도로의 의미가 없다.\n\n\ndef evaluate_boundary(B_ref, B_est, tau):\n    \"\"\"Compute boundary evaluation measures [FMP, Section 4.5.4]\n\n    Args:\n        B_ref (np.ndarray): Reference boundary annotations\n        B_est (np.ndarray): Estimated boundary annotations\n        tau (int): Tolerance parameter.\n            Note: Condition ``|b_{k+1}-b_k|>2tau`` should be fulfilled [FMP, Eq. 4.58]\n\n    Returns:\n        P (float): Precision\n        R (float): Recall\n        F (float): F-measure\n        num_TP (int): Number of true positives\n        num_FN (int): Number of false negatives\n        num_FP (int): Number of false positives\n        B_tol (np.ndarray): Data structure encoding B_ref with tolerance\n        I_eval (np.ndarray): Data structure encoding TP, FN, FP\n    \"\"\"\n    N = len(B_ref)\n    num_TP = 0\n    num_FN = 0\n    num_FP = 0\n    B_tol = np.zeros((np.array([B_ref])).shape)\n    B_eval = np.zeros((np.array([B_ref])).shape)\n    for n in range(N):\n        min_idx = max(0, n - tau)\n        max_idx = min(N - 1, n + tau)\n        if B_ref[n] == 1:\n            B_tol[:, min_idx:max_idx+1] = 2\n            B_tol[:, n] = 1\n            temp = sum(B_est[min_idx:max_idx+1])\n            if temp > 0:\n                num_TP += temp\n            else:\n                num_FN += 1\n                B_eval[:, n] = 2\n        if B_est[n] == 1:\n            if sum(B_ref[min_idx:max_idx+1]) == 0:\n                num_FP += 1\n                B_eval[:, n] = 3\n            else:\n                B_eval[:, n] = 1\n    P, R, F = measure_prf(num_TP, num_FN, num_FP)\n    return P, R, F, num_TP, num_FN, num_FP, B_tol, B_eval\n\n\ndef plot_boundary_measures(B_ref, B_est, tau, figsize=(8, 2.5)):\n    \"\"\"Plot B_ref and B_est (see :func:`libfmp.c4.c4s5_evaluation.evaluate_boundary`)\n\n    Args:\n        B_ref: Reference boundary annotations\n        B_est: Estimated boundary annotations\n        tau: Tolerance parameter\n        figsize: Figure size (Default value = (8, 2.5))\n\n    Returns:\n        fig: Handle for figure\n        ax: Handle for axes\n    \"\"\"\n    P, R, F, num_TP, num_FN, num_FP, B_tol, B_eval = evaluate_boundary(B_ref, B_est, tau)\n\n    colorList = np.array([[1., 1., 1., 1.], [0., 0., 0., 1.], [0.7, 0.7, 0.7, 1.]])\n    cmap_tol = ListedColormap(colorList)\n    colorList = np.array([[1, 1, 1, 1], [0, 0.7, 0, 1], [1, 0, 0, 1], [1, 0.5, 0.5, 1]])\n    cmap_measures = ListedColormap(colorList)\n\n    fig, ax = plt.subplots(3, 2, gridspec_kw={'width_ratios': [1, 0.02],\n                                              'wspace': 0.2, 'height_ratios': [1, 1, 1]},\n                           figsize=figsize)\n\n    im = ax[0, 0].imshow(B_tol, cmap=cmap_tol, interpolation='nearest')\n    ax[0, 0].set_title('Reference boundaries (with tolerance)')\n    im.set_clim(vmin=-0.5, vmax=2.5)\n    ax[0, 0].set_xticks([])\n    ax[0, 0].set_yticks([])\n    ax_cb = plt.colorbar(im, cax=ax[0, 1])\n    ax_cb.set_ticks(np.arange(0, 3, 1))\n    ax_cb.set_ticklabels(['', 'Positive', 'Tolerance'])\n\n    im = ax[1, 0].imshow(np.array([B_est]), cmap=cmap_tol, interpolation='nearest')\n    ax[1, 0].set_title('Estimated boundaries')\n    im.set_clim(vmin=-0.5, vmax=2.5)\n    ax[1, 0].set_xticks([])\n    ax[1, 0].set_yticks([])\n    ax_cb = plt.colorbar(im, cax=ax[1, 1])\n    ax_cb.set_ticks(np.arange(0, 3, 1))\n    ax_cb.set_ticklabels(['', 'Positive', 'Tolerance'])\n\n    im = ax[2, 0].imshow(B_eval, cmap=cmap_measures, interpolation='nearest')\n    ax[2, 0].set_title('Evaluation')\n    im.set_clim(vmin=-0.5, vmax=3.5)\n    ax[2, 0].set_xticks([])\n    ax[2, 0].set_yticks([])\n    ax_cb = plt.colorbar(im, cax=ax[2, 1])\n    ax_cb.set_ticks(np.arange(0, 4, 1))\n    ax_cb.set_ticklabels(['', 'TP', 'FN', 'FP'])\n    plt.show()\n    return fig, ax\n\n\nB_ref = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\nB_est = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\ntau_list = [0,1,2]\n\nfor tau in tau_list:\n    print('====== Evaluation using tau = %d ======'%tau)\n    P, R, F, num_TP, num_FN, num_FP, B_tol, B_eval = evaluate_boundary(B_ref, B_est, tau)    \n    print('#TP = ', num_TP, ';  #FN = ', num_FN, ';  #FP = ', num_FP)\n    print('P = %0.3f;  R = %0.3f;  F = %0.3f' % (P, R, F))\n    fig, ax = plot_boundary_measures(B_ref, B_est, tau=tau, figsize=(6,2))\n\n====== Evaluation using tau = 0 ======\n#TP =  1 ;  #FN =  2 ;  #FP =  3\nP = 0.250;  R = 0.333;  F = 0.286\n\n\n\n\n\n====== Evaluation using tau = 1 ======\n#TP =  2 ;  #FN =  1 ;  #FP =  2\nP = 0.500;  R = 0.667;  F = 0.571\n\n\n\n\n\n====== Evaluation using tau = 2 ======\n#TP =  4 ;  #FN =  0 ;  #FP =  0\nP = 1.000;  R = 1.000;  F = 1.000\n\n\n\n\n\n이외에도\n\n파이썬 라이브러리 mir_eval를 사용할 수도 있다.\n자세한 것은 사이트에서 확인해보자: https://craffel.github.io/mir_eval/#module-mir_eval.segment\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C4/C4S5_Evaluation.html\n\n\n구글 Colab 링크"
  }
]