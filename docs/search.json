[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\n음악정보검색(Music Information Retrieval)에 대한 포스트를 올리는 개인 블로그입니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "음악정보검색 블로그 (testing)",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\n2.1. 악보 (Sheet Music)\n\n\n\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\n  \n\n\n\n\n2.2. 기호 표현 (Symbolic Representation)\n\n\n\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nCheonghyo Cho\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "",
    "text": "음악의 표현 방법 중 악보와 기보법, 음, 피치, 크로마 등에 대해 다룬다.\n이 글은 FMP(Fundamentals of Music Processing) Notebooks을 참고로 한다."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "악보",
    "text": "악보\nFull Score (전체 악보) - 위에서부터 악기별로 악보가 정렬되어 있다.\n\nImage(\"../img/2.music_representation/FMP_C1_F10.png\", width=400, height=400)\n\n\n\n\n\n예전에는 고품질의 표기를 그리는 것이 중요했으며, 이는 “music engraving”이라고 불렸다.\n하지만 요즘은 컴퓨터 소프트웨어가 악보를 그릴 수 있다. 아래는 위의 악보를 컴퓨터가 똑같이 제작한 버전의 악보이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "기보법 (Music Notation)",
    "text": "기보법 (Music Notation)\n\n오선보(staff)는 5개의 수평선들과 네 개의 공백의 집합으로, 각기 다른 음 높낮이를 표현한다.\n5선 만으로는 음의 높이를 알 수 없다. 따라서, 음의 자리를 정해주는 음자리표(clef)를 5선의 맨 앞에 그려 넣는데, 이렇게 음자리표까지 그려져 음의 자리가 정해져야 비로소 보표가 된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F04.png\", width=500)\n\n\n\n\n\n조표(key signature)란 악보에서 음자리표와 박자표 사이에 붙는 올림표나 내림표를 말하며, 음표 앞에 표기하는 임시표와는 달리 보통의 음표보다 반음이 지속적으로 높거나 낮은 상태를 나타내기 위해 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F05.png\", width=500)\n\n\n\n\n\n악보는 음표(note), 쉼표(rest)로 형성되어 있다. (음표에 대한 자세한 설명은 생략한다.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_F07.png\", width=500)\n\n\n\n\n\n박자표(time signature)는 악곡의 박자 종류를 가리킨다. 박자표는 모두 분수의 꼴로 쓴다\n\n\nImage(\"../img/2.music_representation/FMP_C1_F06.png\", width=500)\n\n\n\n\n\n여러 오선을 합쳐 staff system을 만들 수 있다. 다양한 악기를 동시에 연주할 때 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F08.png\", width=500)\n\n\n\n\n\n템포, 다이나믹, 표현 등을 위한 설명으로 아티큘레이션(articulation)을 쓸 수 있다. 아래의 그림에 나와있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F09.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "음과 피치",
    "text": "음과 피치\n\n피치(=음고, 음높낮이)(pitch)란 음(note)이 얼마나 높은지 낮은지를 다루는 속성이다. 피치는 음파의 기본 주파수(fundamental frequency)와 긴밀히 연관되어 있다.\n옥타브(ocatve)는 두 음의 간격을 의미하는데, 한 옥타브 높은 음은 낮은 음은 두배의 기본 주파수이다. 예를 들어 440Hz의 A와 880Hz의 A는 한 옥타브를 사이에 두고 나눠진다.\n피치 클래스(pitch class)란 옥타브를 간격으로 있는 모든 음의 집합이다. 예를 들어 C {…, C1, C2, …}는 하나의 피치 클래스, D {…, D1, D2, …}는 또다른 피치 클래스이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_PitchClassC.png\", width=500)\n\n\n\n\n\nimport numpy as np\n\ndef generate_sinusoid_pitches(pitches=[69], dur=0.5, Fs=4000, amp=0.25):\n    \"\"\"Generation of sinusoids for a given list of MIDI pitches\n\n    Args:\n        pitches (list): List of MIDI pitches (Default value = [69])\n        dur (float): Duration (in seconds) of each sinusoid (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 4000)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = []\n    for p in pitches:\n        freq = 2 ** ((p - 69) / 12) * 440\n        x = np.append(x, np.sin(2 * np.pi * freq * t))\n    x = amp * x / np.max(x)\n    return x, t\n\n\nFs = 22050\n\npitches = [36,48,60,72,84,96,108]\nx, t = generate_sinusoid_pitches(pitches=pitches, Fs=Fs)\nprint('Pitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}', flush=True)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nPitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n음계(scale)는 음악에서 피치(pitch) 순서로 된 음의 집합을 말한다. 악곡을 주로 구성하는 음을 나타내며, 음계의 종류에 따라 곡의 분위기가 달라진다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_MusicalScales.png\", width=500)\n\n\n\n\n\ndur = 0.5\nFs = 22050\n\nx_maj, t = generate_sinusoid_pitches(pitches=[60,62,64,65,67,69,71,72], Fs=Fs)\nx_min, t = generate_sinusoid_pitches(pitches=[60,62,63,65,67,68,70,72], Fs=Fs)\n\nprint('C major scale', flush=True)\nipd.display(ipd.Audio(data=x_maj, rate=Fs))\nprint('C minor scale', flush=True)\nipd.display(ipd.Audio(data=x_min, rate=Fs))\n\nC major scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nC minor scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n평균율(equal temperament)이란 한 옥타브를 12개의 동일한 음계 단계로 나눈 것을 의미한다.\n두 연속된 음계 사이의 차이를 반음(semitone)이라고 하는데, 이는 12음 음계의 가장 작은 간격이다. 음악인들은 이를 ’half-step’이라고도 말한다.\n12음 평균율 음계에는 12개의 피치 클래스가 있다. 서양 음악 표기법에서 이러한 피치 클래스는 알파벳과 임시표(accidental)를 결합하여 표시된다. 7개의 피치 클래스(C 장조에 해당)는 문자 C, D, E, F, G, A 및 B로 표시된다. 이러한 피치 클래스는 피아노 건반의 흰색 건반에 해당된다. 나머지 5개의 피치 등급은 피아노 건반의 검은 건반에 해당하며 알파벳과 임시표(♯ ,♭)의 조합으로 표시된다. 샵(♯)은 음을 반음 올리고 플랫(♭)은 반음 내린 것으로 음 이름 뒤에 표시된다: C♯, D♯, F♯, G♯, A♯ 혹은 D♭, E♭, G♭, A♭, B♭. 이 때 C♯과 D♭는 같은 피치 클래스를 나타낸다. 이는 “enharmonic equivalence”로도 알려져 있다.\n\n과학적 피치 표기\n\n12음 평균율의 음에 이름을 지정하기 위해 피치 클래스를 표시하는 것 외에도 옥타브에 대한 식별자가 필요하다. 과학적 피치 표기법에 따라 각 음은 피치 클래스 이름과 옥타브를 나타내는 숫자로 지정된다. 음 A4는 440Hz의 기본 주파수를 갖는 것으로 결정되어 기준 역할을 한다. 옥타브 수는 피치 클래스 B의 음에서 피치 클래스 C의 음으로 올라갈 때 1씩 증가한다.\n다음 그림은 C3에서 C5까지의 건반과 서양 음악 표기법을 사용하는 해당 음표가 있는 피아노 건반 부분을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F02.png\", width=500)\n\n\n\n\n\ndur = 0.2\nFs = 22050\npitches = range(48,73)\n\nx_chromatic, t = generate_sinusoid_pitches(pitches=pitches, dur=dur, Fs=Fs)\n\nprint('Sinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):', flush=True)\nipd.display(ipd.Audio(data=x_chromatic, rate=Fs))\n\nSinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)",
    "text": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)\n크로마란?\n\n피치에 따라 평균율 음계의 모든 음을 순서대로 배열하면, 음계의 모든 음이 같은 간격으로 배열된 평균율의 크로마틱 음계(chromatic scale)를 얻을 수 있다.\n“Chromatic”이라는 용어는 색을 의미하는 그리스어 “chroma”에서 유래했다.\n음악적 맥락에서 크로마(chroma)라는 용어는 12개의 다른 피치 클래시와 밀접한 관련이 있다. 예를 들어, C2와 C5 음은 모두 같은 크로마 값 C를 가지고 있다.\n즉, 크로마 값이 같은 모든 음은 동일한 피치 클래스에 속한다.\n같은 피치클래스에 속하거나 크로마 값이 같은 음은 유사하게 인식된다. 반면에, 다른 피치 클래스에 속하거나 다른 크로마 값을 갖는 음은 서로 다른 것으로 인식된다.\n크로마 값의 주기적 특성은 아래 그림과 같이 크로마 원에 의해 설명된다.\n이 개념을 확장하면, 로저 셰퍼드(1929)의 이름을 딴 셰퍼드의 피치 나선(Shepard’s helix of pitch)은 선형 피치 공간을 하나의 수직선을 따라 옥타브 관련 피치가 놓이도록 원통을 감싸고 있는 나선으로 표현한다. 실린더가 수평면에 투영되면 크로마원이 생성된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F03.png\", width=500)\n\n\n\n\n셰퍼드 톤\n\nShepard의 피치 나선은 Shepard 톤을 사용하여 음향화할 수 있으며, 각 톤은 옥타브로 구분된 사인파의 가중 중첩이다.\n반음계 위로 올라가는 이 음조를 연주할 때, 계속해서 위로 올라가는 음조의 청각적 환영을 얻는다(펜로즈 계단의 시각적 착시와 유사; 아래 그림).\n\n\nImage(\"../img/2.music_representation/FMP_C1_PenroseStairs.png\", width=200)\n\n\n\n\n\n뒤의 코드 예시에서 인간이 들을 수 있는 사인파 (20~20000헤르츠의 주파수)만 사용해보자. 특정 가중은 사용되지 않는다(모든 사인파는 1의 크기를 가짐).\n마지막으로 셰퍼드 톤은 크로마틱 스케일로 C3 (MIDI pitch 48) 부터 C5 (MIDI pitch 72)까지로 생성된다.\n\n\ndef generate_shepard_tone(freq=440, dur=0.5, Fs=44100, amp=1):\n    \"\"\"Generate Shepard tone\n\n    Args:\n        freq (float): Frequency of Shepard tone (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Shepard tone\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    num_sin = 1\n    x = np.sin(2 * np.pi * freq * t)\n    freq_lower = freq / 2\n    while freq_lower > 20:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_lower * t)\n        freq_lower = freq_lower / 2\n    freq_upper = freq * 2\n    while freq_upper < 20000:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_upper * t)\n        freq_upper = freq_upper * 2\n    x = x / num_sin\n    x = amp * x / np.max(x)\n    return x, t\n\ndef f_pitch(p):\n    F_A4 = 440\n    return F_A4 * 2 ** ((p - 69) / 12)\n    \nFs = 44100\ndur = 0.5\n\npitch_start = 48\npitch_end = 72\nscale = []\nfor p in range(pitch_start, pitch_end + 1):\n    freq = f_pitch(p)    \n    s, t = generate_shepard_tone(freq=freq, dur=dur, Fs=Fs, amp = 0.5)\n    scale = np.concatenate((scale, s))\n    \nipd.display(ipd.Audio(scale, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nShepard–Risset Glissando\n\n이산적인 스케일을 사용하는대신 연속적인 셰퍼든 톤의 등락을 생성할 수 있다.: (Shepard–Risset glissando)\n뒤의 코드 예시는 상승하는 glissando를 생성한다.\n첫 째로 기하급수적으로 상승하는 chirp 신호가 정의된다. 이때 순간 주파수(instantaneous frequency)는 정현파 변수의 미분으로 주어진다.\n생성된 chirp 신호는 정확히 1옥타브를 커버한다. 그런 다음 Shepared 톤과 유사하게, 옥타브로 분리된 처프의 중첩(superposition)이 생성된다. 한 옥타브를 커버하고 Shepard–Risset glissando의 끝 부분은 (지각적으로) 시작 부분과 일치한다. 따라서 여러 glissando를 연결하여 논스톱 버전을 얻는다.\n\n\ndef generate_chirp_exp_octave(freq_start=440, dur=8, Fs=44100, amp=1):\n    \"\"\"Generate one octave of a chirp with exponential frequency increase\n\n    Args:\n        freq_start (float): Start frequency of chirp (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Chirp signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = np.sin(2 * np.pi * freq_start * np.power(2, t / dur) / np.log(2) * dur)\n    x = amp * x / np.max(x)\n    return x, t\n\n\ndef generate_shepard_glissando(num_octaves=3, dur_octave=8, Fs=44100):\n    \"\"\"Generate several ocatves of a Shepared glissando\n\n    Args:\n        num_octaves (int): Number of octaves (Default value = 3)\n        dur_octave (int): Duration (in seconds) per octave (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n\n    Returns:\n        x (np.ndarray): Shepared glissando\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    freqs_start = 10 * 2**np.arange(0, 11)\n    # Generate Shepard glissando by superimposing chirps that differ by octaves\n    for freq in freqs_start:\n        if freq == 10:\n            x, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n        else:\n            chirp, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n            x = x + chirp\n    x = x / len(freqs_start)\n    # Concatenate several octaves\n    x = np.tile(x, num_octaves)\n    N = len(x)\n    t = np.arange(N) / Fs\n    return x, t\n    \nglissando, t = generate_shepard_glissando(num_octaves=3, dur_octave=8)\nipd.display(ipd.Audio(glissando, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_SheetMusic.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_MusicalNotesPitches.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_ChromaShepard.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "",
    "text": "음악의 표현 방법 중 기호(심볼릭) 표현에 대해 알아본다. 피아노-롤, 미디(MIDI) 등이 있다.\n이 글은 FMP(Fundamentals of Music Processing) Notebooks을 참고로 한다."
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "피아노-롤(piano-roll) 표현",
    "text": "피아노-롤(piano-roll) 표현\n\n피아노-롤은 피아노와 관련된 음 정보들을 모아 가시화한 것을 일반적으로 말한다.\n드뷔시와 베토벤 음악의 피아노롤을 아래 영상과 같이 표현할 수 있다.\n\n\nipd.display( ipd.YouTubeVideo(\"LlvUepMa31o\", start=15) )\n\n\n        \n        \n\n\n\nipd.display( ipd.YouTubeVideo(\"Kri2jWr08S4\", start=11) )"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "미디 (MIDI) 표현",
    "text": "미디 (MIDI) 표현\n\n또다른 기호 표현으로는 MIDI(Musical Instrument Digital Interface) 스탠다드가 있다. MIDI는 1980년대 초반 전자 음악 악기 시장의 급성장과 함께 출현했다.\nMIDI 메시지는 음(note) 온셋, 음 오프셋, 강도(intensity or “velocity”)와 같은 정보를 인코딩한다. 컴퓨터에서 MIDI 파일은 MIDI 메시지들과 다른 메타데이터를 보관한다.\nMIDI 노트넘버(MIDI note number)는 0과 127 사이의 정수로 노트의 피치를 인코딩한다. 가장 중요한 것으로는 C4(중간 C)는 MIDI 노트넘버 60이고, A4(concert A440)은 MIDI 노트넘버 69이다. MIDI 노트넘버는 12개로 나누어져있으며 한 옥타브씩 나누어진다 (e.g. 72 = C5, 84 = C6, etc.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_MIDI-NoteNumbers.png\", width=500)\n\n\n\n\n\n키 벨로시티(key velocity)는 0과 127 사이의 정수로 소리의 강도를 조정한다.\nMIDI 채널은 0과 15 사이의 정수로 신디사이저가 특정 악기를 사용하도록 안내한다.\nMIDI는 사분음표를 clock pulses 또는 틱으로 세분화한다. 예를 들어, 분기 음 당 펄스 수(PPQN)를 120으로 정의하면 60개의 틱이 8번째 음의 길이를 나타낸다.\n또한 MIDI는 템포를 BPM으로 인코딩하여 절대적인 시간 정보를 알려준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F13.png\", width=600)\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.mid\")\nmidi_list = []\n\nfor instrument in midi_data.instruments:\n    for note in instrument.notes:\n        start = note.start\n        end = note.end\n        pitch = note.pitch\n        velocity = note.velocity\n        midi_list.append([start, end, pitch, velocity, instrument.name])\n        \nmidi_list = sorted(midi_list, key=lambda x: (x[0], x[2]))\n\ndf = pd.DataFrame(midi_list, columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.25\n      0.50\n      43\n      113\n      Piano\n    \n    \n      0.25\n      0.50\n      55\n      76\n      Piano\n    \n    \n      0.25\n      0.50\n      67\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      43\n      113\n      Piano\n    \n    \n      0.50\n      0.75\n      55\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      67\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      43\n      113\n      Piano\n    \n    \n      0.75\n      1.00\n      55\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      67\n      76\n      Piano\n    \n    \n      1.00\n      2.00\n      39\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      51\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      63\n      70\n      Piano\n    \n    \n      2.25\n      2.50\n      41\n      113\n      Piano\n    \n    \n      2.25\n      2.50\n      53\n      76\n      Piano\n    \n    \n      2.25\n      2.50\n      65\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      41\n      113\n      Piano\n    \n    \n      2.50\n      2.75\n      53\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      65\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      41\n      113\n      Piano\n    \n    \n      2.75\n      3.00\n      53\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      65\n      76\n      Piano\n    \n    \n      3.00\n      5.00\n      38\n      112\n      Piano\n    \n    \n      3.00\n      5.00\n      50\n      126\n      Piano\n    \n    \n      3.00\n      5.00\n      62\n      71\n      Piano\n    \n  \n\n\n\n\nFs = 22050\naudio_data = midi_data.synthesize(fs=Fs)\nipd.Audio(audio_data, rate=Fs)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\ndef midi_to_list(midi):\n    \"\"\"Convert a midi file to a list of note events\n\n    Args:\n        midi (str or pretty_midi.pretty_midi.PrettyMIDI): Either a path to a midi file or PrettyMIDI object\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(midi, str):\n        midi_data = pretty_midi.pretty_midi.PrettyMIDI(midi)\n    elif isinstance(midi, pretty_midi.pretty_midi.PrettyMIDI):\n        midi_data = midi\n    else:\n        raise RuntimeError('midi must be a path to a midi file or pretty_midi.PrettyMIDI')\n\n    score = []\n\n    for instrument in midi_data.instruments:\n        for note in instrument.notes:\n            start = note.start\n            duration = note.end - start\n            pitch = note.pitch\n            velocity = note.velocity / 128.\n            score.append([start, duration, pitch, velocity, instrument.name])\n    return score\n\n\ndef visualize_piano_roll(score, xlabel='Time (seconds)', ylabel='Pitch', colors='FMP_1', velocity_alpha=False,\n                         figsize=(12, 4), ax=None, dpi=72):\n    \"\"\"Plot a pianoroll visualization\n    Args:\n        score: List of note events\n        xlabel: Label for x axis (Default value = 'Time (seconds)')\n        ylabel: Label for y axis (Default value = 'Pitch')\n        colors: Several options: 1. string of FMP_COLORMAPS, 2. string of matplotlib colormap,\n            3. list or np.ndarray of matplotlib color specifications,\n            4. dict that assigns labels  to colors (Default value = 'FMP_1')\n        velocity_alpha: Use the velocity value for the alpha value of the corresponding rectangle\n            (Default value = False)\n        figsize: Width, height in inches (Default value = (12)\n        ax: The Axes instance to plot on (Default value = None)\n        dpi: Dots per inch (Default value = 72)\n    Returns:\n        fig: The created matplotlib figure or None if ax was given.\n        ax: The used axes\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize, dpi=dpi)\n        ax = plt.subplot(1, 1, 1)\n\n    labels_set = sorted(set([note[4] for note in score]))\n    colors = color_argument_to_dict(colors, labels_set)\n\n    pitch_min = min(note[2] for note in score)\n    pitch_max = max(note[2] for note in score)\n    time_min = min(note[0] for note in score)\n    time_max = max(note[0] + note[1] for note in score)\n\n    for start, duration, pitch, velocity, label in score:\n        if velocity_alpha is False:\n            velocity = None\n        rect = patches.Rectangle((start, pitch - 0.5), duration, 1, linewidth=1,\n                                 edgecolor='k', facecolor=colors[label], alpha=velocity)\n        ax.add_patch(rect)\n\n    ax.set_ylim([pitch_min - 1.5, pitch_max + 1.5])\n    ax.set_xlim([min(time_min, 0), time_max + 0.5])\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.grid()\n    ax.set_axisbelow(True)\n    ax.legend([patches.Patch(linewidth=1, edgecolor='k', facecolor=colors[key]) for key in labels_set],\n              labels_set, loc='upper right', framealpha=1)\n\n    if fig is not None:\n        plt.tight_layout()\n\n    return fig, \n\n\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nimport music21 as m21\n\ns = m21.converter.parse(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\ns.plot('pianoroll', figureSize=(10, 3))"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "악보적(score) 표현",
    "text": "악보적(score) 표현\n\n기호적 악보 표현은 “2.1.Sheet_Music.ipynb”에서 설명한 음악적 기호들을 인코딩한다. (음자리표, 조표 등등) 하지만 이를 악보로 가시화하는 것이 아니라 저장하는데, MusicXML같은 파일로 저장한다.\n아래 그 예시가 있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F15.png\", width=400)\n\n\n\n\n\ndef xml_to_list(xml):\n    \"\"\"Convert a music xml file to a list of note events\n\n    Args:\n        xml (str or music21.stream.Score): Either a path to a music xml file or a music21.stream.Score\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(xml, str):\n        xml_data = m21.converter.parse(xml)\n    elif isinstance(xml, m21.stream.Score):\n        xml_data = xml\n    else:\n        raise RuntimeError('midi must be a path to a midi file or music21.stream.Score')\n\n    score = []\n\n    for part in xml_data.parts:\n        instrument = part.getInstrument().instrumentName\n\n        for note in part.flat.notes:\n\n            if note.isChord:\n                start = note.offset\n                duration = note.quarterLength\n\n                for chord_note in note.pitches:\n                    pitch = chord_note.ps\n                    volume = note.volume.realized\n                    score.append([start, duration, pitch, volume, instrument])\n\n            else:\n                start = note.offset\n                duration = note.quarterLength\n                pitch = note.pitch.ps\n                volume = note.volume.realized\n                score.append([start, duration, pitch, volume, instrument])\n\n    score = sorted(score, key=lambda x: (x[0], x[2]))\n    return score\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.xml\")\nxml_list = xml_to_list(xml_data)\n\ndf = pd.DataFrame(xml_list[:9], columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False, float_format='%.2f', max_rows=8)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.50\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      0.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      2.00\n      2.00\n      63.00\n      0.71\n      Piano (2)\n    \n    \n      2.50\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n    \n      3.00\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n  \n\n\n\n\nvisualize_piano_roll(xml_list, figsize=(8, 3), velocity_alpha=True,\n                               xlabel='Time (quarter lengths)');\n\n\n\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.xml\")\nxml_list = xml_to_list(xml_data)\n\nvisualize_piano_roll(xml_list, figsize=(10, 7), velocity_alpha=False,\n                               colors='gist_rainbow', xlabel='Time (quarter lengths)');\n\n\n\n\n기호 음악 표현법을 사용하는 파이썬 라이브러리\n\nPrettyMIDI: MIDI 읽기, 컨버팅 등\nmusic21: musicxml파일 다루기\npypianoroll: 피아노롤 비주얼\n\n\n출처:\n\nhttps://musicinformationretrieval.com/\nhttps://www.audiolabs-erlangen.de/FMP\n\n\n구글 Colab 링크"
  }
]