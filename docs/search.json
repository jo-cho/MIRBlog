[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "음악정보검색(Music Information Retrieval)에 대한 포스트를 올리는 블로그입니다. 음악정보검색을 독학하며 배운 내용을 기록하는 초보자의 입문기라고 생각해주세요."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Music Information Retrieval",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n2.1. 악보 (Sheet Music)\n\n\n\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\n2.2. 기호 표현 (Symbolic Representation)\n\n\n\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\n2.3. 오디오 표현 (Audio Representation)\n\n\n\n\n\n\n\n음악표현\n\n\n\n\n\n\n\n\n\n\n\nFeb 14, 2023\n\n\n\n\n\n\n  \n\n\n\n\n3.1. 수학리뷰 - 복소수와 지수함수\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\n3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\n3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\n3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\n3.5. 디지털 신호 (Digital Signals)\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "",
    "text": "음악의 표현 방법 중 악보(sheet)와 기보법(notation), 음(note), 피치(pitch), 크로마(chroma) 등에 대해 다룬다."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#악보",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "악보",
    "text": "악보\nFull Score (전체 악보) - 위에서부터 악기별로 악보가 정렬되어 있다.\n\nImage(\"../img/2.music_representation/FMP_C1_F10.png\", width=400, height=400)\n\n\n\n\n\n예전에는 고품질의 표기를 그리는 것이 중요했으며, 이는 “music engraving”이라고 불렸다.\n하지만 요즘은 컴퓨터 소프트웨어가 악보를 그릴 수 있다. 아래는 위의 악보를 컴퓨터가 똑같이 제작한 버전의 악보이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#기보법-music-notation",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "기보법 (Music Notation)",
    "text": "기보법 (Music Notation)\n\n오선보(staff)는 5개의 수평선들과 네 개의 공백의 집합으로, 각기 다른 음 높낮이를 표현한다.\n5선 만으로는 음의 높이를 알 수 없다. 따라서, 음의 자리를 정해주는 음자리표(clef)를 5선의 맨 앞에 그려 넣는데, 이렇게 음자리표까지 그려져 음의 자리가 정해져야 비로소 보표가 된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F04.png\", width=500)\n\n\n\n\n\n조표(key signature)란 악보에서 음자리표와 박자표 사이에 붙는 올림표나 내림표를 말하며, 음표 앞에 표기하는 임시표와는 달리 보통의 음표보다 반음이 지속적으로 높거나 낮은 상태를 나타내기 위해 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F05.png\", width=500)\n\n\n\n\n\n악보는 음표(note), 쉼표(rest)로 형성되어 있다. (음표에 대한 자세한 설명은 생략한다.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_F07.png\", width=500)\n\n\n\n\n\n박자표(time signature)는 악곡의 박자 종류를 가리킨다. 박자표는 모두 분수의 꼴로 쓴다\n\n\nImage(\"../img/2.music_representation/FMP_C1_F06.png\", width=500)\n\n\n\n\n\n여러 오선을 합쳐 staff system을 만들 수 있다. 다양한 악기를 동시에 연주할 때 사용된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F08.png\", width=500)\n\n\n\n\n\n템포, 다이나믹, 표현 등을 위한 설명으로 아티큘레이션(articulation)을 쓸 수 있다. 아래의 그림에 나와있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F09.png\", width=500)"
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#음과-피치",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "음과 피치",
    "text": "음과 피치\n\n피치(=음고, 음높낮이)(pitch)란 음(note)이 얼마나 높은지 낮은지를 다루는 속성이다. 피치는 음파의 기본 주파수(fundamental frequency)와 긴밀히 연관되어 있다.\n옥타브(ocatve)는 두 음의 간격을 의미하는데, 한 옥타브 높은 음은 낮은 음은 두배의 기본 주파수이다. 예를 들어 440Hz의 A와 880Hz의 A는 한 옥타브를 사이에 두고 나눠진다.\n피치 클래스(pitch class)란 옥타브를 간격으로 있는 모든 음의 집합이다. 예를 들어 C {…, C1, C2, …}는 하나의 피치 클래스, D {…, D1, D2, …}는 또다른 피치 클래스이다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_PitchClassC.png\", width=500)\n\n\n\n\n\nimport numpy as np\n\ndef generate_sinusoid_pitches(pitches=[69], dur=0.5, Fs=4000, amp=0.25):\n    \"\"\"Generation of sinusoids for a given list of MIDI pitches\n\n    Args:\n        pitches (list): List of MIDI pitches (Default value = [69])\n        dur (float): Duration (in seconds) of each sinusoid (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 4000)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = []\n    for p in pitches:\n        freq = 2 ** ((p - 69) / 12) * 440\n        x = np.append(x, np.sin(2 * np.pi * freq * t))\n    x = amp * x / np.max(x)\n    return x, t\n\n\nFs = 22050\n\npitches = [36,48,60,72,84,96,108]\nx, t = generate_sinusoid_pitches(pitches=pitches, Fs=Fs)\nprint('Pitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}', flush=True)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nPitch class C = {..., C1, C2, C3, C4, C5, C6, C7, ...}\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n음계(scale)는 음악에서 피치(pitch) 순서로 된 음의 집합을 말한다. 악곡을 주로 구성하는 음을 나타내며, 음계의 종류에 따라 곡의 분위기가 달라진다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_MusicalScales.png\", width=500)\n\n\n\n\n\ndur = 0.5\nFs = 22050\n\nx_maj, t = generate_sinusoid_pitches(pitches=[60,62,64,65,67,69,71,72], Fs=Fs)\nx_min, t = generate_sinusoid_pitches(pitches=[60,62,63,65,67,68,70,72], Fs=Fs)\n\nprint('C major scale', flush=True)\nipd.display(ipd.Audio(data=x_maj, rate=Fs))\nprint('C minor scale', flush=True)\nipd.display(ipd.Audio(data=x_min, rate=Fs))\n\nC major scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nC minor scale\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n평균율(equal temperament)이란 한 옥타브를 12개의 동일한 음계 단계로 나눈 것을 의미한다.\n두 연속된 음계 사이의 차이를 반음(semitone)이라고 하는데, 이는 12음 음계의 가장 작은 간격이다. 음악인들은 이를 ’half-step’이라고도 말한다.\n12음 평균율 음계에는 12개의 피치 클래스가 있다. 서양 음악 표기법에서 이러한 피치 클래스는 알파벳과 임시표(accidental)를 결합하여 표시된다. 7개의 피치 클래스(C 장조에 해당)는 문자 C, D, E, F, G, A 및 B로 표시된다. 이러한 피치 클래스는 피아노 건반의 흰색 건반에 해당된다. 나머지 5개의 피치 등급은 피아노 건반의 검은 건반에 해당하며 알파벳과 임시표(♯ ,♭)의 조합으로 표시된다. 샵(♯)은 음을 반음 올리고 플랫(♭)은 반음 내린 것으로 음 이름 뒤에 표시된다: C♯, D♯, F♯, G♯, A♯ 혹은 D♭, E♭, G♭, A♭, B♭. 이 때 C♯과 D♭는 같은 피치 클래스를 나타낸다. 이는 “enharmonic equivalence”로도 알려져 있다.\n\n과학적 피치 표기\n\n12음 평균율의 음에 이름을 지정하기 위해 피치 클래스를 표시하는 것 외에도 옥타브에 대한 식별자가 필요하다. 과학적 피치 표기법에 따라 각 음은 피치 클래스 이름과 옥타브를 나타내는 숫자로 지정된다. 음 A4는 440Hz의 기본 주파수를 갖는 것으로 결정되어 기준 역할을 한다. 옥타브 수는 피치 클래스 B의 음에서 피치 클래스 C의 음으로 올라갈 때 1씩 증가한다.\n다음 그림은 C3에서 C5까지의 건반과 서양 음악 표기법을 사용하는 해당 음표가 있는 피아노 건반 부분을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F02.png\", width=500)\n\n\n\n\n\ndur = 0.2\nFs = 22050\npitches = range(48,73)\n\nx_chromatic, t = generate_sinusoid_pitches(pitches=pitches, dur=dur, Fs=Fs)\n\nprint('Sinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):', flush=True)\nipd.display(ipd.Audio(data=x_chromatic, rate=Fs))\n\nSinusoidal sonification of the chromatic scale ranging from C3 (p=48) to C5 (p=72):\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "href": "posts/2. Music Representation/2.1.Sheet_Music.html#크로마chroma와-셰퍼드-톤shepard-tones",
    "title": "2.1. 악보 (Sheet Music)",
    "section": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)",
    "text": "크로마(Chroma)와 셰퍼드 톤(Shepard Tones)\n크로마란?\n\n피치에 따라 평균율 음계의 모든 음을 순서대로 배열하면, 음계의 모든 음이 같은 간격으로 배열된 평균율의 크로마틱 음계(chromatic scale)를 얻을 수 있다.\n“Chromatic”이라는 용어는 색을 의미하는 그리스어 “chroma”에서 유래했다.\n음악적 맥락에서 크로마(chroma)라는 용어는 12개의 다른 피치 클래시와 밀접한 관련이 있다. 예를 들어, C2와 C5 음은 모두 같은 크로마 값 C를 가지고 있다.\n즉, 크로마 값이 같은 모든 음은 동일한 피치 클래스에 속한다.\n같은 피치클래스에 속하거나 크로마 값이 같은 음은 유사하게 인식된다. 반면에, 다른 피치 클래스에 속하거나 다른 크로마 값을 갖는 음은 서로 다른 것으로 인식된다.\n크로마 값의 주기적 특성은 아래 그림과 같이 크로마 원에 의해 설명된다.\n이 개념을 확장하면, 로저 셰퍼드(1929)의 이름을 딴 셰퍼드의 피치 나선(Shepard’s helix of pitch)은 선형 피치 공간을 하나의 수직선을 따라 옥타브 관련 피치가 놓이도록 원통을 감싸고 있는 나선으로 표현한다. 실린더가 수평면에 투영되면 크로마원이 생성된다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F03.png\", width=500)\n\n\n\n\n셰퍼드 톤\n\nShepard의 피치 나선은 Shepard 톤을 사용하여 음향화할 수 있으며, 각 톤은 옥타브로 구분된 사인파의 가중 중첩이다.\n반음계 위로 올라가는 이 음조를 연주할 때, 계속해서 위로 올라가는 음조의 청각적 환영을 얻는다(펜로즈 계단의 시각적 착시와 유사; 아래 그림).\n\n\nImage(\"../img/2.music_representation/FMP_C1_PenroseStairs.png\", width=200)\n\n\n\n\n\n뒤의 코드 예시에서 인간이 들을 수 있는 사인파 (20~20000헤르츠의 주파수)만 사용해보자. 특정 가중은 사용되지 않는다(모든 사인파는 1의 크기를 가짐).\n마지막으로 셰퍼드 톤은 크로마틱 스케일로 C3 (MIDI pitch 48) 부터 C5 (MIDI pitch 72)까지로 생성된다.\n\n\ndef generate_shepard_tone(freq=440, dur=0.5, Fs=44100, amp=1):\n    \"\"\"Generate Shepard tone\n\n    Args:\n        freq (float): Frequency of Shepard tone (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 0.5)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Shepard tone\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    num_sin = 1\n    x = np.sin(2 * np.pi * freq * t)\n    freq_lower = freq / 2\n    while freq_lower > 20:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_lower * t)\n        freq_lower = freq_lower / 2\n    freq_upper = freq * 2\n    while freq_upper < 20000:\n        num_sin += 1\n        x = x + np.sin(2 * np.pi * freq_upper * t)\n        freq_upper = freq_upper * 2\n    x = x / num_sin\n    x = amp * x / np.max(x)\n    return x, t\n\ndef f_pitch(p):\n    F_A4 = 440\n    return F_A4 * 2 ** ((p - 69) / 12)\n    \nFs = 44100\ndur = 0.5\n\npitch_start = 48\npitch_end = 72\nscale = []\nfor p in range(pitch_start, pitch_end + 1):\n    freq = f_pitch(p)    \n    s, t = generate_shepard_tone(freq=freq, dur=dur, Fs=Fs, amp = 0.5)\n    scale = np.concatenate((scale, s))\n    \nipd.display(ipd.Audio(scale, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nShepard–Risset Glissando\n\n이산적인 스케일을 사용하는대신 연속적인 셰퍼든 톤의 등락을 생성할 수 있다.: (Shepard–Risset glissando)\n뒤의 코드 예시는 상승하는 glissando를 생성한다.\n첫 째로 기하급수적으로 상승하는 chirp 신호가 정의된다. 이때 순간 주파수(instantaneous frequency)는 정현파 변수의 미분으로 주어진다.\n생성된 chirp 신호는 정확히 1옥타브를 커버한다. 그런 다음 Shepared 톤과 유사하게, 옥타브로 분리된 처프의 중첩(superposition)이 생성된다. 한 옥타브를 커버하고 Shepard–Risset glissando의 끝 부분은 (지각적으로) 시작 부분과 일치한다. 따라서 여러 glissando를 연결하여 논스톱 버전을 얻는다.\n\n\ndef generate_chirp_exp_octave(freq_start=440, dur=8, Fs=44100, amp=1):\n    \"\"\"Generate one octave of a chirp with exponential frequency increase\n\n    Args:\n        freq_start (float): Start frequency of chirp (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n\n    Returns:\n        x (np.ndarray): Chirp signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = np.sin(2 * np.pi * freq_start * np.power(2, t / dur) / np.log(2) * dur)\n    x = amp * x / np.max(x)\n    return x, t\n\n\ndef generate_shepard_glissando(num_octaves=3, dur_octave=8, Fs=44100):\n    \"\"\"Generate several ocatves of a Shepared glissando\n\n    Args:\n        num_octaves (int): Number of octaves (Default value = 3)\n        dur_octave (int): Duration (in seconds) per octave (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n\n    Returns:\n        x (np.ndarray): Shepared glissando\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    freqs_start = 10 * 2**np.arange(0, 11)\n    # Generate Shepard glissando by superimposing chirps that differ by octaves\n    for freq in freqs_start:\n        if freq == 10:\n            x, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n        else:\n            chirp, t = generate_chirp_exp_octave(freq_start=freq, dur=dur_octave, Fs=Fs, amp=1)\n            x = x + chirp\n    x = x / len(freqs_start)\n    # Concatenate several octaves\n    x = np.tile(x, num_octaves)\n    N = len(x)\n    t = np.arange(N) / Fs\n    return x, t\n    \nglissando, t = generate_shepard_glissando(num_octaves=3, dur_octave=8)\nipd.display(ipd.Audio(glissando, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_SheetMusic.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_MusicalNotesPitches.html\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C1/C1S1_ChromaShepard.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "",
    "text": "음악의 표현 방법 중 기호(심볼릭) 표현에 대해 알아본다. 피아노-롤(piano-roll), 미디(MIDI) 등이 있다."
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#피아노-롤piano-roll-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "피아노-롤(piano-roll) 표현",
    "text": "피아노-롤(piano-roll) 표현\n\n피아노-롤은 피아노와 관련된 음 정보들을 모아 가시화한 것을 일반적으로 말한다.\n드뷔시와 베토벤 음악의 피아노롤을 아래 영상과 같이 표현할 수 있다.\n\n\nipd.display( ipd.YouTubeVideo(\"LlvUepMa31o\", start=15) )\n\n\n        \n        \n\n\n\nipd.display( ipd.YouTubeVideo(\"Kri2jWr08S4\", start=11) )"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#미디-midi-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "미디 (MIDI) 표현",
    "text": "미디 (MIDI) 표현\n\n또다른 기호 표현으로는 MIDI(Musical Instrument Digital Interface) 스탠다드가 있다. MIDI는 1980년대 초반 전자 음악 악기 시장의 급성장과 함께 출현했다.\nMIDI 메시지는 음(note) 온셋, 음 오프셋, 강도(intensity or “velocity”)와 같은 정보를 인코딩한다. 컴퓨터에서 MIDI 파일은 MIDI 메시지들과 다른 메타데이터를 보관한다.\nMIDI 노트넘버(MIDI note number)는 0과 127 사이의 정수로 노트의 피치를 인코딩한다. 가장 중요한 것으로는 C4(중간 C)는 MIDI 노트넘버 60이고, A4(concert A440)은 MIDI 노트넘버 69이다. MIDI 노트넘버는 12개로 나누어져있으며 한 옥타브씩 나누어진다 (e.g. 72 = C5, 84 = C6, etc.)\n\n\nImage(\"../img/2.music_representation/FMP_C1_MIDI-NoteNumbers.png\", width=500)\n\n\n\n\n\n키 벨로시티(key velocity)는 0과 127 사이의 정수로 소리의 강도를 조정한다.\nMIDI 채널은 0과 15 사이의 정수로 신디사이저가 특정 악기를 사용하도록 안내한다.\nMIDI는 사분음표를 clock pulses 또는 틱으로 세분화한다. 예를 들어, 분기 음 당 펄스 수(PPQN)를 120으로 정의하면 60개의 틱이 8번째 음의 길이를 나타낸다.\n또한 MIDI는 템포를 BPM으로 인코딩하여 절대적인 시간 정보를 알려준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F13.png\", width=600)\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.mid\")\nmidi_list = []\n\nfor instrument in midi_data.instruments:\n    for note in instrument.notes:\n        start = note.start\n        end = note.end\n        pitch = note.pitch\n        velocity = note.velocity\n        midi_list.append([start, end, pitch, velocity, instrument.name])\n        \nmidi_list = sorted(midi_list, key=lambda x: (x[0], x[2]))\n\ndf = pd.DataFrame(midi_list, columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.25\n      0.50\n      43\n      113\n      Piano\n    \n    \n      0.25\n      0.50\n      55\n      76\n      Piano\n    \n    \n      0.25\n      0.50\n      67\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      43\n      113\n      Piano\n    \n    \n      0.50\n      0.75\n      55\n      76\n      Piano\n    \n    \n      0.50\n      0.75\n      67\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      43\n      113\n      Piano\n    \n    \n      0.75\n      1.00\n      55\n      76\n      Piano\n    \n    \n      0.75\n      1.00\n      67\n      76\n      Piano\n    \n    \n      1.00\n      2.00\n      39\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      51\n      126\n      Piano\n    \n    \n      1.00\n      2.00\n      63\n      70\n      Piano\n    \n    \n      2.25\n      2.50\n      41\n      113\n      Piano\n    \n    \n      2.25\n      2.50\n      53\n      76\n      Piano\n    \n    \n      2.25\n      2.50\n      65\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      41\n      113\n      Piano\n    \n    \n      2.50\n      2.75\n      53\n      76\n      Piano\n    \n    \n      2.50\n      2.75\n      65\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      41\n      113\n      Piano\n    \n    \n      2.75\n      3.00\n      53\n      76\n      Piano\n    \n    \n      2.75\n      3.00\n      65\n      76\n      Piano\n    \n    \n      3.00\n      5.00\n      38\n      112\n      Piano\n    \n    \n      3.00\n      5.00\n      50\n      126\n      Piano\n    \n    \n      3.00\n      5.00\n      62\n      71\n      Piano\n    \n  \n\n\n\n\nFs = 22050\naudio_data = midi_data.synthesize(fs=Fs)\nipd.Audio(audio_data, rate=Fs)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\ndef midi_to_list(midi):\n    \"\"\"Convert a midi file to a list of note events\n\n    Args:\n        midi (str or pretty_midi.pretty_midi.PrettyMIDI): Either a path to a midi file or PrettyMIDI object\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(midi, str):\n        midi_data = pretty_midi.pretty_midi.PrettyMIDI(midi)\n    elif isinstance(midi, pretty_midi.pretty_midi.PrettyMIDI):\n        midi_data = midi\n    else:\n        raise RuntimeError('midi must be a path to a midi file or pretty_midi.PrettyMIDI')\n\n    score = []\n\n    for instrument in midi_data.instruments:\n        for note in instrument.notes:\n            start = note.start\n            duration = note.end - start\n            pitch = note.pitch\n            velocity = note.velocity / 128.\n            score.append([start, duration, pitch, velocity, instrument.name])\n    return score\n\n\ndef visualize_piano_roll(score, xlabel='Time (seconds)', ylabel='Pitch', colors='FMP_1', velocity_alpha=False,\n                         figsize=(12, 4), ax=None, dpi=72):\n    \"\"\"Plot a pianoroll visualization\n    Args:\n        score: List of note events\n        xlabel: Label for x axis (Default value = 'Time (seconds)')\n        ylabel: Label for y axis (Default value = 'Pitch')\n        colors: Several options: 1. string of FMP_COLORMAPS, 2. string of matplotlib colormap,\n            3. list or np.ndarray of matplotlib color specifications,\n            4. dict that assigns labels  to colors (Default value = 'FMP_1')\n        velocity_alpha: Use the velocity value for the alpha value of the corresponding rectangle\n            (Default value = False)\n        figsize: Width, height in inches (Default value = (12)\n        ax: The Axes instance to plot on (Default value = None)\n        dpi: Dots per inch (Default value = 72)\n    Returns:\n        fig: The created matplotlib figure or None if ax was given.\n        ax: The used axes\n    \"\"\"\n    fig = None\n    if ax is None:\n        fig = plt.figure(figsize=figsize, dpi=dpi)\n        ax = plt.subplot(1, 1, 1)\n\n    labels_set = sorted(set([note[4] for note in score]))\n    colors = color_argument_to_dict(colors, labels_set)\n\n    pitch_min = min(note[2] for note in score)\n    pitch_max = max(note[2] for note in score)\n    time_min = min(note[0] for note in score)\n    time_max = max(note[0] + note[1] for note in score)\n\n    for start, duration, pitch, velocity, label in score:\n        if velocity_alpha is False:\n            velocity = None\n        rect = patches.Rectangle((start, pitch - 0.5), duration, 1, linewidth=1,\n                                 edgecolor='k', facecolor=colors[label], alpha=velocity)\n        ax.add_patch(rect)\n\n    ax.set_ylim([pitch_min - 1.5, pitch_max + 1.5])\n    ax.set_xlim([min(time_min, 0), time_max + 0.5])\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.grid()\n    ax.set_axisbelow(True)\n    ax.legend([patches.Patch(linewidth=1, edgecolor='k', facecolor=colors[key]) for key in labels_set],\n              labels_set, loc='upper right', framealpha=1)\n\n    if fig is not None:\n        plt.tight_layout()\n\n    return fig, \n\n\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nmidi_data = pretty_midi.PrettyMIDI(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\nscore = midi_to_list(midi_data)\nvisualize_piano_roll(score, figsize=(8, 3), velocity_alpha=True);\n\n\n\n\n\nimport music21 as m21\n\ns = m21.converter.parse(\"../data_FMP/FMP_C1_F12_Bach_BWV846_Sibelius-Tracks.mid\")\ns.plot('pianoroll', figureSize=(10, 3))"
  },
  {
    "objectID": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "href": "posts/2. Music Representation/2.2.Symbolic_Representation.html#악보적score-표현",
    "title": "2.2. 기호 표현 (Symbolic Representation)",
    "section": "악보적(score) 표현",
    "text": "악보적(score) 표현\n\n기호적 악보 표현은 “2.1.Sheet_Music.ipynb”에서 설명한 음악적 기호들을 인코딩한다. (음자리표, 조표 등등) 하지만 이를 악보로 가시화하는 것이 아니라 저장하는데, MusicXML같은 파일로 저장한다.\n아래 그 예시가 있다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F15.png\", width=400)\n\n\n\n\n\ndef xml_to_list(xml):\n    \"\"\"Convert a music xml file to a list of note events\n\n    Args:\n        xml (str or music21.stream.Score): Either a path to a music xml file or a music21.stream.Score\n\n    Returns:\n        score (list): A list of note events where each note is specified as\n            ``[start, duration, pitch, velocity, label]``\n    \"\"\"\n\n    if isinstance(xml, str):\n        xml_data = m21.converter.parse(xml)\n    elif isinstance(xml, m21.stream.Score):\n        xml_data = xml\n    else:\n        raise RuntimeError('midi must be a path to a midi file or music21.stream.Score')\n\n    score = []\n\n    for part in xml_data.parts:\n        instrument = part.getInstrument().instrumentName\n\n        for note in part.flat.notes:\n\n            if note.isChord:\n                start = note.offset\n                duration = note.quarterLength\n\n                for chord_note in note.pitches:\n                    pitch = chord_note.ps\n                    volume = note.volume.realized\n                    score.append([start, duration, pitch, volume, instrument])\n\n            else:\n                start = note.offset\n                duration = note.quarterLength\n                pitch = note.pitch.ps\n                volume = note.volume.realized\n                score.append([start, duration, pitch, volume, instrument])\n\n    score = sorted(score, key=lambda x: (x[0], x[2]))\n    return score\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F01_Beethoven_FateMotive_Sibelius-Tracks.xml\")\nxml_list = xml_to_list(xml_data)\n\ndf = pd.DataFrame(xml_list[:9], columns=['Start', 'End', 'Pitch', 'Velocity', 'Instrument'])\nhtml = df.to_html(index=False, float_format='%.2f', max_rows=8)\nipd.HTML(html)\n\n\n\n  \n    \n      Start\n      End\n      Pitch\n      Velocity\n      Instrument\n    \n  \n  \n    \n      0.50\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      0.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      55.00\n      0.71\n      Piano (2)\n    \n    \n      1.00\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1.50\n      0.50\n      67.00\n      0.71\n      Piano (2)\n    \n    \n      2.00\n      2.00\n      63.00\n      0.71\n      Piano (2)\n    \n    \n      2.50\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n    \n      3.00\n      0.50\n      43.00\n      1.00\n      Piano (2)\n    \n  \n\n\n\n\nvisualize_piano_roll(xml_list, figsize=(8, 3), velocity_alpha=True,\n                               xlabel='Time (quarter lengths)');\n\n\n\n\n\nxml_data = m21.converter.parse(\"../data_FMP/FMP_C1_F10_Beethoven_Fifth-MM1-21_Sibelius-Orchestra.xml\")\nxml_list = xml_to_list(xml_data)\n\nvisualize_piano_roll(xml_list, figsize=(10, 7), velocity_alpha=False,\n                               colors='gist_rainbow', xlabel='Time (quarter lengths)');\n\n\n\n\n기호 음악 표현법을 사용하는 파이썬 라이브러리\n\nPrettyMIDI: MIDI 읽기, 컨버팅 등\nmusic21: musicxml파일 다루기\npypianoroll: 피아노롤 비주얼\n\n\n출처:\n\nhttps://musicinformationretrieval.com/\nhttps://www.audiolabs-erlangen.de/FMP\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "",
    "text": "음악의 표현 방법 중 오디오 표현에 대해 알아본다. 음파(wave), 주파수(frequency), 고조파(harmonics), 강도(intensity), 라우드니스(loudness), 음색(timbre) 등의 중요한 개념을 포함한다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#들을-수-있는-주파수-범위",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#들을-수-있는-주파수-범위",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "들을 수 있는 주파수 범위",
    "text": "들을 수 있는 주파수 범위\n\n정현파(sinusoidal wave)의 주파수가 높을수록 더 높은 소리를 낸다.\n인간의 가청 주파수 범위는 약 20Hz와 20000Hz(20 kHz) 사이이다. 다른 동물들은 다른 청력 범위를 가지고 있다. 예를 들어, 개의 청력 범위의 상단은 약 45kHz이고 고양이의 청력은 64kHz인 반면, 박쥐는 심지어 100kHz 이상의 주파수를 감지할 수 있다. 이는 사람의 청각 능력을 뛰어넘는 초음파를 내는 개 호루라기를 이용해 주변 사람들을 방해하지 않고 동물을 훈련시키고 명령할 수 있는 이유이다.\n다음 실험에서 주파수가 초당 2배(1옥타브) 증가하는 처프(chirp) 신호를 생성한다.\n\n\ndef generate_chirp_exp_octave(freq_start=440, dur=8, Fs=44100, amp=1):\n    \"\"\"Generate one octave of a chirp with exponential frequency increase\n    Args:\n        freq_start (float): Start frequency of chirp (Default value = 440)\n        dur (float): Duration (in seconds) (Default value = 8)\n        Fs (scalar): Sampling rate (Default value = 44100)\n        amp (float): Amplitude of generated signal (Default value = 1)\n    Returns:\n        x (np.ndarray): Chirp signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    x = np.sin(2 * np.pi * freq_start * np.power(2, t / dur) / np.log(2) * dur)\n    x = amp * x / np.max(x)\n    return x, t\n\n\n# 20Hz부터 시작하여 주파수는 총 10초 동안 20480Hz까지 상승한다.\nFs = 44100\ndur = 1\nfreq_start = 20 * 2**np.arange(10)\nfor f in freq_start:\n    if f==freq_start[0]:\n        chirp, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=.25)\n    else:\n        chirp_oct, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=.25)\n        chirp = np.concatenate((chirp, chirp_oct))\n\nipd.display(ipd.Audio(chirp, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n# 640Hz부터 시작하여 주파수는 총 10초 동안 20Hz까지 하락한다.\n\nFs = 8000\ndur = 2\nfreq_start = 20 * 2**np.arange(5)\nfor f in freq_start:\n    if f==freq_start[0]:\n        chirp, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=1)\n    else:\n        chirp_oct, t = generate_chirp_exp_octave(freq_start=f, dur=dur, Fs=Fs, amp=1)\n        chirp = np.concatenate((chirp,chirp_oct))    \n        \nchirp = chirp[::-1]    \nipd.display(ipd.Audio(chirp, rate=Fs))\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#피치와-중심-주파수center-frequency",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#피치와-중심-주파수center-frequency",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "피치와 중심 주파수(center frequency)",
    "text": "피치와 중심 주파수(center frequency)\n\n정현파는 음의 음향적 실현의 원형으로 간주될 수 있다. 때때로 정현파에서 나오는 소리를 하모닉 사운드(harmonic sound) 또는 순수 음색(pure tone)이라고 한다.\n주파수의 개념은 소리의 피치를 결정하는 것과 밀접한 관련이 있다. 일반적으로 피치는 소리의 주관적인 속성이다.\n복잡한 혼합음의 경우, 주파수와의 관계가 특히 모호할 수 있다. 그러나 순수 음색의 경우 주파수와 피치의 관계가 명확하다. 예를 들어, 440 Hz의 주파수를 갖는 정현파는 피치 A4에 해당한다. 이 특정한 피치는 콘서트 피치(concert pitch)로 알려져 있으며, 이는 연주를 위해 악기가 튜닝되는 기준 피치로 사용된다.\n주파수의 약간의 변화가 반드시 지각할 수 있는 변화로 이어지는 것은 아니기 때문에, 일반적으로 주파수의 전체 범위를 단일 피치와 연관시킨다.\n두 주파수가 2의 거듭제곱에 의해 차이가 나는 경우, 이는 옥타브의 개념과 연관된다.\n\n예를 들어, 피치 A3(220 Hz)와 피치 A4(440 Hz) 사이의 인식 거리는 피치 A4와 피치 A5(880 Hz) 사이의 인식 거리와 동일하다.\n즉, 피치에 대한 인간의 인식은 본질적으로 로그(logarithm)이다. 이 지각 특성은 이미 로그 주파수 축을 기준으로 옥타브를 12개의 반음으로 세분화하는 평균율(“equal-tempered scale”)을 정의하는 데 사용되었다.\n\n더 공식적으로, MIDI 노트 번호를 사용하여, 다음과 같이 정의된 중심 주파수(center frequency) \\(F_{pitch}(p)\\)(Hz 단위로 측정)를 각 피치 \\(p∈[0:127]\\) 에 연결할 수 있다.\n\n\\(F_{pitch}(p)=2^{(p−69)/12} \\cdot 440\\)\n\nMIDI 노트 번호 \\(p=69\\)는 기준으로 사용되며 피치 A4(440Hz)에 해당된다. 피치 넘버를 12(옥타브) 증가시키면 2배 증가한다. \\(F_{pitch} ( p + 12) = 2 \\cdot F_{pitch} ( p)\\)\n\n\n\n\nImage(\"../img/2.music_representation/FMP_C1_MIDI-NoteNumbers.png\", width=500)\n\n\n\n\n\ndef f_pitch(p):\n    \"\"\"Compute center frequency for (single or array of) MIDI note numbers\n    Args:\n        p (float or np.ndarray): MIDI note numbers\n    Returns:\n        freq_center (float or np.ndarray): Center frequency\n    \"\"\"\n    freq_center = 2 ** ((p - 69) / 12) * 440\n    return freq_center\n\nchroma = ['A ', 'A#', 'B ', 'C ', 'C#', 'D ', 'D#', 'E ', 'F ', 'F#', 'G ', 'G#']\n\nfor p in range(21, 109):\n    print('p = %3d (%2s%1d), freq = %7.2f ' % (p, chroma[(p-69) % 12], (p//12-1), f_pitch(p)))\n\np =  21 (A 0), freq =   27.50 \np =  22 (A#0), freq =   29.14 \np =  23 (B 0), freq =   30.87 \np =  24 (C 1), freq =   32.70 \np =  25 (C#1), freq =   34.65 \np =  26 (D 1), freq =   36.71 \np =  27 (D#1), freq =   38.89 \np =  28 (E 1), freq =   41.20 \np =  29 (F 1), freq =   43.65 \np =  30 (F#1), freq =   46.25 \np =  31 (G 1), freq =   49.00 \np =  32 (G#1), freq =   51.91 \np =  33 (A 1), freq =   55.00 \np =  34 (A#1), freq =   58.27 \np =  35 (B 1), freq =   61.74 \np =  36 (C 2), freq =   65.41 \np =  37 (C#2), freq =   69.30 \np =  38 (D 2), freq =   73.42 \np =  39 (D#2), freq =   77.78 \np =  40 (E 2), freq =   82.41 \np =  41 (F 2), freq =   87.31 \np =  42 (F#2), freq =   92.50 \np =  43 (G 2), freq =   98.00 \np =  44 (G#2), freq =  103.83 \np =  45 (A 2), freq =  110.00 \np =  46 (A#2), freq =  116.54 \np =  47 (B 2), freq =  123.47 \np =  48 (C 3), freq =  130.81 \np =  49 (C#3), freq =  138.59 \np =  50 (D 3), freq =  146.83 \np =  51 (D#3), freq =  155.56 \np =  52 (E 3), freq =  164.81 \np =  53 (F 3), freq =  174.61 \np =  54 (F#3), freq =  185.00 \np =  55 (G 3), freq =  196.00 \np =  56 (G#3), freq =  207.65 \np =  57 (A 3), freq =  220.00 \np =  58 (A#3), freq =  233.08 \np =  59 (B 3), freq =  246.94 \np =  60 (C 4), freq =  261.63 \np =  61 (C#4), freq =  277.18 \np =  62 (D 4), freq =  293.66 \np =  63 (D#4), freq =  311.13 \np =  64 (E 4), freq =  329.63 \np =  65 (F 4), freq =  349.23 \np =  66 (F#4), freq =  369.99 \np =  67 (G 4), freq =  392.00 \np =  68 (G#4), freq =  415.30 \np =  69 (A 4), freq =  440.00 \np =  70 (A#4), freq =  466.16 \np =  71 (B 4), freq =  493.88 \np =  72 (C 5), freq =  523.25 \np =  73 (C#5), freq =  554.37 \np =  74 (D 5), freq =  587.33 \np =  75 (D#5), freq =  622.25 \np =  76 (E 5), freq =  659.26 \np =  77 (F 5), freq =  698.46 \np =  78 (F#5), freq =  739.99 \np =  79 (G 5), freq =  783.99 \np =  80 (G#5), freq =  830.61 \np =  81 (A 5), freq =  880.00 \np =  82 (A#5), freq =  932.33 \np =  83 (B 5), freq =  987.77 \np =  84 (C 6), freq = 1046.50 \np =  85 (C#6), freq = 1108.73 \np =  86 (D 6), freq = 1174.66 \np =  87 (D#6), freq = 1244.51 \np =  88 (E 6), freq = 1318.51 \np =  89 (F 6), freq = 1396.91 \np =  90 (F#6), freq = 1479.98 \np =  91 (G 6), freq = 1567.98 \np =  92 (G#6), freq = 1661.22 \np =  93 (A 6), freq = 1760.00 \np =  94 (A#6), freq = 1864.66 \np =  95 (B 6), freq = 1975.53 \np =  96 (C 7), freq = 2093.00 \np =  97 (C#7), freq = 2217.46 \np =  98 (D 7), freq = 2349.32 \np =  99 (D#7), freq = 2489.02 \np = 100 (E 7), freq = 2637.02 \np = 101 (F 7), freq = 2793.83 \np = 102 (F#7), freq = 2959.96 \np = 103 (G 7), freq = 3135.96 \np = 104 (G#7), freq = 3322.44 \np = 105 (A 7), freq = 3520.00 \np = 106 (A#7), freq = 3729.31 \np = 107 (B 7), freq = 3951.07 \np = 108 (C 8), freq = 4186.01 \n\n\n\n이 공식으로부터, 두 개의 연속된 피치 p+1과 p의 주파수 비율은 일정하다.\n\n\\(F_\\mathrm{pitch}(p+1)/F_\\mathrm{pitch}(p) = 2^{1/12} \\approx 1.059463\\)\n\n반음의 개념을 일반화한 센트(cent)는 음악 간격에 사용되는 로그 단위를 나타낸다. 정의에 따라 옥타브는 \\(1200\\) 센트로 나뉘며, 각 반음은 \\(100\\)센트에 해당한다. 두 주파수(예: \\(\\omega_1\\) 및 \\(\\omega_2\\)) 사이의 센트 차이는 다음과 같다.\n\n\\(\\log_2\\left(\\frac{\\omega_1}{\\omega_2}\\right)\\cdot 1200.\\)\n\n1센트의 간격은 너무 작아서 연속된 음 사이를 지각할 수 없다. 지각할 수 있는 문턱은 사람마다 다르고 음색과 음악적 맥락과 같은 측면에 따라 달라진다.\n경험적으로 일반 성인은 25센트의 작은 피치 차이를 매우 안정적으로 인식할 수 있으며, 10센트의 차이는 훈련된 청취자만이 인식할 수 있다.\n그림에서와 같이, 기준으로 사용되는 \\(440~\\mathrm{Hz}\\)의 정현파와 다양한 차이를 가진 추가 정현파를 생성하여 본다.\n\n\ndef difference_cents(freq_1, freq_2):\n    \"\"\"Difference between two frequency values specified in cents\n\n    Args:\n        freq_1 (float): First frequency\n        freq_2 (float): Second frequency\n\n    Returns:\n        delta (float): Difference in cents\n    \"\"\"\n    delta = np.log2(freq_1 / freq_2) * 1200\n    return delta\n \ndef generate_sinusoid(dur=1, Fs=1000, amp=1, freq=1, phase=0):\n    \"\"\"Generation of sinusoid\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 1)\n        freq (float): Frequency of sinusoid (Default value = 1)\n        phase (float): Phase of sinusoid (Default value = 0)\n\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = amp * np.sin(2*np.pi*(freq*t-phase))\n    return x, t\n\n\ndur = 1\nFs = 4000\npitch = 69\nref = f_pitch(pitch)\nfreq_list = ref + np.array([0,2,5,10,ref])\nfor freq in freq_list:\n    x, t = generate_sinusoid(dur=dur, Fs=Fs, freq=freq)\n    print('freq = %0.1f Hz (MIDI note number 69 + %0.2f cents)' % (freq, difference_cents(freq,ref)))\n    ipd.display(ipd.Audio(data=x, rate=Fs))  \n\nfreq = 440.0 Hz (MIDI note number 69 + 0.00 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 442.0 Hz (MIDI note number 69 + 7.85 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 445.0 Hz (MIDI note number 69 + 19.56 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 450.0 Hz (MIDI note number 69 + 38.91 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nfreq = 880.0 Hz (MIDI note number 69 + 1200.00 cents)\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#데시벨-스케일-decibel-scale",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#데시벨-스케일-decibel-scale",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "데시벨 스케일 (Decibel Scale)",
    "text": "데시벨 스케일 (Decibel Scale)\n\n음악의 중요한 특성은 음량을 나타내는 음악 기호뿐만 아니라 음량을 나타내는 일반적인 용어인 다이나믹(dynamics)과 관련이 있다.\n물리적 관점에서 소리 힘(sound power)은 공기를 통해 모든 방향으로 흐르는 음원에 의해 단위 시간당 얼마나 많은 에너지가 방출되는지를 나타낸다.\n소리 강도/인텐시티(sound intensity)는 단위 면적당 소리 힘을 나타낸다. 실제로 소리 힘과 소리 강도는 인간 청취자와 연관된 극히 작은 값을 보여줄 수 있다.\n예를 들어, 인간이 들을 수 있는 순수 음색(pure tone)의 최소 소리 강도인 청각의 임계값(threshold of hearing, TOH)은 다음과 같이 작다.\n\n\\(I_\\mathrm{TOH}:=10^{-12}~\\mathrm{W}/\\mathrm{m}^2\\)\n\n게다가, 인간이 지각할 수 있는 강도의 범위는 \\(I_\\mathrm{TOP}:=10~\\mathrm{W}/\\mathrm{m}^2\\) (통증 임계값(threshold of pain, TOP))으로 매우 크다.\n실질적인 이유로, 힘과 강도를 표현하기 위해 로그 척도로 전환한다. 더 정확하게는 두 값 사이의 비율을 나타내는 로그 단위인 데시벨(dB) 척도를 사용한다.\n일반적으로 소리 강도의 경우 \\(I_\\mathrm{TOH}\\) 같은 값이 참조 역할을 한다.\n그런 다음 dB로 측정된 강도는 다음과 같이 정의된다.\n\n$ (I) := 10_{10}()$\n\n위의 정의에서 \\(\\mathrm{dB}(I_\\mathrm{TOH})=0\\)를 얻을 수 있고, 강도가 두배로 증가하면 대략 3dB 증가한다:\n\n\\(\\mathrm{dB}(2\\cdot I) = 10\\cdot \\log_{10}(2) + \\mathrm{dB}(I) \\approx 3 + \\mathrm{dB}(I)\\)\n\n데시벨 단위로 강도 값을 지정할 때 강도 수준(intensity levels)도 같이 언급된다.\n다음 표는 \\(\\mathrm{W}/\\mathrm{m}^2\\) 와 데시벨 단위로 몇 가지 일반적인 강도값(intensity value)을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_T01.png\", width=400)\n\n\n\n\n\n예시로 이를 보자.\n\n베토벤 5번 교항곡 시작 부분\n\n\n\nipd.Audio(\"../audio/beeth5_orch_21bars.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\ndef compute_power_db(x, Fs, win_len_sec=0.1, power_ref=10**(-12)):\n    \"\"\"Computation of the signal power in dB\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        Fs (scalar): Sampling rate\n        win_len_sec (float): Length (seconds) of the window (Default value = 0.1)\n        power_ref (float): Reference power level (0 dB) (Default value = 10**(-12))\n\n    Returns:\n        power_db (np.ndarray): Signal power in dB\n    \"\"\"\n    win_len = round(win_len_sec * Fs)\n    win = np.ones(win_len) / win_len\n    power_db = 10 * np.log10(np.convolve(x**2, win, mode='same') / power_ref)\n    return power_db\n\n\nFs = 22050\nx, Fs = librosa.load(\"../audio/beeth5_orch_21bars.wav\", sr=Fs, mono=True)\n\nwin_len_sec = 0.2\npower_db = compute_power_db(x, win_len_sec=win_len_sec, Fs=Fs)\n\n\nplot_signal(x, Fs, ylabel='Amplitude', color='gray')\nplot_signal(power_db, Fs, ylabel='Power (dB)', color='red')\nplt.show()"
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#라우드니스loudness",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#라우드니스loudness",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "라우드니스(Loudness)",
    "text": "라우드니스(Loudness)\n\n다이나믹과 소리 강도는 소리가 조용한 것에서 큰 것으로 확장되는 규모로 소리를 정렬할 수 있는 라우드니스(loudness)라고 불리는 지각적 특성과 관련이 있다.\n라우드니스는 주관적인 측정이며, 이는 개별 청취자(예: 나이는 소리에 대한 인간의 귀의 반응에 영향을 미치는 요인 중 하나)뿐만 아니라 지속 시간(duration) 또는 주파수와 같은 다른 소리 특성에도 영향을 미친다.\n\n예를 들어, 사람은 200ms 동안 지속되는 소리가 50ms 동안만 지속되는 유사한 소리보다 더 크게 느껴진다.\n게다가, 강도는 같지만 주파수가 다른 두 소리는 일반적으로 동일한 라우드니스로 인식되지 않는다.\n정상적인 청력을 가진 사람은 2~4kHz 정도의 소리에 가장 민감하며, 낮은 주파수뿐만 아니라 높은 주파수에서도 감도가 감소한다.\n\n정신음향(psychoacoustic) 실험을 바탕으로 주파수에 따른 순수 음색의 라우드니스는 단위 폰(unit phon)으로 결정되고 표현되어 왔다.\n다음 그림은 동일한 음량 윤곽선(equal loudness contours)을 보여준다. 각 윤곽선은 폰(phon)으로 주어진 고정된 음량에 대해 (로그로 간격을 둔) 주파수 축에 대한 소리 강도를 지정한다. 하나의 폰 단위는 1000Hz의 주파수에 대해 정규화되며, 여기서 하나의 폰 값은 dB 단위의 강도 수준과 같다. 0폰의 윤곽선은 주파수에 따라 청각 임계값(threshold of hearing)이 어떻게 달라지는지를 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F21.png\", width=400)\n\n\n\n\n\n윤곽선은 가중치 함수에 의해 대략적으로 설명될 수 있다. 다음 코드 셀에서 동일한 음량 윤곽선에 질적으로 근사하는 함수의 예를 찾을 수 있다.\n\n\ndef compute_equal_loudness_contour(freq_min=30, freq_max=15000, num_points=100):\n    \"\"\"Computation of the equal loudness contour\n\n    Args:\n        freq_min (float): Lowest frequency to be evaluated (Default value = 30)\n        freq_max (float): Highest frequency to be evaluated (Default value = 15000)\n        num_points (int): Number of evaluation points (Default value = 100)\n\n    Returns:\n        equal_loudness_contour (np.ndarray): Equal loudness contour (in dB)\n        freq_range (np.ndarray): Evaluated frequency points\n    \"\"\"\n    freq_range = np.logspace(np.log10(freq_min), np.log10(freq_max), num=num_points)\n    freq = 1000\n    # Function D from https://bar.wikipedia.org/wiki/Datei:Acoustic_weighting_curves.svg\n    h_freq = ((1037918.48 - freq**2)**2 + 1080768.16 * freq**2) / ((9837328 - freq**2)**2 + 11723776 * freq**2)\n    n_freq = (freq / (6.8966888496476 * 10**(-5))) * np.sqrt(h_freq / ((freq**2 + 79919.29) * (freq**2 + 1345600)))\n    h_freq_range = ((1037918.48 - freq_range**2)**2 + 1080768.16 * freq_range**2) / ((9837328 - freq_range**2)**2\n                                                                                     + 11723776 * freq_range**2)\n    n_freq_range = (freq_range / (6.8966888496476 * 10**(-5))) * np.sqrt(h_freq_range / ((freq_range**2 + 79919.29) *\n                                                                         (freq_range**2 + 1345600)))\n    equal_loudness_contour = 20 * np.log10(np.abs(n_freq / n_freq_range))\n    return equal_loudness_contour, freq_range\n\n\nequal_loudness_contour, freq_range = compute_equal_loudness_contour()\n\nplot_signal(equal_loudness_contour, T_coef=freq_range, figsize=(6,3), xlabel='Frequency (Hz)',\n            ylabel='Intensity (dB)', title='Equal loudness contour', color='red')\nplt.xscale('log')\nplt.grid()\nplt.show()\n\n\n\n\n\n동일 힘을 가지는 처프 신호\n\n이제 30Hz에서 시작하여 10000Hz로 끝나는, 주파수가 기하급수적으로 증가하는 차프 신호에 대한 작은 실험을 해보자.\n먼저, 전체 시간 간격에 걸쳐 동일한 강도의 차프 신호를 생성한다. 이 신호를 들을 때는 주파수가 증가함에 따라 신호가 먼저 커지고 약 4000Hz의 주파수를 지나면 다시 부드러워지는 느낌이 든다.\n\n\n\ndef generate_chirp_exp(dur, freq_start, freq_end, Fs=22050):\n    \"\"\"Generation chirp with exponential frequency increase\n\n    Args:\n        dur (float): Length (seconds) of the signal\n        freq_start (float): Start frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    freq = np.exp(np.linspace(np.log(freq_start), np.log(freq_end), N))\n    phases = np.zeros(N)\n    for n in range(1, N):\n        phases[n] = phases[n-1] + 2 * np.pi * freq[n-1] / Fs\n    x = np.sin(phases)\n    return x, t, freq\n\n\nFs = 22050\nfreq_start = 30 \nfreq_end = 10000\ndur = 10\nx, t, freq = generate_chirp_exp(dur, freq_start, freq_end, Fs=Fs)\n\n\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [3, 2]}, figsize=(7, 5))\nN, H = 1024, 512\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, pad_mode='constant')\nplot_matrix(np.log(1+np.abs(X)), Fs=Fs/H, Fs_F=N/Fs, ax=[ax[0,0], ax[0,1]], \n            title='Spectrogram of chirp', colorbar=True)\n\nwin_len_sec = 0.1\npower_db = compute_power_db(x, win_len_sec=win_len_sec, Fs=Fs)\nplot_signal(power_db, Fs=Fs, ax=ax[1,0], title='Sound power level', ylabel='Power (dB)', color='red')\nax[1,0].set_ylim([103, 137])\nax[1,1].set_axis_off()\nplt.tight_layout()\nplt.show()\n\ndisplay(Audio(x, rate=Fs) )\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n동일 라우드니스를 가지는 처프 신호\n\n둘째로, 위에서 생성된 동일 라우드니스 윤곽에 따라 신호의 진폭(amplitude)을 조정한다.\n이 경우 전체 주파수 범위를 통해 스위핑할 때 결과로 발생하는 처프 신호의 라우드니스가 동일한 것으로 보인다.\n\n\n\ndef generate_chirp_exp_equal_loudness(dur, freq_start, freq_end, Fs=22050):\n    \"\"\"Generation chirp with exponential frequency increase and equal loudness\n\n    Args:\n        dur (float): Length (seconds) of the signal\n        freq_start (float): Starting frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n        intensity (np.ndarray): Instant intensity of the signal\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    intensity, freq = compute_equal_loudness_contour(freq_min=freq_start, freq_max=freq_end, num_points=N)\n    amp = 10**(intensity / 20)\n    phases = np.zeros(N)\n    for n in range(1, N):\n        phases[n] = phases[n-1] + 2 * np.pi * freq[n-1] / Fs\n    x = amp * np.sin(phases)\n    return x, t, freq, intensity\n\n\nx_equal_loudness, t, freq, intensity = generate_chirp_exp_equal_loudness(dur, freq_start, freq_end, Fs=Fs)\n\nfig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 0.05], \n                                          'height_ratios': [3, 2]}, figsize=(7, 5))\nN, H = 1024, 512\nX = librosa.stft(x_equal_loudness, n_fft=N, hop_length=H, win_length=N, pad_mode='constant')\nplot_matrix(np.log(1+np.abs(X)), Fs=Fs/H, Fs_F=N/Fs, ax=[ax[0,0], ax[0,1]], \n                     title='Spectrogram of chirp with equal loudness', colorbar=True)\n\nwin_len_sec = 0.1\npower_db = compute_power_db(x_equal_loudness, win_len_sec=win_len_sec, Fs=Fs)\nplot_signal(power_db, Fs=Fs, ax=ax[1,0], title='Sound power level', ylabel='Power (dB)', color='red')\nax[1,0].set_ylim([103, 137])\nax[1,1].set_axis_off()\nplt.tight_layout()\nplt.show()\n\ndisplay( Audio(x_equal_loudness, rate=Fs) )\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프와-adsr-모형envelope-and-adsr-model",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프와-adsr-모형envelope-and-adsr-model",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "엔벨로프와 ADSR 모형(Envelope and ADSR Model)",
    "text": "엔벨로프와 ADSR 모형(Envelope and ADSR Model)\n\n소리의 음색에 영향을 미치는 한 가지 소리 특성은 파형의 엔벨로프(envelope)이며, 이는 진폭에서 극단을 나타내는 매끄러운 곡선으로 간주될 수 있다.\n음향 합성에서 생성되는 신호의 엔벨로프는 어택(attack, A), 디케이(decay, D), 서스테인(sustain, S), 릴리스(release, R) 단계로 구성된 ADSR이라는 모델에 의해 종종 설명된다.\n4단계의 상대적 지속 시간과 진폭은 합성된 음색이 어떻게 들릴지에 큰 영향을 미친다.\n다음 그림은 이상적인 ADSR 모델과 피아노와 바이올린 사운드의 엔벨로프(단음 C4 재생)를 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F22a-23.png\", width=800)\n\n\n\n\n\n그림에서 알 수 있듯이, 하나의 음을 연주하면 이미 주기적인 요소뿐만 아니라 비주기적인 요소를 포함하여 시간이 지남에 따라 지속적으로 변화할 수 있는 특성을 가진 복잡한 음향 혼합물이 생성된다.\n어택(attack) 단계 동안, 소리는 보통 넓은 주파수 범위에 걸쳐 소음 같은 구성 요소로 축적된다. 소리가 시작될 때 소음과 같은 짧은 지속 시간의 소리를 과도음/트랜지언트(transient)라고 한다.\n디케이(decay) 단계 동안, 소리는 안정화되고 일정한 주기 패턴에 도달한다.\n서스테인(sustain) 단계 동안, 에너지는 꽤 일정하게 유지된다.\n릴리스(release) 단계에서는 소리가 사라진다.\n다음 코드 셀에서, 이상화된 ADSR 모델을 생성한다.\n\n\ndef compute_adsr(len_A=10, len_D=10, len_S=60, len_R=10, height_A=1.0, height_S=0.5):\n    \"\"\"Computation of idealized ADSR model\n\n    Args:\n        len_A (int): Length (samples) of A phase (Default value = 10)\n        len_D (int): Length (samples) of D phase (Default value = 10)\n        len_S (int): Length (samples) of S phase (Default value = 60)\n        len_R (int): Length (samples) of R phase (Default value = 10)\n        height_A (float): Height of A phase (Default value = 1.0)\n        height_S (float): Height of S phase (Default value = 0.5)\n\n    Returns:\n        curve_ADSR (np.ndarray): ADSR model\n    \"\"\"\n    curve_A = np.arange(len_A) * height_A / len_A\n    curve_D = height_A - np.arange(len_D) * (height_A - height_S) / len_D\n    curve_S = np.ones(len_S) * height_S\n    curve_R = height_S * (1 - np.arange(1, len_R + 1) / len_R)\n    curve_ADSR = np.concatenate((curve_A, curve_D, curve_S, curve_R))\n    return curve_ADSR\n\n\ncurve_ADSR = compute_adsr(len_A=10, len_D=10, len_S=60, len_R=10, height_A=1.0, height_S=0.5)\n\nplot_signal(curve_ADSR, figsize=(4,2.5), ylabel='Amplitude', title='ADSR model', color='red')\nplt.show()\n\ncurve_ADSR = compute_adsr(len_A=20, len_D=2, len_S=60, len_R=1, height_A=2.0, height_S=1.2)\nplot_signal(curve_ADSR, figsize=(4,2.5), ylabel='Amplitude', title='ADSR model', color='red')\nplt.show()\n\n\n\n\n\n\n\n\nADSR 모델은 단순화된 형태이며 특정 악기에서 생성되는 톤의 진폭 엔벨로프에 대한 의미 있는 근사치만 산출한다.\n예를 들어, 위와 같은 바이올린 소리는 ADSR 모델에 의해 잘 근사되지 않는다.\n\n우선 음량을 점차 늘려가며 부드럽게 연주하기 때문에 어택 국면이 퍼진다. 게다가, 디케이 단계가 없는 것처럼 보이고 그 이후의 서스테인 단계는 일정하지 않다; 대신 진폭 엔벨로프는 규칙적인 방식으로 진동한다. 바이올린 연주자가 활로 현을 켜는 것을 멈추면 릴리즈 단계가 시작된다. 그리고 나서 그 소리는 빠르게 사라진다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프-계산",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#엔벨로프-계산",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "엔벨로프 계산",
    "text": "엔벨로프 계산\n\n파형의 엔벨로프를 계산하는 방법은 여러 가지가 있다. 다음에서는 각 윈도우 섹션에 최대 필터를 적용하여 간단한 슬라이딩 윈도우 방식을 사용한다. 다음 코드 셀에서는 주어진 파형의 상한 엔벨로프와 하한 엔벨로프 및 파형의 크기 엔벨로프를 계산한다.\n\n\ndef compute_envelope(x, win_len_sec=0.01, Fs=4000):\n    \"\"\"Computation of a signal's envelopes\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        win_len_sec (float): Length (seconds) of the window (Default value = 0.01)\n        Fs (scalar): Sampling rate (Default value = 4000)\n\n    Returns:\n        env (np.ndarray): Magnitude envelope\n        env_upper (np.ndarray): Upper envelope\n        env_lower (np.ndarray): Lower envelope\n    \"\"\"\n    win_len_half = round(win_len_sec * Fs * 0.5)\n    N = x.shape[0]\n    env = np.zeros(N)\n    env_upper = np.zeros(N)\n    env_lower = np.zeros(N)\n    for i in range(N):\n        i_start = max(0, i - win_len_half)\n        i_end = min(N, i + win_len_half)\n        env[i] = np.amax(np.abs(x)[i_start:i_end])\n        env_upper[i] = np.amax(x[i_start:i_end])\n        env_lower[i] = np.amin(x[i_start:i_end])\n    return env, env_upper, env_lower\n    \n    \ndef compute_plot_envelope(x, win_len_sec, Fs, figsize=(6, 3), title=''):\n    \"\"\"Computation and subsequent plotting of a signal's envelope\n\n    Args:\n        x (np.ndarray): Signal (waveform) to be analyzed\n        win_len_sec (float): Length (seconds) of the window\n        Fs (scalar): Sampling rate\n        figsize (tuple): Size of the figure (Default value = (6, 3))\n        title (str): Title of the figure (Default value = '')\n\n    Returns:\n        fig (mpl.figure.Figure): Generated figure\n    \"\"\"\n    t = np.arange(x.size)/Fs\n    env, env_upper, env_lower = compute_envelope(x, win_len_sec=win_len_sec, Fs=Fs)\n    fig = plt.figure(figsize=figsize)\n    plt.plot(t, x, color='gray', label='Waveform')\n    plt.plot(t, env_upper, linewidth=2, color='cyan', label='Upper envelope')\n    plt.plot(t, env_lower, linewidth=2, color='blue', label='Lower envelope')\n    plt.plot(t, env, linewidth=2, color='red', label='Magnitude envelope')\n    plt.title(title)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.xlim([t[0], t[-1]])\n    #plt.ylim([-0.7, 0.7])\n    plt.legend(loc='lower right')\n    plt.show()\n    ipd.display(ipd.Audio(data=x, rate=Fs))\n    return fig\n\n\nFs = 11025\nwin_len_sec=0.05\n\nx, Fs = librosa.load(\"../audio/piano_c4.wav\", sr=Fs)\nfig = compute_plot_envelope(x, win_len_sec=win_len_sec, Fs=Fs, title='piano sound')\n\nx, Fs = librosa.load(\"../audio/violin_c4.wav\", sr=Fs)\nfig = compute_plot_envelope(x, win_len_sec=win_len_sec, Fs=Fs, title='violin sound')\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#비브라토-트레몰로-vibrato-and-tremolo",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#비브라토-트레몰로-vibrato-and-tremolo",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "비브라토, 트레몰로 Vibrato and Tremolo",
    "text": "비브라토, 트레몰로 Vibrato and Tremolo\n\n바이올린의 예에서 음색과 관련된 다른 현상들이 나타난다. 예를 들어, 진폭의 주기적인 변화를 관찰할 수 있다. 이러한 진폭 변조는 트레몰로(tremolo)로도 알려져 있다.\n트레몰로의 효과는 진동수의 규칙적인 변화(주파수 변조)로 구성된 음악적 효과인 비브라토와 함께 종종 동반된다.\n현악 이외에도 비브라토는 인간 가수들이 표현을 더하기 위해 주로 사용된다. 트레몰로와 비브라토가 단순히 강도와 주파수의 국소적인 변화라고 할지라도, 그것들이 반드시 전체적인 음조의 음량이나 음조의 지각된 변화를 불러일으키지는 않는다. 오히려, 그것들은 음악적 음색에 영향을 미치는 특징들이다.\n다음 코드 셀에서, 단순한 정현파, 비브라토가 있는 정현파, 트레몰로가 있는 정현파를 생성한다.\n\n\ndef generate_sinusoid_vibrato(dur=5, Fs=1000, amp=0.5, freq=440, vib_amp=1, vib_rate=5):\n    \"\"\"Generation of a sinusoid signal with vibrato\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 0.5)\n        freq (float): Frequency (Hz) of sinusoid (Default value = 440)\n        vib_amp (float): Amplitude (Hz) of the frequency oscillation (Default value = 1)\n        vib_rate (float): Rate (Hz) of the frequency oscillation (Default value = 5)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    freq_vib = freq + vib_amp * np.sin(t * 2 * np.pi * vib_rate)\n    phase_vib = np.zeros(num_samples)\n    for i in range(1, num_samples):\n        phase_vib[i] = phase_vib[i-1] + 2 * np.pi * freq_vib[i-1] / Fs\n    x = amp * np.sin(phase_vib)\n    return x, t\n\ndef generate_sinusoid_tremolo(dur=5, Fs=1000, amp=0.5, freq=440, trem_amp=0.1, trem_rate=5):\n    \"\"\"Generation of a sinusoid signal with tremolo\n\n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 0.5)\n        freq (float): Frequency (Hz) of sinusoid (Default value = 440)\n        trem_amp (float): Amplitude of the amplitude oscillation (Default value = 0.1)\n        trem_rate (float): Rate (Hz) of the amplitude oscillation (Default value = 5)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    amps = amp + trem_amp * np.sin(t * 2 * np.pi * trem_rate)\n    x = amps * np.sin(2*np.pi*(freq*t))\n    return x, t\n\n\nFs = 4000\ndur = 5\nfreq = 220\namp = 0.5\nfigsize = (8,2)\n\nx, t = generate_sinusoid(dur=dur, Fs=Fs, amp=amp, freq=freq)\nx_vib, t = generate_sinusoid_vibrato(dur=dur, Fs=Fs, amp=amp, freq=freq, vib_amp=6, vib_rate=5)\nx_trem, t = generate_sinusoid_tremolo(dur=dur, Fs=Fs, amp=amp, freq=freq, trem_amp=0.3, trem_rate=5)\n\n\nplot_signal(x, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nplot_signal(x_vib, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid with vibrato')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x_vib, rate=Fs))\n\nplot_signal(x_trem, Fs=Fs, figsize=figsize, ylabel='Amplitude', title='Sinusoid with tremolo')\nplt.ylim([-0.9, 0.9])\nplt.show()\nipd.display(ipd.Audio(data=x_trem, rate=Fs))\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#부분음부분파-partials",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#부분음부분파-partials",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "부분음/부분파 (Partials)",
    "text": "부분음/부분파 (Partials)\n\n아마도 음색을 특징 짓는 가장 중요하고 잘 알려진 속성은 특정 부분파(Partials)의 존재와 그 상대적 강점일 것이다.\n부분파는 음악 톤에서 가장 낮은 부분이 기본 주파수(fundamental frequency) 인 지배적 주파수이다.\n소리의 부분파는 스펙트로그램으로 시각화된다. 스펙트로그램(spectrogram)은 시간 경과에 따른 주파수 성분의 강도를 보여준다\n비조화(inharmonicity)는 가장 가까운 이상고조파(ideal harmonic)에서 벗어나는 부분적 정도를 나타낸다.\n명확하게 인식할 수 있는 음정을 가진 음악적 톤과 같은 소리의 경우, 대부분의 부분파는 고조파(harmonics)에 가깝다. 그러나 모든 부분파가 동일한 강도로 발생할 필요는 없다. 다음 그림은 서로 다른 악기에서 재생되는 단일 노트 C4에 대한 스펙트로그램 표현을 보여준다.\n\n\nImage(\"../img/2.music_representation/FMP_C1_F23_FourInstruments.png\", width=800)\n\n\n\n\n\n음의 기본 주파수(261.6Hz)와 고조파(261.6Hz의 정수 배수) 모두 수평 구조로 보인다.\n음악 톤의 디케이는 각각의 부분파에서 그에 상응하는 디케이에 의해 반영된다.\n톤의 에너지의 대부분은 낮은 부분에 포함되어 있고, 높은 부분에 대한 에너지는 낮은 경향이 있다. 이러한 분포는 많은 악기에서 일반적이다. 현악기의 경우, 소리는 풍부한 부분 스펙트럼을 갖는 경향이 있는데, 여기서 많은 에너지가 상부 고조파(harmonics)에도 포함될 수 있다. 이 그림은 또한 트레몰로(특히 플루트의 경우)와 비브라토(특히 바이올린의 경우)를 보여준다.\n\n다른 예\n\n# pure tone\nT = 2.0 # seconds\nf0 = 1047.0\nsr = 22050\nt = np.linspace(0, T, int(T*sr), endpoint=False) # time variable\nx = 0.1*np.sin(2*np.pi*f0*t)\nipd.Audio(x, rate=sr)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[:4096])\nX_mag = np.absolute(X)        # spectral magnitude\nf = np.linspace(0, sr, 4096)  # frequency variable\nplt.figure(figsize=(6, 2))\nplt.title('pure tone')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n# oboe C6\nx, sr = librosa.load('../audio/oboe_c6.wav')\nprint(x.shape)\nipd.Audio(x, rate=sr)\n\n(23625,)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[10000:14096])\nX_mag = np.absolute(X)\nplt.figure(figsize=(6, 2))\nplt.title('oboe C6')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\nx, sr = librosa.load('../audio/clarinet_c6.wav')\nprint(x.shape)\nipd.Audio(x, rate=sr)\n\n(51386,)\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x[10000:14096])\nX_mag = np.absolute(X)\nplt.figure(figsize=(6, 2))\nplt.title('clarinet C6')\nplt.plot(f[:2000], X_mag[:2000]) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n부분파의 구성 요소의 상대적 진폭 차이에 주목해보자. 세 신호 모두 거의 동일한 피치와 기본 주파수를 가지고 있지만, 음색은 다르다."
  },
  {
    "objectID": "posts/2. Music Representation/2.3.Audio_Representation.html#missing-fundamental",
    "href": "posts/2. Music Representation/2.3.Audio_Representation.html#missing-fundamental",
    "title": "2.3. 오디오 표현 (Audio Representation)",
    "section": "Missing Fundamental",
    "text": "Missing Fundamental\n\n앞서 말했듯이, 소리의 음색은 결정적으로 고조파에 걸친 신호의 에너지 분포에 따라 달라진다. 또한, 인식된 피치의 지각은 기본 주파수뿐만 아니라 더 높은 고조파와 그들의 관계에 따라 달라진다. 예를 들어, 인간은 이 피치와 관련된 기본 주파수가 완전히 누락된 경우에도 톤의 피치를 감지할 수 있다. 이 현상은 “missing fundamental”로 알려져 있다.\n다음 코드 예제에서는 음의 중심 주파수(center frequency)의 정수 배수인 주파수를 가진 (가중된) 정현파를 추가하여 소리를 생성한다. 특히 순수 톤(MIDI 피치 𝑝), 고조파가 있는 톤, missing fundamental의 고조파가 있는 톤, 두번 째 순수 톤(MIDI 피치 𝑝+12)을 생성한다.\n\n\ndef generate_tone(p=60, weight_harmonic=np.ones([16, 1]), Fs=11025, dur=2):\n    \"\"\"Generation of a tone with harmonics\n\n    Args:\n        p (float): MIDI pitch of the tone (Default value = 60)\n        weight_harmonic (np.ndarray): Weights for the different harmonics (Default value = np.ones([16, 1])\n        Fs (scalar): Sampling frequency (Default value = 11025)\n        dur (float): Duration (seconds) of the signal (Default value = 2)\n\n    Returns:\n        x (np.ndarray): Generated signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    freq = 2 ** ((p - 69) / 12) * 440\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = np.zeros(t.shape)\n    for h, w in enumerate(weight_harmonic):\n        x = x + w * np.sin(2 * np.pi * freq * (h + 1) * t)\n    return x, t\n\ndef plot_spectrogram(x, Fs=11025, N=4096, H=2048, figsize=(4, 2)):\n    \"\"\"Computation and subsequent plotting of the spectrogram of a signal\n\n    Args:\n        x: Signal (waveform) to be analyzed\n        Fs: Sampling rate (Default value = 11025)\n        N: FFT length (Default value = 4096)\n        H: Hopsize (Default value = 2048)\n        figsize: Size of the figure (Default value = (4, 2))\n\n    \"\"\"\n    N, H = 2048, 1024\n    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann')\n    Y = np.abs(X)\n    plt.figure(figsize=figsize)\n    librosa.display.specshow(librosa.amplitude_to_db(Y, ref=np.max),\n                             y_axis='linear', x_axis='time', sr=Fs, hop_length=H, cmap='gray_r')\n    plt.ylim([0, 3000])\n    # plt.colorbar(format='%+2.0f dB')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.tight_layout()\n    plt.show()\n\n\nFs = 11025\np = 60\n\nprint('Pure tone (p = %s):' % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0.2])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Tone with harmonics (p = %s):' % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Tone with harmonics and missing fundamental (p = %s):'  % p)\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nprint('Pure tone (p = %s):' % (p + 12))\nx, t = generate_tone(Fs=Fs, p=p, weight_harmonic=[0, 0.2])\nplot_spectrogram(x)\nipd.display(ipd.Audio(data=x, rate=Fs))\n\nPure tone (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nTone with harmonics (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nTone with harmonics and missing fundamental (p = 60):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nPure tone (p = 72):\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n출처:\n\nhttps://musicinformationretrieval.com/\nhttps://www.audiolabs-erlangen.de/FMP\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "",
    "text": "푸리에 변환(Fourier transform)을 보기 전에 이와 관련한 몇가지 수학적 개념(복소수, 지수함수)을 리뷰해보록 한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-개념",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-개념",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "기본 개념",
    "text": "기본 개념\n\n실수 부분 \\(\\mathrm{Re}(c) = a\\), 허수 부분 \\(\\mathrm{Im}(c) = b\\) 및 허수 단위 \\(i = \\sqrt{-1}\\)로 복소수 \\(c = a + ib\\)를 쓸 수 있다. 파이썬에서 기호 j는 허수의 단위를 나타내기 위해 사용된다. 또한 j 앞의 계수가 필요하다. 복소수를 지정하기 위해 complex라는 생성자를 사용할 수도 있다.\n\n\na = 1.5\nb = 0.8\nc = a + b*1j\nprint(c)\nc2 = complex(a,b)\nprint(c2)\n\n(1.5+0.8j)\n(1.5+0.8j)\n\n\n\nprint(np.real(c))\nprint(np.imag(c))\n\n1.5\n0.8\n\n\n\ndef generate_figure(figsize=(6, 2), xlim=[0, 1], ylim=[0, 1]):\n    \"\"\"Generate figure for plotting complex numbers\n\n    Args:\n        figsize: Figure size (Default value = (2, 2))\n        xlim: Limits of x-axis (Default value = [0, 1])\n        ylim: Limits of y-axis (Default value = [0, 1])\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.grid()\n    plt.xlim(xlim)\n    plt.ylim(ylim)\n    plt.xlabel(r'$\\mathrm{Re}$')\n    plt.ylabel(r'$\\mathrm{Im}$')\n\ndef plot_vector(c, color='k', start=0, linestyle='-'):\n    \"\"\"Plot arrow corresponding to difference of two complex numbers\n\n    Args:\n        c: Complex number\n        color: Color of arrow (Default value = 'k')\n        start: Complex number encoding the start position (Default value = 0)\n        linestyle: Linestyle of arrow (Default value = '-')\n\n    Returns:\n        arrow (matplotlib.patches.FancyArrow): Arrow\n    \"\"\"\n    return plt.arrow(np.real(start), np.imag(start), np.real(c), np.imag(c),\n                     linestyle=linestyle, head_width=0.05, fc=color, ec=color, overhang=0.3,\n                     length_includes_head=True)\n\n\nc = 1.5 + 0.8j\n\ngenerate_figure(xlim=[0, 2.5], ylim=[0, 1])\nv = plot_vector(c, color='k')\n\nplt.text(1.5, 0.8, '$c$', size='16')\nplt.text(0.8, 0.55, '$|c|$', size='16')\nplt.text(0.25, 0.05, '$\\gamma$', size='16');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표-표현-polar-representation",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표-표현-polar-representation",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "극좌표 표현 (Polar Representation)",
    "text": "극좌표 표현 (Polar Representation)\n\n복소수 \\(a+ib\\) 의 절대값 (absolute value or modulus)은 다음과 같이 정의된다.\n\n\\(|c| := \\sqrt{a^2 + b^2}.\\)\n\n(radian으로 주어진) 각도(angle)는 다음과 같다.\n\n\\(\\gamma := \\mathrm{atan2}(b, a).\\)\n\n이는 \\((-\\pi,\\pi]\\) 간격의 숫자를 생성하며, 이 값은 음의 값에 \\(2\\pi\\)를 추가하여 \\([0,2\\pi)\\)에 매핑될 수 있다. 각도(degree 단위)는 다음과 같이 구한다.\n\n\\(360 \\cdot \\frac{\\gamma}{2\\pi}\\)\n\n\n\nprint('Absolute value:', np.abs(c))\nprint('Angle (in radians):', np.angle(c))\nprint('Angle (in degree):', np.rad2deg(np.angle(c)))\nprint('Angle (in degree):', 360 * np.angle(c)/(2*np.pi) )\n\nAbsolute value: 1.7\nAngle (in radians): 0.48995732625372834\nAngle (in degree): 28.07248693585296\nAngle (in degree): 28.07248693585296\n\n\n\n복소수 \\(c=a+ib\\)는 \\((|c|, \\gamma)\\) 쌍에 의해 고유하게 정의되며, 이는 \\(c\\)의 극좌표 표현(polar representation)이라고도 한다. 다음과 같이 극좌표 표현 \\((|c|,\\gamma)\\)에서 데카르트 표현(Cartesian representation) \\((a,b)\\)를 얻는다.\n\n\\[\\begin{eqnarray}\na &=& |c| \\cdot \\cos(\\gamma) \\\\\nb &=& |c| \\cdot \\sin(\\gamma)\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#연산",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#연산",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "연산",
    "text": "연산\n\n두 복소수 \\(c_1=a_1+ib_1\\)와 \\(c_2=a_2+ib_2\\)의 경우, 합은 다음과 같다.\n\n\\[\nc_1 + c_2 = (a_1 + ib_1) + (a_2 + ib_2) := (a_1 + a_2) + i(b_1 + b_2)\n\\]\n\n실수 부분과 허수 부분을 개별적으로 합산하여 정의한다. 덧셈의 기하학적 직관은 평행사변형으로 시각화할 수 있다.\n\n\nc1 = 1.3 - 0.3j\nc2 = 0.3 + 0.5j\nc = c1 + c2\n\ngenerate_figure(xlim=[-0.3, 2.2], ylim=[-0.4, 0.6])\nv1 = plot_vector(c1, color='k')\nv2 = plot_vector(c2, color='b')\nplot_vector(c1, start=c2, linestyle=':', color='lightgray')\nplot_vector(c2, start=c1, linestyle=':', color='lightgray')\nv3 = plot_vector(c, color='r')\n\nplt.legend([v1, v2, v3], ['$c_1$', '$c_2$', '$c_1+c_2$']);\n\n\n\n\n\n두 숫자 \\(c_1=a_1+ib_1\\)와 \\(c_2=a_2+ib_2\\)의 복소수 곱셈은 다음과 같이 정의된다.\n\n\\[c = c_1 \\cdot c_2 = (a_1 + ib_1) \\cdot (a_2 + ib_2) := (a_1a_2 - b_1b_2) + i(a_1b_2 + b_1a_2).\\]\n\n기하학적으로, 이 곱은 각도를 더하고 절대값을 곱함으로써 얻어진다. 다시 말해, \\((|c_1|, \\gamma_1)\\)와 \\((|c_2|, \\gamma_2)\\)가 각각 \\(c_1\\)와 \\(c_1\\)의 극좌표 표현이라면, \\(c\\)의 극좌표 표현 \\((|c|, \\gamma)\\)는 다음과 같이 주어진다.\n\n\\[\\begin{eqnarray}\n\\gamma &=& \\gamma_1 + \\gamma_2 \\\\\n|c| &=& |c_1| \\cdot |c_2|\n\\end{eqnarray}\\]\n\nc1 = 1.0 - 0.5j\nc2 = 2.3 + 0.7j\nc = c1 * c2\n\ngenerate_figure(xlim=[-0.5, 4.0], ylim=[-0.75, 0.75])\nv1 = plot_vector(c1, color='k')\nv2 = plot_vector(c2, color='b')\nv3 = plot_vector(c, color='r')\nplt.legend([v1, v2, v3], ['$c_1$', '$c_2$', '$c_1 \\cdot c_2$']);"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표계-polar-coordinate-plot",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#극좌표계-polar-coordinate-plot",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "극좌표계 (Polar Coordinate Plot)",
    "text": "극좌표계 (Polar Coordinate Plot)\n\ndef plot_polar_vector(c, label=None, color=None, start=0, linestyle='-'):\n    # plot line in polar plane\n    line = plt.polar([np.angle(start), np.angle(c)], [np.abs(start), np.abs(c)], label=label, \n                     color=color, linestyle=linestyle)\n    # plot arrow in same color\n    this_color = line[0].get_color() if color is None else color\n    plt.annotate('', xytext=(np.angle(start), np.abs(start)), xy=(np.angle(c), np.abs(c)),\n                 arrowprops=dict(facecolor=this_color, edgecolor='none', \n                                 headlength=12, headwidth=10, shrink=1, width=0))\n\n\n#head_width=0.05, fc=color, ec=color, overhang=0.3, length_includes_head=True    \n    \nc_abs = 1.5\nc_angle = 45  # in degree\nc_angle_rad = np.deg2rad(c_angle) \na = c_abs * np.cos(c_angle_rad)\nb = c_abs * np.sin(c_angle_rad)\nc1 = a + b*1j    \nc2 = -0.5 + 0.75*1j\n\nplt.figure(figsize=(6, 6))\nplot_polar_vector(c1, label='$c_1$', color='k')\nplot_polar_vector(np.conj(c1), label='$\\overline{c}_1$', color='gray')\nplot_polar_vector(c2, label='$c_2$', color='b')\nplot_polar_vector(c1*c2, label='$c_1\\cdot c_2$', color='r')\nplot_polar_vector(c1/c2, label='$c_1/c_2$', color='g')\n\nplt.ylim([0, 1.8]);\nplt.legend(framealpha=1);"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#power-series-멱급수",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#power-series-멱급수",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "Power Series (멱급수)",
    "text": "Power Series (멱급수)\n\n실 지수 함수(real exponential function) \\(\\exp:\\mathbb{R}\\to \\mathbb{R}\\)는 많은 수학 응용에서 볼 수 있다. 그리고 이 함수는 많은 다른 방식으로 특성화될 수 있다.\n역사적으로 지수 함수는 금리를 고려할 때 \\(17^\\mathrm{th}\\) 세기에 Johann Bernoulli에 의해 연구된 바 있다.\n\n\\(1\\)의 이자를 매월 복합된 연간 금리로 이자 \\(a\\)를 얻는다고 가정하자. 그런 다음 매달 얻은 이자는 현재 값의 \\(\\frac{a}{12}\\)배이므로, 매달 총 값에 \\(\\left(1+\\frac{a}{12}\\right)\\)를 곱하고 연말의 값은 \\(\\left(1+\\frac{a}{12}\\right)^{12}\\)이다. 매일 이자가 복합되는 경우 \\(\\left(1+\\frac{a}{365}\\right)^{365}\\)가 된다.\n\n시간 간격을 더 짧게 함으로써 매년 증가하도록 하는 것은 지수 함수의 limit 정의로 이어진다.\n\n\\(\\exp(a) = \\mathrm{lim}_{n\\to\\infty} \\left(1+\\frac{a}{n}\\right)^{n},\\)\n\n상수 \\(e:=\\exp(1)\\approx 2.71828 \\ldots\\)는 Euler의 숫자로도 알려져 있다. 위의 정의에서 \\(n\\)-fold 곱을 확장하면 지수 함수가 다음과 같은 멱급수로 표현될 수 있음을 보여줄 수 있다. \\[\\exp(a) := \\sum_{n=0}^{\\infty} \\frac{a^n}{n!} = 1 + a + \\frac{a^2}{1 \\cdot 2} + \\frac{a^3}{1 \\cdot 2 \\cdot 3} + \\cdot\\]\n멱급수에서 실수값 변수 \\(a\\in\\mathbb{R}\\)를 복소수 값 변수 \\(c\\in\\mathbb{C}\\)로 바꾸면, 여전히 다음과 같이 주어진 복소수 지수 함수 \\(\\exp:\\mathbb{C}\\to \\mathbb{C}\\)를 얻는다.\n\n\\[\\exp(c) := \\sum_{n=0}^{\\infty} \\frac{c^n}{n!} = 1 + c + \\frac{c^2}{1 \\cdot 2} + \\frac{c^3}{1 \\cdot 2 \\cdot 3} + \\cdot\\]\n\n복소수 지수 함수의 정의를 기반으로 삼각 함수(예: \\(\\sin\\) 및 \\(\\cos\\))의 정의를 복소 인수로 확장할 수도 있다.\n다음 구현은 매개 변수 \\(N\\in\\mathbb{N}\\)에 의해 지정된 첫 번째 \\(N\\) 항만 고려하여 멱급수의 근사치를 산출한다. \\(c=1\\)의 경우, 숫자 \\(e\\)에 대한 근사치를 산출한다.\n\n\ndef exp_power_series(c, N):\n    \"\"\"Compute power series for exponential function\n\n    Args:\n        c: Complex number\n        N: Number of summands used for approximation\n\n    Returns:\n        exp_c: Approximation of exp(c)\n    \"\"\"    \n    exp_c = 1\n    c_power = 1\n    nfac = 1\n    for n in range(1, N):\n        nfac *= n\n        c_power *= c \n        exp_c += c_power / nfac\n    return exp_c\n\n\nc=1\nprint('Approximation (N =  1):', exp_power_series(c, 1))\nprint('Approximation (N =  2):', exp_power_series(c, 2))\nprint('Approximation (N =  4):', exp_power_series(c, 4))\nprint('Approximation (N =  8):', exp_power_series(c, 8))\nprint('Approximation (N = 12):', exp_power_series(c, 12))\nprint('Numpy:                 ', np.exp(c))\n\nApproximation (N =  1): 1\nApproximation (N =  2): 2.0\nApproximation (N =  4): 2.6666666666666665\nApproximation (N =  8): 2.7182539682539684\nApproximation (N = 12): 2.718281826198493\nNumpy:                  2.718281828459045"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#지수-항등식과-오일러-공식-exponentiation-identity-and-eulers-formula",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#지수-항등식과-오일러-공식-exponentiation-identity-and-eulers-formula",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "지수 항등식과 오일러 공식 (Exponentiation Identity and Euler’s Formula )",
    "text": "지수 항등식과 오일러 공식 (Exponentiation Identity and Euler’s Formula )\n\n멱급수 정의에 기초하여, 많은 속성을 설명하는 지수 함수의 두 가지 유명한 공식을 증명할 수 있다.\n첫 번째 공식은 지수 항등식 exponentation identity로 알려져 있으며 다음과 같다.\n\n\\[\n  \\exp(c_1 + c_2) = \\exp(c_1)\\cdot \\exp(c_2)\n\\]\nfor any complex numbers \\(c_1, c_2\\in\\mathbb{C}\\).\n\n특히, 이 속성은 실수 인수의 기하급수적인 증가를 설명한다. 예를들면,\n\n\\[\n  \\exp(n) = \\exp(1+1+\\ldots +1) = \\exp(1)^n = e^n\n\\]\nfor \\(n\\in\\mathbb{N}\\).\n\n오일러 공식 Euler’s formula로 알려진 두 번째 공식은 순 허수(pure imaginary)의 인수에서 지수 함수의 값을 삼각 함수와 연관시킨다. 이는 일부 실수 값 \\(\\beta\\in\\mathbb{R}\\)와 함께 복소수 \\(c = i\\gamma\\)에 대해, 다음의 항등식을 가진다.\n\n\\[\\mathrm{exp}(i\\gamma) = \\cos(\\gamma) + i\\sin(\\gamma)\\]\n\n실제로 실수 사인 및 코사인 함수를 시작으로 오일러 공식을 사용하여 \\(\\mathrm{exp}(i\\gamma)\\)를 정의하는 경우가 많다.\n다음 그림에 나온 것처럼 허수(수직) 축을 따라 \\(\\exp\\)의 실수 및 허수 부분의 주기적인 행동을 설명한다.\n\n\nA, B = np.meshgrid(np.arange(-2, 2, 0.1), np.arange(-12, 12, 0.1))\nC = A + B*1j\nf_exp = np.exp(C)\n\nplt.figure(figsize=(12, 4))\nextent = [-2, 2, -12, 12]\nplt.subplot(1, 3, 1)\nplt.imshow(np.real(f_exp),  aspect='auto', cmap='seismic', origin='lower', extent=extent)\nplt.title('Real part Re(exp(c))')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.subplot(1, 3, 2)\nplt.imshow(np.imag(f_exp),  aspect='auto', cmap='seismic', origin='lower', extent=extent)\nplt.title('Imaginary part Im(exp(c))')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.subplot(1, 3, 3)\nplt.imshow(np.abs(f_exp),  aspect='auto', cmap='gray_r', origin='lower', extent=extent)\nplt.title('Absolute value |exp(c)|')\nplt.xlabel('a = Re(c)')\nplt.ylabel('b = Im(c)')\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-속성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#기본-속성",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "기본 속성",
    "text": "기본 속성\n\n지수 함수에는 여러 가지 흥미로운 속성이 있다:\n\n\\(\\exp(i\\gamma) = \\exp(i(\\gamma+2\\pi))\\)\n\\(|\\exp(i\\gamma)| = 1\\)\n\\(\\overline{\\exp(i\\gamma)} = \\exp(-i\\gamma)\\)\n\\(\\exp(i(\\gamma_1+\\gamma_2)) = \\exp(i\\gamma_1) \\exp(i\\gamma_2)\\)\n\\(\\frac{d\\exp(i\\gamma)}{d\\gamma} = i\\exp(i\\gamma)\\)\n\n특히, 복소수 값 \\(\\mathrm{exp}(i\\gamma)\\)은 모든 \\(\\gamma\\in\\mathbb{R}\\)에 대해 복소수 평면의 단위 원(unit circle)에 있다. 또한 주기성(periodicity)으로 인해 \\(\\gamma\\in[0,2\\pi)\\)을 고려하기에 충분하다.\n실제로 \\(\\gamma\\)는 복소수 \\(c = \\mathrm{exp}(i\\gamma)\\)의 각도(라디안 단위)를 인코딩한다.(\\(|c|=1\\))\n다음 그림은 각도 \\(\\gamma\\)를 \\(0\\)에서 \\(2\\pi\\)로 증가시킬 때 값 \\(\\mathrm{exp}(i\\gamma)\\)이 어떻게 변하는지 보여준다.\n\n\nfrom matplotlib import ticker \n%matplotlib inline\n\ncmap = plt.cm.get_cmap('hsv') # hsv is nice because it is a circular color map\n\nN = 64\n\nfig = plt.figure(figsize=(5 * 3, 5))\nax1 = fig.add_subplot(1, 3, 1, projection='polar')\nax2 = fig.add_subplot(1, 3, 2)\nax3 = fig.add_subplot(1, 3, 3)\n\nfor i in range(N):\n    gamma = 2 * np.pi * i / N\n    c = np.exp(1j * gamma)\n    color = cmap(i / N)\n    ax1.plot([0, np.angle(c)], [0, np.abs(c)], color=color)\n    ax1.plot(np.angle(c), np.abs(c), 'o', color=color)\n    ax2.plot(gamma, np.real(c), 'o', color=color)\n    ax3.plot(gamma, np.imag(c), 'o', color=color)\n    \nax2.grid()\nax2.set_xlabel('$\\gamma$ [radians]')\nax2.set_ylabel('$\\mathrm{Re}(\\exp(i \\gamma))$')\nax2.xaxis.set_major_formatter(ticker.FormatStrFormatter('$%s$')) \n\nax3.grid()\nax3.set_xlabel('$\\gamma$ [radians]')\nax3.set_ylabel('$\\mathrm{Im}(\\exp(i \\gamma))$')\nax3.xaxis.set_major_formatter(ticker.FormatStrFormatter('$%s$')) \nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#의-거듭제곱근-roots-of-unity",
    "href": "posts/3. Fourier Anaylsis of Signals/3.1.Math_Review.html#의-거듭제곱근-roots-of-unity",
    "title": "3.1. 수학리뷰 - 복소수와 지수함수",
    "section": "1의 거듭제곱근 (Roots of Unity)",
    "text": "1의 거듭제곱근 (Roots of Unity)\n\n\\(N \\in \\mathbb{N}_{>0}\\)를 양의 정수라고 하자. 복소수 \\(\\rho \\in \\mathbb{C}\\)는 \\(\\rho^N = 1\\)인 경우 \\(N^\\mathrm{th}\\) 1의 거듭제곱근(root of unity)라고 한다. 다시말해 1의 거듭제곱근은 거듭제곱하여 1이 되는 복소수이다. 정확히 \\(N\\)개의 뚜렷한 \\(N^\\mathrm{th}\\) root of unity가 있다는 것을 보이는 것은 어렵지 않다.\n또한, 모든 \\(n\\in [1:N-1]\\)에 대해 \\(\\rho^n \\neq 1\\)인 경우, 단위 n승근(primitive \\(N^\\mathrm{th}\\) root of unity)라고 한다.\n위에서 언급한 속성을 통해 \\(\\rho_N:=\\exp(2 \\pi i / N)\\) 이 단위 n승근임을 쉽게 알 수 있다.\n모든 \\(N^\\mathrm{th}\\) root of unity는 \\(\\rho_N\\)의 power을 고려하여 생성될 수 있다.:\n\n\\[1=\\rho_N^0, \\quad \\rho_N^1, \\quad \\rho_N^2, \\quad ...,\\quad \\rho_N^{N-1}\\]\n\n다음 그림은 서로 다른 정수 \\(N \\in \\mathbb{N}_{>0}\\)에 대한 모든 root of unity를 보여준다. primitive root는 빨간색으로 표시되어 있다.\n\n\ndef plot_root_unity(N, figsize=(5, 5)): \n    root_unity = np.exp(2j * np.pi / N)\n    root_unity_power = 1\n\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.grid()  \n    plt.xlim([-1.4, 1.4])\n    plt.ylim([-1.4, 1.4])\n    plt.xlabel('$\\mathrm{Re}$')\n    plt.ylabel('$\\mathrm{Im}$')\n    plt.title('Roots of unity for $N=%d$'%N)\n\n    for n in range(0, N):\n        colorPlot = 'r' if gcd(n, N) == 1 else 'k'\n        plot_vector(root_unity_power, color=colorPlot)\n        plt.text(np.real(1.2*root_unity_power), np.imag(1.2*root_unity_power), \n                 r'$\\rho_{%s}^{%s}$' % (N, n), size='18', \n                 color=colorPlot, ha='center', va='center')\n        root_unity_power *= root_unity\n\n    circle_unit = plt.Circle((0, 0), 1, color='lightgray', fill=0)   \n    ax.add_artist(circle_unit)\n\n\nplot_root_unity(N=8)    \nplot_root_unity(N=11)\nplot_root_unity(N=12)\n\n\n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "",
    "text": "이산 푸리에 변환(DFT)과 그 기본 속성과 함께, DFT를 평가하는 효율적인 알고리즘인 고속 푸리에 변환(FFT)을 소개한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#내적-inner-product",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#내적-inner-product",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "내적 (Inner Product)",
    "text": "내적 (Inner Product)\n\n푸리에 변환(Fourier transform)을 이해하기 위한 중요한 개념으로 \\(N \\in \\mathbb{N}\\)에 대한 복소(complex) 벡터 공간 \\(\\mathbb{C}^N\\)에 대한 내적(inner product) 이 있다.\n두 개의 복소수 벡터 \\(x, y \\in \\mathbb{C}^N\\)가 주어지면, \\(x\\)와 \\(y\\) 사이의 내적은 다음과 같이 정의된다. \\[\\langle x | y \\rangle := \\sum_{n=0}^{N-1} x(n) \\overline{y(n)}.\\]\n내적의 절대값은 \\(x\\)와 \\(y\\) 사이의 유사성의 척도로 해석될 수 있다.\n\n\\(x\\)와 \\(y\\)가 동일한 방향을 가리키면(즉, \\(x\\)와 \\(y\\)가 유사함), 내적 \\(|\\langle x | y \\rangle|\\)이 크다.\n\\(x\\)와 \\(y\\)가 직교하면(즉, \\(x\\)와 \\(y\\)가 서로 다른 경우), 내적 \\(|\\langle x | y \\rangle|\\)는 0이다.\n\n함수 np.vdot을 사용하여 내적을 계산할 때 첫 번째 인수에 대해 복소 켤레(complex conjugate)가 수행된다는 점에 유의하자.\n따라서, 위에서 정의된 \\(\\langle x | y \\rangle\\)를 계산하려면, np.vdot(y, x)를 사용해야 한다.\n\n\nx = np.array([ 1.0, 1j, 1.0 + 1.0j ])\ny = np.array([ 1.1, 1j, 0.9 + 1.1j ])\nprint('Vectors of high similarity:', np.abs(np.vdot(y, x)))\n\nx = np.array([ 1.0,   1j, 1.0 + 1j ])\ny = np.array([ 1.1, -1j, 0.1      ])\nprint('Vectors of low similarity:', np.abs(np.vdot(y, x)))\n\nVectors of high similarity: 4.104875150354758\nVectors of low similarity: 0.22360679774997913"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft의-정의",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft의-정의",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "DFT의 정의",
    "text": "DFT의 정의\n\n\\(x\\in \\mathbb{C}^N\\)을 길이가 \\(N\\in\\mathbb{N}\\)인 벡터라고 하자. 음악 신호의 맥락에서 \\(x\\)는 샘플 \\(x(0), x(1), ..., x(N-1)\\)가 있는 이산(discrete) 신호로 해석될 수 있다.\n이산 푸리에 변환(DFT)은 다음과 같이 정의된다. \\[ X(k) := \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N) \\] for \\(k \\in [0:N-1]\\).\n벡터 \\(X\\in\\mathbb{C}^N\\)는 시간 영역(time-domain) 신호 \\(x\\)의 주파수 표현(frequency representation)으로 해석될 수 있다.\nDFT의 기하학적 해석을 얻기 위해 벡터 \\(\\mathbf{u}_k\\in\\mathbb{C}^N\\)를 다음과 같이 정의한다. \\[\\mathbf{u}_k(n) :=  \\exp(2 \\pi i k n / N) = \\cos(2 \\pi k n / N) + i \\sin(2 \\pi k n / N)\\] for \\(k \\in [0:N-1]\\).\n이 벡터는 주파수 \\(k/N\\)의 지수 함수의 샘플링된 버전으로 볼 수 있다. 그러면 DFT는 신호 \\(x\\) 및 샘플링된 지수 함수 \\(\\mathbf{u}_k\\)의 내적으로 표현될 수 있다. \\[ X(k) := \\sum_{n=0}^{N-1} x(n) \\overline{\\mathbf{u}_k} = \\langle x | \\mathbf{u}_k \\rangle\\]\n절대값 \\(|X(k)|\\)는 신호 \\(x\\)와 \\(\\mathbf{u}_k\\) 사이의 유사도를 나타낸다.\n\\(x\\in \\mathbb{R}^N\\)이 실수 값 벡터(음악 신호 시나리오의 경우, 항상 해당)인 경우 다음을 얻는다.\n\n\\[ X(k) := \\langle x |\\mathrm{Re}(\\mathbf{u}_k) \\rangle - i\\langle x | \\mathrm{Im}(\\mathbf{u}_k) \\rangle \\]\n\n다음 그림은 두 개의 서로 다른 주파수 파라미터 \\(k\\)에 대한 함수 \\(\\overline{\\mathbf{u}_k}\\)와 비교한 신호 \\(x\\)의 예를 보여준다.\n\n\\(\\overline{\\mathbf{u}_k}\\)의 실수부와 허수부는 각각  빨간색 및  파란색으로 표시된다.\n\n\n\nN = 64\nn = np.arange(N)\nk = 3\nx = np.cos(2 * np.pi * (k * n / N) + (1.2*np.random.rand(N) - 0.0))\n\nplt.figure(figsize=(6, 4))\n\nplt.subplot(2, 1, 1)\nplt.plot(n, x, 'k', marker='.', markersize='5', linewidth=2.0, label='$x$')\nplt.xlabel('Time (samples)')\nk = 3\nu_k_real = np.cos(2 * np.pi * k * n / N)\nu_k_imag = -np.sin(2 * np.pi * k * n / N)\nu_k = u_k_real + u_k_imag*1j\nsim_complex = np.vdot(u_k, x)\nsim_abs = np.abs(sim_complex)\nplt.title(r'Signal $x$ and some $u_k$ (k=3) having high similarity: Re($X(k)$) = %0.2f, Im($X(k)$) = %0.2f,  $|X(k)|$=%0.2f'%(sim_complex.real,sim_complex.imag,sim_abs))\nplt.plot(n, u_k_real, 'r', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Re}(\\overline{\\mathbf{u}}_k)$');\nplt.plot(n, u_k_imag, 'b', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Im}(\\overline{\\mathbf{u}}_k)$');\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(n, x, 'k', marker='.', markersize='5', linewidth=2.0, label='$x$')\nplt.xlabel('Time (samples)')\nk = 5\nu_k_real = np.cos(2 * np.pi * k * n / N)\nu_k_imag = -np.sin(2 * np.pi * k * n / N)\nu_k = u_k_real + u_k_imag*1j\nsim_complex = np.vdot(u_k, x)\nsim_abs = np.abs(sim_complex)\nplt.title(r'Signal $x$ and some $u_k$ (k=5) having low similarity: Re($X(k)$) = %0.2f, Im($X(k)$) = %0.2f,  $|X(k)|$=%0.2f'%(sim_complex.real,sim_complex.imag,sim_abs))\nplt.plot(n, u_k_real, 'r', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Re}(\\overline{\\mathbf{u}}_k)$');\nplt.plot(n, u_k_imag, 'b', marker='.', markersize='3', \n         linewidth=1.0, linestyle=':', label='$\\mathrm{Im}(\\overline{\\mathbf{u}}_k)$');\nplt.legend()\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft-행렬-dft-matrix",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#dft-행렬-dft-matrix",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "DFT 행렬 (DFT Matrix)",
    "text": "DFT 행렬 (DFT Matrix)\n\n선형 연산자 \\(\\mathbb{C}^N \\to \\mathbb{C}^N\\)이면, DFT는 \\(N\\times N\\)-행렬로 표현할 수 있다. 이는 다음과 같은 유명한 DFT 행렬 \\(\\mathrm{DFT}_N \\in \\mathbb{C}^{N\\times N}\\) 행렬로 이어진다. \\[\\mathrm{DFT}_N(n, k) = \\mathrm{exp}(-2 \\pi i k n / N)\\] for \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\\(\\rho_N:=\\exp(2 \\pi i / N)\\)를 단위 N승근 (primitive Nth roots of unity)이라고 한다. 또한 단위 N승근을 다음과 같이 정의한다.\n\n\\(\\sigma_N:= \\overline{\\rho_N} = \\mathrm{exp}(-2 \\pi i / N)\\)\n\n지수 함수의 속성으로부터 다음을 얻을 수 있다.\n\n\\(\\sigma_N^{kn} = \\mathrm{exp}(-2 \\pi i / N)^{kn} = \\mathrm{exp}(-2 \\pi i k n / N)\\)\n\n이로부터 다음의 행렬을 얻는다. \\[\n\\mathrm{DFT}_N =\n\\begin{pmatrix}\n  1 & 1 & 1 & \\dots  & 1 \\\\\n  1 & \\sigma_N & \\sigma_N^2 & \\dots  & \\sigma_N^{N-1} \\\\\n  1 & \\sigma_N^2 & \\sigma_N^4 & \\dots  & \\sigma_N^{2(N-1)} \\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n  1 & \\sigma_N^{N-1} & \\sigma_N^{2(N-1)} & \\dots  & \\sigma_N^{(N-1)(N-1)} \\\\\n\\end{pmatrix}\n\\]\n다음 그림에서 \\(\\mathrm{DFT}_N\\)의 실수 및 허수 부분이 표시되며, 값은 적절한 색상으로 인코딩된다. \\(\\mathrm{DFT}_N\\)의 \\(k^\\mathrm{th}\\) 행은 위에 정의된 벡터 \\(\\mathbf{u}_k\\)에 해당한다.\n\n\ndef generate_matrix_dft(N, K):\n    \"\"\"Generates a DFT (discrete Fourier transfrom) matrix\n\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n\n    Returns:\n        dft (np.ndarray): The DFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(-2j * np.pi * k * n / N)\n    return dft\n\ndef dft(x):\n    \"\"\"Compute the disrcete Fourier transfrom (DFT)\n\n    Args:\n        x (np.ndarray): Signal to be transformed\n\n    Returns:\n        X (np.ndarray): Fourier transform of x\n    \"\"\"\n    x = x.astype(np.complex128)\n    N = len(x)\n    dft_mat = generate_matrix_dft(N, N)\n    return np.dot(dft_mat, x)\n\n\nN = 32\ndft_mat = generate_matrix_dft(N, N)\n\nplt.figure(figsize=(10, 3))\n\nplt.subplot(1, 2, 1)\nplt.title('$\\mathrm{Re}(\\mathrm{DFT}_N)$')\nplt.imshow(np.real(dft_mat), origin='lower', cmap='seismic', aspect='equal')\nplt.xlabel('Time index $n$')\nplt.ylabel('Frequency index $k$')\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\nplt.title('$\\mathrm{Im}(\\mathrm{DFT}_N)$')\nplt.imshow(np.imag(dft_mat), origin='lower', cmap='seismic', aspect='equal')\nplt.xlabel('Time index $n$')\nplt.ylabel('Frequency index $k$')\nplt.colorbar()\nplt.tight_layout()\n\n\n\n\n\nN = 128\nn = np.arange(N)\nk = 10\nx = np.cos(2 * np.pi * (k * n / N) + 2 * (np.random.rand(N) - 0.5)) \nX = dft(x)\n\nplt.figure(figsize=(8, 3))\n\nplt.subplot(1, 2, 1)\nplt.title('$x$')\nplt.plot(x)\nplt.xlabel('Time (index $n$)')\n\nplt.subplot(1, 2, 2)\nplt.title('$|X|$')\nplt.plot(np.abs(X))\nplt.xlabel('Frequency (index $k$)')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#계산-복잡성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#계산-복잡성",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "계산 복잡성",
    "text": "계산 복잡성\n\nFFT는 전체 작업 수를 \\(N^2\\)(일반적인 행렬-벡터 곱 \\(\\mathrm{DFT}_N \\cdot x\\)를 계산할 때 필요함)에서 \\(N\\log_2N\\) 정도로 줄인다. 예를 들어 \\(N=2^{10}=1024\\)를 사용하면 원래의 접근 방식의 \\(N^2=1048576\\) 작업 대신 FFT에 대략 \\(N\\log_2N=10240\\)가 필요하다.\nPython 코드의 작은 비트의 시간을 측정하는 간단한 방법을 제공하는 timeit 모듈을 사용하여 실행 시간을 비교한다.\n\n\nN = 512\nn = np.arange(N)\nx = np.sin(2 * np.pi * 5 * n / N )\n\nprint('Timing for DFT: ', end='')\n%timeit dft(x)\nprint('Timing for FFT: ', end='')\n%timeit fft(x)\n\nTiming for DFT: 284 ms ± 6.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\nTiming for FFT: 9.31 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nimport timeit\n\nNs = [2 ** n for n in range(5, 11)]\ntimes_dft = []\ntimes_fft = []\nexecuctions = 5\n\nfor N in Ns:\n    n = np.arange(N)\n    x = np.sin(2 * np.pi * 5 * n / N )\n    \n    time_dft = timeit.timeit(lambda: dft(x), number=execuctions) / execuctions\n    time_fft = timeit.timeit(lambda: fft(x), number=execuctions) / execuctions\n    times_dft.append(time_dft)\n    times_fft.append(time_fft)\n    \nplt.figure(figsize=(6, 3))\n    \nplt.plot(Ns, times_dft, '-xk', label='DFT')\nplt.plot(Ns, times_fft, '-xr', label='FFT')\nplt.xticks(Ns)\nplt.legend()\nplt.grid()\nplt.xlabel('$N$')\nplt.ylabel('Runtime (seconds)');\n\n\n\n\n\nFFT의 경우 계산이 훨씬 빠른 것을 볼 수 있다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#fft-예시",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#fft-예시",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "FFT 예시",
    "text": "FFT 예시\n\nlibrosa\n\n\nx, sr = librosa.load(\"../audio/c_strum.wav\")\nprint(x.shape)\nprint(sr)\nipd.Audio(x, rate=sr)\n\n(102400,)\n22050\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nX = scipy.fft.fft(x)\nX_mag = np.absolute(X)\nf = np.linspace(0, sr, len(X_mag)) # frequency variable\n\n\nplt.figure(figsize=(6, 2))\nplt.plot(f, X_mag) # magnitude spectrum\nplt.xlabel('Frequency (Hz)')\nplt.show()\n\n\n\n\n\n# zoom in\nplt.figure(figsize=(6, 2))\nplt.plot(f[:5000], X_mag[:5000])\nplt.xlabel('Frequency (Hz)')\nplt.show()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#푸리에-계수의-극좌표-표현-polar-representation-of-fourier-coefficients",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#푸리에-계수의-극좌표-표현-polar-representation-of-fourier-coefficients",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "푸리에 계수의 극좌표 표현 (Polar Representation of Fourier Coefficients)",
    "text": "푸리에 계수의 극좌표 표현 (Polar Representation of Fourier Coefficients)\n\n\\(x=(x(0), x(1), ..., x(N-1))\\)을 샘플 \\(x(n)\\in\\mathbb{R}\\) for \\(n\\in[0:N-1]\\)을 가지는 시그널이라고 하자. 복소 푸리에 계수 \\(c_k:=X(k)\\in\\mathbb{C}\\) for \\(k\\in[0:N-1]\\)는 DFT에 계산되어 다음과 같다. \\[\nc_k :=X(k) = \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N).\n\\]\n\\(c_k = a_k + i b_k\\)를 실수부 \\(a_k\\in\\mathbb{R}\\)와 허수부 \\(b_k\\in\\mathbb{R}\\)로 구성된 복소수라고 할 때,\n절대값은 \\(|c_k| := \\sqrt{a_k^2 + b_k^2}\\)이고,\n각도(래디안 단위)는 \\(\\gamma_k := \\mathrm{angle}(c_k) := \\mathrm{atan2}(b_k, a_k) \\in [0,2\\pi)\\)이다.\n지수 함수를 쓰면, 다음의 극좌표 표현을 얻는다. \\[\n  c_k = |c_k| \\cdot \\mathrm{exp}(i \\gamma_k).\n\\]"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#최적화-optimality-속성",
    "href": "posts/3. Fourier Anaylsis of Signals/3.2.Discrete_Fourier_Transform.html#최적화-optimality-속성",
    "title": "3.2. 이산 푸리에 변환 (Discrete Fourier Transform, DFT) & 고속 푸리에 변환 (Fast Fourier Transform, FFT)",
    "section": "최적화 Optimality 속성",
    "text": "최적화 Optimality 속성\n\n\\(\\mathbf{cos}_{k,\\varphi}:[0:N-1]\\to\\mathbb{R}\\)를 주파수 파라미터 \\(k\\) 및 위상 \\(\\varphi\\in[0 ,1)\\)와 함께 샘플 정현파(sinusoid)라고 하면 다음과 같이 정의된다. \\[\n  \\mathbf{cos}_{k,\\varphi}(n) = \\sqrt{2}\\mathrm{cos}\\big( 2\\pi (kn/N - \\varphi) \\big)\n\\] for \\(n\\in[0,N-1]\\)\n직관적으로 말하자면, 길이 \\(N\\)의 이산 신호 \\(x\\)와 주파수 파라미터 \\(k\\)에 대한 푸리에 변환을 계산할 때 신호 \\(x\\)와 정현파 \\(\\mathbf{cos}_{k,\\varphi_k}\\)의 내적(일종의 상관 관계)을 계산한다.\n\\(\\varphi_k\\) 위상은 \\(\\varphi\\in[0,1)\\)로 \\(x\\)와 모든 가능한 정현파 \\(\\mathbf{cos}_{k,\\varphi}\\) 사이의 상관관계를 최대화한다는 속성을 가지고 있다.\n\n\\[\n      \\varphi_k = \\mathrm{argmax}_{\\varphi\\in[0,1)} \\langle x | \\mathbf{cos}_{k,\\varphi} \\rangle.\n\\]\n\n복소 푸리에 계수 \\(X(k)\\)는 기본적으로 복소수의 각도로 주어지는 이 최적 위상을 인코딩한다. 보다 정확하게 \\(\\gamma_k\\)를 \\(X(k)\\)의 각도라고 하면, 최적 위상 \\(\\varphi_k\\)가 다음과 같이 주어진다는 것을 알 수 있다.\n\n\\[\n       \\varphi_k := - \\frac{\\gamma_k}{2 \\pi}.\n\\]\n\n# Generate a chirp-like test signal (details not important)\nN = 256\nt_index = np.arange(N)\nx = 1.8 * np.cos(2 * np.pi * (3 * (t_index * (1 + t_index / (4 * N))) / N))\n\nk = 4\nexponential = np.exp(-2 * np.pi * 1j * k * t_index / N)\nX_k = np.sum(x * exponential)\nphase_k = - np.angle(X_k) / (2 * np.pi)\n\ndef compute_plot_correlation(x, N, k, phase):\n    sinusoid = np.cos(2 * np.pi * (k * t_index / N - phase)) \n    d_k = np.sum(x * sinusoid)\n    plt.figure(figsize=(6,1.5))\n    plt.plot(t_index, x, 'k')\n    plt.plot(sinusoid, 'r')\n    plt.title('Phase = %0.2f; correlation = %0.2f (optimal  = %0.2f)' % (phase, d_k, np.abs(X_k)))\n    plt.tight_layout()\n    plt.show()\n\nprint('Sinusoid with phase from Fourier coefficient resulting in an optimal correlation.')    \ncompute_plot_correlation(x, N, k, phase=phase_k)\n\nprint('Sinusoid with an arbitrary phase resulting in a medium correlation.')  \ncompute_plot_correlation(x, N, k, phase=0.4)\n\nprint('Sinusoid with a phase that yields a correlation close to zero.')  \ncompute_plot_correlation(x, N, k, phase=0.51)\n\nSinusoid with phase from Fourier coefficient resulting in an optimal correlation.\n\n\n\n\n\nSinusoid with an arbitrary phase resulting in a medium correlation.\n\n\n\n\n\nSinusoid with a phase that yields a correlation close to zero.\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "",
    "text": "단기 푸리에 변환(STFT)를 소개하고, 이와 관련된 윈도우(window), 스펙트로그램(spectrogram), 패딩(padding) 전략 등을 살펴본다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#missing-time-localization",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#missing-time-localization",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "“Missing Time Localization”",
    "text": "“Missing Time Localization”\n\n기존 푸리에 변환은 전체 시간 영역에서 평균화되는 주파수 정보를 생성한다. 그러나 이러한 주파수가 언제 벌생하는지에 대한 정보는 변환에 숨겨져 있다. 이 현상은 다음 그림을 보면 알 수 있다.\n\n\nFs = 128\nduration = 10\nomega1 = 1\nomega2 = 5\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * omega1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * omega2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(8, 2))\nplt.subplot(1, 2, 1)\nplt.plot(t, x)\nplt.xlim([min(t), max(t)])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(1, 2, 2)\nX = np.abs(np.fft.fft(x)) / Fs\nfreq = np.fft.fftfreq(N, d=1/Fs)\nX = X[:N//2]\nfreq = freq[:N//2]\nplt.plot(freq, X)\nplt.xlim([0, 7])\nplt.ylim([0, 3])\nplt.xlabel('Frequency (Hz)')\nplt.tight_layout()\n\n\n\n\n\nImage(\"../img/3.fourier_analysis/f.2.6.PNG\", width=600)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#기본-개념",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#기본-개념",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "기본 개념",
    "text": "기본 개념\n\n숨겨진 시간 정보를 복구하기 위해 Dennis Gabor는 1946년에 단시간 푸리에 변환(STFT)을 도입했다.\n전체 신호를 고려하는 대신 STFT는 신호의 작은 부분만 고려한다. 이를 위해 짧은 시간 동안의 non-zero 함수, 소위 윈도우 함수(window function)를 고정한다. 그런 다음 원래 신호에 윈도우 함수를 곱하여 윈도우(windowed) 신호를 생성한다.\n서로 다른 시간 인스턴스에서 주파수 정보를 얻으려면 시간에 따라 윈도우 함수를 이동하고, 각 결과 윈도우 신호에 대해 푸리에 변환을 계산해야 한다.\n\n\ndef windowed_ft(t, x, Fs, w_pos_sec, w_len):\n    N = len(x)\n    w_pos = int(Fs * w_pos_sec)\n    w_padded = np.zeros(N)\n    w_padded[w_pos:w_pos + w_len] = 1\n    x = x * w_padded\n    \n    X = np.abs(np.fft.fft(x)) / Fs\n    freq = np.fft.fftfreq(N, d=1/Fs)\n    X = X[:N//2]\n    freq = freq[:N//2]\n    \n    plt.figure(figsize=(8, 2))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(t, x, c='k')\n    plt.plot(t, w_padded, c='r')\n    plt.xlim([min(t), max(t)])\n    plt.ylim([-1.1, 1.1])\n    plt.xlabel('Time (seconds)')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(freq, X, c='k')\n    plt.xlim([0, 7])\n    plt.ylim([0, 3])\n    plt.xlabel('Frequency (Hz)')\n    plt.tight_layout()\n    \nprint('서로다른 window 변화에 대한 실험:')\n\nw_len = 4 * Fs\nwindowed_ft(t, x, Fs, w_pos_sec=1, w_len=w_len) # 윈도우 신호 t=1 중심\nwindowed_ft(t, x, Fs, w_pos_sec=3, w_len=w_len) # t=3\nwindowed_ft(t, x, Fs, w_pos_sec=5, w_len=w_len) # t=5\nplt.show()\n\n서로다른 window 변화에 대한 실험:"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#윈도우window",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#윈도우window",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "윈도우(window)",
    "text": "윈도우(window)\n\nSTFT는 원래 신호의 속성뿐만 아니라 윈도우 함수의 속성도 반영한다는 점에 유의해야 한다.\n우선 STFT는 섹션의 크기를 결정하는 윈도우의 길이에 따라 달라진다. 그리고 STFT는 윈도우 모양의 영향을 받는다. 예를 들어 직사각형 윈도우를 사용하면 일반적으로 단면 경계에서 불연속성이 발생하기 때문에 큰 단점이 있다. 이러한 급격한 변화는 전체 주파수 스펙트럼에 걸쳐 전파되는 간섭으로 인해 부작용을 발생시킨다: ripple artifacts.\n\n윈도우 유형\n\n이러한 경계 효과를 줄이기 위해 원하는 섹션 내에서 섹션의 경계를 향해 연속적으로 0으로 떨어지는 음이 아닌 윈도우를 사용한다. 그러한 예 중 하나는 훨씬 더 작은 ripple artifact를 초래하는 삼각형 윈도우(triangular winow) 이다.\n신호 처리에 자주 사용되는 윈도우는 Hann 윈도우(기상학자 Julius von Hann의 이름을 따서 명명됨, 1839~1921)이다. Hann 윈도우는 상승하는 코사인 윈도우로, 섹션 경계에서 스무스(smoothly)하게 0으로 떨어진다. 이는 윈도우 신호의 푸리에 변환에서 부작용을 완화한다. 그러나 단점은 Hann 윈도우가 약간의 주파수 번짐을 유발한다는 것이다.\n결과적으로 신호의 윈도우 영역의 푸리에 변환은 신호의 속성이 제안하는 것보다 더 스무스해 보일 수 있다. 즉, ripple artifact의 감소는 더 안좋은 spectral localization을 통해 달성된다 (trade-off 관계).\n\n\ndef windowed_ft2(t, x, Fs, w_pos_sec, w_len, w_type, upper_y=1.0):\n    \n    N = len(x)\n    w_pos = int(Fs * w_pos_sec)\n    w = np.zeros(N)\n    w[w_pos:w_pos + w_len] = scipy.signal.get_window(w_type, w_len)\n    x = x * w\n    \n    plt.figure(figsize=(8, 2))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(t, x, c='k')\n    plt.plot(t, w, c='r')\n    plt.xlim([min(t), max(t)])\n    plt.ylim([-1.1, 1.1])\n    plt.xlabel('Time (seconds)')\n\n    plt.subplot(1, 2, 2)\n    X = np.abs(np.fft.fft(x)) / N * 2\n    freq = np.fft.fftfreq(N, d=1/Fs)\n    X = X[:N//2]\n    freq = freq[:N//2]\n    plt.plot(freq, X, c='k')\n    plt.xlim([0, 50])\n    plt.ylim([0, upper_y])\n    plt.xlabel('Frequency (Hz)')\n    plt.tight_layout()\n    plt.show()\n\n\nduration = 2.0\nFs = 2000\nomega = 10\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nx = 0.9 * np.sin(2 * np.pi * omega * t * t)\n\nplt.figure(figsize=(8, 2))\n\nplt.subplot(1, 2, 1)\nplt.plot(t, x, c='k')\nplt.xlim([t[0], t[-1]])\nplt.ylim([-1.1, 1.1])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(1, 2, 2)\nX = np.abs(np.fft.fft(x)) / N * 2\nfreq = np.fft.fftfreq(N, d=1/Fs)\nX = X[:N//2]\nfreq = freq[:N//2]\nplt.plot(freq, X, c='k')\nplt.xlim([0, 50])\nplt.ylim(bottom=0)\nplt.xlabel('Frequency (Hz)');\nplt.tight_layout()\n\n\n\n\n\nw_len = 1024\nw_pos = 1280\nprint('Rectangular window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'boxcar', upper_y=0.15)\nprint('Triangular window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'triang', upper_y=0.15)\nprint('Hann window:')\nwindowed_ft2(t, x, Fs, 1.0, w_len, 'hann', upper_y=0.15)\n\nRectangular window:\n\n\n\n\n\nTriangular window:\n\n\n\n\n\nHann window:"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#discrete-stft의-정의",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#discrete-stft의-정의",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "Discrete-STFT의 정의",
    "text": "Discrete-STFT의 정의\n\n이제 STFT의 이산적 사례를 고려하고 실제 적용에 필요한 가장 중요한 수학 공식을 구체화해보자.\n\\(x:[0:L-1]:=\\{0,1,\\ldots,L-1\\}\\to{\\mathbb R}\\)가 길이 \\(L\\)의 실수 값 이산 시간(DT) 신호라고 가정하자. 이는 헤르츠(Hertz)로 주어진 고정 샘플링 비율 \\(F_\\mathrm{s}\\)에 대해 등거리(equidistant) 샘플링에 의해 얻어진다.\n\\(w:[0:N-1]\\to\\mathbb{R}\\)를 길이 \\(N\\in\\mathbb{N}\\)의 표본 윈도우 함수라고 하자. 예를 들어 직사각형 윈도우의 경우 \\(w(n)=1\\) for \\(n\\in[0:N-1]\\)이다. 길이 파라미터 \\(N\\)는 해당 섹션의 기간을 결정하며 이는 \\(N/F_\\mathrm{s}\\)초에 해당된다.\n홉 크기(hop size)라고 하는 추가 파라미터 \\(H\\in\\mathbb{N}\\)를 도입한다. 홉 크기 파라미터는 샘플에 지정되며 신호에서 윈도우가 이동하는 단계 크기(step size)를 결정한다. 이러한 파라미터와 관련하여 신호 \\(x\\)의 이산 STFT \\(\\mathcal{X}\\)는 다음과 같다. \\[ \\mathcal{X}(m,k):= \\sum_{n=0}^{N-1} x(n+mH)w(n)\\mathrm{exp}(-2\\pi ikn/N) \\] with \\(m\\in[0:M]\\) and \\(k\\in[0:K]\\)\n\\(M:=\\lfloor \\frac{L-N}{H} \\rfloor\\)는 윈도우 시간 범위가 신호의 시간 범위에 완전히 포함되도록 하는 최대 프레임 인덱스(maximal frame index)이다(나중에 패딩(padding) 전략을 사용하는 일부 변형을 볼 것).\n또한 \\(K=N/2\\)(\\(N\\)이 짝수라고 가정)는 Nyquist 주파수에 해당하는 주파수 인덱스이다.\n복소수 $ (m,k)$는 \\(m^{\\mathrm{th}}\\) 시간 프레임에 대한 \\(k^{\\mathrm{th}}\\) 푸리에 계수를 나타낸다.\n각 고정 시간 프레임 \\(m\\)에 대해, 0에 대한 계수 \\(\\mathcal{X}(m,k)\\) for \\(k\\in[0:K]\\)에 의해 주어진 크기 \\(K+1\\)의 스펙트럼 벡터(spectral vector) 를 얻는다.\n이러한 각 스펙트럼 벡터의 계산은 \\(N\\) 크기의 DFT에 해당하며 FFT를 사용하여 효율적으로 수행될 수 있다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#시간-및-주파수-인덱스에-대한-해석",
    "href": "posts/3. Fourier Anaylsis of Signals/3.3.Short-term_Fourier_Transform_1.html#시간-및-주파수-인덱스에-대한-해석",
    "title": "3.3. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (1)",
    "section": "시간 및 주파수 인덱스에 대한 해석",
    "text": "시간 및 주파수 인덱스에 대한 해석\n\n시간 차원의 경우, 각 푸리에 계수 \\(\\mathcal{X}(m,k)\\)는 초 단위로 주어진 물리적 시간 위치와 연관된다. \\[\\begin{equation}\n       T_\\mathrm{coef}(m) := \\frac{m\\cdot H}{F_\\mathrm{s}}\n\\end{equation}\\]\n예를 들어 가능한 가장 작은 홉 크기 \\(H=1\\)의 경우 \\(T_\\mathrm{coef}(m)=m/F_\\mathrm{s}=m\\cdot T~\\sec\\)를 얻는다. 이 경우 DT 신호 \\(x\\)의 각 샘플에 대한 스펙트럼 벡터를 얻으므로 데이터 양이 크게 증가한다.\n또한, 하나의 샘플에 의해서만 이동된 섹션을 고려하면 일반적으로 매우 유사한 스펙트럼 벡터가 생성된다. 이러한 유형의 중복성을 줄이기 위해 일반적으로 홉 크기를 윈도우 길이 \\(N\\)에 연관시킨다. 예를 들어, \\(H=N/2\\)를 선택하는 경우가 많으며, 이는 생성된 모든 스펙트럼 계수를 포함하는 데이터 크기와 합리적인 시간의 분해 사이의 좋은 trade-off이다.\n주파수 차원의 경우 \\(\\mathcal{X}(m,k)\\)의 인덱스 \\(k\\)는 물리적 주파수에 해당된다.\n\n\\[\\begin{equation}\n         F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n\nT_coef = np.arange(X.shape[1]) * H / Fs\nF_coef = np.arange(X.shape[0]) * Fs / N\n\nplt.figure(figsize=(3, 4))\n\nplt.subplot(2, 1, 1)\nplt.plot(t, x, c='k')\nplt.xlim([min(t), max(t)])\nplt.xlabel('Time (seconds)')\n\nplt.subplot(2, 1, 2)\nleft = min(T_coef)\nright = max(T_coef) + N / Fs\nlower = min(F_coef)\nupper = max(F_coef)\nplt.imshow(Y, origin='lower', aspect='auto', cmap='gray_r', \n           extent=[left, right, lower, upper])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "",
    "text": "단기 푸리에 변환(SFTF)의 변형을 다룬다. 주파수 그리드 밀도(density), 보간법(interpolation), 그리고 역(inverse) 푸리에 변환 등을 소개한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#dft-주파수-그리드",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#dft-주파수-그리드",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "DFT 주파수 그리드",
    "text": "DFT 주파수 그리드\n\n\\(x\\in \\mathbb{R}^N\\) 를 길이 \\(N\\in\\mathbb{N}\\)의 샘플 \\(x(0), x(1), \\ldots, x(N-1)\\)의 이산 신호라고 하자.\n샘플링 레이트 \\(F_\\mathrm{s}\\)가 주어졌을 때, \\(x\\)는 연속 시간 신호 \\(f:\\mathbb{R}\\to\\mathbb{R}\\)를 샘플링하여 얻는다고 가정한다.\n그러면 이산 푸리에 변환(DFT) \\(X := \\mathrm{DFT}_N \\cdot x\\)은 특정 주파수에 대한 연속 푸리에 변환 \\(\\hat{f}\\)의 근사치로 해석될 수 있다. \\[\nX(k) := \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / N)\n\\approx {F_\\mathrm{s}} \\cdot \\hat{f} \\left(k \\cdot \\frac{F_\\mathrm{s}}{N}\\right)\n\\] for \\(k\\in[0:N-1]\\).\n따라서 \\(X(k)\\)의 인덱스 \\(k\\)는 다음의 물리적 주파수(헤르츠단위)에 해당된다. \\[\\begin{equation}\n       F_\\mathrm{coef}^N(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n즉, 이산 푸리에 변환은 \\(\\mathrm{DFT}_N\\)의 크기 \\(N\\)에 따라 달라지는, 해상도 \\(F_\\mathrm{s}/N\\)의 선형 주파수 그리드(frequency grid)를 얻는다.\n주파수 그리드의 밀도를 높이기 위한 한 가지 아이디어는 인위적으로 신호에 0을 추가하여 DFT의 크기를 늘리는 것이다.\n이를 위해 \\(L\\in\\mathbb{N}\\) with \\(L\\geq N\\)라고 하자. 그런 다음 \\(\\tilde{x}\\in \\mathbb{R}^L\\) 신호를 얻기 위해 \\(x\\) 신호 오른쪽에 제로 패딩(zero padding)을 적용한다.\n\n\\[\\tilde{x}(n) :=\\left\\{\\begin{array}{ll}\n    x(n) , \\,\\,\\mbox{for}\\,\\, n \\in[0:N-1]\\\\\n    0,     \\,\\,\\mbox{for}\\,\\, n \\in[N:L-1]\n\\end{array}\\right.\\]\n\n\\(\\mathrm{DFT}_L\\)을 적용하면 다음을 얻는다. \\[\n\\tilde{X}(k) = \\mathrm{DFT}_L \\cdot \\tilde{x}\n= \\sum_{n=0}^{L-1} \\tilde{x}(n) \\exp(-2 \\pi i k n / L)\n= \\sum_{n=0}^{N-1} x(n) \\exp(-2 \\pi i k n / L)\n\\approx {F_\\mathrm{s}} \\cdot \\hat{f} \\left(k \\cdot \\frac{F_\\mathrm{s}}{L}\\right)\n\\] for \\(k\\in[0:L-1]\\).\n이제 계수 \\(\\tilde{X}(k)\\)는 다음의 물리적 주파수에 대응된다. \\[\\begin{equation}\n       F_\\mathrm{coef}^L(k) := \\frac{k\\cdot F_\\mathrm{s}}{L},\n\\end{equation}\\]\n이는 선형 주파수 해상도 \\(F_\\mathrm{s}/L\\)를 보인다.\n예를 들어, \\(L=2N\\)인 경우 주파수 그리드 해상도는 2배 증가한다. 즉, DFT가 길수록 간격이 더 가까운 주파수 빈(bin)이 더 많아진다.\n그러나 이 트릭은 DFT의 근사 품질을 개선하지 않는다는 점에 유의해야 한다(리만(Riemann) 근사의 합계 수는 여전히 \\(N\\)임에 유의하자).\n단, \\(L\\geq N\\) 및 제로 패딩을 사용할 때 주파수 축의 선형 샘플링이 정제(refine)된다.\n다음 예는 \\(\\mathrm{DFT}_N \\cdot x\\)를 \\(\\mathrm{DFT}_L \\cdot \\tilde{x}\\)와 비교한다.\n\n\nFs = 32\nduration = 2\nfreq1 = 5\nfreq2 = 15\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * freq1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * freq2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(8, 2))\n\nax1 = plt.subplot(1, 2, 1)\nplt.plot(x)\nplt.title('Orginal signal ($N$=%d)' % N)\nplt.xlabel('Time (samples)')\nplt.xlim([0, N - 1])\nplt.subplot(1, 2, 2)\nY = np.abs(np.fft.fft(x)) / Fs\nplt.plot(Y)\nplt.title('Magnitude DFT of original signal ($N$=%d)' % N)\nplt.xlabel('Frequency (bins)')\nplt.xlim([0, N - 1])\nplt.tight_layout()\n\nL = 2 * N\npad_len = L - N\nt_tilde = np.concatenate((t, np.arange(len(x), len(x) + pad_len) / Fs))\nx_tilde = np.concatenate((x, np.zeros(pad_len)))\n                         \nplt.figure(figsize=(8, 2))\nax1 = plt.subplot(1, 2, 1)\nplt.plot(x_tilde)\nplt.title('Padded signal ($L$=%d)' % L)\nplt.xlabel('Time (samples)')\nplt.xlim([0, L - 1])\nplt.subplot(1, 2, 2)\nY_tilde = np.abs(np.fft.fft(x_tilde)) / Fs\nplt.plot(Y_tilde)\nplt.title('Magnitude DFT of padded signal ($L$=%d)' % L)\nplt.xlabel('Frequency (bins)')\nplt.xlim([0, L - 1])\n\nplt.tight_layout()                       \n\n\n\n\n\n\n\n\n다음 코드 예제는 증가된 주파수 그리드 해상도로 DFT를 계산하는 함수를 구현한다.\n여기에서 모든 파라미터는 물리적 방식으로 해석된다(초 및 헤르츠 기준).\n\n\ndef compute_plot_DFT_extended(t, x, Fs, L):\n    N = len(x)\n    pad_len = L - N\n    t_tilde = np.concatenate((t, np.arange(len(x), len(x) + pad_len) / Fs))\n    x_tilde = np.concatenate((x, np.zeros(pad_len)))\n    Y = np.abs(np.fft.fft(x_tilde)) / Fs    \n    Y = Y[:L//2]\n    freq = np.arange(L//2)*Fs/L\n    # freq = np.fft.fftfreq(L, d=1/Fs)\n    # freq = freq[:L//2]\n    plt.figure(figsize=(10, 2))\n    \n    ax1 = plt.subplot(1, 3, 1)\n    plt.plot(t_tilde, x_tilde)\n    plt.title('Signal ($N$=%d)' % N)\n    plt.xlabel('Time (seconds)')\n    plt.xlim([t[0], t[-1]])\n    \n    ax2 = plt.subplot(1, 3, 2)\n    plt.plot(t_tilde, x_tilde)\n    plt.title('Padded signal (of size $L$=%d)' % L)\n    plt.xlabel('Time (seconds)')\n    plt.xlim([t_tilde[0], t_tilde[-1]])    \n    \n    ax3 = plt.subplot(1, 3, 3)\n    plt.plot(freq, Y)\n    plt.title('Magnitude DFT of padded signal ($L$=%d)' % L)\n    plt.xlabel('Frequency (Hz)')\n    plt.xlim([freq[0], freq[-1]])\n    plt.tight_layout()           \n\n    return ax1, ax2, ax3\n\n\nN = len(x)\n\nL = N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)\n\nL = 2 * N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)\n\nL = 4 * N\nax1, ax2, ax3 = compute_plot_DFT_extended(t, x, Fs, L)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-그리드-해상도가-증가된-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-그리드-해상도가-증가된-stft",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "주파수 그리드 해상도가 증가된 STFT",
    "text": "주파수 그리드 해상도가 증가된 STFT\n\n이제 동일한 제로-패딩 전략을 사용하여 STFT의 주파수 그리드 해상도를 높이는 방법을 보자. librosa 함수 librosa.stft는 두 개의 파라미터 n_fft(\\(L\\)에 해당) 및 win_length(\\(N\\)에 해당)를 통해 이 아이디어를 구현한다. 파라미터를 물리적 도메인으로 변환할 때 주의해야 한다.\n바이올린이 연주하는 음 C4의 예를 보자\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\nt_wav = np.arange(0, x.shape[0]) * 1 / Fs\nplt.figure(figsize=(5, 1.5))\nplt.plot(t_wav, x, c='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)')\nplt.tight_layout()\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n이제 제로 패딩으로 STFT를 계산한다. 그림에서 축은 시간 프레임 및 주파수 빈으로 표시된다.\n\n\ndef compute_stft(x, Fs, N, H, L=N, pad_mode='constant', center=True):    \n    X = librosa.stft(x, n_fft=L, hop_length=H, win_length=N, \n                     window='hann', pad_mode=pad_mode, center=center)\n    Y = np.log(1 + 100 * np.abs(X) ** 2)\n    F_coef = librosa.fft_frequencies(sr=Fs, n_fft=L)\n    T_coef = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H) \n    return Y, F_coef, T_coef\n\ndef plot_compute_spectrogram(x, Fs, N, H, L, color='gray_r'):\n    Y, F_coef, T_coef = compute_stft(x, Fs, N, H, L)\n    plt.imshow(Y, cmap=color, aspect='auto', origin='lower')\n    plt.xlabel('Time (frames)')\n    plt.ylabel('Frequency (bins)')\n    plt.title('L=%d' % L)\n    plt.colorbar()\n\n\nN = 256\nH = 64\ncolor = 'gray_r' \nplt.figure(figsize=(8, 3))\n\nL = N\nplt.subplot(1,3,1)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nL = 2 * N\nplt.subplot(1,3,2)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nL = 4 * N\nplt.subplot(1,3,3)\nplot_compute_spectrogram(x, Fs, N, H, L)\n\nplt.tight_layout()\n\n\n\n\n\n다음으로 동일한 계산을 반복한다. 여기서 축은 이제 초와 헤르츠로 지정된 물리적 단위를 표시하도록 변환된다. 또한 시간-주파수 평면을 확대하여 밀도가 높은 주파수 그리드 밀도의 효과를 강조한다.\n\n\ndef plot_compute_spectrogram_physical(x, Fs, N, H, L, xlim, ylim, color='gray_r'):\n    Y, F_coef, T_coef = compute_stft(x, Fs, N, H, L)\n    extent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\n    plt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title('L=%d' % L)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.colorbar()\n\n\nxlim_sec = [1, 2]\nylim_hz = [2000, 3000]\n\nplt.figure(figsize=(8, 3))\n\nL = N\nplt.subplot(1,3,1)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nL = 2 * N\nplt.subplot(1,3,2)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nL = 4 * N\nplt.subplot(1,3,3)\nplot_compute_spectrogram_physical(x, Fs, N, H, L, xlim=xlim_sec, ylim=ylim_hz)\n\nplt.tight_layout()\n\n\n\n\n\nlibrosa 함수 librosa.stft는 두 개의 파라미터 n_fft(패딩된 섹션의 크기 \\(L\\)에 해당) 및 win_length(\\(N\\)에 해당, 윈도우 부분)가 있다. 이 패딩 변형을 \\(L\\)(\\(N\\) 대신)와 함께 사용하면, 함수 \\(F_\\mathrm{coef}\\)의 계산을 다음과 같이 조정해야 한다. \\[\\begin{equation}\n       F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{L}\n\\end{equation}\\] for \\(k\\in [0:K]\\) with \\(K=L/2\\).\n반올림 문제를 방지하려면 짝수 \\(L\\)(아마도 2의 거듭제곱)를 선택하는 것이 좋다.\n\n\nN = 256\nL = 512\nH = 64\ncolor = 'gray_r' \n\nX = librosa.stft(x, n_fft=L, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True) # center에 대해서는 밑에서 다루기로 한다\nY = np.log(1 + 100 * np.abs(X) ** 2)\n\nT_coef = np.arange(0, X.shape[1]) * H / Fs\n\nK = L // 2\nF_coef = np.arange(K + 1) * Fs / L # 공식에 따라\nF_coef_librosa = librosa.fft_frequencies(sr=Fs, n_fft=L) # librosa 내장\nprint('F_coef 결과가 같은가:', np.allclose(F_coef, F_coef_librosa))\nprint('Y.shape = (%d,%d)'%(Y.shape[0],Y.shape[1]))\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\n\nF_coef 결과가 같은가: True\nY.shape = (257,1034)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#보간법-interpolation",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#보간법-interpolation",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "보간법 (Interpolation)",
    "text": "보간법 (Interpolation)\n\n데이터 포인트 시퀀스가 주어지면 보간법 interpolation의 목표는 의미 있는 방식으로 시퀀스를 정제(refine)하는 중간(intermediate) 데이터 포인트를 계산하는 것이다.\n보다 구체적으로, 파라미터 \\(t\\in\\mathbb{R}\\)를 \\(f(t)\\in\\mathbb{R}\\)로 매핑하는 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\) 함수를 고려해보자.\n\\(n\\in\\mathbb{Z}\\)에 대한 파라미터 \\(t_n\\in\\mathbb{R}\\)의 이산 집합에 대해서만 \\(f(t_n)\\) 값이 있다고 가정하자. \\(t_{n} > t_ {n-1}\\).\n그런 다음 보간법의 목표는 \\(f^\\ast(t)\\) 값을 추정하는 것이다. \\(f(t_n)\\)는 다음과 같이 주어진다.\n\n\\[f^\\ast(t) \\approx f(t)\\] for any \\(t\\in\\mathbb{R}\\)\n\n실제로는 \\(f\\) 함수는 알 수 없지만, 종종 \\(f\\)의 연속성, 평활성, 미분 가능성 등과 같은 특정 속성을 가정한다.\n가장 간단한 보간법 방법은 조각 상수 보간(piecewise constant interpolation)(또는 최근접 이웃(nearest neighbor) 보간법)이다. 파라미터 \\(t\\in\\mathbb{R}\\)가 주어지면, 가장 가까운 파라미터 \\(t_n\\)을 취하여 다음을 정의한다.\n\n\\(f^\\ast(t)=f(t_n).\\)\n\n\n\n# Simulates the original function\nt = np.arange(-0.5, 10.5, 0.01)\nf = np.sin(2 * t)\n\n# Known funcion values\nt_n = np.arange(0, 11)\nf_n = np.sin(2 * t_n)\n\n# Interpolation\nf_interpol_nearest = interp1d(t_n, f_n, kind='nearest', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_nearest, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Piecewise constant interpolation')\nplt.tight_layout()\n\n\n\n\n\n최근접 이웃 보간법은 일반적으로 이산 함수를 생성한다. 연속적인 보간법 함수를 얻기 위한 간단한 대안으로는 선형 보간법(linear interpolation)이 있다.\n\\(t_{n-1}\\)와 \\(t_n\\) 사이에 있는 파라미터 \\(t\\)가 주어지면, 다음과 같이 정의할 수 있다. \\[\nf^\\ast(t)=f(t_{n-1}) + (f(t_{n})-f(t_{n-1}))\\cdot\\frac{t-t_{n-1}}{t_{n} - t_{n-1}}.\n\\]\n\n\nf_interpol_linear = interp1d(t_n, f_n, kind='linear', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_linear, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Linear interpolation')\nplt.tight_layout()\n\n\n\n\n\nPython 클래스 scipy.inperploate.interp1d는 Nearest-neighbor, 선형 및 다양한 차수의 spline 보간을 포함하여 여러 종류의 보간 방법을 제공한다. 또 다른 예로, 3차 보간(3차 스플라인)에 대한 결과를 보자.\n\n\nf_interpol_cubic = interp1d(t_n, f_n, kind='cubic', fill_value='extrapolate')(t)\n\nplt.figure(figsize=(8, 2)) \nplt.plot(t, f, color=(0.8, 0.8, 0.8))\nplt.plot(t, f_interpol_cubic, 'r-')\nplt.plot(t_n, f_n, 'ko')\nplt.ylim([-1.5,1.5])\nplt.title('Cubic interpolation')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-보간법",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-보간법",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "주파수 보간법",
    "text": "주파수 보간법\n\n선형 주파수 그리드의 밀도를 증가시키기 위해 제로 패딩을 기반으로 더 큰 DFT를 사용할 수 있었다. 이제 주파수 영역에서 보간법을 적용하여 대안을 소개한다.\n\\(x\\in \\mathbb{R}^N\\)를 길이 \\(N\\in\\mathbb{N}\\), 샘플링 레이트 \\(F_\\mathrm{s}\\), DFT \\(X = \\mathrm{DFT} _N \\cdot x\\), 및 DFT 크기 \\(Y=|X|\\)의 이산 신호라고 하자. 그러면 \\(Y(k)\\)의 인덱스 \\(k\\)는 다음의 헤르츠로 주어진 물리적 주파수에 해당한다.\n\n\\[\\begin{equation}\n         F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\n\\end{equation}\\]\n\n즉, 주파수 그리드 결과의 해상도는 \\(F_\\mathrm{s}/N\\)이다. 팩터 \\(\\rho\\in\\mathbb{N}\\)를 도입하여, 해상도 \\(F_\\mathrm{s}/(\\rho\\cdot N)\\)를 고려하여 주파수 그리드를 정제(refine)한다. 이 주파수 그리드를 기반으로 보간 기술을 사용하여 크기 주파수 계수(magnitude frequency coefficient)를 계산한다.\n\n\nFs = 32\nduration = 2\nomega1 = 5\nomega2 = 15\nN = int(duration * Fs)\nt = np.arange(N) / Fs\nt1 = t[:N//2]\nt2 = t[N//2:]\n\nx1 = 1.0 * np.sin(2 * np.pi * omega1 * t1)\nx2 = 0.7 * np.sin(2 * np.pi * omega2 * t2)\nx = np.concatenate((x1, x2))\n\nplt.figure(figsize=(6, 2))\nplt.plot(t, x)\nplt.title('Orginal signal ($N$=%d)' % N)\nplt.xlabel('Time (seconds)')\nplt.xlim([t[0], t[-1]])   \nplt.tight_layout()\n\nY = np.abs(np.fft.fft(x)) / Fs\nY = Y[:N//2+1]\nF_coef = np.arange(N//2+1)*Fs/N\nplt.figure(figsize=(6, 2))\nplt.plot(F_coef,Y)\nplt.title('Magnitude DFT ($N$=%d)' % N)\nplt.xlabel('Frequency (Hz)')\nplt.xlim([F_coef[0], F_coef[-1]])     \nplt.tight_layout()\n\n\n\n\n\n\n\n\ndef interpolate_plot_DFT(N, Fs, F_coef, rho, int_method):\n    F_coef_interpol = np.arange(F_coef[0], F_coef[-1], Fs/(rho*N))\n    Y_interpol = interp1d(F_coef, Y, kind=int_method)(F_coef_interpol)\n    plt.figure(figsize=(6, 2))\n    plt.plot(F_coef_interpol, Y_interpol)\n    plt.title(r'Magnitude DFT (interpolation: %s, $\\rho$=%d)'%(int_method,rho))\n    plt.xlabel('Frequency (Hz)')\n    plt.xlim([F_coef[0], F_coef[-1]])\n    plt.tight_layout()\n\n\nrho = 4\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='nearest')\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='linear')\ninterpolate_plot_DFT(N=N, Fs=Fs, F_coef=F_coef, rho=rho, int_method='cubic')"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#stft를-위한-보간법",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#stft를-위한-보간법",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "STFT를 위한 보간법",
    "text": "STFT를 위한 보간법\n\nSTFT의 주파수 그리드를 정제하기 위해서 주파수 방향을 따라 보간법을 적용할 수 있다.\n이전과 같은 바이올린(C4)의 예로 보자.\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.display(ipd.Audio(x, rate=Fs))\n\nt_wav = np.arange(0, x.shape[0]) * 1 / Fs\nplt.figure(figsize=(6, 1))\nplt.plot(t_wav, x, c='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)');\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\ndef stft_convention_fmp(x, Fs, N, H, pad_mode='constant', center=True, mag=False, gamma=0):\n    \"\"\"Compute the discrete short-time Fourier transform (STFT)\n\n    Args:\n        x (np.ndarray): Signal to be transformed\n        Fs (scalar): Sampling rate\n        N (int): Window size\n        H (int): Hopsize\n        pad_mode (str): Padding strategy is used in librosa (Default value = 'constant')\n        center (bool): Centric view as used in librosa (Default value = True)\n        mag (bool): Computes magnitude STFT if mag==True (Default value = False)\n        gamma (float): Constant for logarithmic compression (only applied when mag==True) (Default value = 0)\n\n    Returns:\n        X (np.ndarray): Discrete (magnitude) short-time Fourier transform\n    \"\"\"\n    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N,\n                     window='hann', pad_mode=pad_mode, center=center)\n    if mag:\n        X = np.abs(X)**2\n        if gamma > 0:\n            X = np.log(1 + gamma * X)\n    F_coef = librosa.fft_frequencies(sr=Fs, n_fft=N)\n    T_coef = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H)\n    # T_coef = np.arange(X.shape[1]) * H/Fs\n    # F_coef = np.arange(N//2+1) * Fs/N\n    return X, T_coef, F_coef\n\n\ndef compute_f_coef_linear(N, Fs, rho=1):\n    \"\"\"Refines the frequency vector by factor of rho\n\n    Args:\n        N (int): Window size\n        Fs (scalar): Sampling rate\n        rho (int): Factor for refinement (Default value = 1)\n\n    Returns:\n        F_coef_new (np.ndarray): Refined frequency vector\n    \"\"\"\n    L = rho * N\n    F_coef_new = np.arange(0, L//2+1) * Fs / L\n    return F_coef_new\n\n\ndef interpolate_freq_stft(Y, F_coef, F_coef_new):\n    \"\"\"Interpolation of STFT along frequency axis\n\n    Args:\n        Y (np.ndarray): Magnitude STFT\n        F_coef (np.ndarray): Vector of frequency values\n        F_coef_new (np.ndarray): Vector of new frequency values\n\n    Returns:\n        Y_interpol (np.ndarray): Interploated magnitude STFT\n    \"\"\"\n    compute_Y_interpol = interp1d(F_coef, Y, kind='cubic', axis=0)\n    Y_interpol = compute_Y_interpol(F_coef_new)\n    return Y_interpol\n\n\ndef plot_compute_spectrogram_physical(x, Fs, N, H, xlim, ylim, rho=1, color='gray_r'):\n    Y, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H, mag=True, gamma=100)\n    F_coef_new = compute_f_coef_linear(N, Fs, rho=rho)\n    Y_interpol = interpolate_freq_stft(Y, F_coef, F_coef_new)    \n    extent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\n    plt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(r'$\\rho$=%d' % rho)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.colorbar()\n\n\nxlim_sec = [1, 2]\nylim_hz = [2000, 3000]\n\nN = 256\nH = 64\nplt.figure(figsize=(10, 4))\n \nplt.subplot(1, 3, 1)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=1)\n\nplt.subplot(1, 3, 2)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=2)\n\nplt.subplot(1, 3, 3)\nplot_compute_spectrogram_physical(x, Fs, N, H, xlim=xlim_sec, ylim=ylim_hz, rho=4)\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#로그-주파수-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#로그-주파수-stft",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "로그-주파수 STFT",
    "text": "로그-주파수 STFT\n\n이 보간법은 주파수 그리드의 비선형 변형에 사용될 수 있다. 예를 들어 선형 간격의 주파수 축(헤르츠로 측정)을 로그 간격의 주파수 축(피치 또는 센트로 측정)으로 변환할 수 있다.\n로그 간격의 주파수 그리드를 정의하는 것이 주요 단계이다. 이때 음정에 사용되는 대수 측정 단위인 센트라는 개념을 사용한다. 참조 주파수 \\(\\omega_0\\)가 주어지면 임의의 주파수 \\(\\omega\\)와 \\(\\omega_0\\) 사이의 거리는 다음과 같이 지정된다. \\[\n    \\log_2\\left(\\frac{\\omega}{\\omega_0}\\right)\\cdot 1200\n\\]\n다음 함수에서는 최소 주파수 값(매개변수 F_min이 기준 주파수 \\(\\omega_0\\)로 사용되므로 \\(0\\) cents에 해당함)에서 시작하여 로그 간격의 주파수 축을 계산한다.\n또한 이 함수에는 로그 해상도를 센트 단위로 지정하는 파라미터 R이 있다. 즉, 로그 주파수 축에서 두 개의 연속된 주파수 빈은 R 센트 떨어져 있다.\n최대 주파수는 다른 매개변수 F_max에 의해 지정된다.\n다음 예에서 주파수 F_min = 100(\\(0\\) 센트에 해당) 및 F_max = 3200(\\(6000\\) 센트에 해당)을 사용한다. 또한 해상도는 R=20(옥타브당 \\(60\\) 주파수 빈에 해당)으로 설정한다.\n\n\ndef compute_f_coef_log(R, F_min, F_max):\n    \"\"\"Adapts the frequency vector in a logarithmic fashion\n\n    Args:\n        R (scalar): Resolution (cents)\n        F_min (float): Minimum frequency\n        F_max (float): Maximum frequency (not included)\n\n    Returns:\n        F_coef_log (np.ndarray): Refined frequency vector with values given in Hz)\n        F_coef_cents (np.ndarray): Refined frequency vector with values given in cents.\n            Note: F_min serves as reference (0 cents)\n    \"\"\"\n    n_bins = np.ceil(1200 * np.log2(F_max / F_min) / R).astype(int)\n    F_coef_log = 2 ** (np.arange(0, n_bins) * R / 1200) * F_min\n    F_coef_cents = 1200 * np.log2(F_coef_log / F_min)\n    return F_coef_log, F_coef_cents\n\n\nN = 1024\nH = 256\nY, T_coef, F_coef = stft_convention_fmp(x, Fs, N, H, mag=True, gamma=100)\n\nF_min = 100\nF_max = 3200\nR = 20\nF_coef_log, F_coef_cents = compute_f_coef_log(R, F_min, F_max)\n\nprint('#bins=%3d, F_coef[0]      =%6.2f, F_coef[1]      =%6.2f, F_coef[-1]      =%6.2f'%(len(F_coef),F_coef[0], F_coef[1], F_coef[-1]))\nprint('#bins=%3d, F_coef_log[0]  =%6.2f, F_coef_log[1]  =%6.2f, F_coef_log[-1]  =%6.2f'%(len(F_coef_log),F_coef_log[0], F_coef_log[1], F_coef_log[-1]))\nprint('#bins=%3d, F_coef_cents[0]=%6.2f, F_coef_cents[1]=%6.2f, F_coef_cents[-1]=%6.2f'%(len(F_coef_cents),F_coef_cents[0], F_coef_cents[1], F_coef_cents[-1]))\n\n#bins=513, F_coef[0]      =  0.00, F_coef[1]      = 21.53, F_coef[-1]      =11025.00\n#bins=300, F_coef_log[0]  =100.00, F_coef_log[1]  =101.16, F_coef_log[-1]  =3163.24\n#bins=300, F_coef_cents[0]=  0.00, F_coef_cents[1]= 20.00, F_coef_cents[-1]=5980.00\n\n\n\nY_interpol = interpolate_freq_stft(Y, F_coef, F_coef_log)\ncolor = 'gray_r' \n\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 3, 1)\nextent=[T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_ticks_freq = np.array([100, 400, 800, 1200, 1600, 2000, 2400, 2800, 3200])\nplt.yticks(y_ticks_freq)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.title('Linear frequency axis')\nplt.ylim([F_min, F_max])\nplt.colorbar()\n\nplt.subplot(1, 3, 2)\nextent=[T_coef[0], T_coef[-1], F_coef_cents[0], F_coef_cents[-1]]\nplt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_tick_freq_cents = 1200 * np.log2(y_ticks_freq / F_min)\nplt.yticks(y_tick_freq_cents, y_ticks_freq)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.title('Log-frequency axis')\nplt.title('Log-frequency axis with R=%d' % R)\nplt.colorbar()\n\nplt.subplot(1, 3, 3)\nextent=[T_coef[0], T_coef[-1], F_coef_cents[0], F_coef_cents[-1]]\nplt.imshow(Y_interpol, cmap=color, aspect='auto', origin='lower', extent=extent)\ny_ticks_cents = np.array([0, 1200, 2400, 3600, 4800, 6000])\nplt.yticks(y_ticks_cents)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (cents)')\nplt.title('Log-frequency axis')\nplt.title('Log-frequency axis with R=%d' % R)\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#샘플-신호에-대한-시간-축",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#샘플-신호에-대한-시간-축",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "샘플 신호에 대한 시간 축",
    "text": "샘플 신호에 대한 시간 축\n\n\\(x=(x(0),x(1), \\ldots x(L-1))^\\top \\in \\mathbb{R}^L\\)을 길이가 \\(L\\in\\mathbb{N}\\)인 이산-시간 신호라고 가정하자. 또한 \\(F_\\mathrm{s}\\)를 샘플 레이트라고 하자.\n그런 다음 물리적 시간 위치(초 단위로 표시)의 벡터 \\(t=(t(0),t(1), \\ldots t(L-1))^\\top \\in \\mathbb{R}^L\\)을 \\(x\\)에 대입하면 다음과 같이 정의된다. \\[\n   t(n) = \\frac{n}{F_\\mathrm{s}}\n\\] for \\(n\\in[0:L-1]\\)\n다시 말해,\n\n샘플 \\(x(0)\\)는 물리적 시간 \\(t(0)=0\\)(초 단위로 표시됨)와 연관된다.\n신호 \\(x\\)의 기간(duration)(초 단위)은 샘플 수를 샘플링 속도로 나눈 것이다: \\(L/F_\\mathrm{s}\\). 단, 이것은 \\(t(L-1)=(L-1)/F_\\mathrm{s}\\)와 동일하지 않다.\n두 샘플 \\(x(n-1)\\) 및 \\(x(n)\\) 사이의 거리(샘플링 기간 sampling period이라고 함)는 \\(1/F_\\mathrm{s}\\)이다.\n\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")\nipd.Audio(x, rate=Fs)\nL = x.shape[0] #샘플 수\nt_wav = np.arange(L) / Fs\nx_duration = L / Fs #듀레이션\n\nprint('t[0] = %0.4f, t[-1] = (L-1)/Fs = %0.4f, Fs = %0.0f, L = %0.0f, dur_x=%0.4f'\n      % (t_wav[0], t_wav[-1], Fs, L, x_duration))\nipd.display(ipd.Audio(x, rate=Fs))\n\nplt.figure(figsize=(6, 2))\nplt.plot(t_wav, x, color='gray')\nplt.xlim([t_wav[0], t_wav[-1]])\nplt.xlabel('Time (seconds)')\nplt.tight_layout()\n\nt[0] = 0.0000, t[-1] = (L-1)/Fs = 3.0000, Fs = 22050, L = 66150, dur_x=3.0000\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n# librosa를 이용한 plot\n# 단 librosa는 파형의 샘플이 아닌 symmetric amplitude envelope를 그림\n\nplt.figure(figsize=(6, 2))\nlibrosa.display.waveshow(x, color='gray')\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#중심-윈도우잉과-시간-변환-centered-windowing-and-time-conversion",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#중심-윈도우잉과-시간-변환-centered-windowing-and-time-conversion",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "중심 윈도우잉과 시간 변환 (Centered Windowing and Time Conversion)",
    "text": "중심 윈도우잉과 시간 변환 (Centered Windowing and Time Conversion)\n\n신호의 윈도우 부분을 고려할 때 중앙 (centered) 시점을 채택한다. 여기서 윈도우의 중심이란 물리적 도메인과 관련된 참조로 사용된다.\n특히 STFT를 계산할 때, 윈도우 길이의 절반의 제로-패딩을 적용하여 신호를 왼쪽으로 확장한다.\n보다 정확히 말하면, \\(w:[0:N-1]\\to\\mathbb{R}\\)를 짝수 윈도우 길이 \\(N\\in\\mathbb{N}\\)의 윈도우 함수라고 하고 \\(H\\in\\mathbb{ N}\\)를 홉(hop) 크기라고 하자. 그리고 \\(N/2\\)개 0값을 앞에 넣는다.\n\n\\[\n\\tilde{x}=(0,\\ldots,0,x(0),x(1), \\ldots x(L-1))^\\top \\in \\mathbb{R}^{L+N/2}\n\\]\n\\[\n   \\mathcal{X}(m,k):= \\sum_{n=0}^{N-1} \\tilde{x}(n+mH)w(n)\\mathrm{exp}(-2\\pi ikn/N).\n\\]\n\n또한 프레임 인덱스 \\(m\\)이 물리적 시간 위치와 연관되어 있는 규칙을 사용한다.\n\n\\(T_\\mathrm{coef}(m) := \\frac{m\\cdot H}{F_\\mathrm{s}}\\)\n\n특히 다음이 성립한다.\n\n프레임 인덱스 \\(m=0\\)는 물리적 시간 \\(T_\\mathrm{coef}(0)=0\\)(초 단위)에 해당한다.\n시간 해상도(즉, 연속되는 두 프레임 사이의 거리)은 \\(\\Delta t = H/F_\\mathrm{s}\\)(초 단위)이다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-변환-frequency-conversion",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#주파수-변환-frequency-conversion",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "주파수 변환 (Frequency Conversion)",
    "text": "주파수 변환 (Frequency Conversion)\n\n\\(x\\) 및 \\(w\\)가 실수이면 주파수 계수의 상위 절반이 중복된다. 따라서 계수 \\(k\\in[0:K]\\) (\\(K=N/2\\))만 사용된다.\n특히 인덱스 \\(k=N/2\\)는 나이퀴스트(Nyquist) 주파수 \\(\\omega=F_\\mathrm{s}/2\\)에 해당한다.\n또한 인덱스 \\(k\\)는 다음의 주파수에 해당한다(헤르츠 단위).\n\n\\(F_\\mathrm{coef}(k) := \\frac{k\\cdot F_\\mathrm{s}}{N}\\)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#스펙트로그램-시각화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#스펙트로그램-시각화",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "스펙트로그램 시각화",
    "text": "스펙트로그램 시각화\n\n다음 코드는 이러한 규칙을 구현하기 위해 librosa 함수 librosa.stft를 사용하는 방법을 보여준다. 파라미터 설정 center=True는 centered view를 활성화하고 pad_mode='constant'는 제로-패딩 모드로 전환한다.\n또한 이 코드는 변환 함수 \\(T_\\mathrm{coef}\\) 및 \\(F_\\mathrm{coef}\\)를 한 번은 위의 공식을 사용하고 한 번은 librosa 내장 함수를 사용하여 구현하는 방법을 보여준다. 홀수 윈도우 크기 \\(N\\)의 경우 반올림에 대한 다른 규칙이 있을 수 있다. 실제로는 일반적으로 짝수 윈도우 크기를 사용한다(특히 FFT algorithm 관점에서 2의 거듭제곱임).\n\n\nN = 256\nH = 64\ncolor = 'gray_r' \n\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nY = np.log(1 + 100 * np.abs(X) ** 2)\n\nT_coef = np.arange(X.shape[1]) * H / Fs #위의 공식\nT_coef_librosa = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H) #librosa 내장\nprint('T_coef 계산 결과가 같은가:', np.allclose(T_coef, T_coef_librosa))\n\nK = N // 2\nF_coef = np.arange(K+1) * Fs / N #위의 공식\nF_coef_librosa = librosa.fft_frequencies(sr=Fs, n_fft=N) #librosa 내장\nprint('F_coef 계산 결과가 같은가:', np.allclose(F_coef, F_coef_librosa))\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0], T_coef[-1], F_coef[0], F_coef[-1]]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\nplt.show()\n\nT_coef 계산 결과가 같은가: True\nF_coef 계산 결과가 같은가: True\n\n\n\n\n\n\n시각화에서 centered view를 채택하려면 프레임 길이의 절반만큼 왼쪽 및 오른쪽 여백을 조정하고, 빈(bin) 너비의 절반만큼 아래쪽 및 위쪽 여백을 조정해야 한다.\n그러나 큰 스펙트로그램의 경우 시각화의 이러한 작은 조정은 상관 없다.\n\n\nplt.figure(figsize=(6, 3))\nextent = [T_coef[0] - (H / 2) / Fs, T_coef[-1] + (H / 2) / Fs,\n          F_coef[0] - (Fs / N) / 2, F_coef[-1] + (Fs / N) / 2]\nplt.imshow(Y, cmap=color, aspect='auto', origin='lower', extent=extent)\nplt.xlim([T_coef[0], T_coef[-1]])\nplt.ylim([F_coef[0], F_coef[-1]])\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency (Hz)')\nplt.colorbar()\nplt.tight_layout()\n\n\n\n\n\n# librosa의 내장 함수로 결과를 비교하자\n\nplt.figure(figsize=(6, 3))\nlibrosa.display.specshow(Y, y_axis='linear', x_axis='time', sr=Fs, hop_length=H, cmap=color)\nplt.colorbar()\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-dft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-dft",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "역(Inverse) DFT",
    "text": "역(Inverse) DFT\n\n\\(N\\in\\mathbb{N}\\) 길이의 벡터 \\(x\\in \\mathbb{C}^N\\)가 주어지면 DFT은 행렬-벡터 곱으로 정의된다. \\[X = \\mathrm{DFT}_N \\cdot x\\]\n\nwith \\(\\mathrm{DFT}_N \\in \\mathbb{C}^{N\\times N}\\)\ngiven by \\(\\mathrm{DFT}_N(n, k) = \\mathrm{exp}(-2 \\pi i k n / N)\\)\nfor \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\nDFT는 벡터 \\(x\\)를 스펙트럼 벡터 \\(X\\)에서 복구할 수 있다는 점에서 invertible하다. 역 DFT는 행렬-벡터 곱으로 다시 지정된다. \\[ x = \\mathrm{DFT}_N^{-1} \\cdot X, \\]\n여기서 \\(\\mathrm{DFT}_N^{-1}\\)는 DFT 행렬 \\(\\mathrm{DFT}_N\\)의 역을 나타낸다.\n\n\\(\\mathrm{DFT}_N^{-1}(n, k) = \\frac{1}{N}\\mathrm{exp}(2 \\pi i k n / N)\\)\nfor \\(n\\in[0:N-1]\\) and \\(k\\in[0:N-1]\\).\n\n즉, 역함수는 본질적으로 일부 정규화 인자(normalizing factor) 및 켤레 복소수(complex conjugation)까지 DFT 행렬과 일치한다.\n다음 코드 셀에서 DFT 행렬과 그 역행렬을 생성한다. 또한 두 행렬이 실제로 서로 역임을 보여준다.\n\n이를 위해 \\(\\mathrm{DFT}_N \\cdot \\mathrm{DFT}_N^{-1}\\)와 항등 행렬 \\(I_N\\in \\mathbb{R}^{N\\times N}\\)의 차이, 그리고 \\(\\mathrm{DFT}_N^{-1} \\cdot\\mathrm{DFT}_N\\)와 \\(I_N\\)의 차이를 측정한다.\n\n\n\ndef generate_matrix_dft(N, K):\n    \"\"\"Generates a DFT (discrete Fourier transfrom) matrix\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n    Returns:\n        dft (np.ndarray): The DFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(-2j * np.pi * k * n / N)\n    return dft\n\ndef generate_matrix_dft_inv(N, K):\n    \"\"\"Generates an IDFT (inverse discrete Fourier transfrom) matrix\n    Args:\n        N (int): Number of samples\n        K (int): Number of frequency bins\n    Returns:\n        dft (np.ndarray): The IDFT matrix\n    \"\"\"\n    dft = np.zeros((K, N), dtype=np.complex128)\n    for n in range(N):\n        for k in range(K):\n            dft[k, n] = np.exp(2j * np.pi * k * n / N) / N\n    return dft\n\n\nN = 32\ndft_mat = generate_matrix_dft(N, N)\ndft_mat_inv = generate_matrix_dft_inv(N, N)\n\nI = np.eye(N)\nA =  np.dot(dft_mat, dft_mat_inv)\nB =  np.dot(dft_mat_inv, dft_mat)\n\nplt.figure(figsize=(11, 3))\n\nplt.subplot(1, 3, 1)\nplt.title(r'$I_N$ for $N = %d$'%N)\nplt.imshow(I, origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar()\n\nplt.subplot(1, 3, 2)\nplt.title(r'$|I_N - \\mathrm{DFT}_N \\cdot \\mathrm{DFT}_N^{-1}|$')\nplt.imshow(np.abs(I-A), origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar()\n\nplt.subplot(1, 3, 3)\nplt.title(r'$|I_N - \\mathrm{DFT}_N^{-1} \\cdot \\mathrm{DFT}_N|$')\nplt.imshow(np.abs(I-B), origin='lower', cmap='seismic', aspect='equal')\nplt.colorbar();\n\nplt.tight_layout()\n\n\n\n\n\nDFT는 FFT 알고리즘을 사용하여 효율적으로 계산할 수 있다. 역 DFT 계산에도 적용할 수 있다. 다음에서는 numpy.fft.fft 및 numpy.fft.ifft를 사용해 구현한다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-stft",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#역inverse-stft",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "역(Inverse) STFT",
    "text": "역(Inverse) STFT\n\n다음으로 이산 STFT을 inverting하는 법을 보자.\n\\(x:\\mathbb{Z}\\to\\mathbb{R}\\)를 이산-시간 신호라고 하고, \\(\\mathcal{X}\\)를 그것의 STFT라고 하자.\n또한 \\(w:[0:N-1]\\to\\mathbb{R}\\)를 길이 \\(N\\in\\mathbb{N}\\) 및 홉 크기 파라미터 \\(H\\in\\mathbb{N}\\)의 실수 값 이산 윈도우 함수를 나타낸다고 하자.\n표기상 편의를 위해 제로-패딩을 사용하여 윈도우 함수를 \\(w:\\mathbb{Z}\\to\\mathbb{R}\\)로 확장한다.\n\\(x_n:\\mathbb{Z}\\to\\mathbb{R}\\)를 다음에 의해 정의된 윈도우 신호라고 하자.\n\n\\(x_n(r):=x(r+nH)w(r)\\) for \\(r\\in\\mathbb{Z}\\).\n\n그러면 STFT 계수 \\(\\mathcal{X}(n,k)\\) for \\(k\\in[0:N-1]\\)가 다음에 의해 얻어진다.\n\n\\((\\mathcal{X}(n,0),\\ldots, \\mathcal{X}(n,N-1))^\\top = \\mathrm{DFT}_N \\cdot (x_n(0),\\ldots, x_n(N-1))^\\top.\\)\n\n\\(\\mathrm{DFT}_N\\)가 invertible 행렬이기 때문에 STFT에서의 윈도우 신호 \\(x_n\\)를 다음과 같이 재구성할 수 있다. \\[(x_n(0),\\ldots x_n(N-1))^\\top = \\mathrm{DFT}_N^{-1} \\cdot (\\mathcal{X}(n,0),\\ldots, \\mathcal{X}(n,N-1))^\\top\\]\n원래 신호의 샘플 \\(x(r)\\)을 얻으려면 윈도우 프로세스를 반대로 해야 한다. 이것은 윈도우 프로세스에서 상대적으로 약한 조건에서 가능하다는 것을 볼 수 있다. 신호의 윈도우 섹션의 적절하게 이동된 모든 버전에 대한 중첩(superposition)을 고려해 보자. \\[\\sum_{n\\in\\mathbb{Z}} x_n(r-nH)\n  = \\sum_{n\\in\\mathbb{Z}} x(r-nH+nH)w(r-nH)\n  = x(r)\\sum_{n\\in\\mathbb{Z}} w(r-nH)\\]\n따라서 샘플 \\(x(r)\\)를 다음을 통해 복구할 수 있다. \\[x(r) = \\frac{\\sum_{n\\in\\mathbb{Z}} x_n(r-nH)}{\\sum_{n\\in\\mathbb{Z}} w(r-nH)}\\]\n\n\\(\\sum_{n\\in\\mathbb{Z}} w(r-nH)\\not= 0\\)\n\n이 전반적인 접근 방식은 소위 overlap–add technique을 기반으로 한다. 이 기술에서는 겹치는 재구성된 윈도우 섹션이 단순히 오버레이되고 합산된다(그런 다음 windowing을 보상하기 위해 정규화됨)."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#단위-분할-partition-of-unity",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#단위-분할-partition-of-unity",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "단위 분할 (Partition of Unity)",
    "text": "단위 분할 (Partition of Unity)\n\n위의 조건을 만족하는 홉 크기와 함께 윈도우 함수를 찾는 것은 어렵지 않다. 예를 들어 윈도우 함수 \\(w:[0:N-1]\\to\\mathbb{R}\\)가 양수이고 홉 크기가 윈도우 길이보다 작거나 같을 때 time-shifted 윈도우에 대한 합계는 항상 양수이다.\n종종 윈도우 함수와 홉 크기를 다음의 더 강한 조건으로 선택할 수도 있다.\n\n\\(\\sum_{n\\in\\mathbb{Z}} w(r-nH) = 1\\) (for all \\(r\\in\\mathbb{Z}\\) is fulfilled.)\n\n이 경우, time-shifted 윈도우 함수는 이산 시간 축 \\(\\mathbb{Z}\\)의 단위 분할 (partition of unity)을 정의한다고 한다.\n예를 들어, 다음과 같이 정의된 윈도우 \\(w:\\mathbb{Z}\\to\\mathbb{R}\\)로 squared sinusoidal을 사용할 때 단위 분할을 얻는다.\n\n\\(w(r):= \\left\\{ \\begin{array}{cl}  \\sin(\\pi r/N)^2 \\quad \\mbox{if}\\,\\,\\, r\\in[0:N-1] \\\\  0 \\quad \\mbox{otherwise}  \\end{array} \\right.\\)\n홉 사이즈는 \\(H=N/2\\)\n\n단위 분할이 되는 속성은 윈도우 함수 자체뿐만 아니라 홉 크기 파라미터에도 의존한다는 점에 유의해야 한다.\n다음 그림은 \\(N\\) 길이의 다양한 윈도우 함수와 홉 크기 \\(H\\)를 사용하는 time-shifted 버전을 보여준다. time-shifted 버전의 합은 두꺼운 빨간색 곡선으로 표시된다.\n\n\ndef plot_sum_window(w, H, L, title='', figsize=(6, 2)):\n    N = len(w)\n    M = np.floor((L - N) / H).astype(int) + 1\n    w_sum = np.zeros(L)\n    plt.figure(figsize=figsize)\n    for m in range(M):\n        w_shifted = np.zeros(L)\n        w_shifted[m * H:m * H + N] = w\n        plt.plot(w_shifted, 'k')\n        w_sum = w_sum + w_shifted\n    plt.plot(w_sum, 'r', linewidth=3)\n    plt.xlim([0, L-1])\n    plt.ylim([0, 1.1*np.max(w_sum)])\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n    return w_sum\n\n\nL = 256\nN = 64\n\nH = N//2\nw_type = 'triang'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Triangular window, H = N/2');\n\nH = N//2\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Hann window, H = N/2');\n\nH = 3*N//8\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nplot_sum_window(w, H, L, title='Hann window, H = 3N/8');\n\nH = N//4\nw = scipy.signal.gaussian(N, std=8)\nplot_sum_window(w, H, L, title='Gaussian window, H = N/4');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#구현",
    "href": "posts/3. Fourier Anaylsis of Signals/3.4.Short-term_Fourier_Transfrom_2.html#구현",
    "title": "3.4. 단기 푸리에 변환 (Short-Term Fourier Transform, STFT) (2)",
    "section": "구현",
    "text": "구현\n\n역 DFT에서 작은 허수값을 피하기 위해 재구성된 윈도우 신호의 실수 부분만 유지하는게 이득일 수 있다.\n역 DFT를 적용한 후에는 윈도잉을 보상해야 한다. 프레임 기반 레벨에서(즉, 각 윈도우 섹션에 대해 개별적으로) 이 작업을 수행하는 것 보다는 모든 윈도우 신호와 이동된 모든 윈도우를 개별적으로 누적하여 전역적으로(globally) 보상을 수행해야 한다. 전역 보상이 가능한 이유는 DFT의 선형성에 있다. 또한 보상에서 0으로 나누기를 피해야 한다.\n주어진 홉 크기에 대해 이동된 윈도우가 단위 분할(a partition of unity)을 형성하는 경우, 보상을 수행할 필요가 없다.\nSTFT 계산에서 패딩이 적용된 경우 역 STFT 계산 시 이를 고려해야 한다.\n\n\ndef stft_basic(x, w, H=8, only_positive_frequencies=False):\n    \"\"\"Compute a basic version of the discrete short-time Fourier transform (STFT)\n    Args:\n        x (np.ndarray): Signal to be transformed\n        w (np.ndarray): Window function\n        H (int): Hopsize (Default value = 8)\n        only_positive_frequencies (bool): Return only positive frequency part of spectrum (non-invertible)\n            (Default value = False)\n    Returns:\n        X (np.ndarray): The discrete short-time Fourier transform\n    \"\"\"\n    N = len(w)\n    L = len(x)\n    M = np.floor((L - N) / H).astype(int) + 1\n    X = np.zeros((N, M), dtype='complex')\n    for m in range(M):\n        x_win = x[m * H:m * H + N] * w\n        X_win = np.fft.fft(x_win)\n        X[:, m] = X_win\n\n    if only_positive_frequencies:\n        K = 1 + N // 2\n        X = X[0:K, :]\n    return X\n\ndef istft_basic(X, w, H, L):\n    \"\"\"Compute the inverse of the basic discrete short-time Fourier transform (ISTFT)\n    Args:\n        X (np.ndarray): The discrete short-time Fourier transform\n        w (np.ndarray): Window function\n        H (int): Hopsize\n        L (int): Length of time signal\n    Returns:\n        x (np.ndarray): Time signal\n    \"\"\"\n    N = len(w)\n    M = X.shape[1]\n    x_win_sum = np.zeros(L)\n    w_sum = np.zeros(L)\n    for m in range(M):\n        x_win = np.fft.ifft(X[:, m])\n        # Avoid imaginary values (due to floating point arithmetic)\n        x_win = np.real(x_win)\n        x_win_sum[m * H:m * H + N] = x_win_sum[m * H:m * H + N] + x_win\n        w_shifted = np.zeros(L)\n        w_shifted[m * H:m * H + N] = w\n        w_sum = w_sum + w_shifted\n    # Avoid division by zero\n    w_sum[w_sum == 0] = np.finfo(np.float32).eps\n    x_rec = x_win_sum / w_sum\n    return x_rec, x_win_sum, w_sum\n\n\nL = 256\nt = np.arange(L) / L\nomega = 4\nx = np.sin(2 * np.pi * omega * t * t)\n\nN = 64\nH = 3 * N // 8\nw_type = 'hann'\nw = scipy.signal.get_window(w_type, N)\nX = stft_basic(x, w=w, H=H)\nx_rec, x_win_sum, w_sum = istft_basic(X, w=w, H=H, L=L)\n\nplt.figure(figsize=(8, 3))\nplt.plot(x, color=[0, 0, 0], linewidth=4, label='Original signal')\nplt.plot(x_win_sum, 'b', label='Summed windowed signals')\nplt.plot(w_sum, 'r', label='Summed windows')\nplt.plot(x_rec, color=[0.8, 0.8, 0.8], linestyle=':', linewidth=4, label='Reconstructed signal')\nplt.xlim([0,L-1])\nplt.legend(loc='lower left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nlibrosa 예제\n\n단, librosa.istft에서는 다른 윈도우 보상 방법을 사용한다. \\[x(r) = \\frac{\\sum_{n\\in\\mathbb{Z}} w(r-nH)x_n(r-nH)}{\\sum_{n\\in\\mathbb{Z}} w(r-nH)^2}\\]\n\n\ndef print_plot(x, x_rec):\n    print('Number of samples of x:    ', x.shape[0])\n    print('Number of samples of x_rec:', x_rec.shape[0])\n    if x.shape[0] == x_rec.shape[0]:\n        print('Signals x and x_inv agree:', np.allclose(x, x_rec))\n        plt.figure(figsize=(6, 2))\n        plt.plot(x-x_rec, color='red')\n        plt.xlim([0, x.shape[0]])\n        plt.title('Differences between x and x_rec')\n        plt.xlabel('Time (samples)');\n        plt.tight_layout()\n        plt.show()\n    else:\n        print('Number of samples of x and x_rec does not agree.')\n\n\nx, Fs = librosa.load(\"../audio/violin_c4_legato.wav\")        \n        \nN = 4096\nH = 2048\nL = x.shape[0]\n\nprint('=== Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=True, length=L)\nprint('stft: center=True; istft: center=True')\nprint_plot(x, x_rec)\n\nprint('=== Non-Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=False)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=False, length=L)\nprint('stft: center=False; istft: center=False')\nprint_plot(x, x_rec)\n\nprint('=== Centered vs. Non-Centered Case ===')\nX = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', pad_mode='constant', center=True)\nx_rec = librosa.istft(X, hop_length=H, win_length=N, window='hann', center=False, length=L)\nprint('stft: center=True; istft: center=False')\nprint_plot(x, x_rec)\n\nplt.figure(figsize=(6, 2))\nplt.plot(x, color='black')\nplt.xlim([0, x.shape[0]])\nplt.plot(x_rec, color='gray')\nplt.title('Signal x (black) and x_rec (gray)')\nplt.xlabel('Time (samples)');\nplt.tight_layout()\nplt.show()\n\n=== Centered Case ===\nstft: center=True; istft: center=True\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: True\n\n\n\n\n\n=== Non-Centered Case ===\nstft: center=False; istft: center=False\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: False\n\n\n\n\n\n=== Centered vs. Non-Centered Case ===\nstft: center=True; istft: center=False\nNumber of samples of x:     66150\nNumber of samples of x_rec: 66150\nSignals x and x_inv agree: False\n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\nhttps://musicinformationretrieval.com/\n\n\n구글 Colab 링크"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "",
    "text": "오디오 신호(signal)의 디지털화에 필요한 샘플링(sampling)과 양자화(quantization)에 대해 소개하며, 또한 간섭(interference) 및 비팅(beating) 현상을 다룬다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링sampling",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링sampling",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "샘플링(Sampling)",
    "text": "샘플링(Sampling)\n\n신호 처리(signal processing)에서, 샘플링이란 연속 신호를 시간 축의 이산적 부분집합으로만 정의된 이산 신호로 축소시키는 것을 말한다.\n적절한 인코딩을 통해 이산 집합이 정수 집합 \\(\\mathbb{Z}\\)의 하위 집합 \\(I\\)라고 가정하고는 한다. 그런 다음 이산시간(discrete time, DT)-신호는 함수 \\(x\\colon I\\to\\mathbb{R}\\)로 정의되며 여기서 도메인 \\(I\\)는 시점에 해당한다.\n\\(\\mathbb{Z}\\setminus I\\)의 포인트에 대해 모든 값을 0으로 설정하는 것만으로 도메인 \\(I\\)에서 도메인 \\(\\mathbb{Z}\\)로 모든 DT 신호를 확장할 수 있으므로 \\(I=\\mathbb{Z}\\)를 가정할 수 있다.\n연속시간(continuous time, CT)-신호 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\)를 DT-신호 \\(x\\colon\\mathbb{Z}\\to\\mathbb{R}\\)로 변환하는 가장 일반적인 샘플링 절차는 등거리 샘플링(equidistant sampling)이라고 한다.\n양의 실수 \\(T>0\\)를 고정하면, DT-신호 \\(x\\)는 다음과 같이 설정하여 얻는다.\n\n\\(x(n):= f(n \\cdot T)\\) for \\(n\\in\\mathbb{Z}\\)\n\n\\(x(n)\\) 값은 원래 아날로그 신호 \\(f\\)의 시간 \\(t=n\\cdot T\\)에서 가져온 샘플이라고 한다. 간단히 말해서 이 절차를 \\(T\\)-샘플링 이라고도 한다.\n숫자 \\(T\\)는 샘플링 주기 (sampling period) 라고 하고 역(inverse) \\(F_\\mathrm{s}:=1/T\\)는 샘플링 레이트/속도 (sampling rate) 라고 한다. 샘플링 레이트는 초당 샘플 수를 지정하며 헤르츠(Hz) 단위로 측정된다.\n다음 코드 셀에서 높은 샘플링 속도로 샘플링된 DT-신호의 선형 보간법을 통해 정의된 CT-신호 \\(f\\)로 시작한다. 그림에서 이 CT-신호는 검은색 곡선으로 표시된다. 등거리 샘플링을 적용하여 빨간색 줄기 플롯으로 시각화된 DT 신호 \\(x\\)를 얻는다.\n\n\ndef generate_function(Fs, dur=1):\n    \"\"\"Generate example function\n    \n    Args:\n        Fs (scalar): Sampling rate\n        dur (float): Duration (in seconds) of signal to be generated (Default value = 1)\n        \n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    N = int(Fs * dur)\n    t = np.arange(N) / Fs\n    x = 1 * np.sin(2 * np.pi * (2 * t - 0))\n    x += 0.5 * np.sin(2 * np.pi * (6 * t - 0.1))\n    x += 0.1 * np.sin(2 * np.pi * (20 * t - 0.2))\n    return x, t\n\n\ndef sampling_equidistant(x_1, t_1, Fs_2, dur=None):\n    \"\"\"Equidistant sampling of interpolated signal\n\n    Args:\n        x_1 (np.ndarray): Signal to be interpolated and sampled\n        t_1 (np.ndarray): Time axis (in seconds) of x_1\n        Fs_2 (scalar): Sampling rate used for equidistant sampling\n        dur (float): Duration (in seconds) of sampled signal (Default value = None)\n        \n    Returns:\n        x (np.ndarray): Sampled signal\n        t (np.ndarray): Time axis (in seconds) of sampled signal\n    \"\"\"\n    if dur is None:\n        dur = len(t_1) * t_1[1]\n    N = int(Fs_2 * dur)\n    t_2 = np.arange(N) / Fs_2\n    x_2 = interp1d(t_1, x_1, kind='linear', fill_value='extrapolate')(t_2)\n    return x_2, t_2\n\n\nFs_1 = 100\nx_1, t_1 = generate_function(Fs=Fs_1, dur=2)\n\nFs_2 = 20\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\n    \nplt.figure(figsize=(6, 2))\nplt.plot(t_1, x_1, 'k')\nplt.title('Original CT-signal')\nplt.xlabel('Time (seconds)')\nplt.ylim([-1.5, 1.5])\nplt.xlim([t_1[0], t_1[-1]])\nplt.tight_layout()\n\nplt.figure(figsize=(6, 2))\nplt.stem(t_2, x_2, linefmt='r', markerfmt='ro', basefmt='None')\nplt.plot(t_1, x_1, 'k', linewidth=1, linestyle='dotted')\nplt.title(r'Sampling rate $F_\\mathrm{s} = %.0f$'%Fs_2)\nplt.xlabel('Time (seconds)')\nplt.ylim([-1.5, 1.5])\nplt.xlim([t_1[0], t_1[-1]])\nplt.tight_layout()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#에일리어싱-aliasing",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#에일리어싱-aliasing",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "에일리어싱 (Aliasing)",
    "text": "에일리어싱 (Aliasing)\n또는 위신호현상\n\n일반적으로 샘플링은 처리 과정에서 정보가 손실되고 원본 CT-신호를 샘플링된 버전으로부터 복구할 수 없다는 점에서 손실적인(lossy) 작업이다.\nCT-신호에 주파수 스펙트럼 측면(대역 제한(bandlimited) 필요)에서 추가 속성이 있는 경우에만 완벽한 재구성이 가능하다. 이것이 유명한 샘플링 정리(sampling theorem)의 주장이다. 샘플링 이론은 또한 DT-신호의 샘플에 의해 가중된 적절하게 이동된 \\(\\mathrm{sinc}\\)-함수를 중첩하여 원래 CT-신호가 어떻게 재구성될 수 있는지 보여준다.\n추가적인 속성이 없다면 샘플링으로 인해 신호의 특정 주파수 구성 요소를 구분할 수 없게 되는 에일리어싱(aliasing)이라는 현상이 발생할 수 있다.\n이 효과는 다음 그림에 설명되어 있다. 높은 샘플링 속도를 사용하면 원본 CT-신호를 높은 정확도로 재구성할 수 있다. 그러나 샘플링 속도를 낮추면 더 높은 주파수 구성 요소가 잘 캡처되지 않고 원래 신호의 대략적인 근사치만 남는다.\n\n\ndef reconstruction_sinc(x, t, t_sinc):\n    \"\"\"Reconstruction from sampled signal using sinc-functions\n\n    Args:\n        x (np.ndarray): Sampled signal\n        t (np.ndarray): Equidistant discrete time axis (in seconds) of x\n        t_sinc (np.ndarray): Equidistant discrete time axis (in seconds) of signal to be reconstructed\n\n    Returns:\n        x_sinc (np.ndarray): Reconstructed signal having time axis t_sinc\n    \"\"\"\n    Fs = 1 / t[1]\n    x_sinc = np.zeros(len(t_sinc))\n    for n in range(0, len(t)):\n        x_sinc += x[n] * np.sinc(Fs * t_sinc - n)\n    return x_sinc\n\ndef plot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc):\n    plt.figure(figsize=(6, 2))\n    plt.plot(t_1, x_1, 'k', linewidth=1, linestyle='dotted', label='Orignal signal')\n    plt.stem(t_2, x_2, linefmt='r:', markerfmt='r.', basefmt='None', label='Samples')\n    plt.plot(t_1, x_sinc, 'b', label='Reconstructed signal')\n    plt.title(r'Sampling rate $F_\\mathrm{s} = %.0f$'%(1/t_2[1]))\n    plt.xlabel('Time (seconds)')\n    plt.ylim([-1.5, 1.5])\n    plt.xlim([t_1[0], t_1[-1]])\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.show()\n\n\nFs_2 = 40\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\nFs_2 = 20\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\nFs_2 = 10\nx_2, t_2 = sampling_equidistant(x_1, t_1, Fs_2)\nt_sinc = t_1\nx_sinc = reconstruction_sinc(x_2, t_2, t_sinc)\nplot_signal_reconstructed(t_1, x_1, t_2, x_2, t_sinc, x_sinc);\n\n\n\n\n\n\n\n\n\n\n\n다음 예는 에일리어싱이 음질에 미치는 영향을 나타낸다. 높은 샘플링 속도(\\(F_s=8192Hz\\))의 음악 신호로 시작한 다음 두배씩 줄여나가보자.\n\n\nx, Fs = librosa.load('../audio/piano_c_scale.wav', sr=8000)\nFs_orig = Fs\nlen_orig = len(x)\nfor i in range(5):\n    print('Sampling rate Fs = %s; Number of samples = %s' % (Fs, len(x)))\n    x_play = scipy.signal.resample(x, len_orig)\n    ipd.display(ipd.Audio(data=x_play, rate=Fs_orig))\n    Fs = Fs // 2\n    x = x[::2]\n\nSampling rate Fs = 8000; Number of samples = 54001\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 4000; Number of samples = 27001\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 2000; Number of samples = 13501\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 1000; Number of samples = 6751\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSampling rate Fs = 500; Number of samples = 3376\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링-정리-sampling-theorem",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#샘플링-정리-sampling-theorem",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "샘플링 정리 (Sampling Theorem)",
    "text": "샘플링 정리 (Sampling Theorem)\n\n샘플링 정리 (sampling theorem)는 대역 제한이 있는(bandlimited) 연속 시간(CT) 신호를 특정 조건에서 완벽하게 재구성할 수 있다고 말한다.\n보다 정확하게는 \\(|\\omega|>\\Omega\\) 에 대해 푸리에 변환 \\(\\hat{f}\\)가 사라지면 CT 신호 \\(f\\in L^2(\\mathbb{R})\\)를 \\(\\Omega\\)-bandlimited 라고 한다 (즉, \\(\\hat{f}(\\omega) = 0\\) for \\(|\\omega|>\\Omega\\)).\n\\(f\\in L^2(\\mathbb{R})\\)를 \\(\\Omega\\)-bandlimited 함수라고 하고, \\(x\\)를 \\(f\\)의 (with \\(T:=1/(2\\Omega)\\)) \\(T\\)-샘플 버전이라고 하자 (즉, \\(x(n)=f(nT)\\), \\(n\\in\\mathbb{Z}\\)).\n그러면 \\(f\\)는 다음과 같이 \\(x\\)로부터 재구성될 수 있다.\n\n\\[\nf(t)=\\sum_{n\\in\\mathbb{Z}}x(n)\\mathrm{sinc}\\left(\\frac{t-nT}{T}\\right)\n=\\sum_{n\\in\\mathbb{Z}}f\\left(\\frac{n}{2\\Omega}\\right) \\mathrm{sinc}\\left(2\\Omega t-n\\right),\n\\]\nwhere the \\(\\mathrm{sinc}\\)-function is defined as\n\\[\\begin{equation}\n    \\mathrm{sinc}(t):=\\left\\{\\begin{array}{ll}\n    \\frac{\\sin \\pi t}{\\pi t},&\\mbox{ if $t\\not= 0$,}\\\\\n    1,&\\mbox{ if $t= 0$.}\n\\end{array}\\right.\n\\end{equation}\\]\n\n즉, 대역 제한이 샘플링 속도의 절반 이하인 경우, 등거리 샘플링으로 얻은 DT 신호에서 CT 신호 \\(f\\)를 완벽하게 재구성할 수 있다.\n\\(\\mathrm{sinc}\\) 함수를 기반으로 한 이 재구성은 reconstruction_sinc 함수에서 사용되었다."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#이산화-discretization",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#이산화-discretization",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "이산화 (Discretization)",
    "text": "이산화 (Discretization)\n\n위에서 연속-시간 축을 이산-시간 축으로 변환하는 과정으로서의 샘플링을 보았다. 이것은 아날로그-to-디지털의 첫번째 단계였다.\n두 번째 단계에서는 가능한 진폭(amplitude)의 연속 범위(\\(\\mathbb{R}\\)로 인코딩됨)를 가능한 값의 이산 범위(이산 집합 \\(\\Gamma\\subset \\mathbb{R}\\)로 인코딩됨)로 대체해야 한다. 이 프로세스를 일반적으로 양자화(quantization) 라고 한다.\n\n\nImage('../img/3.fourier_analysis/f.2.13.PNG', width=500)"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#균일uniform-양자화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#균일uniform-양자화",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "균일(Uniform) 양자화",
    "text": "균일(Uniform) 양자화\n\n양자화는 각 진폭 값 \\(a\\in\\mathbb{R}\\)에 값 \\(Q(a)\\in\\Gamma\\)을 할당하는 quantizer라고 하는 함수 \\(Q:\\mathbb{R}\\to\\Gamma\\)로 모델링할 수 있다.\n사용되는 많은 quantizer는 단순히 아날로그 값을 일부 정밀도 단위로 반올림하거나 자른다(truncate). 예를 들어 어떤 값 \\(\\Delta\\)와 동일한 quantization step size를 갖는 일반적인 uniform quantizer는 양자화 수준을 균일하게 배치한다.\n\n\\(Q(a) := \\mathrm{sgn}(a) \\cdot \\Delta \\cdot \\left\\lfloor \\frac{|a|}{\\Delta} + \\frac{1}{2} \\right\\rfloor\\) for \\(a\\in\\mathbb{R}\\),\n\\(\\mathrm{sgn}(\\cdot)\\)는 실수의 부호를 생성하는 signum 함수이며, 대괄호 \\(\\lfloor \\cdot \\rfloor\\)는 실수를 잘라(truncate) 이 숫자 아래에서 가장 큰 정수를 생성하는 것이다.\n\\(\\Delta=1\\)의 경우 quantizer \\(Q\\)는 가장 가까운 정수로 간단히 반올림된다.\n\n\n\n양자화 오류 (Quantization Error)\n\n샘플링과 마찬가지로 양자화는 일반적으로 손실이 많은 작업이다. 다른 아날로그 값이 동일한 디지털 값에 매핑될 수 있기 때문이다. 실제 아날로그 값과 양자화된 값의 차이를 양자화 오류라고 한다.\n양자화 step size \\(\\Delta\\)를 줄이면 일반적으로 양자화 오류가 더 작아진다. 그러나 동시에 양자화된 값의 수(따라서 이러한 값을 인코딩하는 데 필요한 비트 수)도 증가한다.\n예를 들어 양자화 단계 크기 \\(\\Delta=1/3\\)가 사용되면 주어진 신호에 대해 \\(8\\)의 서로 다른 양자화 값이 생성된다. 따라서 \\(3\\) 비트 코딩 방식을 사용하여 양자화된 값을 나타낼 수 있다. CD 녹음의 경우 \\(65536\\) 가능한 값을 표현할 수 있는 \\(16\\) 비트 코딩 체계가 사용된다.\n\n\n\n균일 양자화 구현\n\n다음에서 모든 아날로그 값이 \\(s,t\\in\\mathbb{R}\\)에 대해 \\([s,t]\\) 범위 내에 있다고 가정한다. 또한 여러 양자화 수준이 \\(\\lambda\\in\\mathbb{N}\\)인 경우, 양자화 step size를 \\(\\Delta=|t-s|/(\\lambda-1)\\)로 정의한다. 이는 \\(\\lambda\\) 양자화 레벨로 구성되는 (\\(s\\) 값으로 시작하여 \\(t\\) 값으로 끝남), 값 \\(s\\)와 \\(t\\) 사이의 uniform 양자화로 정의한다.\n예를 들어 파형 기반 오디오 신호는 일반적으로 \\([-1,1]\\) 범위에 있다.\n\\(s=-1\\), \\(t=1\\) 및 \\(\\lambda=9\\)의 경우 결과는 \\(\\Delta=1/4\\)이다. 이 경우 결과 양자화 오류는 최대 1/8입니다. 다음 코드 셀에서 서로 다른 매개변수 \\(s\\), \\(t\\) 및 \\(\\lambda\\)에 대해 균일한 양자화를 산출하는 quantize_uniform 함수를 정의해보자.\n\n\ndef quantize_uniform(x, quant_min=-1.0, quant_max=1.0, quant_level=5):\n    \"\"\"Uniform quantization approach\n\n    Args:\n        x (np.ndarray): Original signal\n        quant_min (float): Minimum quantization level (Default value = -1.0)\n        quant_max (float): Maximum quantization level (Default value = 1.0)\n        quant_level (int): Number of quantization levels (Default value = 5)\n\n    Returns:\n        x_quant (np.ndarray): Quantized signal\n    \"\"\"\n    x_normalize = (x-quant_min) * (quant_level-1) / (quant_max-quant_min)\n    x_normalize[x_normalize > quant_level - 1] = quant_level - 1\n    x_normalize[x_normalize < 0] = 0\n    x_normalize_quant = np.around(x_normalize)\n    x_quant = (x_normalize_quant) * (quant_max-quant_min) / (quant_level-1) + quant_min\n    return x_quant\n\n\ndef plot_graph_quant_function(ax, quant_min=-1.0, quant_max=1.0, quant_level=256, mu=255.0, quant='uniform'):\n    \"\"\"Helper function for plotting a graph of quantization function and quantization error\n\n    Args:\n        ax (mpl.axes.Axes): Axis\n        quant_min (float): Minimum quantization level (Default value = -1.0)\n        quant_max (float): Maximum quantization level (Default value = 1.0)\n        quant_level (int): Number of quantization levels (Default value = 256)\n        mu (float): Encoding parameter (Default value = 255.0)\n        quant (str): Type of quantization (Default value = 'uniform')\n    \"\"\"\n    x = np.linspace(quant_min, quant_max, 1000)\n    if quant == 'uniform':\n        x_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, quant_level=quant_level)\n        quant_stepsize = (quant_max - quant_min) / (quant_level-1)\n        title = r'$\\lambda = %d, \\Delta=%0.2f$' % (quant_level, quant_stepsize)\n    if quant == 'nonuniform':\n        x_quant = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\n        title = r'$\\lambda = %d, \\mu=%0.1f$' % (quant_level, mu)\n    error = np.abs(x_quant - x)\n    ax.plot(x, x, color='k', label='Original amplitude')\n    ax.plot(x, x_quant, color='b', label='Quantized amplitude')\n    ax.plot(x, error, 'r--', label='Quantization error')\n    ax.set_title(title)\n    ax.set_xlabel('Amplitude')\n    ax.set_ylabel('Quantized amplitude/error')\n    ax.set_xlim([quant_min, quant_max])\n    ax.set_ylim([quant_min, quant_max])\n    ax.grid('on')\n    ax.legend()\n\n\nplt.figure(figsize=(12,4))\nax = plt.subplot(1, 3, 1)\nplot_graph_quant_function(ax, quant_min=-1, quant_max=4, quant_level=3)\nax = plt.subplot(1, 3, 2)\nplot_graph_quant_function(ax, quant_min=-2, quant_max=2, quant_level=4)\nax = plt.subplot(1, 3, 3)\nplot_graph_quant_function(ax, quant_min=-1, quant_max=1, quant_level=9)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n다음 코드 셀에서는 정현파를 신호로 사용하여 다양한 파라미터 설정에 대한 균일(uniform) 양자화 결과를 본다.\n\n\ndef generate_sinusoid(dur=5, Fs=1000, amp=1, freq=1, phase=0):\n    \"\"\"Generation of sinusoid\n    \n    2.3.Audio_Represenation에 쓰인 바 있음\n    \n    Args:\n        dur (float): Duration (in seconds) (Default value = 5)\n        Fs (scalar): Sampling rate (Default value = 1000)\n        amp (float): Amplitude of sinusoid (Default value = 1)\n        freq (float): Frequency of sinusoid (Default value = 1)\n        phase (float): Phase of sinusoid (Default value = 0)\n    Returns:\n        x (np.ndarray): Signal\n        t (np.ndarray): Time axis (in seconds)\n    \"\"\"\n    num_samples = int(Fs * dur)\n    t = np.arange(num_samples) / Fs\n    x = amp * np.sin(2*np.pi*(freq*t-phase))\n    return x, t\n\n\ndef plot_signal_quant(x, t, x_quant, figsize=(6, 2), xlim=None, ylim=None, title=''):\n    \"\"\"Helper function for plotting a signal and its quantized version\n\n    Args:\n        x: Original Signal\n        t: Time\n        x_quant: Quantized signal\n        figsize: Figure size (Default value = (8, 2))\n        xlim: Limits for x-axis (Default value = None)\n        ylim: Limits for y-axis (Default value = None)\n        title: Title of figure (Default value = '')\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.plot(t, x, color='gray', linewidth=1.0, linestyle='-', label='Original signal')\n    plt.plot(t, x_quant, color='red', linewidth=2.0, linestyle='-', label='Quantized signal')\n    if xlim is None:\n        plt.xlim([0, t[-1]])\n    else:\n        plt.xlim(xlim)\n    if ylim is not None:\n        plt.ylim(ylim)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.title(title)\n    plt.legend(loc='upper right', framealpha=1)\n    plt.tight_layout()\n    plt.show()\n\n\ndur = 5\nx, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1, phase=0.0)\n\nquant_min = -1\nquant_max = 1\nquant_level = 5\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));\n\nquant_min = -0.5\nquant_max = 1\nquant_level = 3\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));\n\nquant_min = -1.2\nquant_max = 1.2\nquant_level = 4\nx_quant = quantize_uniform(x, quant_min=quant_min, quant_max=quant_max, \n                          quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \n                  title=r'Uniform quantization with min=$%0.1f$, max=$%0.1f$, $\\lambda$=$%d$'%(quant_min, quant_max, quant_level));"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비균일nonuniform-양자화",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비균일nonuniform-양자화",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "비균일(Nonuniform) 양자화",
    "text": "비균일(Nonuniform) 양자화\n\n균일 양자화에서 양자화 수준은 등거리(equidistant) 방식으로 배치(spaced)된다. 그렇지 않은 경우 비균일(nonuniform) 양자화라고 한다. 예를 들어 오디오 신호의 경우 로그 방식으로 간격을 둔 양자화 수준을 선택하는 경우가 많다. 소리 강도에 대한 인간의 인식이 본질적으로 대수적이기 때문이다.\n따라서 인지적 관점에서 보면 높은 진폭 값을 인코딩하는 것보다 낮은 진폭 값을 인코딩하는 데 더 많은 비트를 활용하는 것이 유리할 수 있다(낮은 진폭 값에서 인간은 소리 강도의 변화에 더 민감함).\n로그 양자화에 대한 한 가지 접근 방식으로 다음과 같이 정의되는 \\(\\mu\\)-law 인코딩이 있다. \\[F_\\mu(v) = \\mathrm{sgn}(v) \\frac{\\ln(1+ \\mu |v|)}{\\ln(1+\\mu)}\\] for values \\(v\\in[-1,1]\\), where \\(\\mathrm{sgn}\\) denotes the signum function\n파라미터 \\(\\mu\\in\\mathbb{R}_{>0}\\)는 적용되는 compression 정도를 결정하는 정수이다.\n실제로는 비균일 \\(8\\)비트 양자화 체계를 도출하기 위해 \\(\\mu=255\\)를 자주 사용한다. 인코딩 \\(F_\\mu\\)는 strictly 증가 단조 함수로, \\([-1,1]\\) 간격을 낮은 값은 확장되고 높은 값은 압축되도록 자기 자체에 매핑한다.\n그 역인 \\(\\mu\\)-law 디코딩(decoding) 은 다음과 같다. \\[F_\\mu^{-1}(v) = \\mathrm{sgn}(v) \\frac{(1 + \\mu)^{|v|}- 1}{\\mu}\\] for values \\(v\\in[-1,1]\\)\n다음 코드 셀에서 \\(F_\\mu\\) 함수와 그 역 \\(F_\\mu^{-1}\\)를 구현하고 다른 파라미터 \\(\\mu\\)에 대한 결과를 설명한다.\n\n\ndef encoding_mu_law(v, mu=255.0):\n    \"\"\"mu-law encoding\n\n    Args:\n        v (float): Value between -1 and 1\n        mu (float): Encoding parameter (Default value = 255.0)\n\n    Returns:\n        v_encode (float): Encoded value\n    \"\"\"\n    v_encode = np.sign(v) * (np.log(1.0 + mu * np.abs(v)) / np.log(1.0 + mu))\n    return v_encode\n\n\ndef decoding_mu_law(v, mu=255.0):\n    \"\"\"mu-law decoding\n\n    Args:\n        v (float): Value between -1 and 1\n        mu (float): Dencoding parameter (Default value = 255.0)\n\n    Returns:\n        v_decode (float): Decoded value\n    \"\"\"\n    v_decode = np.sign(v) * (1.0 / mu) * ((1.0 + mu)**np.abs(v) - 1.0)\n    return v_decode\n\n\ndef plot_mu_law(mu=255.0, figsize=(8, 3)):\n    \"\"\"Helper function for plotting a signal and its quantized version\n\n    Args:\n        mu (float): Dencoding parameter (Default value = 255.0)\n        figsize (tuple): Figure size (Default value = (8.5, 2))\n    \"\"\"\n    values = np.linspace(-1, 1, 1000)\n    values_encoded = encoding_mu_law(values, mu=mu)\n    values_decoded = encoding_mu_law(values, mu=mu)\n\n    plt.figure(figsize=figsize)\n    ax = plt.subplot(1, 2, 1)\n    ax.plot(values, values, color='k', label='Original values')\n    ax.plot(values, values_encoded, color='b', label='Encoded values')\n    ax.set_title(r'$\\mu$-law encoding with $\\mu=%.0f$' % mu)\n    ax.set_xlabel('$v$')\n    ax.set_ylabel(r'$F_\\mu(v)$')\n    ax.set_xlim([-1, 1])\n    ax.set_ylim([-1, 1])\n    ax.grid('on')\n    ax.legend()\n\n    ax = plt.subplot(1, 2, 2)\n    ax.plot(values, values, color='k', label='Original values')\n    ax.plot(values, values_decoded, color='b', label='Decoded values')\n    ax.set_title(r'$\\mu$-law decoding with $\\mu=%.0f$' % mu)\n    ax.set_xlabel('$v$')\n    ax.set_ylabel(r'$F_\\mu^{-1}(v)$')\n    ax.set_xlim([-1, 1])\n    ax.set_ylim([-1, 1])\n    ax.grid('on')\n    ax.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\nplot_mu_law(mu=255.0)\nplot_mu_law(mu=7.0)\n\n\n\n\n\n\n\n\n비균일 양자화 구현\n\n먼저 주어진 신호를 \\(F_\\mu\\)를 사용하여 인코딩한 다음, 균일 양자화를 적용하고, 마지막으로 \\(F_\\mu^{-1}\\)를 사용하여 양자화된 신호를 디코딩해보자. 다음 코드에서 신호 샘플을 \\([-1,1]\\) 범위에 있는 경우로 제한한다. 뒤의 그림은 위의 정현파 예제 형식을 따르는 균일 양자화와 비균일 양자화의 차이를 보여준다.\n\n\ndef quantize_nonuniform_mu(x, mu=255.0, quant_level=256):\n    \"\"\"Nonuniform quantization approach using mu-encoding\n\n    Args:\n        x (np.ndarray): Original signal\n        mu (float): Encoding parameter (Default value = 255.0)\n        quant_level (int): Number of quantization levels (Default value = 256)\n\n    Returns:\n        x_quant (np.ndarray): Quantized signal\n    \"\"\"\n    x_en = encoding_mu_law(x, mu=mu)\n    x_en_quant = quantize_uniform(x_en, quant_min=-1, quant_max=1, quant_level=quant_level)\n    x_quant = decoding_mu_law(x_en_quant, mu=mu)\n    return x_quant\n\n\ndur = 5\nx, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1, phase=0.0)\n\nquant_level = 8\nx_quant = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \ntitle=r'Uniform quantization with $\\lambda$=$%d$'%(quant_level));\n\nmu = 7\nx_quant = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\nplot_signal_quant(x, t, x_quant, xlim=[0, dur], ylim=[-1.3,1.3], \ntitle=r'Nonuniform quantization with $\\mu$=$%d$ and $\\lambda$=$%d$'%(mu, quant_level));\n\n\n\n\n\n\n\n\n위의 접근 방식은 두 개의 파라미터, \\(\\mu\\)(인코딩 파라미타) 및 \\(\\lambda\\)(간격 \\([-1,1]\\)의 양자화 레벨 수)에 따라 달라지는 비균일 양자화 함수를 생성한다. 다음 코드 셀에서는 다양한 파라미터 설정에 대한 양자화 오류(quantization error)와 양자화 함수의 그래프를 보여준다. 양자화 오류는 \\(|v|\\approx 1\\)인 \\(v\\) 값보다 \\(|v|\\approx 0\\)인 \\(v\\) 값에서 훨씬 더 낮다.\n\n\nplt.figure(figsize=(12,3))\nax = plt.subplot(1, 3, 1)\nplot_graph_quant_function(ax, mu=3, quant_level=4, quant='nonuniform')\nax = plt.subplot(1, 3, 2)\nplot_graph_quant_function(ax, mu=7, quant_level=8, quant='nonuniform')\nax = plt.subplot(1, 3, 3)\nplot_graph_quant_function(ax, mu=15, quant_level=16, quant='nonuniform')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#양자화-잡음-quantization-noise",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#양자화-잡음-quantization-noise",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "양자화 잡음 (Quantization Noise)",
    "text": "양자화 잡음 (Quantization Noise)\n\n신호의 양자화는 손실이 많은 작업이다. 이 과정에서 발생하는 왜곡을 양자화 잡음이라고 한다. 다음 코드 셀에서 샘플 값을 인코딩하기 위해 다른 수의 비트를 사용하여 C 장음계의 피아노 녹음을 양자화하여 이러한 왜곡의 impression을 줘본다. \\(b\\in\\mathbb{N}\\) 비트를 사용하여 \\(2^b\\)의 서로 다른 양자화 레벨을 인코딩할 수 있다.\n\n\ndef display_signal_quant(x, Fs, number_of_bits):\n    quant_level = 2 ** number_of_bits\n    x_quant = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)    \n    print('Signal after uniform quantization (%d bits) :'%number_of_bits, flush=True)\n    ipd.display(ipd.Audio(x_quant, rate=Fs))\n    return x_quant\n\n\nx, Fs = librosa.load(\"../audio/piano_c_scale.wav\", sr=11025)\n\nprint('Original audio signal (16 bits):', flush=True)\nipd.display(ipd.Audio(x, rate=Fs) )\n\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=8)\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=4)\nx_quant = display_signal_quant(x=x, Fs=Fs, number_of_bits=2)\n\nOriginal audio signal (16 bits):\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (8 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (4 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\nSignal after uniform quantization (2 bits) :\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n균일 및 비균일 양자화에 대한 양자화 노이즈\n\n위의 C 메이저 스케일의 피아노 녹음을 사용하여 양자화 노이즈 결과 균일 및 비균일 양자화를 비교한다. 샘플 값을 인코딩하기 위해 서로 다른 비트 수를 고려한다. 특히, \\(8\\) 비트 균일 양자화를 사용할 때보다 \\(8\\) 비트 비균일 양자화를 사용할 때 더 낮은 노이즈 레벨을 인지한다.\n\n\ndef compare_quant_signal(x, Fs, number_of_bits):\n    quant_level = 2 ** number_of_bits\n    mu = quant_level-1\n    x_qu = quantize_uniform(x, quant_min=-1, quant_max=1, quant_level=quant_level)    \n    x_qn = quantize_nonuniform_mu(x, mu=mu, quant_level=quant_level)\n    audio_player_list([x, x_qu, x_qn], [Fs, Fs, Fs], width=160, \n                columns=['Original (16 bits)', 'Uniform (%d bits)'%number_of_bits, 'Nonuniform (%d bits)'%number_of_bits])\n\n\nx, Fs = librosa.load(\"../audio/piano_c_scale.wav\", sr=11025)\n\ncompare_quant_signal(x, Fs, number_of_bits=8)\ncompare_quant_signal(x, Fs, number_of_bits=4)\ncompare_quant_signal(x, Fs, number_of_bits=2)\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (8 bits)\n      Nonuniform (8 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n    \n  \n\n\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (4 bits)\n      Nonuniform (4 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n    \n  \n\n\n\n\n\n  \n    \n      Original (16 bits)\n      Uniform (2 bits)\n      Nonuniform (2 bits)\n    \n  \n  \n    \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element.                \n                                              Your browser does not support the audio element."
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#간섭interference",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#간섭interference",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "간섭(Interference)",
    "text": "간섭(Interference)\n\n신호 처리에서 간섭(interference)은 한 파동이 비슷한 주파수의 다른 파동과 중첩(superimposed)될 때 발생한다. 한 파동의 파고(crest)가 어떤 지점에서 다른 파동의 파고와 만나면 일정 기간 동안 개별적 크기가 합산되며 이를 보강 간섭(constructive interference)이라고 한다. 반대로, 한 파동의 파고가 다른 파동의 파고와 만나면 크기가 일정 시간 동안 상쇄되는데, 이를 상쇄 간섭(destructive interference)이라고 한다.\n\n\ndef plot_interference(x1, x2, t, figsize=(6, 2), xlim=None, ylim=None, title=''):\n    \"\"\"Helper function for plotting two signals and its superposition\n    Args:\n        x1: Signal 1\n        x2: Signal 2\n        t: Time\n        figsize: figure size (Default value = (8, 2))\n        xlim: x limits (Default value = None)\n        ylim: y limits (Default value = None)\n        title: figure title (Default value = '')\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.plot(t, x1, color='gray', linewidth=.5, linestyle='-', label='x1', alpha=.6)\n    plt.plot(t, x2, color='cyan', linewidth=.5, linestyle='-', label='x2', alpha=.6)\n    plt.plot(t, x1+x2, color='red', linewidth=1.0, linestyle='-', label='x1+x2', alpha=.6)\n    if xlim is None:\n        plt.xlim([0, t[-1]])\n    else:\n        plt.xlim(xlim)\n    if ylim is not None:\n        plt.ylim(ylim)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Amplitude')\n    plt.title(title)\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.show()\n\n\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.05, phase=0.0)\nx2, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=0.95, phase=0.8)\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-2.2,2.2], title='Constructive Interference');\n\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.05, phase=0.0)\nx2, t = generate_sinusoid(dur=dur, Fs=1000, amp=1, freq=1.00, phase=0.4)\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-2.2,2.2], title='Destructive Interference');"
  },
  {
    "objectID": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비팅beating",
    "href": "posts/3. Fourier Anaylsis of Signals/3.5.Digital_Signals.html#비팅beating",
    "title": "3.5. 디지털 신호 (Digital Signals)",
    "section": "비팅(Beating)",
    "text": "비팅(Beating)\n\n앞의 그림은 주파수가 비슷한 두 정현파가 더해지거나(보강 간섭) 상쇄(상쇄 간섭)될 수 있음을 보여주었다.\n\\(f_1(t)=\\sin(2\\pi \\omega_1 t)\\) 및 \\(f_2(t)=\\sin(2\\pi \\omega_2 t)\\)를 뚜렷하지만 가까운 주파수 \\(\\omega_1\\approx\\omega_2\\)의 두 정현파라고 하자.\n이제 이 두 정현파의 중첩 \\(f_1+f_2\\)가 진폭이 천천히 변하는 단일 사인파처럼 보이는 함수를 생성한다는 것을 볼 수 있다. 이 현상은 비팅(beating) 이라고 한다. 수학적으로 이 현상은 삼각 항등식 (trigonometric identity)의 결과이다. \\[\\sin(2\\pi \\omega_1t)+\\sin(2\\pi \\omega_2t)=\n2\\cos\\left(2\\pi\\frac{\\omega_1-\\omega_2}{2}t\\right)\\sin\\left(2\\pi\\frac{\\omega_1+\\omega_2}{2}t\\right).\\]\n\\(\\omega_1-\\omega_2\\)의 차이가 작으면 코사인 항은 사인 항에 비해 빈도가 낮다.\n결과적으로 신호 \\(f_1+f_2\\)는 주파수 \\(|\\omega_1-\\omega_2|\\)의 천천히 변하는 진폭 포락선(amplitude envelope)을 가지는 주파수 \\((\\omega_1+\\omega_2)/2\\)의 사인파로 볼 수 있다.\n이 비율은 코사인 항의 빈도 \\((\\omega_1-\\omega_2)/2\\)의 두 배이다.\n\n\nFs = 4000\ndur = 5\nx1, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=200)\nx2, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=203)\nplot_interference(x1, x2, t, ylim=[-1.1,1.1], xlim=[0, dur],\n    title=r'Beating with beating frequency $|\\omega_1-\\omega_2|=3$ ($\\omega_1=200, \\omega_2=203$)');\nplot_interference(x1, x2, t, ylim=[-1.1,1.1], xlim=[1.115, 1.225], title=r'Zoom-in section');\n\nipd.display(ipd.Audio(x1+x2, rate=Fs))\n\n\n\n\n\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n처프(Chirp) 실험\n\n비팅(beating)효과를 설명하기 위해 처프 신호(시간에 따라 주파수가 증가)를 보자.\n\\(\\omega_0,\\omega_1\\in\\mathbb{R}\\)를 두 주파수 파라미터(헤르츠 단위)라고 하고, \\(T\\in\\mathbb{R}\\)를 듀레이션 파라미터(초단위)라고 하자.\n\\(\\omega_0\\)에서 시작하여 \\(\\omega_1\\)로 주파수가 선형적으로 증가하는 듀레이션 \\(d\\)의 선형 처프는 다음과 같이 계산된다.\n\n$ f(t)=( t^2 + 2_0t)$ for \\(t\\in[0,T]\\)\n\n시간 \\(t\\)에서 처프 신호 \\(f\\)의 순간 주파수 (instantaneous frequency) 는 정현파의 인수를 \\(2\\pi\\)로 나눈 것의 도함수로 주어진다.\n\n\\[\n   g(t) = \\frac{\\omega_1-\\omega_0}{T} t + \\omega_0.\n\\]\n\n주파수 \\(\\omega_0=220.0~\\mathrm{Hz}\\)(피치 \\(\\mathrm{A3}\\))에서 시작하여 주파수 \\(\\omega_1=311.1~\\mathrm{Hz}\\)(피치 \\(\\mathrm{E}^\\flat 4\\))로 끝나는 듀레이션 \\(T=20~\\mathrm{sec}\\)의 선형 처프 신호를 보자.\n또한 동일한 듀레이션의 주파수 \\(261.5~\\mathrm{Hz}\\)(피치 \\(\\mathrm{C4}\\))를 갖는 정현파를 생각해보자.\n이 신호의 중첩을 들을 때, 처음에는 \\(\\mathrm{A3}\\) 및 \\(\\mathrm{C4}\\) 두 개의 개별 피치를 인식한다.\n처프가 \\(\\mathrm{C4}\\)에 가까워지면 두 음이 하나의 소리로 합쳐지기 시작한다. 동시에 처음에는 속도가 느려졌다가 사라지고(처프가 \\(\\mathrm{C4}\\)에 도달하면), 다시 속도가 빨라지는 비팅 효과를 볼 수 있다. 마지막에 다시 \\(\\mathrm{E}^\\flat 4\\) 및 \\(\\mathrm{C4}\\)인 두 피치를 인식한다.\n\n\ndef generate_chirp_linear(dur, freq_start, freq_end, amp=1.0, Fs=22050):\n    \"\"\"Generation chirp with linear frequency increase\n\n    Args:\n        dur (float): Duration (seconds) of the signal\n        freq_start (float): Start frequency of the chirp\n        freq_end (float): End frequency of the chirp\n        amp (float): Amplitude of chirp (Default value = 1.0)\n        Fs (scalar): Sampling rate (Default value = 22050)\n\n    Returns:\n        x (np.ndarray): Generated chirp signal\n        t (np.ndarray): Time axis (in seconds)\n        freq (np.ndarray): Instant frequency (in Hz)\n    \"\"\"\n    N = int(dur * Fs)\n    t = np.arange(N) / Fs\n    a = (freq_end - freq_start) / dur\n    freq = a * t + freq_start\n    x = amp * np.sin(np.pi * a * t ** 2 + 2 * np.pi * freq_start * t)\n    return x, t, freq\n\n\nf_pitch = lambda p: 440 * 2 ** ((p - 69) / 12)\n\nFs = 4000\ndur = 20\nfreq_start = f_pitch(57)   # A3\nfreq_end = f_pitch(63)     # Eflatp4\nfreq_sin = f_pitch(60)     # C4\nx1, t, freq = generate_chirp_linear(dur=dur, freq_start=freq_start, freq_end=freq_end, amp=0.5, Fs=Fs)\nx2, t = generate_sinusoid(dur=dur, Fs=Fs, amp=0.5, freq=freq_sin)\n\ny = x1 + x2\nipd.display(ipd.Audio(y, rate=Fs))\nplot_interference(x1, x2, t, xlim=[0, dur], ylim=[-1.1,1.1], \n    title=r'Superposition of a linear chirp $x_1$ (A3 to E$^\\flat$4) and sinusoid $x_2$ (C4)');\nplot_interference(x1, x2, t, xlim=[7, 11], ylim=[-1.1,1.1], title='Zoom-in section');\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\n\n\n\n\n\n출처:\n\nhttps://www.audiolabs-erlangen.de/resources/MIR/FMP/C2/C2.html\n\n\n구글 Colab 링크"
  }
]